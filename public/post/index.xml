<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on [R]eliability</title>
    <link>/post/</link>
    <description>Recent content in Posts on [R]eliability</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019. All rights reserved.</copyright>
    <lastBuildDate>Thu, 17 Dec 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Boundary Conditions and Anatomy - Exploring Correlated Data Simulation in R</title>
      <link>/post/boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/viz/viz.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/DiagrammeR-styles/styles.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/grViz-binding/grViz.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Measurements taken from patient anatomy are often correlated. For example, larger blood vessels might tend to have less curvature. Additionally, data are rarely Gaussian, favoring skewed shapes with some very large values and a lower bound of zero. These properties can make simulation and inference hard. In this post I will walk through a workflow for an engineering problem that might be presented in my industry. It involves simulating a population of patients and identifying a subset of interest.&lt;/p&gt;
&lt;p&gt;Imagine we have been assigned the task of identifying boundary conditions for a benchtop durability test of an implantable, artificial heart valve. In other words, we need to identify credible parameters for a physical test such that our test engineers can challenge the device under severe but realistic geometries and loads. To facilitate this task our clinical team has analyzed images and extracted pressure measurements and geometric features for a sample of n=300 patients. The rest of this post explores what we should do with these data.&lt;/p&gt;
&lt;p&gt;For the sake of simplicity, assume that the three parameters we care about are the &lt;strong&gt;&lt;em&gt;ellipticity&lt;/em&gt;&lt;/strong&gt; of the vessel cross section, &lt;strong&gt;&lt;em&gt;curvature&lt;/em&gt;&lt;/strong&gt; of the vessel in the vessel region of interest, and the blood &lt;strong&gt;&lt;em&gt;pressure&lt;/em&gt;&lt;/strong&gt;. Features such as these are important because they influence both the equilibrium geometry and the magnitude of forces acting on the implantable valve (in other words: the boundary conditions). The image below shows a schematic/example of ellipticity and vessel curvature in the LVOT and aortic valve annulus as observed in CT imaging.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/ellipticity_curvature.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are two main challenges when working with these data:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;How do we use our sample to simulate the full population?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;How do we use the simulated, full population to identify groups of interest and recommend boundary conditions for the test&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here is our dataset.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; It turns out that each of these features can be well described by a &lt;strong&gt;lognormal distribution&lt;/strong&gt; and we will assume that this is confirmed via prior domain knowledge. Large pressures, large ellipticities, and small radius of curvature are all bad because they would represent more extreme geometries and/or loads for the implant to resist without migrating or fracturing.&lt;/p&gt;
&lt;p&gt;As normal, we’re working in R and will lean on the tidyverse packages to accelerate things. I wasn’t intending for this post to go as long as it did so I’m also offering this table of contents to show I bear no malice.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(readxl)
library(knitr)
library(DiagrammeR)
library(fitdistrplus)
library(MASS)
library(ggrepel)
library(readxl)
library(ks)
library(broom)
library(ggExtra)
library(GGally)
library(car)
library(rgl)
library(anySim)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#correlations-in-the-original-dataset&#34;&gt;Correlations in the Original Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#approach-1---manually-transform-everything-to-normal&#34;&gt;Approach 1 - Manually Transform Everything to Normal&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#step-1---fit-distributions-to-each-variable&#34;&gt;Step 1 - Fit Distributions to Each Variable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-2---transform-all-variables-to-normal&#34;&gt;Step 2 - Transform all variables to normal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-3---fit-normal-distributions-to-each-transformed-variable&#34;&gt;Step 3 - Fit normal distributions to each transformed variable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-4---draw-joint-distribution-using-mvrnorm()-or-equivalent-function&#34;&gt;Step 4 - Draw joint distribution using mvrnorm() or equivalent function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-5---back-transform-simulated-data-to-original-distribution&#34;&gt;Step 5 - Back-transform simulated data to original distribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-6---evaluate-parameters-and-marginal-distributions-of-the-back-transfomed-data&#34;&gt;Step 6 - Evaluate parameters and marginal distributions of the back-transfomed data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#compare-original-data-to-simulated-data&#34;&gt;Compare Original Data to Simulated Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#approach-2---anysim&#34;&gt;Approach 2 - AnySim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#using-the-simulated-population-to-define-desired-test-conditions-and-groups-of-interest&#34;&gt;Using the Simulated Population to Define Desired Test Conditions and Groups of Interest&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#identify-a-percentage-of-worst-case-patients-relative-to-some-value-of-interest&#34;&gt;Identify a percentage of worst-case patients relative to some value of interest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#identify-probability-contours-using-ks-package-and-kernel-density-estimation&#34;&gt;Identify probability contours using ks package and kernel density estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#density-percentiles-from-kde-estimate&#34;&gt;Density percentiles from kde estimate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kde-estimates-in-the-range-of-the-variables&#34;&gt;KDE estimates in the range of the variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#density-plot-with-probability-contours-in-2d&#34;&gt;Density Plot with Probability Contours in 2d&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#density-plot-with-probability-contours-in-3d&#34;&gt;Density Plot with Probability Contours in 3d&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Start by reading in the data and taking a look at the format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_data &amp;lt;- readRDS(file = &amp;quot;sim_anatomy_data.rds&amp;quot;)
sample_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 300 x 3
##    ellip  curv pressure
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1  1.26  4.51     92.7
##  2  1.28  5.02    183. 
##  3  1.29  4.03    154. 
##  4  1.23  2.14    109. 
##  5  1.13  3.67    124. 
##  6  1.22  2.37    114. 
##  7  1.10  3.06    113. 
##  8  1.04  2.31    105. 
##  9  1.11  5.31    115. 
## 10  1.09  2.04    109. 
## # ... with 290 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As expected, 300 rows with our 3 features of interest.&lt;/p&gt;
&lt;p&gt;Key Point:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Since we are asked to find a worst-case set of values, it might seem reasonable or tempting to extract the maximum value from each group (or maybe something like the 95th percentile) and report those values together as a conservative worst-case for ellipticity, curvature, and pressure. Our test engineers would then set up a benchtop test to challenge our prototype devices in those same conditions to see if they survive. The problem with this approach is that each row of data is from a specific patient, so the variables may be correlated. It could be that those severe, 95th percentile values for each variable never occur together in the same patient. If we choose them together, we would over-test the device and over-design the device, potentially setting the program way behind. We must instead look at the data as a joint distribution and investigate correlations and covariance among the variables.&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let’s verify the shape of the distributions for each feature and see if there is any correlation between the variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ellip_curv_plt &amp;lt;- sample_data %&amp;gt;%
  ggplot(aes(x = ellip, y = curv)) +
  geom_point(alpha = .5) +
  labs(
    title = &amp;quot;Patient Data From n=300 Scans&amp;quot;,
    subtitle = &amp;quot;Vessel Ellipticity and Vessel Curvature Joint Distribution&amp;quot;,
    x = &amp;quot;Ellipticity&amp;quot;,
    y = &amp;quot;Curvature (mm)&amp;quot;
  )

ellip_pressure_plt &amp;lt;- sample_data %&amp;gt;%
  ggplot(aes(x = ellip, y = pressure)) +
  geom_point(alpha = .5, color = &amp;quot;firebrick&amp;quot;) +
  labs(
    title = &amp;quot;Patient Data From n=300 Scans&amp;quot;,
    subtitle = &amp;quot;Vessel Ellipticity and Blood Pressure Joint Distribution&amp;quot;,
    x = &amp;quot;Ellipticity&amp;quot;,
    y = &amp;quot;Pressure (mm Hg)&amp;quot;
  )

curv_pressure_plt &amp;lt;- sample_data %&amp;gt;%
  ggplot(aes(x = curv, y = pressure)) +
  geom_point(alpha = .5, color = &amp;quot;limegreen&amp;quot;) +
  labs(
    title = &amp;quot;Patient Data From n=300 Scans&amp;quot;,
    subtitle = &amp;quot;Vessel Curvature and Blood Pressure Joint Distribution&amp;quot;,
    x = &amp;quot;Curvature (mm)&amp;quot;,
    y = &amp;quot;Pressure (mm Hg&amp;quot;
  )

ellip_curv_mplt &amp;lt;- ggExtra::ggMarginal(ellip_curv_plt, type = &amp;quot;density&amp;quot;, fill = &amp;quot;#2c3e50&amp;quot;, alpha = .5)
ellip_pressure_mplt &amp;lt;- ggExtra::ggMarginal(ellip_pressure_plt, type = &amp;quot;density&amp;quot;, fill = &amp;quot;firebrick&amp;quot;, alpha = .5)
curv_pressure_mplt &amp;lt;- ggExtra::ggMarginal(curv_pressure_plt, type = &amp;quot;density&amp;quot;, fill = &amp;quot;limegreen&amp;quot;, alpha = .5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;correlations-in-the-original-dataset&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Correlations in the Original Dataset&lt;/h1&gt;
&lt;p&gt;ggcorr() from the GGally package is very convenient for visualizing correlations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_data %&amp;gt;% ggcorr(
  high = &amp;quot;#20a486ff&amp;quot;,
  low = &amp;quot;#fde725ff&amp;quot;,
  label = TRUE,
  hjust = .75,
  size = 3,
  label_size = 3,
  label_round = 3,
  nbreaks = 3
) +
  labs(
    title = &amp;quot;Correlation Matrix - n=300 Patient Set&amp;quot;,
    subtitle = &amp;quot;Pearson Method Using Pairwise Observations&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;
We see that there are some positive correlations in this dataset.&lt;/p&gt;
&lt;p&gt;To build out the sample into a simulated population we will fit a MLE estimate and use the model to push out a lot of predictions. If each variable was independent the job would be easy - just execute a few rlnorm()s and bind them together. The job is more challenging when the variables are correlated because they must be simulated all at once. I will show 2 approaches in the sections below. Note that the 2nd approach is more efficient but it helped me to walk through the first one to understand the workflow. If you are impatient I would skip to the section on approach 2.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;approach-1---manually-transform-everything-to-normal&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Approach 1 - Manually Transform Everything to Normal&lt;/h1&gt;
&lt;p&gt;For cases where each variable is normal or can be easily transformed there is a straightforward and relatively simple workflow to generate simulated joint distribution using the &lt;strong&gt;mvrnorm()&lt;/strong&gt; function from the MASS package:&lt;/p&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:500px;&#34; class=&#34;grViz html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;diagram&#34;:&#34;digraph flowchart {\n      # node definitions with substituted label text\n      node [fontname = Helvetica, shape = rectangle, fillcolor = yellow]        \n      tab1 [label = \&#34;Step 1: Fit distributions to each variable in the original dataset.\n Note parameters, correlations, covariances in original data\&#34;]\n      tab2 [label = \&#34;Step 2: Transform all variables to normal\&#34;]\n      tab3 [label = \&#34;Step 3: Fit normal distributions to each transformed variablet.\n Note parameters, correlations, covariances in transformed data\&#34;]\n      tab4 [label = \&#34;Step 4: Draw joint distribution using MASS::mvrnorm() or equivalent function.\n Use parameters and covariance matrix from normal, transformed data\&#34;]\n      tab5 [label = \&#34;Step 5: Back-transform simulated data to original distribution\&#34;]\n      tab6 [label = \&#34;Step 6: Evaluate parameters and marginal distributions of the back-transfomed data.\n Compare to raw, original data to see if marginals and correlations were recreated in the sim\&#34;]\n      # edge definitions with the node IDs\n      tab1 -&gt; tab2 -&gt; tab3 -&gt; tab4 -&gt; tab5 -&gt; tab6;\n      }\n      &#34;,&#34;config&#34;:{&#34;engine&#34;:&#34;dot&#34;,&#34;options&#34;:null}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;In our case, we can easily convert our data from lognormal to normal and will then be able to use the mvrnorm() function to draw from a multivariate normal distribution and then undo the transformation later to recover a simulated population with desired correlations (as shown above). From there we can identify patients of interest, whether they be extreme challenging cases or a central, common group.&lt;/p&gt;
&lt;p&gt;Per the workflow above, start by fitting the native data to lognormal distributions using fitdist() and extract the parameters. Storing all the parameters as objects is a bit tedious and I only do it here so we can make a nice summary table of everything at the end.&lt;/p&gt;
&lt;div id=&#34;step-1---fit-distributions-to-each-variable&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1 - Fit Distributions to Each Variable&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ellip_fit &amp;lt;- fitdist(sample_data$ellip, &amp;quot;lnorm&amp;quot;)
curv_fit &amp;lt;- fitdist(sample_data$curv, &amp;quot;lnorm&amp;quot;)
pressure_fit &amp;lt;- fitdist(sample_data$pressure, &amp;quot;lnorm&amp;quot;)

# store lognormal parameters of original data
ellip_meanlog &amp;lt;- ellip_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
ellip_sdlog &amp;lt;- ellip_fit$estimate[[&amp;quot;sdlog&amp;quot;]]
curv_meanlog &amp;lt;- curv_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
curv_sdlog &amp;lt;- curv_fit$estimate[[&amp;quot;sdlog&amp;quot;]]
pressure_meanlog &amp;lt;- pressure_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
pressure_sdlog &amp;lt;- pressure_fit$estimate[[&amp;quot;sdlog&amp;quot;]]

# store correlations in original data
cor_ec &amp;lt;- cor(x = sample_data$ellip, y = sample_data$curv)
cor_ep &amp;lt;- cor(x = sample_data$ellip, y = sample_data$pressure)
cor_cp &amp;lt;- cor(x = sample_data$curv, y = sample_data$pressure)

# store covariances in original data
cov_ellip_curv &amp;lt;- cov(x = sample_data$ellip, y = sample_data$curv)
cov_ellip_ellip &amp;lt;- cov(x = sample_data$ellip, y = sample_data$ellip)
cov_curv_curv &amp;lt;- cov(x = sample_data$curv, y = sample_data$curv)
cov_ellip_pressure &amp;lt;- cov(x = sample_data$ellip, y = sample_data$pressure)
cov_pressure_pressure &amp;lt;- cov(x = sample_data$pressure, y = sample_data$pressure)
cov_curv_pressure &amp;lt;- cov(x = sample_data$curv, y = sample_data$pressure)

# summarize the parameters and reshape a bit
original_data_param_tbl &amp;lt;- tibble(
  ellip_meanlog = ellip_meanlog,
  ellip_sdlog = ellip_sdlog,
  curv_meanlog = curv_meanlog,
  curv_sdlog = curv_sdlog,
  pressure_meanlog = pressure_meanlog,
  pressure_sdlog = pressure_sdlog,
  ellip_curv_correlation = cor_ec,
  ellip_pressure_correlation = cor_ep,
  curv_pressure_correlation = cor_cp,
  ellip_ellip_covariance = cov_ellip_ellip,
  ellip_curv_covariance = cov_ellip_curv,
  curv_curv_covariance = cov_curv_curv,
  ellip_pressure_covariance = cov_ellip_pressure,
  pressure_pressure_covariance = cov_pressure_pressure,
  curv_pressure_covariance = cov_curv_pressure
) %&amp;gt;%
  pivot_longer(cols = everything(), names_to = &amp;quot;feature&amp;quot;, values_to = &amp;quot;value&amp;quot;) %&amp;gt;%
  mutate(dataset = &amp;quot;original_data&amp;quot;) %&amp;gt;%
  mutate_if(is.character, as_factor)

# View summary table of original data
original_data_param_tbl %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;, digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;feature&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;value&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;dataset&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.193&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.064&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.158&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.309&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.783&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.191&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_curv_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.268&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_pressure_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.369&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_pressure_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.213&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_ellip_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_curv_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.022&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_curv_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.157&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.659&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;530.683&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.285&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2---transform-all-variables-to-normal&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2 - Transform all variables to normal&lt;/h2&gt;
&lt;p&gt;A simple log operation brings the lognormal variable to normal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# transform original, lognormal data to normal
normal_sample_data &amp;lt;- sample_data %&amp;gt;%
  mutate(
    n_ellip = log(ellip),
    n_curv = log(curv),
    n_pressure = log(pressure)
  )

normal_sample_data %&amp;gt;%
  head() %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;, digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;ellip&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_ellip&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_curv&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_pressure&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.255&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.506&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;92.739&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.228&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.505&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.530&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.285&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.019&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;182.970&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.251&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.613&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.209&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.289&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.027&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;153.858&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.254&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.393&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.036&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.234&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.139&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;108.669&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.210&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.760&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.688&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.133&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.673&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;123.633&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.125&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.301&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.817&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.219&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.373&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;113.944&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.198&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.864&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.736&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3---fit-normal-distributions-to-each-transformed-variable&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3 - Fit normal distributions to each transformed variable&lt;/h2&gt;
&lt;p&gt;We don’t actually have to formally fit normal distributions since it is convenient to obtain the mean and standard deviation at any time using the mean() or sd() functions. But we will extract and store correlations and covariances for the simulation to come.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get correlations of transformed, normal data
ncor_ec &amp;lt;- cor(
  x = normal_sample_data$n_ellip,
  normal_sample_data$n_curv
)
ncor_ep &amp;lt;- cor(
  x = normal_sample_data$n_ellip,
  normal_sample_data$n_pressure
)
ncor_cp &amp;lt;- cor(
  x = normal_sample_data$n_curv,
  normal_sample_data$n_pressure
)

# get covariance of transformed, normal data
n_cov_ellip_curv &amp;lt;- cov(
  x = normal_sample_data$n_ellip,
  y = normal_sample_data$n_curv
)
n_cov_ellip_ellip &amp;lt;- cov(
  x = normal_sample_data$n_ellip,
  y = normal_sample_data$n_ellip
)
n_cov_curv_curv &amp;lt;- cov(
  x = normal_sample_data$n_curv,
  y = normal_sample_data$n_curv
)

n_cov_ellip_pressure &amp;lt;- cov(
  x = normal_sample_data$n_ellip,
  y = normal_sample_data$n_pressure
)
n_cov_pressure_pressure &amp;lt;- cov(
  x = normal_sample_data$n_pressure,
  y = normal_sample_data$n_pressure
)
n_cov_curv_pressure &amp;lt;- cov(
  x = normal_sample_data$n_curv,
  y = normal_sample_data$n_pressure
)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4---draw-joint-distribution-using-mvrnorm-or-equivalent-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 4 - Draw joint distribution using mvrnorm() or equivalent function&lt;/h2&gt;
&lt;p&gt;Time to actually draw the correlated values. I store them here in an object called mult_norm.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# draw from multivariate normal with parameters from transformed normal distributions and correlation
set.seed(0118)

mult_norm &amp;lt;- as_tibble(MASS::mvrnorm(
  10000, c(
    mean(normal_sample_data$n_ellip),
    mean(normal_sample_data$n_curv),
    mean(normal_sample_data$n_pressure)
  ),
  matrix(c(
    n_cov_ellip_ellip,
    n_cov_ellip_curv,
    n_cov_ellip_pressure,
    n_cov_ellip_curv,
    n_cov_curv_curv,
    n_cov_curv_pressure,
    n_cov_ellip_pressure,
    n_cov_curv_pressure,
    n_cov_pressure_pressure
  ), 3, 3)
)) %&amp;gt;%
  rename(
    n_ellip_sim = V1,
    n_curv_sim = V2,
    n_pressure_sim = V3
  )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-5---back-transform-simulated-data-to-original-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 5 - Back-transform simulated data to original distribution&lt;/h2&gt;
&lt;p&gt;Exponentiating the data brings it back to lognormal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert back to lognormal
log_norm &amp;lt;- mult_norm %&amp;gt;%
  mutate(
    ellip_sim = exp(n_ellip_sim),
    curv_sim = exp(n_curv_sim),
    pressure_sim = exp(n_pressure_sim)
  )

log_norm %&amp;gt;%
  head() %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;, digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;n_ellip_sim&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_curv_sim&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_pressure_sim&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;ellip_sim&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv_sim&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure_sim&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.254&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.600&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.248&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.290&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.952&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;190.266&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.233&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.038&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.107&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.262&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.823&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;165.178&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.236&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.152&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.812&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.266&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.165&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;123.018&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.313&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.003&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.048&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.368&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.727&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;155.636&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.224&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.622&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.192&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.251&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.066&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;179.912&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.197&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.486&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.822&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.218&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.422&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;124.185&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;step-6---evaluate-parameters-and-marginal-distributions-of-the-back-transfomed-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 6 - Evaluate parameters and marginal distributions of the back-transfomed data&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# evaluate the marginal distributions of the simulated data
ellip_sim_fit &amp;lt;- fitdistrplus::fitdist(log_norm$ellip_sim, &amp;quot;lnorm&amp;quot;)
curv_sim_fit &amp;lt;- fitdistrplus::fitdist(log_norm$curv_sim, &amp;quot;lnorm&amp;quot;)
pressure_sim_fit &amp;lt;- fitdistrplus::fitdist(log_norm$pressure_sim, &amp;quot;lnorm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Obtain and store the correlation, covariances, and parameters of simulated set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get correlation and covariances of simulated data
sim_cor_ec &amp;lt;- cor(x = log_norm$ellip_sim, log_norm$curv_sim)
sim_cor_ep &amp;lt;- cor(x = log_norm$ellip_sim, log_norm$pressure_sim)
sim_cor_cp &amp;lt;- cor(x = log_norm$curv_sim, log_norm$pressure_sim)

sim_cov_ellip_curv &amp;lt;- cov(x = log_norm$ellip_sim, y = log_norm$curv_sim)
sim_cov_ellip_ellip &amp;lt;- cov(x = log_norm$ellip_sim, y = log_norm$ellip_sim)
sim_cov_curv_curv &amp;lt;- cov(x = log_norm$curv_sim, y = log_norm$curv_sim)

sim_cov_ellip_pressure &amp;lt;- cov(x = log_norm$ellip_sim, y = log_norm$pressure_sim)
sim_cov_pressure_pressure &amp;lt;- cov(x = log_norm$pressure_sim, y = log_norm$pressure_sim)
sim_cov_curv_pressure &amp;lt;- cov(x = log_norm$curv_sim, y = log_norm$pressure_sim)

# store parameters of simulated data
ellip_sim_meanlog &amp;lt;- ellip_sim_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
ellip_sim_sdlog &amp;lt;- ellip_sim_fit$estimate[[&amp;quot;sdlog&amp;quot;]]
curv_sim_meanlog &amp;lt;- curv_sim_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
curv_sim_sdlog &amp;lt;- curv_sim_fit$estimate[[&amp;quot;sdlog&amp;quot;]]
pressure_sim_meanlog &amp;lt;- pressure_sim_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
pressure_sim_sdlog &amp;lt;- pressure_sim_fit$estimate[[&amp;quot;sdlog&amp;quot;]]

# collect parameters from simulated data
sim_data_param_tbl &amp;lt;- tibble(
  ellip_meanlog = ellip_sim_meanlog,
  ellip_sdlog = ellip_sim_sdlog,
  curv_meanlog = curv_sim_meanlog,
  curv_sdlog = curv_sim_sdlog,
  pressure_meanlog = pressure_sim_meanlog,
  pressure_sdlog = pressure_sim_sdlog,

  ellip_curv_correlation = sim_cor_ec,
  ellip_pressure_correlation = sim_cor_ep,
  curv_pressure_correlation = sim_cor_cp,

  ellip_curv_covariance = sim_cov_ellip_curv,
  ellip_ellip_covariance = sim_cov_ellip_ellip,
  curv_curv_covariance = sim_cov_curv_curv,

  ellip_pressure_covariance = sim_cov_ellip_pressure,
  pressure_pressure_covariance = sim_cov_pressure_pressure,
  curv_pressure_covariance = sim_cov_curv_pressure
) %&amp;gt;%
  pivot_longer(cols = everything(), names_to = &amp;quot;feature&amp;quot;, values_to = &amp;quot;value&amp;quot;) %&amp;gt;%
  mutate(dataset = &amp;quot;simulated_data&amp;quot;) %&amp;gt;%
  mutate_if(is.character, as_factor)

sim_data_param_tbl %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;feature&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;value&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;dataset&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1932042&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0630117&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1626798&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.3092643&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.7878497&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1900026&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_curv_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2505145&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_pressure_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.3644292&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_pressure_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1956149&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_curv_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0203344&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_ellip_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0058779&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_curv_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1209300&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.6534943&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;547.0647415&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.8440727&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;compare-original-data-to-simulated-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compare Original Data to Simulated Data&lt;/h2&gt;
&lt;p&gt;A bit more wrangling let’s us compare the feature of the original dataset to the new, simulated population to see if they agree.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compare_tbl &amp;lt;- bind_rows(original_data_param_tbl, sim_data_param_tbl) %&amp;gt;%
  pivot_wider(id_cols = everything(), names_from = dataset)

compare_tbl %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;, digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;feature&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;original_data&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;simulated_data&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.193&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.193&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.064&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.063&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.158&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.163&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.309&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.309&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.783&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.788&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.191&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.190&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_curv_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.268&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.251&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_pressure_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.369&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.364&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_pressure_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.213&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.196&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_ellip_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.006&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_curv_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.022&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.020&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_curv_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.157&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.121&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.659&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.653&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;530.683&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;547.065&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.285&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.844&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Everything appears to align well, but this sure took a while. Wouldn’t it be nice if there was a faster way than to manually fit and extract values from mvrnorm() ? Fortunately, we’re in the R ecosystem, where somebody smart has usually tackled the problem and provided the tools to the community. The tool that I had success with is the AnySim package.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here’s how to perform the simulation in a much more efficient way. Note: this is how I created the original dataset of 300 that we’ve been working with.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;approach-2---anysim&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Approach 2 - AnySim&lt;/h1&gt;
&lt;p&gt;The AnySim workflow:&lt;/p&gt;
&lt;div id=&#34;htmlwidget-2&#34; style=&#34;width:100%;height:500px;&#34; class=&#34;grViz html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-2&#34;&gt;{&#34;x&#34;:{&#34;diagram&#34;:&#34;digraph flowchart {\n      # node definitions with substituted label text\n      node [fontname = Helvetica, shape = rectangle, fillcolor = yellow]        \n      tab1 [label = \&#34;Step 1: Specify desired distributions for each variable and store as object\&#34;]\n      tab2 [label = \&#34;Step 2: Specify parameters for each variable and store as object\&#34;]\n      tab3 [label = \&#34;Step 3: Specify desired correlation matrix and store as object\&#34;]\n      tab4 [label = \&#34;Step 4: Provide the above information to EstCorrRVs() to estimate\n parameters of auxiliary Gaussian model\&#34;]\n      tab5 [label = \&#34;Step 5: Generate simulated values using SimcorrRVs()\&#34;]\n      # edge definitions with the node IDs\n      tab1 -&gt; tab2 -&gt; tab3 -&gt; tab4 -&gt; tab5;\n      }\n      &#34;,&#34;config&#34;:{&#34;engine&#34;:&#34;dot&#34;,&#34;options&#34;:null}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;It may look similar in the flowchart but in practice its way easier than Method 1. Here’s how it works in only a few lines of code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(13)
# Define the target distribution functions (ICDFs) of each random variable.

ellip_dist &amp;lt;- &amp;quot;qlnorm&amp;quot;
curv_dist &amp;lt;- &amp;quot;qlnorm&amp;quot;
pressure_dist &amp;lt;- &amp;quot;qlnorm&amp;quot;

# store the 3 ICDFs in a vector
dist_vec &amp;lt;- c(ellip_dist, curv_dist, pressure_dist)

# Define the parameters of the target distribution functions - store them in a list
ellip_params &amp;lt;- list(meanlog = 0.20, sdlog = .067)
curv_params &amp;lt;- list(meanlog = 1.15, sdlog = 0.3)
pressure_params &amp;lt;- list(meanlog = 4.80, sdlog = 0.2)

# this is a weird way to do it but I&amp;#39;m following along with an example from AnySim vignette :)
params_list &amp;lt;- list(NULL)
params_list[[1]] &amp;lt;- ellip_params
params_list[[2]] &amp;lt;- curv_params
params_list[[3]] &amp;lt;- pressure_params

# Define the target correlation matrix.
corr_matrix &amp;lt;- matrix(c(
  1, 0.21, 0.4,
  0.21, 1, .21,
  0.4, 0.21, 1
),
ncol = 3,
nrow = 3,
byrow = T
)
# Estimate the parameters of the auxiliary Gaussian model.
aux_gaussion_param_tbl &amp;lt;- EstCorrRVs(
  R = corr_matrix, dist = dist_vec, params = params_list,
  NatafIntMethod = &amp;quot;GH&amp;quot;, NoEval = 9, polydeg = 8
)


# Generate 10000 synthetic realizations of the 3 correlated RVs.
correlated_ln_draws_tbl &amp;lt;- as_tibble(SimCorrRVs(n = 10000, paramsRVs = aux_gaussion_param_tbl)) %&amp;gt;%
  rename(
    ellip = V1,
    curv = V2,
    pressure = V3
  )

correlated_ln_draws_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;ellip&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.267618&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.158739&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;133.3040&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.198681&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.437176&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;127.1982&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.375663&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.649938&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;160.2052&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.236829&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.621202&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;141.5427&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.318572&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.541340&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;129.3427&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.255885&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.236722&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;146.9361&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.326279&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.387357&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;167.8579&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.240926&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.254830&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;145.7207&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.191865&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.853877&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;87.7240&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.315273&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.144667&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;90.5485&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Let’s see if we were able to produce the desired relationships between the variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit synthetic data
ellip_ln_fit &amp;lt;- tidy(fitdistr(correlated_ln_draws_tbl$ellip, &amp;quot;log-normal&amp;quot;)) %&amp;gt;% mutate(
  var = &amp;quot;ellipticity&amp;quot;,
  dataset = &amp;quot;sim_draws&amp;quot;
)
curv_ln_fit &amp;lt;- tidy(fitdistr(correlated_ln_draws_tbl$curv, &amp;quot;log-normal&amp;quot;)) %&amp;gt;% mutate(
  var = &amp;quot;curvature&amp;quot;,
  dataset = &amp;quot;sim_draws&amp;quot;
)
pressure_ln_fit &amp;lt;- tidy(fitdistr(correlated_ln_draws_tbl$pressure, &amp;quot;log-normal&amp;quot;)) %&amp;gt;% mutate(
  var = &amp;quot;pressure&amp;quot;,
  dataset = &amp;quot;sim_draws&amp;quot;
)
recovered_params_tbl &amp;lt;- bind_rows(ellip_ln_fit, curv_ln_fit, pressure_ln_fit)

# Show target values
target_tbl &amp;lt;- tibble(
  term = rep(c(&amp;quot;meanlog&amp;quot;, &amp;quot;sdlog&amp;quot;), 3),
  estimate = c(.20, .067, 1.15, .3, 4.80, .20),
  var = c(&amp;quot;ellipticity&amp;quot;, &amp;quot;ellipticity&amp;quot;, &amp;quot;curvature&amp;quot;, &amp;quot;curvature&amp;quot;, &amp;quot;pressure&amp;quot;, &amp;quot;pressure&amp;quot;),
  dataset = &amp;quot;target values&amp;quot;
)

# Compare simulated values to target values
bind_rows(recovered_params_tbl, target_tbl) %&amp;gt;%
  select(-std.error) %&amp;gt;%
  pivot_wider(id_cols = everything(), names_from = dataset, values_from = estimate) %&amp;gt;%
  mutate_if(is.numeric, round, 2) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;var&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sim_draws&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;target values&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;ellipticity&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.20&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;ellipticity&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.07&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.07&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;curvature&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.15&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;curvature&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;pressure&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.80&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.80&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;pressure&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.20&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.20&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Excellent agreement. Now check to see if the correlations were preserved:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Check correlations
correlated_ln_draws_tbl %&amp;gt;% ggcorr(
  high = &amp;quot;#20a486ff&amp;quot;,
  low = &amp;quot;#fde725ff&amp;quot;,
  label = TRUE,
  hjust = .75,
  size = 3,
  label_size = 3,
  label_round = 3,
  nbreaks = 3
) +
  labs(
    title = &amp;quot;Correlation Matrix&amp;quot;,
    subtitle = &amp;quot;Pearson Method Using Pairwise Observations&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Again, perfect agreement to 2 decimal places. Thank you AnySim!&lt;/p&gt;
&lt;p&gt;Now that I’ve shown 2 ways to preserve the correlation structure in a simulation, we can return to the original question: what are the worst-case (or most common) values of this (simulated) population?&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-simulated-population-to-define-desired-test-conditions-and-groups-of-interest&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Using the Simulated Population to Define Desired Test Conditions and Groups of Interest&lt;/h1&gt;
&lt;p&gt;The simulated population is useful because its density properties provide a means to determine how extreme any values of interest are. The trick is that we have to define the boundary of interest based on the question we are trying to answer. Two common questions we have pertain to finding the most common set of patients, or the most extreme patients relative to some point or region of interest. I discuss both below.&lt;/p&gt;
&lt;div id=&#34;identify-a-percentage-of-worst-case-patients-relative-to-some-value-of-interest&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Identify a percentage of worst-case patients relative to some value of interest&lt;/h2&gt;
&lt;p&gt;Consider a 2d test case where we are interested in the joint distribution of 2 variables: curvature and pressure. These would be appropriate for something like a migration test, where the pressure wants to pull the implant out of place a curved configuration is worse than straight (like a pipe elbow).&lt;/p&gt;
&lt;p&gt;If we know that the worst-case conditions that are physiologically relevant occur when the curvature is 1 mm (radius-of-curvature) and the pressure is 300 mm Hg (extremely high). How could we identify the worst-case 5% of patients using our simulated population data from above? In this case we don’t need an algorithm, just a bit of geometry.&lt;/p&gt;
&lt;p&gt;We can leverage the standard geometric formula for distance between two points:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ {\displaystyle d(p,q)={\sqrt {(p_{1}-q_{1})^{2}+(p_{2}-q_{2})^{2}}}} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here’s how to calculate this number for each value in the joint distribution for curvature and pressure:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# specify theoretical worst-case point in space
theoretical_worst_curv &amp;lt;- 1
theoretical_worst_pressure &amp;lt;- 300

# calculated each point&amp;#39;s distance from the theoretical worst-case
d_data &amp;lt;- log_norm %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(d = ((theoretical_worst_curv - curv_sim)^2 + (theoretical_worst_pressure - pressure_sim)^2)^.5) %&amp;gt;%
  arrange(desc(d)) %&amp;gt;%
  ungroup()

# make ecdf to map points to percentiles of empirical distribution
d_ECDF_fcn &amp;lt;- ecdf(d_data$d)

# map the ecdf over all the calculated distances to convert them to percentiles
d_pct_data &amp;lt;- d_data %&amp;gt;%
  mutate(d_pct = map_dbl(d, d_ECDF_fcn)) %&amp;gt;%
  mutate(in_out = case_when(
    d_pct &amp;lt;= .05 ~ &amp;quot;5% Worst-Case Points&amp;quot;,
    TRUE ~ &amp;quot;95% Less Severe Population&amp;quot;
  )) %&amp;gt;%
  mutate(in_out = as_factor(in_out))

wc_tbl &amp;lt;- tibble(x = 1, y = 300)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now visualize.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# visualize
d_plt &amp;lt;- d_pct_data %&amp;gt;%
  ggplot(aes(x = curv_sim, y = pressure_sim, color = in_out)) +
  geom_point(alpha = .5, size = 1) +
  geom_point(aes(x = 1, y = 300), color = &amp;quot;firebrick&amp;quot;) +
  geom_label_repel(
    data = wc_tbl, aes(x, y),
    label = &amp;quot;Worst-Case Combination of \n vessel curvature and pressure&amp;quot;,
    fill = &amp;quot;firebrick&amp;quot;,
    color = &amp;quot;white&amp;quot;,
    segment.color = &amp;quot;black&amp;quot;,
    segment.size = 1,
    #                   min.segment.length = unit(1, &amp;quot;lines&amp;quot;),
    nudge_y = 50,
    nudge_x = 2
  ) +
  labs(
    title = &amp;quot;Joint Distribution of Curvature and Pressure&amp;quot;,
    subtitle = &amp;quot;5% of points nearest to worst-case are identified&amp;quot;,
    x = &amp;quot;Radius of Curvature (mm)&amp;quot;,
    y = &amp;quot;Blood Presure (mm Hg)&amp;quot;
  ) +
  theme_classic() +
  ylim(c(0, 300)) +
  theme(
    legend.position = &amp;quot;bottom&amp;quot;,
    legend.title = element_blank()
  ) +
  scale_color_viridis_d(option = &amp;quot;D&amp;quot;, end = .7)

d_plt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It’s a bit of an illusion since the axes aren’t scaled 1:1. Here’s a look at a scaled version showing the teal points closest to the point of interest.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-30-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Neat! We just split the data into the most severe 5% and least severe 95% based on a known point we want to avoid. You could imagine a similar calculation if we had a line that defined a worst-case boundary like we use for the failure threshold in a Goodman Diagram.&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In other cases we just want to know the most common values (values in the region of highest probability) based on the multi-dimensional density calculation. In other words, we want to identify contours based on how close the points are to each other, not some arbitrary point in space or line. A kernel density estimate is going to be our tool of choice in all but the most basic cases. The KDE is non-parametric and can accommodate very complex joint distributions and density shapes.&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Typically, the default contours on a density plot show an output called “level” but they can be converted to denote upper percentages of highest density regions. This is the method I show below.&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;identify-probability-contours-using-ks-package-and-kernel-density-estimation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Identify probability contours using ks package and kernel density estimation&lt;/h2&gt;
&lt;p&gt;This first chunk converts the data and generated the KDE. The bandwidth parameters controls the “smoothness” or granularity of the estimate and can be hard to specify in multiple dimensions. Hscv() provides a method of determining a reasonable bandwidth through cross-validation; see documentation in footnotes for more information if interested.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert simulated data tibble to matrix
d3m &amp;lt;- correlated_ln_draws_tbl %&amp;gt;%
  as.matrix()

# cross-validated bandwidth for kd (takes a while to calculate)
# hscv1 &amp;lt;- Hscv(correlated_ln_draws_tbl)
# hscv1 %&amp;gt;% write_rds(here::here(&amp;quot;hscv1.rds&amp;quot;))

hscv1 &amp;lt;- read_rds(here::here(&amp;quot;hscv1.rds&amp;quot;))

# generate kernel density estimate from simulated population
kd_d3m &amp;lt;- ks::kde(d3m, H = hscv1, compute.cont = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;density-percentiles-from-kde-estimate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Density percentiles from kde estimate&lt;/h2&gt;
&lt;p&gt;The KDE estimate provides density percentiles that can be used to generate the contours the define the density regions in multiple dimensions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# see the kde&amp;#39;s calculated density thresholds for specified proportions
cont_vals_tbl &amp;lt;- tidy(kd_d3m$cont) %&amp;gt;%
  mutate(n_row = row_number()) %&amp;gt;%
  mutate(probs = 100 - n_row) %&amp;gt;%
  select(probs, x)

reference_grid_probs_tbl &amp;lt;- cont_vals_tbl %&amp;gt;%
  rename(estimate = x)

reference_grid_probs_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;probs&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0332949&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;98&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0321061&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;97&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0310773&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0303446&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;95&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0295937&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;94&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0288550&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0282270&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;92&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0276995&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;91&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0271418&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;90&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0266409&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reference_grid_probs_tbl %&amp;gt;%
  tail(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;probs&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0018141&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0016195&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0014430&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0012654&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0010786&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0008795&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0007005&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0005288&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0003976&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0002657&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;kde-estimates-in-the-range-of-the-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;KDE estimates in the range of the variables&lt;/h2&gt;
&lt;p&gt;By default the KDE provides density estimates for a grid of points that covers the space of the variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kd_grid_estimates &amp;lt;- kd_d3m&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we want to know the value at each point in the simulated population we use the eval.points argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_estimates &amp;lt;- ks::kde(
  x = d3m, H = hscv1,
  compute.cont = TRUE,
  eval.points = correlated_ln_draws_tbl %&amp;gt;% as.matrix()
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are a couple different ways to convert the kde object features into a tibble:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_est_tbl_10000 &amp;lt;- tibble(estimate = mc_estimates$estimate) %&amp;gt;%
  bind_cols(correlated_ln_draws_tbl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kd_grid_est_tbl_29k &amp;lt;- broom:::tidy.kde(kd_grid_estimates) %&amp;gt;%
  pivot_wider(names_from = variable, values_from = value) %&amp;gt;%
  rename(ellip = x1, curv = x2, pressure = x3) %&amp;gt;%
  select(-obs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_est_tbl_10000 %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;ellip&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0140082&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.267618&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.158739&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;133.3040&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0118702&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.198681&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.437176&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;127.1982&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0026530&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.375663&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.649938&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;160.2052&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0194232&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.236829&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.621202&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;141.5427&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0122134&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.318572&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.541340&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;129.3427&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0167723&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.255885&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.236722&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;146.9361&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0055484&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.326279&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.387357&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;167.8579&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0112270&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.240926&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.254830&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;145.7207&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0082627&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.191865&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.853877&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;87.7240&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0019651&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.315273&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.144667&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;90.5485&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kd_grid_est_tbl_29k %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;ellip&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8880910&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1331512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;31.02793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9131427&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1331512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;31.02793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9381944&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1331512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;31.02793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9632461&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1331512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;31.02793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9882978&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1331512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;31.02793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0133495&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1331512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;31.02793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0384012&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1331512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;31.02793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0634528&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1331512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;31.02793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0885045&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1331512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;31.02793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1135562&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1331512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;31.02793&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Identify the 5% threshold value:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 5% contour line from kd grid based on 10k MC data
percentile_5 &amp;lt;- kd_d3m[[&amp;quot;cont&amp;quot;]][&amp;quot;5%&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Verify that 5% (500/10,000) values fall below the threshold:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_est_tbl_10000 %&amp;gt;% filter(estimate &amp;lt;= percentile_5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 500 x 4
##     estimate ellip  curv pressure
##        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 0.000243   1.19  6.67    166. 
##  2 0.000371   1.37  2.29     81.7
##  3 0.000356   1.22  2.73    200. 
##  4 0.000134   1.27  7.91    114. 
##  5 0.000560   1.47  3.89    163. 
##  6 0.0000732  1.47  4.67    282. 
##  7 0.000527   1.29  6.13    185. 
##  8 0.000254   1.48  2.44    136. 
##  9 0.000644   1.19  6.63    135. 
## 10 0.000856   1.43  4.98    156. 
## # ... with 490 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we wanted to know the nearest probability contour line for every point we could make a function to do so.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_probs_fcn &amp;lt;- function(value) {
  t &amp;lt;- reference_grid_probs_tbl %&amp;gt;%
    mutate(value = value) %&amp;gt;%
    mutate(dif = abs(estimate - value)) %&amp;gt;%
    filter(dif == min(dif))

  t[[1, 1]]
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Map the function over each value in the dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mc_1_to_99_tbl &amp;lt;- mc_est_tbl_10000 %&amp;gt;%
#   mutate(nearest_prob = map_dbl(estimate, get_probs_fcn))

# mc_1_to_99_tbl %&amp;gt;% write_rds(here::here(&amp;quot;mc_1_to_99_tbl.rds&amp;quot;))
mc_1_to_99_tbl &amp;lt;- read_rds(here::here(&amp;quot;mc_1_to_99_tbl.rds&amp;quot;))

mc_1_to_99_tbl&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10,000 x 5
##    estimate ellip  curv pressure nearest_prob
##       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
##  1  0.0140   1.27  2.16    133.            59
##  2  0.0119   1.20  4.44    127.            52
##  3  0.00265  1.38  2.65    160.            14
##  4  0.0194   1.24  3.62    142.            75
##  5  0.0122   1.32  2.54    129.            53
##  6  0.0168   1.26  3.24    147.            68
##  7  0.00555  1.33  3.39    168.            28
##  8  0.0112   1.24  4.25    146.            50
##  9  0.00826  1.19  1.85     87.7           39
## 10  0.00197  1.32  4.14     90.5           11
## # ... with 9,990 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see what this actually did by comparing the probability contours estimated from the function above vs. the reference contours produced during generation of the kde object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- mc_1_to_99_tbl %&amp;gt;%
  select(nearest_prob, estimate) %&amp;gt;%
  mutate(set = as_factor(&amp;quot;manual_fit_10k&amp;quot;))

p &amp;lt;- cont_vals_tbl %&amp;gt;%
  mutate(set = as_factor(&amp;quot;kde_output&amp;quot;)) %&amp;gt;%
  rename(estimate = x, nearest_prob = probs)

bind_rows(n, p) %&amp;gt;%
  filter(estimate &amp;lt; .005 &amp;amp; estimate &amp;gt; 0) %&amp;gt;%
  ggplot(aes(x = estimate, y = nearest_prob)) +
  geom_point(aes(color = set)) +
  geom_vline(xintercept = percentile_5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-42-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So it appropriately rounded each value in the simulated population to the nearest whole percentile, as desired.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;density-plot-with-probability-contours-in-2d&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Density Plot with Probability Contours in 2d&lt;/h2&gt;
&lt;p&gt;Now the fun part - Visualization. Here’s how I’d go about creating a 2d density plots. If you don’t care about specific probability contours, you can use the built in ggplot method. All you need is the raw data points, not the kde object or estimates. ggplot can do that for you.&lt;/p&gt;
&lt;p&gt;Here’s ellipticity vs. curvature:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cp_plt &amp;lt;- correlated_ln_draws_tbl %&amp;gt;%
  ggplot(aes(x = ellip, y = curv)) +
  geom_point(alpha = .3, size = .5) +
  geom_density2d(size = 1.3) +
  theme_classic() +
  xlim(c(.9, 1.6)) +
  ylim(c(1, 7.5)) +
  labs(
    title = &amp;quot;Joint Distribution of Vessel Ellipticity and Curvature&amp;quot;,
    subtitle = &amp;quot;Density Contours at Default Settings&amp;quot;,
    x = &amp;quot;Ellipticity (unitless)&amp;quot;,
    y = &amp;quot;Radius of Curvature (mm)&amp;quot;
  )

cp_plt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-43-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is pretty good. But for specifying specific contours and specifically we’ll need a bit more. Here’s a solution that I adapted from one I found on Cross Validated.&lt;/p&gt;
&lt;p&gt;First, select the 2 variables of interest.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;- correlated_ln_draws_tbl %&amp;gt;% select(ellip, curv)

## density function
kd &amp;lt;- ks::kde(d, compute.cont = TRUE, h = 0.05)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now a a function to extract the points of the contour line from the kde:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_contour &amp;lt;- function(kd_out = kd, prob = &amp;quot;5%&amp;quot;) {
  contour_95 &amp;lt;- with(kd_out, contourLines(
    x = eval.points[[1]], y = eval.points[[2]],
    z = estimate, levels = cont[prob]
  )[[1]])
  as_tibble(contour_95) %&amp;gt;%
    mutate(prob = prob)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Map it over the kd object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_out &amp;lt;- map_dfr(c(&amp;quot;5%&amp;quot;, &amp;quot;20%&amp;quot;, &amp;quot;40%&amp;quot;, &amp;quot;60%&amp;quot;, &amp;quot;80%&amp;quot;, &amp;quot;95%&amp;quot;), ~ get_contour(kd, .)) %&amp;gt;%
  group_by(prob) %&amp;gt;%
  mutate(n_val = 1:n()) %&amp;gt;%
  ungroup()

dat_out %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;level&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;x&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;y&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;prob&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_val&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1050379&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.024919&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.053556&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1050379&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.023034&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.112579&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1050379&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.022015&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.176684&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1050379&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.021665&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.240789&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1050379&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.021762&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.304894&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1050379&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.022205&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.368999&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1050379&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.022956&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.433104&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1050379&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.024009&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.497208&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1050379&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.024919&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.540507&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1050379&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.025311&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.561313&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Clean kde output&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kd_df &amp;lt;- expand_grid(x = kd$eval.points[[1]], y = kd$eval.points[[2]]) %&amp;gt;%
  mutate(z = c(kd$estimate %&amp;gt;% t()))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now visualize again, this time with probability contours at specified values and the 5% curve labeled with geom_label_repel().&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;label_tbl &amp;lt;- dat_out %&amp;gt;%
  filter(
    prob == &amp;quot;5%&amp;quot;,
    n_val == 100
  )

# visualize
ellip_curv_2plt &amp;lt;- ggplot(data = kd_df, aes(x, y)) +
  geom_tile(aes(fill = z)) +
  geom_point(data = d, aes(x = ellip, y = curv), alpha = .4, size = .4, colour = &amp;quot;white&amp;quot;) +
  geom_path(aes(x, y, group = prob),
    data = dat_out %&amp;gt;% filter(prob %in% c(&amp;quot;5%&amp;quot;, &amp;quot;20%&amp;quot;, &amp;quot;40%&amp;quot;, &amp;quot;60%&amp;quot;, &amp;quot;80%&amp;quot;, &amp;quot;95%&amp;quot;)), colour = &amp;quot;white&amp;quot;, size = 1.2, alpha = .8
  ) +
  #  geom_text(aes(label = prob), data =
  #              filter(dat_out, (prob %in% c(&amp;quot;5%&amp;quot;) &amp;amp; n_val==1)), # | (prob %in% c(&amp;quot;90%&amp;quot;) &amp;amp; n_val==20)),
  #            colour = &amp;quot;yellow&amp;quot;, size = 5)+
  geom_label_repel(
    data = label_tbl, aes(x, y),
    label = label_tbl$prob[1],
    fill = &amp;quot;yellow&amp;quot;,
    color = &amp;quot;black&amp;quot;,
    segment.color = &amp;quot;yellow&amp;quot;,
    #    segment.size = 1,
    min.segment.length = unit(1, &amp;quot;lines&amp;quot;),
    nudge_y = .5,
    nudge_x = -.025
  ) +
  xlim(c(.95, 1.5)) +
  ylim(c(0, 7.5)) +
  labs(
    title = &amp;quot;Joint Distribution [Ellipticity and Radius of Curvature]&amp;quot;,
    subtitle = &amp;quot;Simulated Data&amp;quot;,
    caption = &amp;quot;Density Contours shown at 5%, 20%, 40%, 60%, 80%, 95%&amp;quot;
  ) +
  scale_fill_viridis_c(end = .9) +
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  labs(x = &amp;quot;Ellipticity (unitless)&amp;quot;, y = &amp;quot;Radius of Curvature (mm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggExtra::ggMarginal(ellip_curv_2plt, type = &amp;quot;density&amp;quot;, fill = &amp;quot;#403891ff&amp;quot;, alpha = .7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-49-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Nice! Now we have a clear delineation of the most common patients and most extreme patients and we can group them as desired. Almost done - the last thing to do is to see how to extend into 3d.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;density-plot-with-probability-contours-in-3d&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Density Plot with Probability Contours in 3d&lt;/h2&gt;
&lt;p&gt;Honestly, this part is pretty easy thanks to a built in plot.kde method. Just use the cont argument to specify with probability contours you want.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(x = kd_d3m, cont = c(45, 70, 95), drawpoints = FALSE, col.pt = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/3d_cont_1.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Add points using the points3d function. In this case I add 2 sets, 1 for the 5% most extreme and 1 for the 95% most common.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot(x = kd_d3m, cont = c(95) ,drawpoints = FALSE, col.pt = 1)
mc_lowest_5_tbl &amp;lt;- mc_1_to_99_tbl %&amp;gt;% filter(estimate &amp;lt; percentile_5)
mc_6_to_100_tbl &amp;lt;- mc_1_to_99_tbl %&amp;gt;% filter(estimate &amp;gt;= percentile_5)

# points3d(x = mc_lowest_5_tbl$ellip, y = mc_lowest_5_tbl$curv, z = mc_lowest_5_tbl$pressure, color = &amp;quot;dodgerblue&amp;quot;,  size = 3, alpha = 1)

# points3d(x = mc_6_to_100_tbl$ellip, y = mc_6_to_100_tbl$curv, z = mc_6_to_100_tbl$pressure, color = &amp;quot;black&amp;quot;,  size = 3, alpha = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/3dd1.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/3dd2.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/3dd3.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And there we have it! A 3d joint distribution with 95% probability density contour and groups separated by color and confirmed to cover 95/5% of the population.&lt;/p&gt;
&lt;p&gt;If you’ve made it this far, I thank you. Here is a brief summary of what I tried to capture in this post:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Manual method to simulate a population from a sample with known correlation structure using mvrnorm()&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Simplified / Efficient way to do the same using AnySim package&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method for identifying worst-case 5% of patients when there is a known target point to stay away from&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method for identifying most common 95% of patients with respect the their density&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Simple way to plot 2d density with ggplot, showing “levels”&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generate 2d density plots with specified probability density contours and labels&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method for creating 3d plots with specified probability density contours and in/out groups&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Hamdan et. al. Journal of the American College of Cardiology, Volume 59, Issue 2, 2012, Pages 119-127&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;The units of measure aren’t really important for the analysis but just for calibration the ellipticity is generally unitless (it is a ratio of the long axis over the short axis); curvature is usually in mm and represents the radius of curvature on the inner curve of the vessel; pressure is usually in mm Hg and can be assumed to be the systolic blood pressure.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;see Water 2020, 12, 1645; &lt;a href=&#34;doi:10.3390/w12061645&#34; class=&#34;uri&#34;&gt;doi:10.3390/w12061645&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;simulated population conditional on the model - no sampling error is considered here. For population inference that takes into account sampling error, see tolerance intervals and the tolerance package in R&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Goodman_relation&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/wiki/Goodman_relation&lt;/a&gt;&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://bookdown.org/egarpor/NP-UC3M/#welcome&#34; class=&#34;uri&#34;&gt;https://bookdown.org/egarpor/NP-UC3M/#welcome&lt;/a&gt;&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;Adapted from this Stack Overflow response: &lt;a href=&#34;https://stackoverflow.com/questions/23437000/how-to-plot-a-contour-line-showing-where-95-of-values-fall-within-in-r-and-in&#34; class=&#34;uri&#34;&gt;https://stackoverflow.com/questions/23437000/how-to-plot-a-contour-line-showing-where-95-of-values-fall-within-in-r-and-in&lt;/a&gt;&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simulation With a Random Effects Model - Gage R&amp;R as a Case Study</title>
      <link>/post/simulation-with-a-random-effects-model-gage-r-r-as-a-case-study/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/simulation-with-a-random-effects-model-gage-r-r-as-a-case-study/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/viz/viz.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/DiagrammeR-styles/styles.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/grViz-binding/grViz.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I&#39;ve heard it said that common statistical tests are just linear models.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; It turns out that Gage R&amp;amp;R, a commonly used measurement system analysis (MSA), is no different. In this post I&#39;ll attempt to provide some background on Gage R&amp;amp;R, describe the underlying model, and then walk through a method for simulation that can be useful for things like power analysis or visualization of uncertainty.&lt;/p&gt;
&lt;p&gt;What is Gage R&amp;amp;R?&lt;/p&gt;
&lt;p&gt;When evaluating implantable medical devices it is generally necessary to perform the following types of inspection to ensure product quality:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dimensional inspection of implant features&lt;/li&gt;
&lt;li&gt;Visual inspection of implant surface and component interfaces&lt;/li&gt;
&lt;li&gt;Benchtop performance evaluation of implant&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The primary purpose of these costly and rigorous inspection processes is to screen out bad product. The ramifications of non-conforming parts reaching the field can be fatal. As such, it is important to understand any limitations of key measurement systems and, if possible, quantity their uncertainty. The primary statistical tool for this job is called Gage R&amp;amp;R. The Gage R&amp;amp;R attempts to quantify the total variation within a series of measurements and then describe the relative contributions of parts, operators, and repeated measurements (unexplained error). Operator error is called &amp;quot;reproducibility&amp;quot;; unexplained error when a measurement is repeated under presumably identical conditions is called &amp;quot;repeatability&amp;quot;. The total variation among these components must be controlled and limited. A typical crossed structure is shown below: &lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/crossed.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Gage R&amp;amp;R training for engineers usually involves:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Definitions of repeatability and reproducibility (the &amp;quot;R&amp;amp;R&amp;quot;)&lt;/li&gt;
&lt;li&gt;Guidance for directing Minitab to set up the experiment&lt;/li&gt;
&lt;li&gt;Guidance for directing Minitab to analyze the results and provide an output&lt;/li&gt;
&lt;li&gt;An acceptance criteria (with no or limited context)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When I was first exposed to the material, I recall grappling with terminology and definitions, struggling with rote memorization, and having no understanding of the assumptions or limitations of the technique. Here&#39;s the piece that was never explained to me (and many other engineers):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A Gage R&amp;amp;R study is a random effects regression model with two random variables: operator and part. By modeling the factors as random effects and applying a few assumptions, we can access and analyze the variance associated with each component using standard ANOVA techniques.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Specifically, the model commonly used for a crossed Gage R&amp;amp;R is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\ y_{ijk} = \mu + O_i + P_j + (PO)_{ij} + E_{(ij)k} \]&lt;/span&gt; where:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\ y_{ijk}\)&lt;/span&gt; = a specific, individual measurement&lt;br /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\ \mu\)&lt;/span&gt; = overall mean of all the measurements&lt;br /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\ O\)&lt;/span&gt; = random variable for effect of operator. Assumed normal: &lt;span class=&#34;math inline&#34;&gt;\(\ O_i \sim N(0,\sigma^2_O)\)&lt;/span&gt;&lt;br /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\ P\)&lt;/span&gt; = random variable for effect of part. Assumed normal: &lt;span class=&#34;math inline&#34;&gt;\(\ P_i \sim N(0,\sigma^2_P)\)&lt;/span&gt;&lt;br /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\ (PO)\)&lt;/span&gt; = random variable for sample x operator interaction. Assumed normal: &lt;span class=&#34;math inline&#34;&gt;\(\ (PO)_{ij} \sim N(0,\sigma^2_{PO})\)&lt;/span&gt;&lt;br /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\ E\)&lt;/span&gt; = random variable for unexplained, residual error (referred to as &amp;quot;repeatability&amp;quot; since differences in measurements taken under identical conditions are mapped here). &lt;span class=&#34;math inline&#34;&gt;\(\ E_{(ij)k} \sim N(0,\sigma^2_{E})\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is really cool! - Understanding the model unlocks the insight behind the method and casts a bright light on the assumptions. It puts a seemingly obscure, memorized technique into a familiar regression framework. It also facilitates simulation.&lt;/p&gt;
&lt;p&gt;Why is it a random effects model? What is a random effects model? The answer to that question is actually tricky (and beyond the scope of this post) but there is some good information &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/published/banova7.pdf&#34;&gt;here&lt;/a&gt; for those who want to dive deeper. &lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; While not a formal definition, it may be sufficient to know that random effects are estimated with partial pooling while others are not.&lt;/p&gt;
&lt;p&gt;In this post I will attempt to show how to use the lme4 to simulate outcomes using a random effects model like the one listed above and then repeat many such simulations to gain understanding of uncertainty and sensitivity in the underlying experiment.&lt;a href=&#34;#fn4&#34; class=&#34;footnoteRef&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; Fun!&lt;/p&gt;
&lt;p&gt;Here are the libraries we&#39;ll use.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)
library(tidyverse)
library(knitr)
library(here)
library(broom.mixed)
library(tidybayes)
library(DiagrammeR)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;simulating-one-outcome-of-a-gage-rr-experiment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulating One Outcome of a Gage R&amp;amp;R Experiment&lt;/h2&gt;
&lt;p&gt;Before we worry about running a bunch of simulations, let&#39;s just figure out how to run one instance of a Gage R&amp;amp;R. There are some really good tutorials out there for simulating outcomes from random and mixed effects models.&lt;a href=&#34;#fn5&#34; class=&#34;footnoteRef&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn6&#34; class=&#34;footnoteRef&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; It ends up being a little bit tricky because the parameters that you select need to combine within the design matrix in a certain way such that an analysis of the simulated outcomes can recover the specified parameters. If you are good at matrix math you can do this manually. I am &lt;em&gt;not&lt;/em&gt; very good at matrix math - but fortunately Robert Long on Cross Validated&lt;a href=&#34;#fn7&#34; class=&#34;footnoteRef&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt; showed me a really cool little hack for figuring out the form of the Design Matrix Z and using it for simulation. Basically, we will first set up a dummy experiment with the desired number of parts, operators, and measurements and then use lme4 to extract Z and store it. Then we can set up a vector of all our simulated random effects and combine them with matrix multiplication to build the simulated observation. It sounds tricky but it&#39;s surprisingly simple! in summary, here is the plan:&lt;/p&gt;
&lt;p&gt;&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:500px;&#34; class=&#34;grViz html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;diagram&#34;:&#34;digraph flowchart {\n      # node definitions with substituted label text\n      node [fontname = Helvetica, shape = rectangle, fillcolor = yellow]        \n      tab1 [label = \&#34;Step 1: Setup a dummy experiment\&#34;]\n      tab2 [label = \&#34;Step 2: Fit a model to the dummy data\&#34;]\n      tab3 [label = \&#34;Step 3: Extract and store the Design Matrix Z from the dummy model\&#34;]\n      tab4 [label = \&#34;Step 4: Simulate random effects using rnorm or similar\&#34;]\n      tab5 [label = \&#34;Step 5: Multiply Z by random effects vector\&#34;]\n      tab6 [label = \&#34;Step 6: Combine result with simulated residual error to generate simulated observations\&#34;]\n      tab7 [label = \&#34;Step 7: Fit a model to the simulated obervations\&#34;]\n      # edge definitions with the node IDs\n      tab1 -&gt; tab2 -&gt; tab3 -&gt; tab4 -&gt; tab5 -&gt; tab6 -&gt; tab7;\n      }\n      &#34;,&#34;config&#34;:{&#34;engine&#34;:&#34;dot&#34;,&#34;options&#34;:null}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt; The good news is that none of the above steps are very hard, even if they look unfamiliar. Let&#39;s go through it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-1-set-up-a-dummy-experiment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1: Set up a dummy experiment&lt;/h2&gt;
&lt;p&gt;I call this a dummy experiment because while it will have the proper number of operators/parts/replicates, we&#39;ll just drop in some dummy data as the observations. The goal here is to allow lme4 to create the structure of the experiment (the design matrix) which we can use later to get the real simulated observations.&lt;/p&gt;
&lt;p&gt;First, we specify the number of parts, operators, and measurements we want the experiment be comprised of. 10, 3, and 2, respectively, is a common experimental setup in industry and we use it here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_part &amp;lt;- 10 # number of parts
n_oper &amp;lt;- 3 # number of opers
n_measurements &amp;lt;- 2 # number of replications&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now assign names to each part, operator, trial and determine how many observations will be in the study: n_matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# assign names to each part, operator, trial
part &amp;lt;- str_glue(&amp;quot;part_{1:n_part}&amp;quot;) %&amp;gt;% as_factor()
operator &amp;lt;- str_glue(&amp;quot;oper_{1:n_oper}&amp;quot;) %&amp;gt;% as_factor()
measurement &amp;lt;- str_glue(&amp;quot;measurment_{1:n_measurements}&amp;quot;) %&amp;gt;% as_factor()

n_matrix &amp;lt;- n_part * n_oper * n_measurements # number of observations in the study

n_matrix&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 60&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we use crossing() to build the full set of experimental conditions. Dummy observations are created for each setting and assigned to a new col: &amp;quot;measurement&amp;quot;. Overall mean of 10 is chosen arbitrarily and isn&#39;t important. Note: we are creating observations(measurements) here but have not concerned ourselves with specifying the parameters of any random variables yet. We just need a placeholder in the measurement column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# generate experimental design and outcomes for dummy study
grr_dummy_tbl &amp;lt;- crossing(part, operator, measurement) %&amp;gt;%
  mutate(measurement = 10 + rnorm(n_matrix))

grr_dummy_tbl %&amp;gt;%
  head(7) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;operator&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;measurement&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.87815&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.82016&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.12168&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.21272&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.55464&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.18606&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.95731&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grr_dummy_tbl %&amp;gt;%
  tail(7) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;operator&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;measurement&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9.661665&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.319520&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.668104&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.483027&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9.700252&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.967124&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9.627140&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-fit-a-model-to-the-dummy-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2: Fit a model to the dummy data&lt;/h2&gt;
&lt;p&gt;Now we fit a model to the dummy data. The summary isn&#39;t important - we just want access to the structure which we will get in the next step.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit model for dummy study
m1 &amp;lt;- lmer(measurement ~ (1 | part) + (1 | operator) + (1 | part:operator), data = grr_dummy_tbl)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-extract-and-store-the-design-matrix-z-from-the-dummy-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3: Extract and store the Design Matrix Z from the dummy model&lt;/h2&gt;
&lt;p&gt;Here&#39;s the little hack: Use getME() to pull the design matrix Z from the dummy model. Alternately, you can use lFormula() but you will have to fish the matrix out and transpose it which is not as intuitive to me.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract design matrix Z from dummy model
design_matrix_Z &amp;lt;- getME(m1, &amp;quot;Z&amp;quot;) %&amp;gt;% as.matrix()

design_matrix_Z %&amp;gt;% head(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   part_1:oper_1 part_1:oper_2 part_1:oper_3 part_2:oper_1 part_2:oper_2
## 1             1             0             0             0             0
##   part_2:oper_3 part_3:oper_1 part_3:oper_2 part_3:oper_3 part_4:oper_1
## 1             0             0             0             0             0
##   part_4:oper_2 part_4:oper_3 part_5:oper_1 part_5:oper_2 part_5:oper_3
## 1             0             0             0             0             0
##   part_6:oper_1 part_6:oper_2 part_6:oper_3 part_7:oper_1 part_7:oper_2
## 1             0             0             0             0             0
##   part_7:oper_3 part_8:oper_1 part_8:oper_2 part_8:oper_3 part_9:oper_1
## 1             0             0             0             0             0
##   part_9:oper_2 part_9:oper_3 part_10:oper_1 part_10:oper_2 part_10:oper_3
## 1             0             0              0              0              0
##   part_1 part_2 part_3 part_4 part_5 part_6 part_7 part_8 part_9 part_10
## 1      1      0      0      0      0      0      0      0      0       0
##   oper_1 oper_2 oper_3
## 1      1      0      0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# alternate method:
# mylF &amp;lt;- lFormula(m1, data = grr_dummy_tbl) # Process the formula against the data
# design_matrix_Z &amp;lt;- mylF$reTrms$Zt %&amp;gt;% as.matrix() %&amp;gt;% t()  # Extract the Z matrix&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So much easier than constructing this matrix yourself! (at least for me - it&#39;s been a while now since I took linear algebra course and tensor notation was always challenging).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4-simulate-random-effects-using-rnorm-or-similar&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 4: Simulate random effects using rnorm or similar&lt;/h2&gt;
&lt;p&gt;With the matrix Z in hand we can get get rid of the dummy model and get down to business with specifying and simulating our random effects. Specify standard deviations for each effect and simulate using rnorm(). 1, 2, 9, and 4 are the parameters that we will compare our estimates against later on.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(0118)
int_intercepts_sd &amp;lt;- 1 # standard dev of interaction random effects
oper_intercepts_sd &amp;lt;- 2 # standard dev of operator random effects
part_intercepts_sd &amp;lt;- 9 # standard dev of operator random effects
random_error_repeatability &amp;lt;- 4 # standard dev of random error (repeatability)

# simulate random effects using input params for sd
int_intercepts &amp;lt;- rnorm(n = n_part * n_oper, mean = 0, sd = int_intercepts_sd)
oper_intercepts &amp;lt;- rnorm(n = n_oper, mean = 0, sd = oper_intercepts_sd)
part_intercepts &amp;lt;- rnorm(n = n_part, mean = 0, sd = part_intercepts_sd)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Combine all the random effects into a vector. Order does matter here - see comment below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# vector of all random effect intercepts (order matters here: ineraction, part, oper if n_oper &amp;lt; n_part, else swith part and oper)

random_effects_intercepts &amp;lt;- c(int_intercepts, part_intercepts, oper_intercepts)
random_effects_intercepts&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  -1.676079782   0.167651720  -0.008545182   0.296888139  -1.706489201
##  [6]  -1.049094451  -0.102206749   0.682492401  -0.511117703   0.487346673
## [11]  -1.345812057   0.527128496   0.686104071  -0.221484626   0.532399538
## [16]   0.597393622   0.831437918   0.735023009   0.830043214   0.769163682
## [21]   1.830416344   0.182049999   1.018859437   0.844012288   0.575312043
## [26]   0.006855854  -0.231251230   0.205834471   0.250942908  -1.575663200
## [31]  19.280822421  10.499576059  -3.997253469  -7.111499870   6.986996777
## [36]  -4.861684848 -13.031232590  14.723410605  16.967969396  22.293922487
## [41]  -1.345816596  -3.905496830  -4.061788248&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-5-multiply-z-by-random-effects-vector&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 5: Multiply Z by random effects vector&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;step-6-combine-result-with-simulated-residual-error-to-generate-simulated-observations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 6: Combine result with simulated residual error to generate simulated observations&lt;/h2&gt;
&lt;p&gt;We&#39;ll do steps 5 and 6 together here: multiply the design matrix Z by the vector of random effects intercepts and then add in a residual error. %*% is the matrix multiplication operator. Again - the overall mean of 10 is arbitrary and does not change the analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create observations (add in repeatability random error to each term). %*% is matrix multiplication
grr_sim_tbl &amp;lt;- grr_dummy_tbl %&amp;gt;%
  mutate(measurement = 10 + design_matrix_Z %*% random_effects_intercepts + rnorm(
    n = nrow(grr_dummy_tbl),
    mean = 0,
    sd = random_error_repeatability
  ))

grr_sim_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;operator&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;measurement&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;25.335155&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;28.246367&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;15.799074&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;23.051405&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;22.791039&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;17.986515&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;19.378715&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14.934401&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9.109815&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14.250238&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;step-7-fit-a-model-to-the-simulated-obervations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 7: Fit a model to the simulated obervations&lt;/h2&gt;
&lt;p&gt;Once again we fit a model, but this time the observations are meaningful because we constructed them properly using the design matrix Z. broom.mixed::tidy() is able to bring the results into tibble format where we can clean a bit and view the variance contribution of each variable. This gives a point estimate of standard deviations for the random effects that can be compared against the reference inputs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit a model to the simulated dataset
sim_m_fit &amp;lt;- lmer(measurement ~ (1 | part) + (1 | operator) + (1 | part:operator), data = grr_sim_tbl)

# tibble of results for a single simulation
one_grr_result_tbl &amp;lt;-
  broom.mixed::tidy(sim_m_fit, effects = &amp;quot;ran_pars&amp;quot;) %&amp;gt;%
  rename(
    st_dev_estimate = estimate,
    variable = group
  ) %&amp;gt;%
  mutate(
    variance_estimate = st_dev_estimate^2,
    sim_number = 1
  ) %&amp;gt;%
  select(sim_number, variable, st_dev_estimate, variance_estimate)

one_grr_result_tbl %&amp;gt;% kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;sim_number&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;variable&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;st_dev_estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;variance_estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.4484307&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2010901&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.4718335&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;131.6029628&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6062900&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.5801677&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.9540576&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;15.6345714&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Recall that the true parameters for sd were 1, 9, 2, and 4. These estimates aren&#39;t dead on but we don&#39;t really understand how much uncertainty is involved with our estimate. We&#39;ll return to that in a moment.&lt;/p&gt;
&lt;p&gt;One common performance metric for a Gage R&amp;amp;R is %tolerance: 6 (or some other constant) times the sum of the measurement system variance (everything except for part variance) divided by the tolerance span for this particular measurement.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\ Percent\space Tolerance = 6 \times (\hat\sigma_E^2 + \hat\sigma_O^2 + \hat\sigma_{PO}^2)\space/\space Tolerance \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It is common for the tolerance span to be approximately 6 x the standard deviation of the parts population. Let&#39;s make that assumption here so we can estimate the percent tolerance from the data and compare to the true value. Once the simulation is established, the standard deviation of the parts can be adjusted to see how the percent tolerance changes for a given sd of operators, part:operator interaction, and residual.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one_grr_tol_outcome_tbl &amp;lt;- one_grr_result_tbl %&amp;gt;%
  filter(variable != &amp;quot;part&amp;quot;) %&amp;gt;%
  group_by(sim_number) %&amp;gt;%
  summarize(grr_variance_est = sum(variance_estimate)) %&amp;gt;%
  mutate(true_tol_pct = scales::percent((int_intercepts_sd^2 + oper_intercepts_sd^2 + random_error_repeatability^2) / part_intercepts_sd)) %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(est_tol_pct = scales::percent(grr_variance_est / part_intercepts_sd))

one_grr_tol_outcome_tbl %&amp;gt;% kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;sim_number&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;grr_variance_est&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;true_tol_pct&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;est_tol_pct&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;18.41583&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;233%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;205%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Since 205% is &amp;gt; 30%, this experiment would &amp;quot;fail&amp;quot; and the measurement system would not be validated. Not really interesting since we just chose arbitrary numbers but the estimate is reasonably close to the true value which is more important. It would be good to know that if we repeated the simulation a lot of times, the average estimate will converge near the true value.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scale-simulation-with-a-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Scale Simulation with a Function&lt;/h1&gt;
&lt;p&gt;If want to simulate a lot of Gage R&amp;amp;R&#39;s, we can take all the code chunks above and wrap them in a function and then just swap out the values we want to adjust for argument in the function. The function below will take:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;n = number of simulations&lt;/li&gt;
&lt;li&gt;np = number of parts&lt;/li&gt;
&lt;li&gt;no = number of operators&lt;/li&gt;
&lt;li&gt;nm = number of measurements per operator&lt;/li&gt;
&lt;li&gt;iisd = interaction intercepts standard deviation&lt;/li&gt;
&lt;li&gt;oisd = operator intercepts standard deviation&lt;/li&gt;
&lt;li&gt;pisd = part intercepts standard deviation&lt;/li&gt;
&lt;li&gt;rer = random error (repeatability) standard deviation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&#39;m pretty sure this operation could be done faster and cleaner than the code shown below, but I like how the code maps to the single case simulation above for easy human readability. For this reason, I use a for loop instead of some map() variant.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grr_fct &amp;lt;- function(n, np, no, nm, iisd, oisd, pisd, rer) {
  all_grr_results_tbl &amp;lt;- NULL # tibble to hold results
  n_sims &amp;lt;- n # number of simulations
  n_part &amp;lt;- np # number of parts
  n_oper &amp;lt;- no # number of opers
  n_measurements &amp;lt;- nm # number of replications

  int_intercepts_sd &amp;lt;- iisd # standard dev of interaction random effects
  oper_intercepts_sd &amp;lt;- oisd # standard dev of operator random effects
  part_intercepts_sd &amp;lt;- pisd # standard dev of parts random effects
  random_error_repeatability &amp;lt;- rer # standard dev of random error (repeatability)

  # assign names to each per, operator, trial
  part &amp;lt;- str_glue(&amp;quot;part_{1:n_part}&amp;quot;) %&amp;gt;% as_factor()
  operator &amp;lt;- str_glue(&amp;quot;oper_{1:n_oper}&amp;quot;) %&amp;gt;% as_factor()
  measurement &amp;lt;- str_glue(&amp;quot;measurment_{1:n_measurements}&amp;quot;) %&amp;gt;% as_factor()

  n_matrix &amp;lt;- n_part * n_oper * n_measurements # number of observations in the study

  for (i in 1:n) {

    # generate experimental designa and outcomes for dummy study
    grr_dummy_tbl &amp;lt;- crossing(part, operator, measurement) %&amp;gt;%
      mutate(measurement = 10 + rnorm(n_matrix))

    # fit model for dummy study
    m1 &amp;lt;- lmer(measurement ~ (1 | part) + (1 | operator) + (1 | part:operator), data = grr_dummy_tbl)

    # extract design matrix Z from dummy model
    design_matrix_Z &amp;lt;- getME(m1, &amp;quot;Z&amp;quot;) %&amp;gt;% as.matrix()

    # simulate random effects using input params for sd
    int_intercepts &amp;lt;- rnorm(n = n_part * n_oper, mean = 0, sd = int_intercepts_sd)
    oper_intercepts &amp;lt;- rnorm(n = n_oper, mean = 0, sd = oper_intercepts_sd)
    part_intercepts &amp;lt;- rnorm(n = n_part, mean = 0, sd = part_intercepts_sd)

    # vector of all random effect intercepts (order matters here: ineraction, oper, part)
    random_effects_intercepts &amp;lt;- c(int_intercepts, part_intercepts, oper_intercepts)

    # create observations (add in repeatability random error to each term). %*% is matrix multiplication
    grr_sim_tbl &amp;lt;- grr_dummy_tbl %&amp;gt;%
      mutate(measurement = 10 + design_matrix_Z %*% random_effects_intercepts + rnorm(
        n = nrow(grr_dummy_tbl),
        mean = 0,
        sd = random_error_repeatability
      ))

    # fit a model to the simulated dataset
    sim_m_fit &amp;lt;- lmer(measurement ~ (1 | part) + (1 | operator) + (1 | part:operator), data = grr_sim_tbl)

    # tibble of results for a single simulation
    one_grr_result_tbl &amp;lt;-
      broom.mixed::tidy(sim_m_fit, effects = &amp;quot;ran_pars&amp;quot;) %&amp;gt;%
      rename(
        st_dev_estimate = estimate,
        variable = group
      ) %&amp;gt;%
      mutate(
        variance_estimate = st_dev_estimate^2,
        sim_number = i
      ) %&amp;gt;%
      select(sim_number, variable, st_dev_estimate, variance_estimate)

    # append this recent simulation to the others
    all_grr_results_tbl &amp;lt;- bind_rows(all_grr_results_tbl, one_grr_result_tbl)
  }
  return(all_grr_results_tbl)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test the function by calling it once, asking for just 3 simulations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fcn_test_tbl &amp;lt;- grr_fct(n = 3, np = 10, no = 3, nm = 2, iisd = 4, oisd = 3, pisd = 2, rer = 1)

fcn_test_tbl %&amp;gt;% kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;sim_number&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;variable&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;st_dev_estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;variance_estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.4214284&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.7061726&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.1832882&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.7667475&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6916881&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.8618086&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0355244&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0723107&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.7726138&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;22.7778428&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0010317&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0000011&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0763577&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1585460&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.0704728&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16.5687489&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2724219&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6190574&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.2107023&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.3086089&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9178515&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8424514&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Everything is looking good! The results from n=3 simulations have completed and are summarized nicely in the results tbl.&lt;/p&gt;
&lt;p&gt;Rather than manually call the function and input the arguments every time, we can populate a &amp;quot;setup tbl&amp;quot; that contains all the arguments that we will want to look at. Within the tbl we can look at anything we want. For example, we might want several different values for number of operators, or several different levels of standard deviation for one of the random effects. In this case, I was interested in several different magnitudes of standard deviation for the population of parts because the part sd is used as a surrogate for the tolerance percentage calculation as shown above. This is a useful simulation because we should be able to visualize:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Does the average of the simulation converge near the true value for percent tolerance?&lt;/li&gt;
&lt;li&gt;How often might individual estimates of pct tol &amp;quot;fail&amp;quot; (&amp;gt; 30%) when the average of the estimates passes (&amp;lt; 30%)?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Fist, the setup_tbl. Note: the variance of the random variables for operator, repeatability(residual), and part:operator interaction are all held at 1 while the variance for part is increased.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_setup_tbl &amp;lt;- tibble(
  n_sims = 200,
  n_part = 10,
  n_oper = 3,
  n_meas = 2,
  int_sd = 1,
  oper_sd = 1,
  #  part_var = 1,
  part_var = c(2^(0:10)),
  repeatab_sd = 1
) %&amp;gt;%
  mutate(
    row_id = row_number()
  ) %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(part_sd = part_var^.5) %&amp;gt;%
  mutate(tol_pct_true = 6 * (int_sd^2 + oper_sd^2 + repeatab_sd^2) / (6 * part_sd))

sim_setup_tbl %&amp;gt;% kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;n_sims&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_oper&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_meas&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;int_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;oper_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;part_var&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;repeatab_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;row_id&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;part_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;tol_pct_true&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.414214&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.1213203&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.828427&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0606602&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.7500000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.656854&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5303301&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;64&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.3750000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;128&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.313709&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2651650&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;256&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1875000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;22.627417&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1325825&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1024&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;32.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0937500&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The following code executes many simulations, one for each set of arguments from the rows above. Each simulation from each row results in a tibble of outcomes which is stored in a list column and the unnested later on to make a big tibble. I&#39;m not actually 100% sure that you need rowwise() here - it works fine with it in place and makes sense to me that you would group by rows here but I&#39;m still trying to figure out what row-based workflow works best for me. I believe there are other good options that use the map family.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(0118)

#commented out because this takes a while to run

# sim_outcomes_tbl &amp;lt;- sim_setup_tbl %&amp;gt;%
#   rowwise() %&amp;gt;% # may not be needed
#   mutate(sim_outcomes = list(grr_fct(n = n_sims, np = n_part, no = n_oper, nm = n_meas, iisd = int_sd, oisd = oper_sd, pisd = part_sd, rer = repeatab_sd))) %&amp;gt;%
#   select(sim_outcomes, everything()) %&amp;gt;%
#   unnest(cols = c(sim_outcomes)) %&amp;gt;%
#   mutate_if(is.character, as_factor)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_outcomes_tbl %&amp;gt;%
  select(sim_number, variable, st_dev_estimate, n_sims, n_part, n_meas, int_sd, oper_sd, repeatab_sd, part_sd) %&amp;gt;%
  head(12) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;sim_number&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;variable&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;st_dev_estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_sims&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_meas&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;int_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;oper_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;repeatab_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;part_sd&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5511238&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8165034&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5369841&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0638795&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8046511&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1717770&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9339445&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9631640&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0850250&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0031052&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7490297&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9284068&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We might look at the results for a single group of arguments in the setup tbl by filtering to a specific row (I choose row 4 arbitrarily here). Note that &amp;quot;row_id&amp;quot; is a little misleading here because the data has been reshaped. Filtering fora specific row_id returns results from the set of simulations from a single row of parameters in the original setup_tbl. Here we look at the results form row_4 where the true part sd was 2.82 while the sd for operator, Residual, and interaction were all 1.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- sim_outcomes_tbl %&amp;gt;%
  filter(row_id == 4) %&amp;gt;%
  filter(st_dev_estimate &amp;gt; .001) %&amp;gt;%
  ggplot(aes(x = variable, y = st_dev_estimate)) +
  geom_jitter(width = .05, alpha = .5, size = .6) +
  geom_hline(yintercept = 1, lty = 2, color = &amp;quot;#2c3e50&amp;quot;) +
  geom_hline(yintercept = 2.8428472, lty = 2, color = &amp;quot;#2c3e50&amp;quot;) +
  #    stat_summary(fun.y= mean, fun.ymin=mean, fun.ymax=mean, geom=&amp;quot;crossbar&amp;quot;, width=0.2, color=&amp;quot;red&amp;quot;) +
  stat_halfeye(aes(fill = variable), point_interval = mean_qi, alpha = .7, position = position_nudge(x = .15)) +
  labs(
    title = &amp;quot;Gage R&amp;amp;R - Estimates for Component Standard Deviations&amp;quot;,
    subtitle = str_glue(&amp;quot;Settings: {sim_outcomes_tbl$n_part[1]} Parts, {sim_outcomes_tbl$n_oper[1]} Operators, {sim_outcomes_tbl$n_meas[1]} Measurements&amp;quot;),
    x = &amp;quot;&amp;quot;,
    y = &amp;quot;Standard Deviation Estimate&amp;quot;,
    caption = &amp;quot;dotted line marks true population standard dev\n Interval marks median, .66 quantile, .95 quantile&amp;quot;
  ) +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  scale_fill_viridis_d(option = &amp;quot;c&amp;quot;, end = .7)

a&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-09-simulation-with-a-random-effects-model-gage-r-r-as-a-case-study_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks good! The averages of the set of simulations are converging nicely and we get a good feel for how much uncertainty would be expected for a single trial.&lt;/p&gt;
&lt;p&gt;Now to plot multiple simulations. A bit of data preparation is required to plot the true values on the same canvas as the individual sims. There is probably a cleaner way to do this directly within ggplot - but the way I do it here is to pull the values from the rows down into tidy format with pivot_longer and then do some grouping and joining.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_tbl &amp;lt;- sim_outcomes_tbl %&amp;gt;% select(sim_number, row_id)

t &amp;lt;- sim_outcomes_tbl %&amp;gt;%
  select(sim_number, variable, row_id, int_sd, oper_sd, part_sd, repeatab_sd, st_dev_estimate) %&amp;gt;%
  pivot_longer(cols = c(int_sd, oper_sd, part_sd, repeatab_sd)) %&amp;gt;%
  right_join(sim_tbl) %&amp;gt;%
  group_by(variable, name, value, row_id) %&amp;gt;%
  count() %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(variable = case_when(
    name == &amp;quot;int_sd&amp;quot; ~ &amp;quot;part:operator&amp;quot;,
    name == &amp;quot;oper_sd&amp;quot; ~ &amp;quot;operator&amp;quot;,
    name == &amp;quot;part_sd&amp;quot; ~ &amp;quot;part&amp;quot;,
    TRUE ~ &amp;quot;Residual&amp;quot;
  )) %&amp;gt;%
  right_join(sim_setup_tbl)

t %&amp;gt;%
  head(10) %&amp;gt;%
  select(variable, value, row_id, n_sims, n_part, n_oper, n_meas, int_sd, oper_sd, part_sd, repeatab_sd, tol_pct_true) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;variable&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;value&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;row_id&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_sims&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_oper&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_meas&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;int_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;oper_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;part_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;repeatab_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;tol_pct_true&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It would be cool to see all the data from all the simulations. Recall that the true values of sd for operator, part:operator interaction, and Residual were 1 and that part variation increased across the different sims. All of this is plotted below, with the true values in red while the results of the simulation shown in black. It can be seen that the simulations group nicely around the true values and we can see the uncertainty.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_outcomes_tbl %&amp;gt;%
  ggplot(aes(x = part_sd, y = st_dev_estimate)) +
  geom_point(size = .4) +
  geom_point(data = t, aes(x = part_sd, y = value), color = &amp;quot;firebrick&amp;quot;) +
  facet_wrap(~variable, scales = &amp;quot;free&amp;quot;) +
  labs(
    title = &amp;quot;Simulation Results Across a Range of Possible Part Standard Deviations&amp;quot;,
    subtitle = &amp;quot;Gage R&amp;amp;R with n=10 parts, n=3 operators, n=2 measurements&amp;quot;,
    x = &amp;quot;True Part Standard Deviation&amp;quot;,
    y = &amp;quot;Estimate of Standard Deviation&amp;quot;,
    caption = &amp;quot;red points mark true value of standard deviation for the effect&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-09-simulation-with-a-random-effects-model-gage-r-r-as-a-case-study_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; Let&#39;s see how the estimated percent tolerance lines up with the true values from the population. This tbl calculates the percent tol across all the simulations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tol_outcomes_tbl &amp;lt;- sim_outcomes_tbl %&amp;gt;%
  filter(variable != &amp;quot;part&amp;quot;) %&amp;gt;%
  group_by(sim_number, row_id) %&amp;gt;%
  summarize(grr_variance_est = sum(variance_estimate)) %&amp;gt;%
  right_join(sim_setup_tbl) %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(est_tol_pct = (grr_variance_est) / (part_sd)) %&amp;gt;%
  select(n_part, n_oper, n_meas, int_sd, oper_sd, part_sd, tol_pct_true, est_tol_pct, everything())

tol_outcomes_tbl %&amp;gt;%
  select(n_part, n_oper, n_meas, int_sd, oper_sd, part_sd, tol_pct_true, est_tol_pct, sim_number, row_id) %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;n_part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_oper&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_meas&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;int_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;oper_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;part_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;tol_pct_true&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;est_tol_pct&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sim_number&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;row_id&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.723929&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.447401&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.098323&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.882222&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.702724&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.381758&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.619832&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.986048&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.440299&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.441025&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This summary tbl captures the mean from simulations conducted at each level.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tol_est_tbl &amp;lt;- tol_outcomes_tbl %&amp;gt;%
  group_by(row_id, part_var) %&amp;gt;%
  summarize(mean_est_tol_pct = mean(est_tol_pct))

tol_est_tbl %&amp;gt;% kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;row_id&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;part_var&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;mean_est_tol_pct&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.9902181&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.1352549&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5002527&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0354094&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.7362949&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5330749&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;64&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.3708208&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;128&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2657111&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;256&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1880981&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1372343&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1024&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0937739&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Visualize the mean from the simulations vs. the true tol percent:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tol_outcomes_tbl %&amp;gt;%
  ggplot(aes(x = part_var, y = est_tol_pct)) +
  #  geom_point(size = .5) +
  geom_point(aes(x = part_var, y = tol_pct_true), size = 3, color = &amp;quot;limegreen&amp;quot;, position = position_nudge(2), alpha = .85) +
  geom_line(aes(x = part_var, y = tol_pct_true), color = &amp;quot;limegreen&amp;quot;) +
  geom_point(data = tol_est_tbl, aes(x = part_var, y = mean_est_tol_pct), size = 3, color = &amp;quot;firebrick&amp;quot;, position = position_nudge(-2), alpha = .85) +
  geom_hline(yintercept = .3, lty = 2, color = &amp;quot;#2c3e50&amp;quot;) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = &amp;quot;Comparison of Simulation Results to True: Tolerance Percent Metric&amp;quot;,
    subtitle = &amp;quot;Green is true population, Red is mean of simulation estimates&amp;quot;,
    x = &amp;quot;Part Variance&amp;quot;,
    y = &amp;quot;Tolerance Percent&amp;quot;,
    caption = &amp;quot;dotted line shows 30% acceptance limit&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-09-simulation-with-a-random-effects-model-gage-r-r-as-a-case-study_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Very nice agreement between the simulations and the true population values. But the above plot just shows the mean. How much uncertainty is expected across experiments at the same settings? Here I show a subset of data below the 100% level (just to keep the plot a little less messy).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tol_outcomes_tbl %&amp;gt;%
  ggplot(aes(x = part_var, y = est_tol_pct)) +
  geom_point(size = .5) +
  geom_point(aes(x = part_var, y = tol_pct_true), size = 3, color = &amp;quot;limegreen&amp;quot;, position = position_nudge(2), alpha = .85) +
  geom_line(aes(x = part_var, y = tol_pct_true), color = &amp;quot;limegreen&amp;quot;) +
  geom_point(data = tol_est_tbl, aes(x = part_var, y = mean_est_tol_pct), size = 3, color = &amp;quot;firebrick&amp;quot;, position = position_nudge(-2), alpha = .85) +
  geom_hline(yintercept = .3, lty = 2) +
  scale_y_continuous(
    labels = scales::percent,
    expand = expansion(),
    limits = c(0, 1)
  ) +
  labs(
    title = &amp;quot;Comparison of Simulation Results to True: Tolerance Percent Metric&amp;quot;,
    subtitle = &amp;quot;Green is true population, Red is mean of simulation estimates, Black is intividual estimates&amp;quot;,
    x = &amp;quot;Part Variance&amp;quot;,
    y = &amp;quot;Tolerance Percent&amp;quot;,
    caption = &amp;quot;dotted line shows 30% acceptance limit&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-09-simulation-with-a-random-effects-model-gage-r-r-as-a-case-study_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Pretty interesting. There is quite a bit of uncertainty here and there are quite a few cases where individual simulations fail just due to chance. The probability of this happening is worst when the part variance is around 100-400% of the operator and repeatability sd.&lt;/p&gt;
&lt;p&gt;From this point one could start tweaking any values of interest to see how the uncertainty of the performance metric is affected. For example, you might look at the optimal number of operators or replicates to give the best chance of passing when the true population value would pass. Pretty powerful stuff!&lt;/p&gt;
&lt;p&gt;In this post I attempted to show how a Gage R&amp;amp;R test can be modeled with random effects model. A simulation was constructed using the extracted design matrix Z and a vector of random effects. The simulation was then scaled to see how well the mean of the simulations converge with the true population parameter and the uncertainty was visualized by plotting individual estimates on the same grid. Good luck and I hope this post is useful!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://lindeloev.github.io/tests-as-linear/&#34; class=&#34;uri&#34;&gt;https://lindeloev.github.io/tests-as-linear/&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Assessment of the Adequacy of Gauge Repeatability and Reproducibility Study Using a Monte Carlo Simulation, &lt;a href=&#34;https://www.hindawi.com/journals/mpe/2017/7237486/&#34; class=&#34;uri&#34;&gt;https://www.hindawi.com/journals/mpe/2017/7237486/&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Conflicting definitions of random/mixed effects &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2005/01/25/why_i_dont_use/&#34; class=&#34;uri&#34;&gt;https://statmodeling.stat.columbia.edu/2005/01/25/why_i_dont_use/&lt;/a&gt;&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Some simulations are motivated/recreated/expanded from the excellent paper by Ha et al, &lt;a href=&#34;https://doi.org/10.1155/2017/7237486&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1155/2017/7237486&lt;/a&gt;&lt;a href=&#34;#fnref4&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://debruine.github.io/tutorials/sim-lmer.html&#34; class=&#34;uri&#34;&gt;https://debruine.github.io/tutorials/sim-lmer.html&lt;/a&gt;&lt;a href=&#34;#fnref5&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://aosmith.rbind.io/2018/04/23/simulate-simulate-part-2/&#34; class=&#34;uri&#34;&gt;https://aosmith.rbind.io/2018/04/23/simulate-simulate-part-2/&lt;/a&gt;&lt;a href=&#34;#fnref6&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/483509/simulating-observations-for-a-2-way-anova-in-r-w-mixed-effects-model-and-reco&#34; class=&#34;uri&#34;&gt;https://stats.stackexchange.com/questions/483509/simulating-observations-for-a-2-way-anova-in-r-w-mixed-effects-model-and-reco&lt;/a&gt;&lt;a href=&#34;#fnref7&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian Stress-Strength Analysis for Product Design (in R and brms)</title>
      <link>/post/bayesian-stress-strength-inference-in-r-and-brms/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-stress-strength-inference-in-r-and-brms/</guid>
      <description>


&lt;p&gt;Whether you are building bridges, baseball bats, or medical devices, one of the most basic rules of engineering is that the thing you build must be strong enough to survive its service environment. Although a simple concept in principle, variation in use conditions, material properties, and geometric tolerances all introduce uncertainty that can doom a product. Stress-Strength analysis attempts to formalize a more rigorous approach to evaluating overlap between the stress and strength distributions. Graphically, a smaller area of overlap represents a smaller probability of failure and greater expected reliability (although it doesn’t exactly equal the probability of failure).&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/stress_strength.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;However, even formal stress-strength analysis usually infers device reliability from point estimates of material strength and/or use conditions. Monte Carlo simulations intending to respect the full spread of stress and strength distributions generally ignore the uncertainty inherent in the distributional parameters themselves. Fortunately there is a Bayesian extension of Stress-Strength analysis that naturally incorporates the uncertainty of the parameters to provide a true probability distribution of device reliability. In this post I will first walk through the frequentist approach to obtaining a point estimate of reliability and then the Bayesian extension that yields a full posterior for reliability.&lt;/p&gt;
&lt;p&gt;First, load the libraries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(broom)
library(survival)
library(brms)
library(knitr)
library(patchwork)
library(tidybayes)
library(gganimate)
library(transformr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll be using a dataset from Liu and Abeyratne that contains stress and strength data for an electrode connector component in an electronic medical device.&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; The stress-in-service data are compiled from characterization tests and customer usage data. The strength data (here called “failure_stress” to emphasize that they can be directly evaluated against stress-in-service) are obtained from benchtop testing and are right censored at 15. Assume the units of each are the same.&lt;/p&gt;
&lt;p&gt;The stress-in-service data are known from historical testing to follow a lognormal distribution. Likewise, the failure stress data are known to follow a Weibull distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Manually enter data
stress_in_service_tbl &amp;lt;- tibble(stress_in_service = c(2.53, 2.76, 1.89, 3.85, 3.62, 3.89, 3.06, 2.16, 2.20, 1.90, 1.96, 2.09, 1.70, 5.77, 4.35, 5.30, 3.61, 2.63, 4.53, 4.77, 1.68, 1.85, 2.32, 2.11, 1.94, 1.81, 1.53, 1.60, 0.47, 1.06, 1.30, 2.84, 3.84, 3.32))

# Peek at data
stress_in_service_tbl %&amp;gt;%
  head(7) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;stress_in_service&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.76&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.89&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.85&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.62&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.89&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.06&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# manually enter failure stress data
failure_stress_tbl &amp;lt;- tibble(failure_stress = c(7.52, 15, 8.44, 6.67, 11.48, 11.09, 15, 5.85, 13.27, 13.09, 12.73, 11.08, 15, 8.41, 12.34, 8.77, 6.47, 10.51, 7.05, 10.90, 12.38, 7.78, 14.61, 15, 10.99, 11.35, 4.72, 6.72, 11.74, 8.45, 13.26, 13.89, 12.83, 6.49))

# add column to indicate run-out / censoring.  brms convention is 1 = censored, 0 = failure event
failure_stress_tbl &amp;lt;- failure_stress_tbl %&amp;gt;% 
  mutate(censored_brms = case_when(failure_stress == 15 ~ 1, TRUE ~ 0)) %&amp;gt;%
  mutate(censored_surv = case_when(failure_stress == 15 ~ 0,TRUE ~ 1))

# peek at data
failure_stress_tbl %&amp;gt;%
  head(7) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;failure_stress&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;censored_brms&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;censored_surv&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;7.52&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;15.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8.44&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11.48&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11.09&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;15.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;After verifying the data has been imported correctly, the two distributions can be visualized on the same plot and the degree of overlap evaluated qualitatively.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set up a combined stress/strength tibble
a &amp;lt;- tibble(val = stress_in_service_tbl$stress_in_service, label = &amp;quot;stress_in_service&amp;quot;)
b &amp;lt;- tibble(val = failure_stress_tbl$failure_stress, label = &amp;quot;failure_stress&amp;quot;)
overlap_tbl &amp;lt;- bind_rows(a, b) %&amp;gt;%
  mutate(label = as_factor(label))

# view combined tbl
overlap_tbl %&amp;gt;%
  head(5) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;val&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;label&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.53&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;stress_in_service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.76&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;stress_in_service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.89&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;stress_in_service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.85&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;stress_in_service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.62&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;stress_in_service&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;overlap_tbl %&amp;gt;%
  tail(5) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;val&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;label&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8.45&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;failure_stress&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13.26&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;failure_stress&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13.89&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;failure_stress&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;12.83&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;failure_stress&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6.49&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;failure_stress&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot empirical distributions
overlap_tbl %&amp;gt;% ggplot() +
  geom_density(aes(x = val, fill = label), alpha = .5) +
  labs(
    x = &amp;quot;Stress&amp;quot;,
    y = &amp;quot;Density of Observations&amp;quot;,
    title = &amp;quot;Empirical Distributions for Stress-In-Service and Failure Stress&amp;quot;,
    subtitle = &amp;quot;Overlap Region Represents Posssible Device Failure, Failrue Stress Censored at 15&amp;quot;
  ) +
  scale_fill_manual(values = c(&amp;quot;#20A486FF&amp;quot;, &amp;quot;#FDE725FF&amp;quot;)) +
  theme(legend.title = element_blank()) +
  theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;obtain-the-frequentist-point-estimates&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Obtain the Frequentist Point Estimates&lt;/h2&gt;
&lt;p&gt;We can get the best parameter estimates for both data sets using the survreg function from the survival package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#fit stress-in-service data using survreg from survival package
stress_in_service_fit &amp;lt;- survreg(Surv(stress_in_service) ~ 1,
  data = stress_in_service_tbl,
  dist = &amp;quot;lognormal&amp;quot;
)

#extract point estimates of parameters from sis-fit
sis_point_est_tbl &amp;lt;- tidy(stress_in_service_fit)[1, 2] %&amp;gt;%
  rename(meanlog = estimate) %&amp;gt;%
  mutate(sdlog = stress_in_service_fit$scale) %&amp;gt;%
  round(2) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))

sis_point_est_tbl &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;meanlog&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sdlog&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#fit failure stress data using survreg from survival package
failure_stress_fit &amp;lt;- survreg(Surv(failure_stress, censored_surv) ~ 1,
  data = failure_stress_tbl,
  dist = &amp;quot;weibull&amp;quot;
)

# extract scale parameter
scale &amp;lt;- tidy(failure_stress_fit)[1, 2] %&amp;gt;%
  rename(scale = estimate) %&amp;gt;%
  exp() %&amp;gt;%
  round(2)

# extract shape parameter
shape &amp;lt;- tidy(failure_stress_fit)[2, 2] %&amp;gt;%
  rename(shape = estimate) %&amp;gt;%
  exp() %&amp;gt;%
  .^-1 %&amp;gt;%
  round(2)

# summarize
fs_point_est_tbl &amp;lt;- bind_cols(shape, scale) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))

fs_point_est_tbl&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.57&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The reliability point estimate is obtained by drawing randomly from the two fitted distributions and seeing the percentage of occasions where the stress_in_service is greater than the failure_stress:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Monte Carlo to see how often s-i-s &amp;gt; fs
set.seed(10)

#random draws
sis_draws &amp;lt;- rlnorm(n = 100000, meanlog = .88, sdlog = .50)
fs_draws &amp;lt;- rweibull(n = 100000, shape = 3.57, scale = 12)

#assign 1 to cases where sis_draws &amp;gt;= fs_draws
point_sim &amp;lt;- tibble(
  sis_draws = sis_draws,
  fs_draws = fs_draws
) %&amp;gt;%
  mutate(freq = case_when(
    sis_draws &amp;gt;= fs_draws ~ 1,
    TRUE ~ 0
  ))

#take freqency of 0&amp;#39;s
reliability_pt_est &amp;lt;- (1 - mean(point_sim$freq))

#show as tibble
tibble(reliability = 1 - mean(point_sim$freq)) %&amp;gt;%
  round(3) %&amp;gt;% 
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;reliability&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.986&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;model-the-stress-in-service-with-brms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model the Stress-in-Service with brms&lt;/h2&gt;
&lt;p&gt;For the Bayesian approach we fit the models with brms instead of survreg. The result is a posterior of plausible values for each parameter.&lt;/p&gt;
&lt;p&gt;Before running to model, reasonable priors were established through simulation. Code and details are included in the Appendix at the end of this post so as to not derail the flow.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Fit model to stress-in-service data. Data is known to be of lognormal form.  

# stress_in_service_model_1 &amp;lt;-
#  brm(
#    data = stress_in_service_tbl, family = lognormal,
#    stress_in_service ~ 1,
#   prior = c(
#     prior(normal(.5, 1), class = Intercept),
#     prior(uniform(.01, 8), class = sigma)),
#   iter = 41000, warmup = 40000, chains = 4, cores = 4,
#   seed = 4
# )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clean up the posterior tibble and plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract posterior draws 
post_samples_stress_in_service_model_1_tbl &amp;lt;-
  posterior_samples(stress_in_service_model_1) %&amp;gt;%
  select(-lp__) %&amp;gt;%
  rename(&amp;quot;mu&amp;quot; = b_Intercept)

#examine as tibble
post_samples_stress_in_service_model_1_tbl %&amp;gt;%
  head(7) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2), digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;mu&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sigma&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.932&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.537&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.922&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.601&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.801&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.535&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.836&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.526&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.977&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.540&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.732&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.535&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.757&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.535&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get visual of posterior with rough idea of chain convergence
plot(stress_in_service_model_1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here is the summary of the stress-in-service model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# evaluate posterior distribution with 95% CI and rhat diagnostic
summary(stress_in_service_model_1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: lognormal 
##   Links: mu = identity; sigma = identity 
## Formula: stress_in_service ~ 1 
##    Data: stress_in_service_tbl (Number of observations: 34) 
## Samples: 4 chains, each with iter = 41000; warmup = 40000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.88      0.09     0.71     1.06 1.00     1976     2298
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.53      0.07     0.42     0.69 1.00     2399     2016
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-the-failure-stress-data-with-brms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model the Failure Stress Data with brms&lt;/h2&gt;
&lt;p&gt;The failure stress data is fit in a similar way as before. Again, prior predictive simulations are shown in the Appendix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# failure_stress_model_1 &amp;lt;- brm(failure_stress | cens(censored_brms) ~ 1,
# data = failure_stress_tbl, family = weibull(),
# prior = c(
#   prior(student_t(3, 5, 5), class = Intercept),
#   prior(uniform(0, 10), class = shape)),
# iter = 41000, warmup = 40000, chains = 4, cores = 4, seed = 4
# )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following code extracts and converts the parameters from the brms default into the shape and scale that are used in the rweibull() function before displaying the summaries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract posterior draws and examine as tibble
failure_stress_model_1_tbl &amp;lt;-
  posterior_samples(failure_stress_model_1) %&amp;gt;%
  select(-lp__) %&amp;gt;%
  rename(&amp;quot;mu&amp;quot; = b_Intercept)

#compute shape and scale
post_samples_failure_stress_model_1_tbl &amp;lt;- posterior_samples(failure_stress_model_1) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale)

#display as tibble
post_samples_failure_stress_model_1_tbl %&amp;gt;%
  head(7) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2), digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.590&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.972&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.502&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.126&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.363&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.961&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.570&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.310&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.040&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;13.621&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.067&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;13.753&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4.245&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.035&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(failure_stress_model_1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(failure_stress_model_1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: weibull 
##   Links: mu = log; shape = identity 
## Formula: failure_stress | cens(censored_brms) ~ 1 
##    Data: failure_stress_tbl (Number of observations: 34) 
## Samples: 4 chains, each with iter = 41000; warmup = 40000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     2.38      0.06     2.28     2.49 1.00     2257     2279
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## shape     3.56      0.55     2.56     4.67 1.00     1963     2169
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualization-of-uncertainty---credible-curves-for-stress-in-service-and-failure-stress&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualization of Uncertainty - Credible Curves for Stress-in-Service and Failure Stress&lt;/h2&gt;
&lt;p&gt;I haven’t ever used the gganimate package and this seems like a nice opportunity. The code below draws a small handful of parameters from the posterior and plots them to visualize the uncertainty in both distributions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#take 25 sets of parameters, convert to lnorm curves
lnorm_stress_curve_tbl &amp;lt;- post_samples_stress_in_service_model_1_tbl[1:25, ] %&amp;gt;%
  mutate(plotted_y_data = map2(
    mu, sigma,
    ~ tibble(
      x = seq(0, 20, length.out = 100),
      y = dlnorm(x, .x, .y)
    )
  )) %&amp;gt;%
  unnest(plotted_y_data) %&amp;gt;%
  mutate(model = &amp;quot;Stress in Service [lnorm]&amp;quot;) %&amp;gt;%
  rename(
    param_1 = mu,
    param_2 = sigma
  )

#take 25 sets of parameters, convert to Weib curves
weib_stress_curve_tbl &amp;lt;- post_samples_failure_stress_model_1_tbl[1:25, ] %&amp;gt;%
  mutate(plotted_y_data = map2(
    shape, scale,
    ~ tibble(
      x = seq(0, 20, length.out = 100),
      y = dweibull(x, .x, .y)
    )
  )) %&amp;gt;%
  unnest(plotted_y_data) %&amp;gt;%
  mutate(model = &amp;quot;Failure Stress [weib]&amp;quot;) %&amp;gt;%
  rename(
    param_1 = shape,
    param_2 = scale
  )

#combine
a &amp;lt;- bind_rows(lnorm_stress_curve_tbl, weib_stress_curve_tbl) %&amp;gt;% mutate(param_1_fct = as_factor(param_1))

#visualize
p &amp;lt;- a %&amp;gt;%
  ggplot(aes(x, y)) +
  geom_line(aes(x, y, group = param_1_fct, color = model), alpha = 1, size = 1) +
  labs(
    x = &amp;quot;Stress&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    title = &amp;quot;Credible Failure Stress and Service Stress Distributions&amp;quot;,
    subtitle = &amp;quot;n=25 curves sampled from the posterior&amp;quot;
  ) +
  scale_color_viridis_d(end = .8) +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  theme(legend.title = element_blank()) +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  transition_states(param_1_fct, 0, 1) +
  shadow_mark(past = TRUE, future = TRUE, alpha = .3, color = &amp;quot;gray50&amp;quot;, size = .4)

#gganimate 
animate(p, nframes = 50, fps = 2.5, width = 900, height = 600, res = 120, dev = &amp;quot;png&amp;quot;, type = &amp;quot;cairo&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-20-1.gif&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;building-the-credible-reliability-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Building the Credible Reliability Distribution&lt;/h2&gt;
&lt;p&gt;Having now obtained the posterior distributions for both stress-in-service and failure stress, we can select random sets of parameters and compare a random (but credible) pair of distributions. By simulating from each random pair of distributions and calculating a single value of reliability as before, we can build out a credible reliability distribution. The blue vertical line indicates the frequentist point estimate we obtained at the beginning of the analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#set number of simulations
n_sims &amp;lt;- 10000
set.seed(1001)

#stress-in-service (lognormal) simulations
labeled_post_ln_tbl &amp;lt;- post_samples_stress_in_service_model_1_tbl %&amp;gt;%
  mutate(
    model = &amp;quot;lognormal&amp;quot;
  ) %&amp;gt;%
  rename(
    param1 = mu,
    param2 = sigma
  ) %&amp;gt;%
  mutate(nested_data_ln = map2(param1, param2, ~ rlnorm(n_sims, .x, .y)))

#failure stress (Weibull) simulations
labeled_post_wb_tbl &amp;lt;- post_samples_failure_stress_model_1_tbl %&amp;gt;%
  mutate(
    model = &amp;quot;weibull&amp;quot;
  ) %&amp;gt;%
  rename(
    param1 = shape,
    param2 = scale
  ) %&amp;gt;%
  mutate(nested_data_wb = map2(param1, param2, ~ rweibull(n_sims, .x, .y)))

#combine and calculate reliability for each pair to build reliability distribution
all_post_samples_tbl &amp;lt;- bind_cols(labeled_post_ln_tbl, labeled_post_wb_tbl) %&amp;gt;%
  select(nested_data_ln, nested_data_wb) %&amp;gt;%
  mutate(reliability = map2_dbl(nested_data_ln, nested_data_wb, ~ mean(.x &amp;lt; .y)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Visualize the results with some help from tidybayes::geom_halfeyeh()&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#visualize
all_post_samples_tbl %&amp;gt;%
  ggplot(aes(x = reliability, y = 0)) +
  geom_halfeyeh(
    fill = &amp;quot;firebrick&amp;quot;,
    point_interval = median_qi, .width = .95, alpha = .9
  ) +
  geom_vline(xintercept = reliability_pt_est, color = &amp;quot;dodgerblue&amp;quot;, size = 1.1, alpha = .7) +
  #  stat_dotsh(quantiles = 100, size = .5) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(
    title = &amp;quot;Distribution of Predicted Reliability&amp;quot;,
    subtitle = &amp;quot;Marked by median and 95% probability interval. Vertical line is the point estimate&amp;quot;
  ) +
  theme_bw() +
  theme(panel.grid = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Behold, a full reliability distribution supported by the data! So much better for decision making than the point estimate!&lt;/p&gt;
&lt;p&gt;Thank you for reading.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix---prior-predictive-simulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Appendix - Prior Predictive Simulation&lt;/h2&gt;
&lt;div id=&#34;prior-predictive-simulation-for-stress-in-service&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Prior Predictive Simulation for Stress-in-Service&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(45)
mu_prior &amp;lt;- rlnorm(100000, meanlog = .5, sdlog = 1)
mu_prior_tbl &amp;lt;- mu_prior %&amp;gt;%
  as_tibble() %&amp;gt;%
  filter(value &amp;gt; 0)

muuuuu &amp;lt;- mu_prior_tbl %&amp;gt;% ggplot(aes(x = mu_prior)) +
  geom_histogram(aes(y = ..density..), fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6) +
  scale_x_continuous(trans = &amp;quot;log10&amp;quot;)

mu_prior_tbl %&amp;gt;%
  mutate(orig = log(value)) %&amp;gt;%
  pull(orig) %&amp;gt;%
  mean()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5033306&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mu_prior_tbl %&amp;gt;%
  mutate(orig = log(value)) %&amp;gt;%
  pull(orig) %&amp;gt;%
  sd()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.001799&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(45)
sigma_prior &amp;lt;- runif(100000, .01, 8)

p0_priors_tbl &amp;lt;- sigma_prior %&amp;gt;%
  as_tibble() %&amp;gt;%
  bind_cols(mu_prior_tbl) %&amp;gt;%
  rename(sigma = value, mu = value1)


sigmaaa &amp;lt;- p0_priors_tbl %&amp;gt;% ggplot(aes(x = sigma_prior)) +
  geom_histogram(aes(y = ..density..), fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6)

muuuuu + sigmaaa + plot_annotation(title = &amp;quot;Prior Predicitve Simulations for mu and sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Evaluate implied stress-in-service before seeing the data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p0 &amp;lt;- p0_priors_tbl[1:1000, ] %&amp;gt;%
  mutate(row_id = row_number()) %&amp;gt;%
  mutate(plotted_y_data = pmap(
    list(sigma, mu, row_id),
    ~ tibble(
      x = seq(.1, 100, length.out = 1000),
      y = dlnorm(x, .x, .y),
      z = row_id
    )
  )) %&amp;gt;%
  unnest(plotted_y_data) %&amp;gt;%
  filter(x &amp;gt; 1) %&amp;gt;%
  ggplot(aes(x, y)) +
  geom_line(aes(group = row_id), alpha = .15, color = &amp;quot;#2c3e50&amp;quot;) +
  labs(
    x = &amp;quot;Stress-in-Service&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    title = &amp;quot;Implied Stress-in-Service Possibilities&amp;quot;,
    subtitle = &amp;quot;Generated from Priors Only&amp;quot;
  ) +
  scale_x_continuous(trans = &amp;quot;log10&amp;quot;) +
  ylim(c(0, 1))

p0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Evaluate implied failure stress before seeing the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# seed for reproducibility
set.seed(12)

# Evaluate Mildly Informed Priors
shape_prior &amp;lt;- runif(100000, 0, 10)
shape_prior_tbl &amp;lt;- shape_prior %&amp;gt;% as_tibble()
shaaaape &amp;lt;- shape_prior_tbl %&amp;gt;% ggplot(aes(x = shape_prior)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, boundary = 10, fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6)


intercept_prior &amp;lt;- rstudent_t(100000, 3, 5, 5)

priors_tbl &amp;lt;- intercept_prior %&amp;gt;%
  as_tibble() %&amp;gt;%
  bind_cols(shape_prior_tbl) %&amp;gt;%
  rename(intercept = value, shape = value1) %&amp;gt;%
  mutate(scale_prior = exp(intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  filter(scale_prior &amp;lt; 1000) %&amp;gt;%
  select(-intercept)

scaaaale &amp;lt;- priors_tbl %&amp;gt;% ggplot(aes(x = scale_prior)) +
  geom_histogram(aes(y = ..density..), binwidth = 10, boundary = 100, fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6) +
  ylim(c(0, .005))

shaaaape + scaaaale + plot_annotation(title = &amp;quot;Prior Predicitve Simulations for Shape and Scale&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These are the plausible distributions of failure stress we might expect before seeing the data (based on these priors):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- priors_tbl[1:500, ] %&amp;gt;%
  mutate(plotted_y_data = map2(
    shape, scale_prior,
    ~ tibble(
      x = seq(0, 200, length.out = 400),
      y = dweibull(x, .x, .y)
    )
  )) %&amp;gt;%
  unnest(plotted_y_data) %&amp;gt;%
  ggplot(aes(x, y)) +
  geom_line(aes(group = shape), alpha = .2, color = &amp;quot;#2c3e50&amp;quot;) +
  xlim(c(0, 50)) +
  ylim(c(0, .5)) +
  labs(
    x = &amp;quot;Failure Stress Distributions&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    title = &amp;quot;Implied Failure Stress Possibilities&amp;quot;,
    subtitle = &amp;quot;Generated from Priors Only&amp;quot;
  )

p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Image from here: &lt;a href=&#34;https://www.quanterion.com/interference-stressstrength-analysis/&#34; class=&#34;uri&#34;&gt;https://www.quanterion.com/interference-stressstrength-analysis/&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;If the stress and strength distribution were exactly the same and overlapping, the probability of failures would be 50% since you would be pulling 2 draws randomly and comparing stress to strength&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Practical Applications of Bayesian Reliability, pg. 170&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Survival Analysis - Fitting Weibull Models for Improving Device Reliability in R</title>
      <link>/post/bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r/</guid>
      <description>


&lt;p&gt;It’s time to get our hands dirty with some survival analysis! In this post, I’ll explore reliability modeling techniques that are applicable to Class III medical device testing. My goal is to expand on what I’ve been learning about GLM’s and get comfortable fitting data to Weibull distributions. I don’t have a ton of experience with Weibull analysis so I’ll be taking this opportunity to ask questions, probe assumptions, run simulations, explore different libraries, and develop some intuition about what to expect. I will look at the problem from both a frequentist and Bayesian perspective and explore censored and un-censored data types. Fair warning - expect the workflow to be less linear than normal to allow for these excursions.&lt;/p&gt;
&lt;p&gt;First - a bit of background. FDA expects data supporting the durability of implantable devices over a specified service life. Engineers develop and execute benchtop tests that accelerate the cyclic stresses and strains, typically by increasing the frequency. Such a test is shown here for a coronary stent:&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/fracture.gif&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The most common experimental design for this type of testing is to treat the data as attribute i.e. pass/fail by recording whether or not each test article fractured or not after some pre-determined duration &lt;em&gt;t&lt;/em&gt;. By treating each tested device as a Bernoulli trial, a 1-sided confidence interval can be established on the reliability of the population based on the binomial distribution. This approach is not optimal however since it is generally only practical when all tested units pass the test and even then the sample size requirement are quite restricting. Additionally, designers cannot establish any sort of safety margin or understand the failure mode(s) of the design. We can do better by borrowing reliability techniques from other engineering domains where tests are run to failure and modeled as events vs. time. Such data often follows a Weibull distribution which is flexible enough to accommodate many different failure rates and patterns.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#part-1---fitting-models-to-weibull-data-without-censoring-%5Bfrequentist-perspective%5D&#34;&gt;Part 1 - Fitting Models to Weibull Data Without Censoring [Frequentist Perspective]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#construct-weibull-model-from-un-censored-data-using-fitdistrplus&#34;&gt;Construct Weibull model from un-censored data using fitdistrplus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#using-the-model-to-infer-device-reliability&#34;&gt;Using the model to infer device reliability&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#part-2---fitting-models-to-weibull-data-without-censoring-%5Bbayesian-perspective%5D&#34;&gt;Part 2 - Fitting Models to Weibull Data Without Censoring [Bayesian Perspective]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#use-grid-approximation-to-estimate-posterior&#34;&gt;Use grid approximation to estimate posterior&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualize-draws-from-the-posterior&#34;&gt;Visualize draws from the posterior&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#uncertainty-in-the-implied-reliabilty-of-the-device&#34;&gt;Uncertainty in the implied reliabilty of the device&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#part-3---fitting-models-to-weibull-data-with-right-censoring-%5Bfrequentist-perspective%5D&#34;&gt;Part 3 - Fitting Models to Weibull Data with Right-Censoring [Frequentist Perspective]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#point-estimate-with-right-censored-data&#34;&gt;Point estimate with right-censored data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#simulation-to-understand-point-estimate-sensitivity-to-sample-size&#34;&gt;Simulation to understand point estimate sensitivity to sample size&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#simulation-of-95%-confidence-intervals-on-reliability&#34;&gt;Simulation of 95% confidence intervals on reliability&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#part-4---fitting-models-to-weibull-data-with-right-censoring-%5Bbayesian-perspective%5D&#34;&gt;Part 4 - Fitting Models to Weibull Data with Right-Censoring [Bayesian Perspective]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#use-brm()-to-generate-a-posterior-distribution-for-shape-and-scale&#34;&gt;Use brm() to generate a posterior distribution for shape and scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#evaluation-of-priors&#34;&gt;Evaluation of priors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#evaluate-sensitivity-of-posterior-to-sample-size&#34;&gt;Evaluate sensitivity of posterior to sample size&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#evaluate-sensitivity-of-reliability-estimate-to-sample-size.&#34;&gt;Evaluate Sensitivity of Reliability Estimate to Sample Size.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#wrap-up&#34;&gt;Wrap-up&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix---prior-predictive-simulation---beware-it&amp;#39;s-ugly-in-here&#34;&gt;APPENDIX - Prior Predictive Simulation - BEWARE it’s ugly in here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(patchwork)
library(skimr)
library(ggrepel)
library(tidyverse)
library(knitr)
library(rayshader)
library(fitdistrplus)
library(tidymodels)
library(tidybayes)
library(ggridges)
library(ggExtra)
library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;part-1---fitting-models-to-weibull-data-without-censoring-frequentist-perspective&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 1 - Fitting Models to Weibull Data Without Censoring [Frequentist Perspective]&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tools: fitdist() function form fitdistrplus package&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal: Obtain maximum likelihood point estimate of shape and scale parameters from best fitting Weibull distribution&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;In the following section I work with test data representing the number of days a set of devices were on test before failure.&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; Each day on test represents 1 month in service. All devices were tested until failure (no censored data). To start, I’ll read in the data and take a look at it. There are 100 data points, which is more than typically tested for stents or implants but is reasonable for electronic components. We’ll assume that domain knowledge indicates these data come from a process that can be well described by a Weibull distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Read data in and scan with skim()
data &amp;lt;- read.csv(file = &amp;quot;Example3.1Data.txt&amp;quot;, header = FALSE) %&amp;gt;% as_tibble()
data_tbl &amp;lt;- data %&amp;gt;% rename(fatigue_duration = V1)

data_tbl %&amp;gt;% skim()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Skim summary statistics
##  n obs: 100 
##  n variables: 1 
## 
## -- Variable type:integer --------------------------------------------------------------------------------------------------------------------
##          variable missing complete   n  mean    sd p0   p25  p50   p75
##  fatigue_duration       0      100 100 89.44 51.42  5 51.75 79.5 119.5
##  p100     hist
##   290 &amp;lt;U+2583&amp;gt;&amp;lt;U+2587&amp;gt;&amp;lt;U+2586&amp;gt;&amp;lt;U+2583&amp;gt;&amp;lt;U+2582&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;fatigue_duration&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;75&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;28&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;52&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;67&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;78&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;132&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;169&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;97&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;construct-weibull-model-from-un-censored-data-using-fitdistrplus&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Construct Weibull model from un-censored data using fitdistrplus&lt;/h3&gt;
&lt;p&gt;To start out with, let’s take a frequentist approach and fit a 2-parameter Weibull distribution to these data. Once the parameters of the best fitting Weibull distribution of determined, they can be used to make useful inferences and predictions.&lt;/p&gt;
&lt;p&gt;I’ll use the fitdist() function from the fitdistrplus package to identify the best fit via maximum likelihood. The parameters we care about estimating are the shape and scale.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit model and extract parameters of interest
mle_wieb_nocens_fit &amp;lt;- fitdist(data_tbl$fatigue_duration, &amp;quot;weibull&amp;quot;)
weib_shape &amp;lt;- mle_wieb_nocens_fit$estimate[&amp;quot;shape&amp;quot;]
weib_scale &amp;lt;- mle_wieb_nocens_fit$estimate[&amp;quot;scale&amp;quot;]

# Summarize and plot
summary(mle_wieb_nocens_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Fitting of the distribution &amp;#39; weibull &amp;#39; by maximum likelihood 
## Parameters : 
##         estimate Std. Error
## shape   1.832201  0.1401198
## scale 100.841802  5.8068570
## Loglikelihood:  -526.2573   AIC:  1056.515   BIC:  1061.725 
## Correlation matrix:
##           shape     scale
## shape 1.0000000 0.3186071
## scale 0.3186071 1.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(mle_wieb_nocens_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; The Weibull isn’t the only possible distribution we could have fit. Lognormal and gamma are both known to model time-to-failure data well. They are shown below using the denscomp() function from fitdistrplus.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit gamma model, extract shape, rate
mle_gamma_nocens_fit &amp;lt;- fitdist(data_tbl$fatigue_duration, &amp;quot;gamma&amp;quot;)
gamma_shape &amp;lt;- mle_gamma_nocens_fit$estimate[&amp;quot;shape&amp;quot;]
gamma_rate &amp;lt;- mle_gamma_nocens_fit$estimate[&amp;quot;rate&amp;quot;]

# Fit lognormal model, extract mean, sd
mle_lognormal_nocens_fit &amp;lt;- fitdist(data_tbl$fatigue_duration, &amp;quot;lnorm&amp;quot;)
lnorm_meanlog &amp;lt;- mle_lognormal_nocens_fit$estimate[&amp;quot;meanlog&amp;quot;]
lnorm_sdlog &amp;lt;- mle_lognormal_nocens_fit$estimate[&amp;quot;sdlog&amp;quot;]

# visualize in fitdistrplus
plot.legend &amp;lt;- c(&amp;quot;gamma&amp;quot;, &amp;quot;lognormal&amp;quot;, &amp;quot;Weibull&amp;quot;)
denscomp(list(mle_gamma_nocens_fit, mle_lognormal_nocens_fit, mle_wieb_nocens_fit), legendtext = plot.legend)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I recreate the above in ggplot2, for fun and practice.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x_series &amp;lt;- seq(0, 300, by = 1)
x_tbl &amp;lt;- tibble(x = x_series)


wide_densities_tbl &amp;lt;- x_tbl %&amp;gt;%
  mutate(
    Weibull = dweibull(x, shape = weib_shape, scale = weib_scale),
    gamma = dgamma(x, shape = gamma_shape, rate = gamma_rate),
    lognormal = dlnorm(x, meanlog = lnorm_meanlog, sdlog = lnorm_sdlog)
  ) %&amp;gt;%
  gather(&amp;quot;distribution&amp;quot;, &amp;quot;value&amp;quot;, -x)

wide_densities_tbl %&amp;gt;% ggplot(aes(x = x)) +
  geom_line(aes(
    x = x,
    y = value,
    color = distribution,
    linetype = distribution
  ),
  size = .8
  ) +
  geom_histogram(
    data = data_tbl,
    aes(
      x = fatigue_duration,
      y = ..density..
    ),
    binwidth = 50,
    boundary = 300,
    color = &amp;quot;white&amp;quot;,
    fill = &amp;quot;#2c3e50&amp;quot;,
    alpha = .6
  ) +
  labs(
    x = &amp;quot;Time to Fatigue Failure Event (Days)&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    title = &amp;quot;Histogram and theoretical densities for Fatigue Data&amp;quot;,
    subtitle = &amp;quot;Parametric fits using MLE via fitdist() function&amp;quot;
  ) +
  theme(legend.title = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Goodness-of-fit statistics are available and shown below for reference. If available, we would prefer to use domain knowledge and experience to identify what the true distribution is instead of these statistics which are subject to sampling variation. It is not good practice to stare at the histogram and attempt to identify the distribution of the population from which it was drawn. Nevertheless, we might look at the statistics below if we had absolutely no idea the nature of the data generating process / test.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get goodness-of-fit
gofstat(list(mle_wieb_nocens_fit, mle_gamma_nocens_fit, mle_lognormal_nocens_fit),
  fitnames = c(&amp;quot;weib&amp;quot;, &amp;quot;gamma&amp;quot;, &amp;quot;lnorm&amp;quot;)
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Goodness-of-fit statistics
##                                    weib      gamma      lnorm
## Kolmogorov-Smirnov statistic 0.05066902 0.03643609 0.06948557
## Cramer-von Mises statistic   0.03408173 0.02106615 0.12076742
## Anderson-Darling statistic   0.21634543 0.17192106 0.81630880
## 
## Goodness-of-fit criteria
##                                    weib    gamma    lnorm
## Akaike&amp;#39;s Information Criterion 1056.515 1056.408 1067.427
## Bayesian Information Criterion 1061.725 1061.618 1072.637&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-model-to-infer-device-reliability&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using the model to infer device reliability&lt;/h3&gt;
&lt;p&gt;The model by itself isn’t what we are after. It is the vehicle from which we can infer some very important information about the reliability of the implant design. First and foremost - we would be very interested in understanding the reliability of the device at a time of interest. For instance, suppose our voice of customer research indicates that our new generation of device needs to last 10 months &lt;em&gt;in vivo&lt;/em&gt; to be safe and competitive. Recall that each day on test represents 1 month in service. Once we fit a Weibull model to the test data for our device, we can use the reliability function to calculate the probability of survival beyond time &lt;em&gt;t&lt;/em&gt;.&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{R} (t | \beta, \eta) =  e ^ {- \bigg (\frac{t}{\eta} \bigg ) ^ {\beta}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;t = the time of interest (for example, 10 years)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; = the Weibull scale parameter&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; = the Weibull shape parameter&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This looks a little nasty but it reads something like “the probability of a device surviving beyond time &lt;em&gt;t&lt;/em&gt; conditional on parameters &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; is [some mathy function of &lt;em&gt;t&lt;/em&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt;]. For the model we fit above using MLE, a point estimate of the reliability at t=10 years (per the above VoC) can be calculated with a simple 1-liner:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reliability_at_10 &amp;lt;- exp(-(10 / weib_scale)**(weib_shape))
reliability_at_10 %&amp;gt;%
  scales::percent() %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;x&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;98.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In this way we infer something important about the quality of the product by fitting a model from benchtop data.&lt;/p&gt;
&lt;p&gt;It is common to report confidence intervals about the reliability estimate but this practice suffers many limitations. The intervals change with different stopping intentions and/or additional comparisons. They also do not represent true probabilistic distributions as our intuition expects them to and cannot be propagated through complex systems or simulations. What we’d really like is the posterior distribution for each of the parameters in the Weibull model, which provides all credible pairs of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; that are supported by the data. For that, we need Bayesian methods which happen to also be more fun.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-2---fitting-models-to-weibull-data-without-censoring-bayesian-perspective&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 2 - Fitting Models to Weibull Data Without Censoring [Bayesian Perspective]&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tools: Grid Approximation [manual calculations]&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal: Approximate true posterior distributions for shape and scale via discretization of priors&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;use-grid-approximation-to-estimate-posterior&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use grid approximation to estimate posterior&lt;/h3&gt;
&lt;p&gt;This problem is simple enough that we can apply grid approximation to obtain the posterior. In this method we feed in a sequence of candidate combinations for &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; and determine which pairs were most likely to give rise to the data. The likelihood is multiplied by the prior and converted to a probability for each set of candidate &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt;. Flat priors are used here for simplicity - I’ll put more effort into the priors later on in this post. Since the priors are flat, the posterior estimates should agree with the maximum likelihood point estimate.&lt;/p&gt;
&lt;p&gt;Calculate posterior via grid approximation:&lt;a href=&#34;#fn4&#34; class=&#34;footnoteRef&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# function to get log-likelihood of the data for a given shape &amp;amp; scale pair
grid_function &amp;lt;- function(shape, scale) {
  dweibull(data_tbl$fatigue_duration, shape = shape, scale = scale, log = T) %&amp;gt;%
    sum()
}

# set up grid of possible shape, scale parameters
n &amp;lt;- 100
shape_grid &amp;lt;- seq(1, 3, length.out = n)
scale_grid &amp;lt;- seq(60, 130, length.out = n)
two_param_grid &amp;lt;- expand_grid(shape_grid, scale_grid)

# map the grid_function over all candidate parameter pairs
# multiply LL by prior and convert to probability
full_tbl &amp;lt;- two_param_grid %&amp;gt;%
  mutate(log_likelihood = map2(shape_grid, scale_grid, grid_function)) %&amp;gt;%
  unnest() %&amp;gt;%
  mutate(
    shape_prior = 1,
    scale_prior = 1
  ) %&amp;gt;%
  mutate(product = log_likelihood + shape_prior + scale_prior) %&amp;gt;%
  mutate(probability = exp(product - max(product)))

full_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 7))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape_grid&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale_grid&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;log_likelihood&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;shape_prior&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale_prior&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;product&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;probability&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;60.00000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-558.5011&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-556.5011&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;60.70707&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-557.9365&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-555.9365&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;61.41414&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-557.3982&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-555.3982&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;62.12121&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-556.8853&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-554.8853&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;62.82828&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-556.3968&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-554.3968&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;63.53535&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-555.9317&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-553.9317&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;64.24242&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-555.4890&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-553.4890&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;64.94949&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-555.0680&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-553.0680&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;65.65657&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-554.6678&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-552.6678&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;66.36364&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-554.2875&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-552.2875&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Plot the grid approximation of the posterior. If we super-impose our point estimate from Part 1, we see the maximum likelihood estimate agrees well with the mode of the joint posterior distributions for shape and scale.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# need this data to feed to gg_label_repel to tell it where to attach label
point_tbl &amp;lt;- tibble(x = weib_shape, y = weib_scale)

# visualize and compare to MLE
plt_1 &amp;lt;- full_tbl %&amp;gt;%
  ggplot(aes(x = shape_grid, y = scale_grid)) +
  geom_raster(aes(fill = probability),
    interpolate = T
  ) +
  geom_point(x = weib_shape, y = weib_scale, size = 1.3) +
  geom_label_repel(
    data = point_tbl, aes(x, y),
    label = &amp;quot;Maximum Likelihood Estimate \n[from Part 1]&amp;quot;,
    fill = &amp;quot;#8bd646ff&amp;quot;,
    color = &amp;quot;black&amp;quot;,
    segment.color = &amp;quot;black&amp;quot;,
    segment.size = 1,
    #                   min.segment.length = unit(1, &amp;quot;lines&amp;quot;),
    nudge_y = -16,
    nudge_x = .5
  ) +
  scale_fill_viridis_c() +
  labs(
    title = &amp;quot;Posterior for Weibull Shape and Scale Parameters&amp;quot;,
    subtitle = &amp;quot;Calculated with Grid Approximation&amp;quot;,
    x = expression(eta [&amp;quot;shape&amp;quot;]),
    y = expression(beta [&amp;quot;scale&amp;quot;])
  ) +
  theme(panel.grid = element_blank())

plt_1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;3d with rayshader just to flex :)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# par(mfrow = c(1, 1))
# plot_gg(plt_1, width = 5, height = 4, scale = 300, multicore = TRUE, windowsize = c(1200, 960),
#        fov = 70, zoom = 0.45, theta = 330, phi = 40)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/3d_weib_2.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize-draws-from-the-posterior&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualize draws from the posterior&lt;/h3&gt;
&lt;p&gt;We can sample from the grid to get the same if we weight the draws by probability.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2020)

# take a weighted sample from the posterior
grid_approx_posterior_samples &amp;lt;- full_tbl %&amp;gt;%
  sample_n(size = 2000, replace = T, weight = probability)

# visualize
grid_approx_plot &amp;lt;- grid_approx_posterior_samples %&amp;gt;%
  ggplot(aes(x = shape_grid, y = scale_grid)) +
  geom_point(
    colour = &amp;quot;#e56a5dff&amp;quot;,
    size = 2,
    alpha = 0.3
  ) +
  labs(
    x = expression(eta [&amp;quot;shape&amp;quot;]),
    y = expression(beta [&amp;quot;scale&amp;quot;])
  ) +
  geom_density_2d(color = &amp;quot;black&amp;quot;, size = 1.2, alpha = .4) +
  labs(
    title = &amp;quot;Estimate of Joint Probabilities for Shape and Scale&amp;quot;,
    subtitle = &amp;quot;Via Posterior Sampling&amp;quot;
  )

grid_approx_marg_plot &amp;lt;- ggMarginal(grid_approx_plot,
  type = &amp;quot;density&amp;quot;,
  color = &amp;quot;white&amp;quot;,
  alpha = 0.7,
  fill = &amp;quot;#e56a5dff&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;uncertainty-in-the-implied-time-to-failure-curves&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Uncertainty in the implied time-to-failure curves&lt;/h3&gt;
&lt;p&gt;Each of the credible parameter values implies a possible Weibull distribution of time-to-failure data from which a reliability estimate can be inferred. This is a good way to visualize the uncertainty in a way that makes intuitive sense.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sample from posterior; weighted as prob
grid_approx_posterior_samples_4plot &amp;lt;- full_tbl %&amp;gt;%
  sample_n(size = 1000, replace = T, weight = probability) %&amp;gt;%
  select(shape_grid, scale_grid)

# plot 1000 Weibull curves from samples parameters
weib_uncertainty_plt &amp;lt;- grid_approx_posterior_samples_4plot %&amp;gt;%
  mutate(p_y_data = map2(
    shape_grid, scale_grid,
    ~ tibble(
      x = seq(0, 200, length.out = 400),
      y = dweibull(x, .x, .y)
    )
  )) %&amp;gt;%
  mutate(row_id = row_number()) %&amp;gt;%
  unnest(p_y_data) %&amp;gt;%
  ggplot(aes(x = x, y = y)) +
  geom_line(aes(group = row_id), alpha = .05, color = &amp;quot;#440154ff&amp;quot;) +
  labs(
    x = &amp;quot;Time&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    title = &amp;quot;Distribution of Time at Failure Event&amp;quot;,
    subtitle = &amp;quot;Implied by Posterior Distribution [Sample of n=1000]&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/weib_uncertainty_plt.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;uncertainty-in-the-implied-reliabilty-of-the-device&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Uncertainty in the implied reliabilty of the device&lt;/h3&gt;
&lt;p&gt;Any row-wise operations performed will retain the uncertainty in the posterior distribution. This allows for a straightforward computation of the range of credible reliabilities at t=10 via the reliability function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# use params in posterior to calculate correstponding reliabilities at t=10
grid_approx_posterior_samples_4relplot &amp;lt;- full_tbl %&amp;gt;%
  sample_n(size = 4000, replace = T, weight = probability) %&amp;gt;%
  select(shape_grid, scale_grid) %&amp;gt;%
  mutate(reliability_at_10 = exp(-(10 / scale_grid)**(shape_grid)))

# visualize reliability distribution
grid_approx_posterior_samples_4relplot %&amp;gt;%
  ggplot(aes(reliability_at_10)) +
  geom_histogram(aes(y = ..density..), fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6) +
  labs(
    title = &amp;quot;Reliability Distribution&amp;quot;,
    subtitle = &amp;quot;Calculated from Grid Approximation with Flat Priors&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; This distribution gives much richer information than the MLE point estimate of reliability. The most credible estimate of reliability is ~ 98.8%, but it could plausibly also be as low as 96%. This delta can mean the difference between a successful and a failing product and should be considered as you move through project phase gates.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-3---fitting-models-to-weibull-data-with-right-censoring-frequentist-perspective&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 3 - Fitting Models to Weibull Data with Right-Censoring [Frequentist Perspective]&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tools: survreg() function form survival package&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal: Obtain maximum likelihood point estimate of shape and scale parameters from best fitting Weibull distribution&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;In survival analysis we are waiting to observe the event of interest. For benchtop testing, we wait for fracture or some other failure. In a clinical study, we might be waiting for death, re-intervention, or endpoint. Sometimes the events don’t happen within the observation window but we still must draw the study to a close and crunch the data. Cases in which no events were observed are considered “right-censored” in that we know the start date (and therefore how long they were under observation) but don’t know if and when the event of interest would occur. They must inform the analysis in some way - generally within the likelihood.&lt;/p&gt;
&lt;div id=&#34;point-estimate-with-right-censored-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Point estimate with right-censored data&lt;/h3&gt;
&lt;p&gt;First, I’ll set up a function to generate simulated data from a Weibull distribution and censor any observations greater than 100. I set the function up in anticipation of using the survreg() function from the &lt;strong&gt;survival&lt;/strong&gt; package in R. The syntax is a little funky so some additional detail is provided below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# function to generate random Weibull data and censor data &amp;gt; 100
rweibull_cens_mod_fcn &amp;lt;- function(n, shape, scale) {
  raw_times &amp;lt;- rweibull(n, shape = shape, scale = scale)
  tibble(failure_time_raw = raw_times) %&amp;gt;%
    mutate(time = case_when(
      failure_time_raw &amp;lt; 100 ~ failure_time_raw,
      TRUE ~ 100
    )) %&amp;gt;%
    mutate(censor = case_when(
      time == 100 ~ 0,
      TRUE ~ 1
    )) %&amp;gt;%
    mutate(censor = censor == 1) %&amp;gt;%
    mutate(time = time %&amp;gt;% round(digits = 2)) %&amp;gt;%
    select(-failure_time_raw)
}

# set seed for repeatability
set.seed(54)
first_test_fit_tbl &amp;lt;- rweibull_cens_mod_fcn(30, 3, 100)
first_test_fit_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;time&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;censor&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;31.16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;73.94&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;71.90&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;100.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FALSE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;100.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FALSE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;74.91&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;37.79&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;72.28&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;50.63&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;45.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I admit this looks a little strange because the data that were just described as censored (duration greater than 100) show as “FALSE” in the censored column. This is due to the default syntax of the survreg() function in the survival package that we intend to fit the model with:&lt;a href=&#34;#fn5&#34; class=&#34;footnoteRef&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;survival package defaults for censoring:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;0 or FALSE for censoring, 1 or TRUE for observed event&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;To further throw us off the trail, the survreg() function returns “scale”&amp;quot; and “intercept”&amp;quot; that must be converted to recover the shape and scale parameters that align with the rweibull() function used to create the data. Don’t fall for these tricks - just extract the desired information as follows:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;survival package defaults for parameterizing the Weibull distribution:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;survreg’s scale parameter = 1/(rweibull shape parameter)&lt;/li&gt;
&lt;li&gt;survreg’s intercept = log(rweibull scale parameter)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ok let’s see if the model can recover the parameters when we providing survreg() the tibble with n=30 data points (some censored):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit model to simulated data (n=30)
test_fit &amp;lt;- survival::survreg(Surv(time, censor) ~ 1,
  data = first_test_fit_tbl,
  dist = &amp;quot;weibull&amp;quot;
)

# evaluate the fit
summary(test_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## survival::survreg(formula = Surv(time, censor) ~ 1, data = first_test_fit_tbl, 
##     dist = &amp;quot;weibull&amp;quot;)
##               Value Std. Error    z       p
## (Intercept)  4.5469     0.0896 50.7 &amp;lt; 2e-16
## Log(scale)  -0.9266     0.1972 -4.7 2.6e-06
## 
## Scale= 0.396 
## 
## Weibull distribution
## Loglik(model)= -106.7   Loglik(intercept only)= -106.7
## Number of Newton-Raphson Iterations: 5 
## n= 30&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Extract and covert shape and scale with broom::tidy() and dplyr:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract scale parameter
scale &amp;lt;- tidy(test_fit)[1, 2] %&amp;gt;%
  rename(scale = estimate) %&amp;gt;%
  exp() %&amp;gt;%
  round(2)

# extract shape parameter
shape &amp;lt;- tidy(test_fit)[2, 2] %&amp;gt;%
  rename(shape = estimate) %&amp;gt;%
  exp() %&amp;gt;%
  .^-1 %&amp;gt;%
  round(2)

# summarize
point_estimates &amp;lt;- bind_cols(shape, scale)
point_estimates %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.53&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;94.34&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;What has happened here? We know the true parameters are shape = 3, scale = 100 because that’s how the data were generated. These point estimates are pretty far off. Is the survreg() fitting function broken? Are there too few data and we are just seeing sampling variation? Is it confused by the censored data? I honestly don’t know. To answer these questions, we need a new function that fits a model using survreg() for any provided sample size. The data to make the fit are generated internal to the function. The function returns a tibble with estimates of shape and scale for that particular trial:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulation-to-understand-point-estimate-sensitivity-to-sample-size&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Simulation to understand point estimate sensitivity to sample size&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# seed for repeatability
set.seed(2025)

# fcn takes sample size n, simulates weibull(3, 100) data, fits model, estimates params
test_map_fcn &amp;lt;- function(n) {
  holder &amp;lt;- rweibull_cens_mod_fcn(n, 3, 100)

  sr1_fit &amp;lt;- survival::survreg(Surv(time, censor) ~ 1, data = holder, dist = &amp;quot;weibull&amp;quot;)

  scale &amp;lt;- tidy(sr1_fit)[1, 2] %&amp;gt;%
    rename(scale = estimate) %&amp;gt;%
    exp() %&amp;gt;%
    round(2)

  shape &amp;lt;- tidy(sr1_fit)[2, 2] %&amp;gt;%
    rename(shape = estimate) %&amp;gt;%
    exp() %&amp;gt;%
    .^-1 %&amp;gt;%
    round(2)

  point_estimates &amp;lt;- bind_cols(shape, scale)
  point_estimates
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have a function that takes a sample size n and returns fitted shape and scale values, we want to apply the function across many values of n. Let’s look at what happens to our point estimates of shape and scale as the sample size n increases from 10 to 1000 by 1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create sequence of n&amp;#39;s
n_sim_mle &amp;lt;- seq(10, 1000, by = 1) %&amp;gt;%
  tibble() %&amp;gt;%
  rename(n = &amp;quot;.&amp;quot;)

# map the fitting function across vector of n&amp;#39;s.
results_tbl &amp;lt;- n_sim_mle %&amp;gt;%
  mutate(results = map(n, test_map_fcn)) %&amp;gt;%
  unnest()

# peek at format of results
results_tbl %&amp;gt;%
  head(5) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;n&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;85.94&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.89&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;108.29&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;103.04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;82.20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.98&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;101.62&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Visualize results of the simulation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results_tbl %&amp;gt;%
  gather(key = key, value = value, -n) %&amp;gt;%
  ggplot(aes(x = n, y = value)) +
  geom_point(color = &amp;quot;#5C126EFF&amp;quot;, alpha = 0.3) +
  facet_wrap(~key, scales = &amp;quot;free_y&amp;quot;) +
  geom_smooth(color = &amp;quot;#F17020FF&amp;quot;, alpha = 0.9) +
  labs(
    x = &amp;quot;Sample Size&amp;quot;,
    y = &amp;quot;&amp;quot;,
    title = &amp;quot;Estimated Shape and Scale Parameters for Different Data Set Sizes&amp;quot;,
    subtitle = &amp;quot;Weibull Regressions using survival package.  Data generated from Weibull(3, 100)&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This simulation is illuminating. It’s apparent that there is sampling variability effecting the estimates. On average, the true parameters of shape = 3 and scale = 100 are correctly estimated. But on any given experimental run, the estimate might be off by quite a bit. The precision increases with sample size as expected but the variation is still relevant even at large n.&lt;/p&gt;
&lt;p&gt;Based on this simulation we can conclude that our initial point estimate of 2.5, 94.3 fit from n=30 is within the range of what is to be expected and not a software bug or coding error.&lt;/p&gt;
&lt;p&gt;Estimates for product reliability at 15, 30, 45, and 60 months are shown below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results_tbl %&amp;gt;%
  mutate(reliability_at_15 = exp(-(15 / scale)**(shape))) %&amp;gt;%
  mutate(reliability_at_30 = exp(-(30 / scale)**(shape))) %&amp;gt;%
  mutate(reliability_at_45 = exp(-(45 / scale)**(shape))) %&amp;gt;%
  mutate(reliability_at_60 = exp(-(60 / scale)**(shape))) %&amp;gt;%
  select(-c(shape, scale)) %&amp;gt;%
  gather(key = &amp;quot;key&amp;quot;, value = &amp;quot;value&amp;quot;, -n) %&amp;gt;%
  ggplot(aes(x = n, y = value)) +
  geom_point(aes(color = key), alpha = .4) +
  #  geom_smooth(aes(group = key), color = &amp;quot;black&amp;quot;, size = .4, alpha = .5) +
  ylim(c(.73, 1)) +
  scale_color_viridis_d(option = &amp;quot;C&amp;quot;, begin = 0, end = .8, direction = -1) +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  labs(
    title = &amp;quot;Reliability Point Estimates&amp;quot;,
    subtitle = &amp;quot;Effect of Sample Size and Sampling Variability&amp;quot;,
    x = &amp;quot;Sample Size&amp;quot;,
    y = &amp;quot;Reliability Estimate&amp;quot;
  ) +
  theme(legend.title = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above gives a nice sense of the uncertainty in the reliability estimate as sample size increases, but you can’t actually simulate a confidence interval from those data because there aren’t enough data points at any one sample size. To do that, we need many runs at the same sample size.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulation-of-95-confidence-intervals-on-reliability&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Simulation of 95% confidence intervals on reliability&lt;/h3&gt;
&lt;p&gt;In the code below, I generate n=1000 simulations of n=30 samples drawn from a Weibull distribution with shape = 3 and scale = 100. For each set of 30 I fit a model and record the MLE for the parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# each simulation will be like a benchtop test of n=30 parts
ci_reps_tbl &amp;lt;- tibble(sample_size = rep(30, 1000))

set.seed(98)

# loop: draw 30 from rweibull(30, 100); fit model, estimate parameters
ci_results_tbl &amp;lt;- ci_reps_tbl %&amp;gt;%
  mutate(results = map(sample_size, test_map_fcn)) %&amp;gt;%
  unnest()

# peek at results
ci_results_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;sample_size&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.06&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;107.10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.80&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;98.42&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;111.44&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.78&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;108.50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.91&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;100.25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;102.01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;95.47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.72&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;97.98&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;96.99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.74&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;98.30&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;95% of the reliability estimates lik above the .05 quantile. This means the .05 quantile is the analogous boundary for a simulated 95% confidence interval. In the code below, the .05 quantile of reliability is estimated for each time requirement of interest where we have 1000 simulation at each.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# function will take a time of interest and calculate the implied reliability
# only works with the params from the ci_results_tbl above
reliability95_fcn &amp;lt;- function(t_requirement) {
  ci_results2tbl &amp;lt;- ci_results_tbl %&amp;gt;%
    mutate(reliability_at_t = exp(-(t_requirement / scale)**(shape))) %&amp;gt;%
    mutate(q_05 = quantile(reliability_at_t, .05))
  ci_results2tbl
}

# map the function across a sequence of candidate time requirements
reliability_seq_tbl &amp;lt;- tibble(time_requirement = seq(5, 100, by = 5)) %&amp;gt;% mutate(rel_tbl = map(time_requirement, reliability95_fcn))

# calculate the .05 quantile for reliability in each set of 1000 (each candidate time requirement)
reliability_summary_tbl &amp;lt;- reliability_seq_tbl %&amp;gt;%
  unnest(rel_tbl) %&amp;gt;%
  group_by(time_requirement) %&amp;gt;%
  summarize(rel_q05 = mean(q_05)) %&amp;gt;%
  ungroup()

# Peek
reliability_summary_tbl %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;time_requirement&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;rel_q05&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9987176&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9942133&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9858520&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9730873&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9558373&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9344743&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9076116&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;40&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8775053&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;45&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8429503&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;50&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8015775&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;55&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.7562483&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;60&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.7054836&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;65&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.6544688&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;70&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5948305&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;75&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5358066&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;80&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.4756331&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;85&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.4150847&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;90&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.3500516&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;95&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2880577&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2288761&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# reference tibbles for labeling w/ gg_label_repel
label_ci_tbl &amp;lt;- tibble(x = 45, y = 0.8429503)
label_95rel_tbl &amp;lt;- tibble(x = 10, y = 0.95)

# visualize
reliability_seq_tbl %&amp;gt;%
  unnest(rel_tbl) %&amp;gt;%
  ggplot(aes(x = time_requirement, y = reliability_at_t)) +
  geom_jitter(alpha = 0.03) +
  #  geom_point(data = reliability_summary_tbl, aes(x = time_requirement, y = rel_q05), color = &amp;quot;#c44c74ff&amp;quot;, size = 1) +
  geom_smooth(data = reliability_summary_tbl, aes(x = time_requirement, y = rel_q05), color = &amp;quot;#c44c74ff&amp;quot;, size = 1, alpha = .2) +
  geom_hline(aes(yintercept = .95), color = &amp;quot;#240691ff&amp;quot;, size = 1) +
  geom_label_repel(
    data = label_ci_tbl, aes(x, y),
    label = &amp;quot;1-sided 95% Confidence\n bound on Reliability&amp;quot;,
    fill = &amp;quot;#c44c74ff&amp;quot;,
    color = &amp;quot;#f0f921ff&amp;quot;,
    segment.color = &amp;quot;#c44c74ff&amp;quot;,
    segment.size = 1,
    #                   min.segment.length = unit(1, &amp;quot;lines&amp;quot;),
    nudge_y = -.5,
    nudge_x = -5
  ) +
  geom_label_repel(
    data = label_95rel_tbl, aes(x, y),
    label = &amp;quot;Product Reliability\n Requirement: 95%&amp;quot;,
    fill = &amp;quot;#240691ff&amp;quot;,
    color = &amp;quot;#f0f921ff&amp;quot;,
    segment.color = &amp;quot;#240691ff&amp;quot;,
    segment.size = 1,
    #                   min.segment.length = unit(1, &amp;quot;lines&amp;quot;),
    nudge_y = -.25,
    nudge_x = 5
  ) +
  labs(
    title = &amp;quot;Approximate 95% Confidence Interval for Various Durability Requirements&amp;quot;,
    subtitle = &amp;quot;Each Sim: 1000 models fit from 1000 draws of n=30 from Weibull(3, 100)&amp;quot;,
    x = &amp;quot;Device Requirement (Service Life without Failure)&amp;quot;,
    y = &amp;quot;Reliability&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-32-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; There’s a lot going on here so it’s worth it to pause for a minute. If I was to try to communicate this in words, I would say:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Assume we have designed a medical device that fails according to a Weibull distribution with shape = 3 and scale = 100.&lt;/li&gt;
&lt;li&gt;Assume the service life requirement for the device is known and specified within the product’s requirements&lt;/li&gt;
&lt;li&gt;Assume we can only test n=30 units in 1 test run and that testing is expensive and resource intensive&lt;/li&gt;
&lt;li&gt;The n=30 failure/censor times will be subject to sampling variability and the model fit from the data will likely not be Weibull(3, 100)&lt;/li&gt;
&lt;li&gt;The variability in the parameter estimates is propagated to the reliability estimates - a distribution of reliability is generated for each potential service life requirement (in practice we would only have 1 requirement)&lt;/li&gt;
&lt;li&gt;The .05 quantile of the reliability distribution at each requirement approximates the 1-sided lower bound of the 95% confidence interval. This threshold changes for each candidate service life requirement.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Why does any of this even matter? Here’s the TLDR of this whole section:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Suppose the service life requirement for our device is 24 months (2 years). Our boss asks us to set up an experiment to verify with 95% confidence that 95% of our product will meet the 24 month service requirement without failing. The industry standard way to do this is to test n=59 parts for 24 days (each day on test representing 1 month in service). If all n=59 pass then we can claim 95% reliability with 95% confidence. However, if we are willing to test a bit longer then the above figure indicates we can run the test to failure with only n=30 parts instead of n=59. If it cost a lot to obtain and prep test articles (which it often does), then &lt;strong&gt;we just saved a ton of money and test resources by treating the data as variable instead of attribute.&lt;/strong&gt; &lt;a href=&#34;#fn6&#34; class=&#34;footnoteRef&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; We also get information about the failure mode for free.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-4---fitting-models-to-weibull-data-with-right-censoring-bayesian-perspective&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 4 - Fitting Models to Weibull Data with Right-Censoring [Bayesian Perspective]&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tools: brm() function in brms; stan under the hood&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal: Obtain posterior distributions of shape and scale parameters via Hamiltonian Markov Chain Monte Carlo –&amp;gt; calculate reliability distributions&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;These data are just like those used before - a set of n=30 generated from a Weibull with shape = 3 and scale = 100. They represent months to failure as determined by accelerated testing. In the brms framework, censored data are designated by a 1 (not a 0 as with the survival package).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# test data
ttf &amp;lt;- c(100, 84.8, 87.8, 61.5, 99.3, 100, 100, 60.3, 80.3, 100, 51.7, 68.5, 99.6, 100, 53.2, 46.6, 26.4, 72.3, 62.9, 70.5, 22.2, 100, 100, 75.2, 87.2, 47.4, 100, 47.1, 98.2, 67.3)

# indicator of run-out / censoring
censored &amp;lt;- c(1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0)

# combine
months_to_failure_tbl_4.3.3 &amp;lt;- tibble(
  time = ttf,
  censored = censored
)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;use-brm-to-generate-a-posterior-distribution-for-shape-and-scale&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use brm() to generate a posterior distribution for shape and scale&lt;/h3&gt;
&lt;p&gt;The formula for asking brms to fit a model looks relatively the same as with survival. To start, we fit a simple model with default priors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit model with brm() [use default priors]
# mtf_weib_fit &amp;lt;- brm(time | cens(censored) ~ 1,
# data = months_to_failure_tbl_4.3.3, family = weibull())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just like with the survival package, the default parameterization in brms can easily trip you up. We are fitting an intercept-only model meaning there are no predictor variables. The parameters that get estimated by brm() are the Intercept and shape. We can use the shape estimate as-is, but it’s a bit tricky to recover the scale. The key is that brm() uses a log-link function on the mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;. There is no doubt that this is a rambling post - even so, it is not within scope to try to explain link functions and GLM’s (I’m not expert enough to do it anyways, refer to Statistical Rethinking by McElreath). In short, to convert to scale we need to both undo the link function by taking the exponent and then refer to the brms documentation to understand how the mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; relates to the scale &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;. The operation looks like this:&lt;a href=&#34;#fn7&#34; class=&#34;footnoteRef&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#scale = exp(Intercept)/(gamma(1 + 1/shape))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Examine the results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# saveRDS(mtf_weib_fit, file = &amp;quot;censored_data_mtf_weib_fit.rds&amp;quot;)
mtf_weib_fit &amp;lt;- readRDS(file = &amp;quot;censored_data_mtf_weib_fit.rds&amp;quot;)

summary(mtf_weib_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: weibull 
##   Links: mu = log; shape = identity 
## Formula: time | cens(censored) ~ 1 
##    Data: months_to_failure_tbl_4.3.3 (Number of observations: 30) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     4.41      0.08     4.25     4.58 1.00     2349     1782
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## shape     2.74      0.52     1.82     3.84 1.00     2530     2281
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Gut-check on convergence of chains. Things look good visually and Rhat = 1 (also good).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(mtf_weib_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-37-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Within the tibble of posterior draws we convert the intercept to scale using the formula previously stated.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract scale and shape
post_mtf_weib_samples &amp;lt;- posterior_samples(mtf_weib_fit) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale)

# peek
post_mtf_weib_samples %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2), digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.44&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;87.78&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.07&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;91.80&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.49&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.35&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.28&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;86.42&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.23&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;103.19&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.33&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;107.53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.37&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;91.18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;90.43&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here is our first look at the posterior drawn from a model fit with censored data. We know the data were simulated by drawing randomly from a Weibull(3, 100) so the true data generating process is marked with lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtf_plot &amp;lt;- post_mtf_weib_samples %&amp;gt;%
  ggplot(aes(x = shape, y = scale)) +
  geom_point(
    colour = &amp;quot;#453781FF&amp;quot;,
    size = 2,
    alpha = 0.1
  ) +
  geom_hline(aes(yintercept = 100), size = .5, alpha = .3) +
  geom_vline(aes(xintercept = 3), size = .5, alpha = .3) +
  labs(
    title = &amp;quot;Credible Parameters for Shape and Scale&amp;quot;,
    subtitle = &amp;quot;Run-Out Data Treated as Right-Censored&amp;quot;,
    x = expression(eta [&amp;quot;shape&amp;quot;]),
    y = expression(beta [&amp;quot;scale&amp;quot;])
  )


mtf_marg_plot &amp;lt;- ggMarginal(mtf_plot,
  type = &amp;quot;density&amp;quot;,
  color = &amp;quot;white&amp;quot;,
  alpha = 0.7,
  fill = &amp;quot;#453781FF&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-40-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; It looks like we did catch the true parameters of the data generating process within the credible range of our posterior. However, it is certainly not centered. Once again we should question: is the software working properly? Is the sample size a problem? Are the priors appropriate? Was the censoring specified and treated appropriately?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;investigation-of-how-to-treat-censored-data-points&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Investigation of how to treat censored data points&lt;/h3&gt;
&lt;p&gt;Let’s start with the question about the censoring. One question that I’d like to know is: What would happen if we omitted the censored data completely or treated it like the device failed at the last observed time point? This hypothetical should be straightforward to simulate. Let’s fit a model to the same data set, but we’ll just treat the last time point as if the device failed there (i.e. we’ll have lots of failures at t=100).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This model treats the data as though the devices failed at the last observed timepoint
# mtf_weib_nocens_fit &amp;lt;- brm(time ~ 1,
# data = months_to_failure_tbl_4.3.3, family = weibull())&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# saveRDS(mtf_weib_nocens_fit, file = &amp;quot;mtf_weib_nocens_fit.rds&amp;quot;)
mtf_weib_nocens_fit &amp;lt;- readRDS(file = &amp;quot;mtf_weib_nocens_fit.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now another model where we just omit the censored data completely (i.e. remove any units that don’t fail from the data set completely and fit a model to the rest).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This model just omits the censored data completely
# mtf_weib_omit_fit &amp;lt;- brm(time ~ 1,
# data = months_to_failure_tbl_4.3.3 %&amp;gt;% filter(censored == 0), family = weibull())&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt; plot(mtf_weib_nocens_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-45-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt; plot(mtf_weib_omit_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-45-2.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Create tibble of posterior draws from partially censored, un-censored, and censor-omitted models with identifier column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cens_model_post_draws &amp;lt;- posterior_samples(mtf_weib_fit) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale) %&amp;gt;%
  mutate(model = &amp;quot;Weibull with Censoring&amp;quot;)

uncens_model_post_draws &amp;lt;- posterior_samples(mtf_weib_nocens_fit) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale) %&amp;gt;%
  mutate(model = &amp;quot;Weibull (Treat Last Timepoint as Failure)&amp;quot;)

omit_model_post_draws &amp;lt;- posterior_samples(mtf_weib_omit_fit) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale) %&amp;gt;%
  mutate(model = &amp;quot;Weibull Omitting Censored Data&amp;quot;)

combined_weib_tbl &amp;lt;- cens_model_post_draws %&amp;gt;%
  bind_rows(uncens_model_post_draws) %&amp;gt;%
  bind_rows(omit_model_post_draws) %&amp;gt;%
  mutate(model = as_factor(model))

combined_weib_tbl %&amp;gt;%
  head(5) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 3), digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;model&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.44&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;87.78&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Weibull with Censoring&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.07&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;91.80&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Weibull with Censoring&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.49&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Weibull with Censoring&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.28&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.43&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Weibull with Censoring&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;86.42&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Weibull with Censoring&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here we compare the effect of the different treatments of censored data on the parameter estimates. Intervals are 95% HDI.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_shp_1 &amp;lt;- combined_weib_tbl %&amp;gt;% ggplot(aes(x = shape)) +
  geom_density(aes(fill = model), size = 0, alpha = 0.4) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(x = expression(eta[&amp;quot;shape&amp;quot;])) +
  stat_pointintervalh(aes(y = 0),
    point_interval = mode_hdi, .width = .95, show.legend = FALSE
  ) +
  facet_wrap(~model) +
  theme_classic() +
  theme(
    legend.position = &amp;quot;none&amp;quot;,
    axis.line.y = element_blank(),
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    legend.title = element_blank()
  )


d_shp_2 &amp;lt;- combined_weib_tbl %&amp;gt;% ggplot(aes(x = shape)) +
  geom_density(aes(fill = model), size = 0, alpha = 0.4) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(
    x = expression(eta[&amp;quot;shape&amp;quot;]),
    title = &amp;quot;Parameter Estimates&amp;quot;,
    subtitle = &amp;quot;Effect of Including Censored Data in Model&amp;quot;
  ) +
  theme_classic() +
  theme(
    axis.line.y = element_blank(),
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    legend.title = element_blank()
  )

d_scale_1 &amp;lt;- combined_weib_tbl %&amp;gt;% ggplot(aes(x = scale, fill = model)) +
  geom_density(size = 0, alpha = 0.4) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(x = expression(beta[&amp;quot;scale&amp;quot;])) +
  stat_pointintervalh(aes(y = 0),
    point_interval = mode_hdi, .width = .95, show.legend = FALSE
  ) +
  facet_wrap(~model) +
  theme_classic() +
  theme(
    legend.position = &amp;quot;none&amp;quot;,
    axis.line.y = element_blank(),
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    legend.title = element_blank()
  )

d_scale_2 &amp;lt;- combined_weib_tbl %&amp;gt;% ggplot(aes(x = scale)) +
  geom_density(aes(fill = model), size = 0, alpha = 0.4) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(
    x = expression(beta[&amp;quot;scale&amp;quot;]),
    title = &amp;quot;Parameter Estimates&amp;quot;,
    subtitle = &amp;quot;Effect of Including Censored Data in Model&amp;quot;
  ) +
  theme_classic() +
  theme(
    axis.line.y = element_blank(),
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    legend.title = element_blank()
  )

d_shp_2 + d_shp_1 + plot_layout(
  ncol = 1,
  guides = &amp;quot;collect&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-47-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_scale_2 + d_scale_1 + plot_layout(
  ncol = 1,
  guides = &amp;quot;collect&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-47-2.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; When we omit the censored data or treat it as a failure, the shape parameter shifts up and the scale parameter shifts down. In both cases, it moves farther away from true. This should give is confidence that we are treating the censored points appropriately and have specified them correctly in the brm() syntax.&lt;/p&gt;
&lt;p&gt;Plotting the joint distributions for the three groups:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;combined_weib_plt &amp;lt;- combined_weib_tbl %&amp;gt;%
  ggplot(aes(x = shape, y = scale)) +
  geom_point(aes(color = model, fill = model), size = 2, alpha = 0.08) +
  geom_hline(aes(yintercept = 100), size = .5, alpha = .3) +
  geom_vline(aes(xintercept = 3), size = .5, alpha = .3) +
  scale_color_manual(values = c(&amp;quot;#453781FF&amp;quot;, &amp;quot;#EA4F88&amp;quot;, &amp;quot;#FDE725FF&amp;quot;)) +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) + # force legend icons to be alpha = 1 instead of .08
  labs(
    title = &amp;quot;Credible Parameters for Shape and Scale&amp;quot;,
    subtitle = &amp;quot;Effect of Treating Censored Data Points in Different Ways&amp;quot;,
    x = expression(eta [&amp;quot;shape&amp;quot;]),
    y = expression(beta [&amp;quot;scale&amp;quot;])
  ) +
  theme(
    legend.position = &amp;quot;bottom&amp;quot;,
    legend.title = element_blank()
  )

cens_marg_plot &amp;lt;- ggMarginal(combined_weib_plt,
  groupColour = TRUE,
  groupFill = TRUE,
  type = &amp;quot;density&amp;quot;,
  alpha = 0.7
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-49-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; Our censored data set (purple) is closest to true. But we still don’t know why the highest density region of our posterior isn’t centered on the true value.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluation-of-priors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluation of priors&lt;/h3&gt;
&lt;p&gt;We haven’t looked closely at our priors yet (shame on me) so let’s do that now. The default priors are viewed with prior_summary().&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get default priors
prior_summary(mtf_weib_fit) %&amp;gt;%
  select(prior, class) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;prior&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;class&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;student_t(3, 4, 10)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Intercept&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;gamma(0.01, 0.01)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;shape&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I was taught to visualize what the model thinks before seeing the data via prior predictive simulation. I made a good-faith effort to do that, but the results are funky for brms default priors. I an not an expert here, but I believe this is because very vague default Gamma priors aren’t good for prior predictive simulations but quickly adapt to the first few data points they see.&lt;a href=&#34;#fn8&#34; class=&#34;footnoteRef&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;. The prior must be placed on the intercept when must be then propagated to the scale which further muddies things. All in all there isn’t much to see. A lot of the weight is at zero but there are long tails for the defaults. I have all the code for this simulation for the defaults in the Appendix.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/def.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you take this at face value, the model thinks the reliability is always zero before seeing the model. Again, I think this is a special case for vague gamma priors but it doesn’t give us much confidence that we are setting things up correctly.&lt;/p&gt;
&lt;p&gt;After viewing the default predictions, I did my best to iterate on the priors to generate something more realistic. My process was manual and my general plan was to force some crdibility over higher values of shape using a uniform distribution. The intercept values were more diffcult to iterate. Here are the revised priors I tried:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(prior = c(&amp;quot;student_t(3, 5, 5)&amp;quot;, &amp;quot;uniform(0, 10)&amp;quot;),
       class = c(&amp;quot;Intercept&amp;quot;, &amp;quot;shape&amp;quot;)) %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;prior&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;class&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;student_t(3, 5, 5)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Intercept&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;uniform(0, 10)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;shape&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As can be seen, the revised priors were able to spread some credibility up across the middle reliability values but ended up a lot of mass on either end, which wasn’t to goal.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/imp_priors.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Regardless, I refit the model with the (potentially) improved more realistic (but still not great) priors and found minimal difference in the model fit as shown below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/prior_compare.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note: all models throughout the remainder of this post use the “better” priors (even though there is minimal difference in the model fits relative to brms default).&lt;/p&gt;
&lt;p&gt;The above analysis, while not comprehensive, was enough to convince me that the default brms priors are not the problem with initial model fit (recall above where the mode of the posterior was not centered at the true data generating process and we wondered why). I do need to get better at doing these prior predictive simulations but it’s a deep, dark rabbit hole to go down on an already long post. Given the low model sensitivity across the range of priors I tried, I’m comfortable moving on to investigate sample size.&lt;/p&gt;
&lt;p&gt;The original model was fit from n=30. We need a simulation that lets us adjust n.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluate-sensitivity-of-posterior-to-sample-size&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluate sensitivity of posterior to sample size&lt;/h3&gt;
&lt;p&gt;Here we write a function to generate censored data of different shape, scale, and sample size. The syntax of the censoring column is brms (1 = censored).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rweibull_cens_gen_fcn &amp;lt;- function(n, shape, scale) {
  raw_times &amp;lt;- rweibull(n, shape = shape, scale = scale)
  tibble(failure_time_raw = raw_times) %&amp;gt;%
    mutate(time = case_when(
      failure_time_raw &amp;lt; 100 ~ failure_time_raw,
      TRUE ~ 100
    )) %&amp;gt;%
    mutate(censor = case_when(
      time == 100 ~ 1,
      TRUE ~ 0
    )) %&amp;gt;%
    select(-failure_time_raw)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the function above is used to create simulated data sets for different sample sizes (all have shape 3, scale = 100)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(3980)

fit_weib_45_tbl &amp;lt;- rweibull_cens_gen_fcn(45, 3, 100)
fit_weib_60_tbl &amp;lt;- rweibull_cens_gen_fcn(60, 3, 100)
fit_weib_100_tbl &amp;lt;- rweibull_cens_gen_fcn(100, 3, 100)
fit_weib_200_tbl &amp;lt;- rweibull_cens_gen_fcn(200, 3, 100)
fit_weib_300_tbl &amp;lt;- rweibull_cens_gen_fcn(300, 3, 100)
fit_weib_400_tbl &amp;lt;- rweibull_cens_gen_fcn(400, 3, 100)
fit_weib_500_tbl &amp;lt;- rweibull_cens_gen_fcn(500, 3, 100)
fit_weib_600_tbl &amp;lt;- rweibull_cens_gen_fcn(600, 3, 100)
fit_weib_700_tbl &amp;lt;- rweibull_cens_gen_fcn(700, 3, 100)
fit_weib_800_tbl &amp;lt;- rweibull_cens_gen_fcn(800, 3, 100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fit and save a model to each of the above data sets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mtf_700_weib_fit &amp;lt;- brm(time | cens(censor) ~ 1,
# data = fit_weib_700_tbl, family = weibull(),
#    prior = c(
#     prior(student_t(3, 5, 5), class = Intercept),
#     prior(uniform(0, 10), class = shape)
#    ),
#    iter = 41000, warmup = 40000, chains = 4, cores = 4,
#    seed = 4
#  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Draw from the posterior of each model and combine into one tibble along with the original fit from n=30.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtf_30_weib_fit_post_draws &amp;lt;- post_mwnp_samples # this is original data fit to milely informed priors, see Appendix
mtf_60_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_60_weib_fit)
mtf_100_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_100_weib_fit)
mtf_200_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_200_weib_fit)
mtf_300_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_300_weib_fit)
mtf_400_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_400_weib_fit)
mtf_500_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_500_weib_fit)
mtf_600_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_600_weib_fit)
mtf_700_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_700_weib_fit)
mtf_800_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_800_weib_fit)


combined_n_tbl &amp;lt;- bind_rows(
  &amp;quot;60&amp;quot;  = mtf_60_weib_fit_post_draws,
  &amp;quot;100&amp;quot; = mtf_100_weib_fit_post_draws,
  &amp;quot;200&amp;quot; = mtf_200_weib_fit_post_draws,
  &amp;quot;300&amp;quot; = mtf_300_weib_fit_post_draws,
  &amp;quot;400&amp;quot; = mtf_400_weib_fit_post_draws,
  &amp;quot;500&amp;quot; = mtf_500_weib_fit_post_draws,
  &amp;quot;600&amp;quot; = mtf_600_weib_fit_post_draws,
  &amp;quot;700&amp;quot; = mtf_700_weib_fit_post_draws,
  &amp;quot;800&amp;quot; = mtf_800_weib_fit_post_draws,
  .id = &amp;quot;model&amp;quot;
) %&amp;gt;%
  mutate(model = as_factor(model)) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale, model)

# have to add in the n=30 set seperately since it is already converted from Intercept to shape
combined_n_tbl &amp;lt;- mtf_30_weib_fit_post_draws %&amp;gt;%
  mutate(model = &amp;quot;30&amp;quot;) %&amp;gt;%
  bind_rows(combined_n_tbl) %&amp;gt;%
  mutate(model = as_factor(model))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally we can visualize the effect of sample size on precision of posterior estimates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;combined_n_plt &amp;lt;- combined_n_tbl %&amp;gt;%
  ggplot(aes(x = shape, y = scale)) +
  geom_point(aes(color = model, fill = model), size = 2, alpha = 0.01) +
  scale_color_viridis_d() +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) + # force legend icons to be alpha = 1 instead of .05
  geom_hline(yintercept = 100, colour = &amp;quot;black&amp;quot;, alpha = 0.3, size = .5) +
  geom_vline(xintercept = 3, colour = &amp;quot;black&amp;quot;, alpha = 0.3, size = .5) +
  labs(
    title = &amp;quot;Effect of Sample Size on Parameter Estimation&amp;quot;,
    subtitle = &amp;quot;Model: Weibull with Censoring; True ~ Weibull(shape = 3, scale = 100)&amp;quot;,
    x = expression(eta [&amp;quot;shape&amp;quot;]),
    y = expression(beta [&amp;quot;scale&amp;quot;])
  ) +
  theme(
    legend.position = &amp;quot;bottom&amp;quot;,
    legend.title = element_blank()
  )

cens_marg_2_plot &amp;lt;- ggMarginal(combined_n_plt,
  groupColour = TRUE,
  groupFill = TRUE,
  type = &amp;quot;density&amp;quot;,
  alpha = 0.7
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-63-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; This figure tells a lot. We simply needed more data points to zero in on the true data generating process. At n=30, there’s just a lot of uncertainty due to the randomness of sampling.&lt;/p&gt;
&lt;p&gt;This plot looks really cool, but the marginal distributions are bit cluttered. This is a perfect use case for ggridges which will let us see the same type of figure but without overlap.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cn1 &amp;lt;- combined_n_tbl %&amp;gt;%
  gather(key = &amp;quot;key&amp;quot;, value = &amp;quot;value&amp;quot;, -model) %&amp;gt;%
  mutate(true_p = case_when(
    key == &amp;quot;scale&amp;quot; ~ 100,
    TRUE ~ 3
  )) %&amp;gt;%
  ggplot(aes(x = value, y = model, group = model, fill = model)) +
  geom_density_ridges(size = 1 / 3, rel_min_height = .005, alpha = .65) +
  geom_vline(aes(xintercept = true_p), color = &amp;quot;#711a6eff&amp;quot;) +
  stat_pointintervalh(
    point_interval = mode_hdi,
    .width = .95,
    show.legend = FALSE
  ) +
  coord_flip() +
  scale_fill_viridis_d() +
  facet_wrap(~key, scales = &amp;quot;free_y&amp;quot;) +
  labs(
    x = &amp;quot;Parameter Value&amp;quot;,
    y = &amp;quot;Number of Data Points Used to Fit Model&amp;quot;,
    title = &amp;quot;Model Fitting Variability due to Random Sampling [New Draw Each Fit]&amp;quot;,
    subtitle = &amp;quot;True Distribution ~ Weibull(3, 100)&amp;quot;
  ) +
  theme(legend.position = &amp;quot;&amp;quot;)

cn1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-64-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Set of 800 to demonstrate Bayesian updating.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(125)
fit_weib_800_bu_tbl &amp;lt;- rweibull_cens_gen_fcn(800, 3, 100)

fit_weib_30_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:30, ]
fit_weib_60_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:60, ]
fit_weib_100_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:100, ]
fit_weib_200_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:200, ]
fit_weib_300_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:300, ]
fit_weib_400_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:400, ]
fit_weib_500_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:500, ]
fit_weib_600_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:600, ]
fit_weib_700_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:700, ]
fit_weib_800_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:800, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fit a model the first set of n=30&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mtf_30_bu_weib_fit &amp;lt;- brm(time | cens(censor) ~ 1,
# data = fit_weib_30_bu_tbl, family = weibull(),
#    prior = c(
#     prior(student_t(3, 5, 5), class = Intercept),
#     prior(uniform(0, 10), class = shape)
#    ),
#    iter = 41000, warmup = 40000, chains = 4, cores = 4,
#    seed = 4
#  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We use the update() function in brms to update and save each model with additional data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mtf_60_bu_weib_fit &amp;lt;- update(mtf_30_bu_weib_fit, newdata = fit_weib_60_bu_tbl)
# mtf_100_bu_weib_fit &amp;lt;- update(mtf_60_bu_weib_fit, newdata = fit_weib_100_bu_tbl)
# mtf_200_bu_weib_fit &amp;lt;- update(mtf_100_bu_weib_fit, newdata = fit_weib_200_bu_tbl)
# mtf_300_bu_weib_fit &amp;lt;- update(mtf_200_bu_weib_fit, newdata = fit_weib_300_bu_tbl)
# mtf_400_bu_weib_fit &amp;lt;- update(mtf_300_bu_weib_fit, newdata = fit_weib_400_bu_tbl)
# mtf_500_bu_weib_fit &amp;lt;- update(mtf_400_bu_weib_fit, newdata = fit_weib_500_bu_tbl)
# mtf_600_bu_weib_fit &amp;lt;- update(mtf_500_bu_weib_fit, newdata = fit_weib_600_bu_tbl)
# mtf_700_bu_weib_fit &amp;lt;- update(mtf_600_bu_weib_fit, newdata = fit_weib_700_bu_tbl)
# mtf_800_bu_weib_fit &amp;lt;- update(mtf_700_bu_weib_fit, newdata = fit_weib_800_bu_tbl)

# save each one
# saveRDS(mtf_800_bu_weib_fit, file = &amp;quot;mtf_800_bu_weib_fit.rds&amp;quot;)

mtf_800_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_800_bu_weib_fit.rds&amp;quot;)
mtf_700_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_700_bu_weib_fit.rds&amp;quot;)
mtf_600_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_600_bu_weib_fit.rds&amp;quot;)
mtf_500_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_500_bu_weib_fit.rds&amp;quot;)
mtf_400_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_400_bu_weib_fit.rds&amp;quot;)
mtf_300_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_300_bu_weib_fit.rds&amp;quot;)
mtf_200_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_200_bu_weib_fit.rds&amp;quot;)
mtf_100_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_100_bu_weib_fit.rds&amp;quot;)
mtf_60_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_60_bu_weib_fit.rds&amp;quot;)
mtf_30_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_30_bu_weib_fit.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Extract posterior draws for each one.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtf_30_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_30_bu_weib_fit)
mtf_60_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_60_bu_weib_fit)
mtf_100_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_100_bu_weib_fit)
mtf_200_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_200_bu_weib_fit)
mtf_300_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_300_bu_weib_fit)
mtf_400_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_400_bu_weib_fit)
mtf_500_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_500_bu_weib_fit)
mtf_600_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_600_bu_weib_fit)
mtf_700_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_700_bu_weib_fit)
mtf_800_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_800_bu_weib_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Combine into single tibble and convert intercept to scale. Some data wrangling is in anticipation for ggplot().&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;combined_nbu_tbl &amp;lt;- bind_rows(
  &amp;quot;30&amp;quot;  = mtf_30_bu_weib_fit_post_draws, # note: this one is the original dataset
  &amp;quot;60&amp;quot;  = mtf_60_bu_weib_fit_post_draws,
  &amp;quot;100&amp;quot; = mtf_100_bu_weib_fit_post_draws,
  &amp;quot;200&amp;quot; = mtf_200_bu_weib_fit_post_draws,
  &amp;quot;300&amp;quot; = mtf_300_bu_weib_fit_post_draws,
  &amp;quot;400&amp;quot; = mtf_400_bu_weib_fit_post_draws,
  &amp;quot;500&amp;quot; = mtf_500_bu_weib_fit_post_draws,
  &amp;quot;600&amp;quot; = mtf_600_bu_weib_fit_post_draws,
  &amp;quot;700&amp;quot; = mtf_700_bu_weib_fit_post_draws,
  &amp;quot;800&amp;quot; = mtf_800_bu_weib_fit_post_draws,
  .id = &amp;quot;model&amp;quot;
) %&amp;gt;%
  mutate(model = as_factor(model)) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale, model)

cn2 &amp;lt;- combined_nbu_tbl %&amp;gt;%
  gather(key = &amp;quot;key&amp;quot;, value = &amp;quot;value&amp;quot;, -model) %&amp;gt;%
  mutate(true_p = case_when(
    key == &amp;quot;scale&amp;quot; ~ 100,
    TRUE ~ 3
  )) %&amp;gt;%
  ggplot(aes(x = value, y = model, group = model, fill = model)) +
  geom_density_ridges(size = 1 / 3, rel_min_height = .005, alpha = .65) +
  geom_vline(aes(xintercept = true_p), color = &amp;quot;#711a6eff&amp;quot;) +
  stat_pointintervalh(
    point_interval = mode_hdi,
    .width = .95,
    show.legend = FALSE
  ) +
  coord_flip() +
  scale_fill_viridis_d() +
  facet_wrap(~key, scales = &amp;quot;free_y&amp;quot;) +
  labs(
    x = &amp;quot;Parameter Value&amp;quot;,
    y = &amp;quot;Number of Data Points Used to Fit Model&amp;quot;,
    title = &amp;quot;Model Fitting Variability due to Random Sampling [Updated Model Each Fit]&amp;quot;,
    subtitle = &amp;quot;True Distribution ~ Weibull(3, 100)&amp;quot;
  ) +
  theme(legend.position = &amp;quot;&amp;quot;)

cn1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-70-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#cn2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-71-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The precision increase here is more smooth since supplemental data is added to the original set instead of just drawing completely randomly for each sample size. This is Bayesian updating.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluate-sensitivity-of-reliability-estimate-to-sample-size.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluate Sensitivity of Reliability Estimate to Sample Size.&lt;/h3&gt;
&lt;p&gt;To wrap things up, we should should translate the above figures into a reliability metric because that is the prediction we care about at the end of the day. I chose an arbitrary time point of t=40 to evaluate the reliability.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;combined_nbu_rr_tbl &amp;lt;- combined_nbu_tbl %&amp;gt;% mutate(reliability_at_t40 = exp(-(40 / scale)**(shape)))

rq05_tbl &amp;lt;- combined_nbu_rr_tbl %&amp;gt;% group_by(model) %&amp;gt;%
  summarize(rel_q05 = quantile(reliability_at_t40, .05)) %&amp;gt;%
  mutate(model = as.numeric(model)) %&amp;gt;%
  ungroup()

reliability_ridge_plt &amp;lt;- combined_nbu_rr_tbl %&amp;gt;%
  gather(key = &amp;quot;key&amp;quot;, value = &amp;quot;value&amp;quot;, -c(model, reliability_at_t40)) %&amp;gt;%
  ggplot(aes(x = reliability_at_t40, y = model, group = model, fill = model)) +
  geom_density_ridges(size = 1 / 3, rel_min_height = .005, alpha = .8) +
  stat_pointintervalh(
    point_interval = mode_hdi,
    .width = .95,
    show.legend = FALSE
  ) +
  coord_flip() +
  scale_fill_viridis_d() +
  labs(
    x = &amp;quot;Reliability at t=40&amp;quot;,
    y = &amp;quot;Number of Data Points Used to Fit Model&amp;quot;,
    title = &amp;quot;Uncertainty in Reliability Posterior&amp;quot;,
    subtitle = &amp;quot;Reliability Assessed at t = 40&amp;quot;
  ) +
  theme(legend.position = &amp;quot;&amp;quot;) +
  xlim(c(.85, 1))



reliability_ridge_plt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-72-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;wrap-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Wrap-up&lt;/h2&gt;
&lt;p&gt;Here is a summary of where we ended up going in the post:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Fit some models using fitdistr plus using data that was not censored. Calculated reliability at time of interest.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Fit the same models using a Bayesian approach with grid approximation. Visualized what happens if we incorrectly omit the censored data or treat it as if it failed at the last observed time point.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Explored fitting censored data using the survival package. Evaluated sensitivity to sample size.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Used brms to fit Bayesian models with censored data. Assessed sensitivity of priors and tried to improve our priors over the default. Evaluated effect of sample size and explored the different between updating an existing data set vs. drawing new samples.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you made it this far - I appreciate your patience with this long and rambling post. Thank you for reading!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix---prior-predictive-simulation---beware-its-ugly-in-here&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;APPENDIX - Prior Predictive Simulation - BEWARE it’s ugly in here&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# evaluate default priors
default_shape_prior &amp;lt;- rgamma(10000, .01, .01)
default_shape_prior_tbl &amp;lt;- default_shape_prior %&amp;gt;% as_tibble()
default_shape_prior_tbl %&amp;gt;% ggplot(aes(x = default_shape_prior)) +
  geom_histogram(aes(y = ..density..), binwidth = 3, boundary = 0, fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6) + geom_density(color = &amp;quot;#cf4c74ff&amp;quot;) +
  labs(title = &amp;quot;Default Prior for Shape Parameter&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-73-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#   ylim(c(0, 1e-3))

default_intercept_prior &amp;lt;- rstudent_t(10000, 3, 4, 10)

default_priors_tbl &amp;lt;- default_intercept_prior %&amp;gt;%
  as_tibble() %&amp;gt;%
  bind_cols(default_shape_prior_tbl) %&amp;gt;%
  rename(intercept = value, shape = value1) %&amp;gt;%
  mutate(scale_prior = exp(intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  filter(scale_prior &amp;lt; 1000) %&amp;gt;%
  select(-intercept)

default_priors_tbl %&amp;gt;% ggplot(aes(x = scale_prior)) +
  geom_histogram(aes(y = ..density..), binwidth = 5, boundary = 100, fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .8) +
  geom_density(color = &amp;quot;#cf4c74ff&amp;quot;) +
  labs(title = &amp;quot;Default Prior for Scale Parameter&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-73-2.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#  ylim(c(0, .001))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Prior Predictive Simulation - Default Priors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d1 &amp;lt;- default_priors_tbl[1:350, ] %&amp;gt;%
  mutate(plotted_y_data = map2(
    shape, scale_prior,
    ~ tibble(
      x = seq(0, 200, length.out = 400),
      y = dweibull(x, .x, .y)
    )
  )) %&amp;gt;%
  unnest(plotted_y_data) %&amp;gt;%
  ggplot(aes(x, y)) +
  geom_line(aes(group = shape), alpha = .2) +
  labs(
    x = &amp;quot;Time to Event&amp;quot;,
    y = &amp;quot;Density&amp;quot;
  )

d2 &amp;lt;- d1 +
  xlim(c(0, 25)) +
  ylim(c(0, .1))

d1 + d2 + plot_layout(
  nrow = 1,
  guides = &amp;quot;collect&amp;quot;
) +
  plot_annotation(title = &amp;quot;Implied Time-to-Failure Weibull Distributions (from default priors)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-74-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; Here are the reliabilities at t=15 implied by the default priors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r15_pp_default_tbl &amp;lt;- default_priors_tbl %&amp;gt;% mutate(reliability_at_t15 = exp(-(15 / scale_prior)**(shape)))

r1 &amp;lt;- r15_pp_default_tbl %&amp;gt;% ggplot(aes(x = reliability_at_t15)) +
  geom_histogram(aes(y = ..density..), binwidth = .01, boundary = 1, fill = &amp;quot;#de6065ff&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6) +
  labs(title = &amp;quot;Reliability at t=15 implied by default priors&amp;quot;)

def_plt &amp;lt;- (d1 + d2) / r1 + plot_layout(guides = &amp;quot;collect&amp;quot;) +
  plot_annotation(title = &amp;quot;Implied Time-to-Failure Weibull Distributions (from default priors)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not too useful. In the following section I try to tweak the priors such that the simulations indicate some spread of reliability from 0 to 1 before seeing the data. Again, it’s tough because we have to work through the Intercept and the annoying gamma function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Evaluate Mildly Informed Priors
shape_prior &amp;lt;- runif(100000, 0, 10)
shape_prior_tbl &amp;lt;- shape_prior %&amp;gt;% as_tibble()
shaaaape &amp;lt;- shape_prior_tbl %&amp;gt;% ggplot(aes(x = shape_prior)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, boundary = 10, fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6)

intercept_prior &amp;lt;- rstudent_t(100000, 3, 5, 5)

priors_tbl &amp;lt;- intercept_prior %&amp;gt;%
  as_tibble() %&amp;gt;%
  bind_cols(shape_prior_tbl) %&amp;gt;%
  rename(intercept = value, shape = value1) %&amp;gt;%
  mutate(scale_prior = exp(intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  filter(scale_prior &amp;lt; 1000) %&amp;gt;%
  select(-intercept)

scaaaale &amp;lt;- priors_tbl %&amp;gt;% ggplot(aes(x = scale_prior)) +
  geom_histogram(aes(y = ..density..), binwidth = 10, boundary = 100, fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .8) +
  ylim(c(0, .005))

shaaaape + scaaaale + plot_annotation(title = &amp;quot;Prior Predicitve Simulations for Shape and Scale&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-76-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; Implied time-to-event curves:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- priors_tbl[1:500, ] %&amp;gt;%
  mutate(plotted_y_data = map2(
    shape, scale_prior,
    ~ tibble(
      x = seq(0, 200, length.out = 400),
      y = dweibull(x, .x, .y)
    )
  )) %&amp;gt;%
  unnest(plotted_y_data) %&amp;gt;%
  ggplot(aes(x, y)) +
  geom_line(aes(group = shape), alpha = .2) +
  xlim(c(0, 50)) +
  ylim(c(0, .5)) +
  labs(
    x = &amp;quot;Time to Event&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    title = &amp;quot;Implied Time-to-Event Curves from Iterated Priors&amp;quot;
  )

p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-77-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; And the implied prior predictive reliability at t=15:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r15_pp_mi_tbl &amp;lt;- priors_tbl %&amp;gt;% mutate(reliability_at_t15 = exp(-(15 / scale_prior)**(shape)))

pz &amp;lt;- r15_pp_mi_tbl %&amp;gt;% ggplot(aes(x = reliability_at_t15)) +
  geom_histogram(aes(y = ..density..), binwidth = .1, boundary = 1, fill = &amp;quot;#7b0288ff&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6) +
  labs(
    title = &amp;quot;Prior Predictive Estimate at t=15&amp;quot;,
    subtitle = &amp;quot;Iterated Priors&amp;quot;
  )

p1 + pz&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-78-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; This still isn’t great - now I’ve stacked most of the weight at 0 and 1 always fail or never fail. This is hard and I do know I need to get better at it. But since I’m already down a rabbit hole let’s just check to see how the different priors impact the estimates.&lt;/p&gt;
&lt;p&gt;Fit the model with iterated priors: student_t(3, 5, 5) for Intercept and uniform(0, 10) for shape.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit model with better priors (original n=30 data point)
# mtf_weib_new_priors_fit &amp;lt;-
#  brm(
#    data = months_to_failure_tbl_4.3.3, family = weibull(),
#    time | cens(censored) ~ 1,
#    prior = c(
#      prior(student_t(3, 5, 5), class = Intercept),
#     prior(uniform(0, 10), class = shape)
#    ),
#    iter = 41000, warmup = 40000, chains = 4, cores = 4,
#   seed = 4
#  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Evaluate chains and convert to shape and scale&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(mtf_weib_new_priors_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-81-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post_mwnp_samples &amp;lt;- posterior_samples(mtf_weib_new_priors_fit) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale)

post_mwnp_samples %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2), digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.66&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;98.52&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.66&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;98.52&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;98.48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;95.86&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.02&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;92.85&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.05&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;90.54&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;97.18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.50&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;97.05&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.48&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;92.92&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;87.81&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Evaluate the effect of the different priors (default vs. iterated) on the model fit for original n=30 censored data points.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseline_30_default_prior_tbl &amp;lt;- post_mtf_weib_samples %&amp;gt;% mutate(priors = &amp;quot;shape: gamma(.01, .01) \nIntercept: student_t(3, 4, 10)&amp;quot;)

baseline_30_mi_prior_tbl &amp;lt;- post_mwnp_samples %&amp;gt;% mutate(priors = &amp;quot;shape: uniform(0, 10) \nIntercept: student_t(3, 5, 5)&amp;quot;)

baseline_30_prior_compare_tbl &amp;lt;- bind_rows(
  baseline_30_default_prior_tbl,
  baseline_30_mi_prior_tbl
)

b_30_prior_plt &amp;lt;- baseline_30_prior_compare_tbl %&amp;gt;% ggplot(aes(x = shape, y = scale)) +
  geom_point(aes(color = priors), alpha = .1) +
  geom_hline(aes(yintercept = 100), size = .5, alpha = .3) +
  geom_vline(aes(xintercept = 3), size = .5, alpha = .3) +
  scale_color_viridis_d() +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) + # force legend icons to be alpha = 1 instead of .05
  labs(
    title = &amp;quot;Credible Parameters for Shape and Scale; Effect of Priors&amp;quot;,
    subtitle = &amp;quot;Model: Weibull with Censoring; True ~ Weibull(shape = 3, scale = 100)&amp;quot;,
    x = expression(eta [&amp;quot;shape&amp;quot;]),
    y = expression(beta [&amp;quot;scale&amp;quot;])
  ) +
  theme(legend.position = &amp;quot;bottom&amp;quot;)


b_30_prior_marg_plot &amp;lt;- ggMarginal(b_30_prior_plt,
  groupColour = TRUE,
  groupFill = TRUE,
  type = &amp;quot;density&amp;quot;,
  alpha = 0.5
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-84-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;At the end of the day, both the default and the iterated priors result in similar model fits and parameter estimates after seeing just n=30 data points. This is sort of cheating but I’m still new to this so I’m cutting myself some slack.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Stent fatigue testing &lt;a href=&#34;https://www.youtube.com/watch?v=YhUluh5V8uM&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=YhUluh5V8uM&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Data taken from &lt;strong&gt;Practical Applications of Bayesian Reliability&lt;/strong&gt; by Abeyratne and Liu, 2019&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Note: the reliability function is sometimes called the survival function in reference to patient outcomes and survival analysis&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;grid_function borrowed from Kurz, &lt;a href=&#34;https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/&#34; class=&#34;uri&#34;&gt;https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/&lt;/a&gt;&lt;a href=&#34;#fnref4&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Survival package documentation, &lt;a href=&#34;https://stat.ethz.ch/R-manual/R-devel/library/survival/html/survreg.html&#34; class=&#34;uri&#34;&gt;https://stat.ethz.ch/R-manual/R-devel/library/survival/html/survreg.html&lt;/a&gt;&lt;a href=&#34;#fnref5&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;We would want to de-risk this appoach by makng sure we have a bit of historical data on file indicating our device fails at times that follow a Weibull(3, 100) or similar&lt;a href=&#34;#fnref6&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;See the “Survival Model” section of this document: &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_families.html#survival-models&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/brms/vignettes/brms_families.html#survival-models&lt;/a&gt;&lt;a href=&#34;#fnref7&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;Thread about vague gamma priors &lt;a href=&#34;https://math.stackexchange.com/questions/449234/vague-gamma-prior&#34; class=&#34;uri&#34;&gt;https://math.stackexchange.com/questions/449234/vague-gamma-prior&lt;/a&gt;&lt;a href=&#34;#fnref8&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title> Creating and Using a Simple, Bayesian Linear Model (in brms and R)</title>
      <link>/post/creating-and-using-a-simple-bayesian-linear-model-in-brms-and-r/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/creating-and-using-a-simple-bayesian-linear-model-in-brms-and-r/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/viz/viz.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/DiagrammeR-styles/styles.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/grViz-binding/grViz.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This post is my good-faith effort to create a simple linear model using the Bayesian framework and workflow described by Richard McElreath in his Statistical Rethinking book.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; As always - please view this post through the lens of the eager student and not the learned master. I did my best to check my work, but it’s entirely possible that something was missed. Please let me know - I won’t take it personally. As McElreath notes in his lectures - “if you’re confused, it’s because you’re paying attention”. And sometimes I get confused - this a lot harder than my old workflow which consisted of clicking “add a trendline” in Excel. Thinking Bayesian is still relatively new to me. Disclaimer over - let’s get to it.&lt;/p&gt;
&lt;p&gt;I’m playing around with a bunch of fun libraries in this one.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(styler)
library(ggExtra)
library(knitr)
library(brms)
library(cowplot)
library(gridExtra)
library(skimr)
library(DiagrammeR)
library(rayshader)
library(av)
library(rgl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I made up this data set. It represents hypothetical values of ablation time and tissue impedance as measured by sensors embedded in a RF ablation catheter. This type of device is designed to apply RF or thermal energy to the vessel wall. The result is a lesion that can aid in improve arrhythmia, reduce hypertension, or provide some other desired outcome.&lt;/p&gt;
&lt;p&gt;In RF ablations, the tissue heats up over the course of the RF cycle, resulting in a drop in impedance that varies over time. As described above, the goal will be to see how much of the variation in impedance is described by time (over some limited range) and then communicate the uncertainty in the predictions visually. None of this detail is terribly important other than I like to frame my examples from within my industry and McElreath emphasizes grounding our modeling in real world science and domain knowledge. This is what an ablation catheter system looks like:&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/rf_cath.jpg&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To get things started, load the data and give it a look with skim(). There are no missing values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ablation_dta_tbl &amp;lt;- read.csv(file = &amp;quot;abl_data_2.csv&amp;quot;)
ablation_dta_tbl &amp;lt;- ablation_dta_tbl %&amp;gt;% select(temp, time)
ablation_dta_tbl %&amp;gt;% skim()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Skim summary statistics
##  n obs: 331 
##  n variables: 2 
## 
## -- Variable type:numeric ------------------------------------------------------------------------------------------------------------
##  variable missing complete   n  mean   sd    p0   p25   p50   p75  p100
##      temp       0      331 331 77.37 3.9  68.26 74.61 77.15 80.33 89.53
##      time       0      331 331 22.57 3.22 15.83 20.22 22.54 24.69 31.5 
##      hist
##  &amp;lt;U+2581&amp;gt;&amp;lt;U+2585&amp;gt;&amp;lt;U+2587&amp;gt;&amp;lt;U+2586&amp;gt;&amp;lt;U+2586&amp;gt;&amp;lt;U+2583&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;
##  &amp;lt;U+2582&amp;gt;&amp;lt;U+2586&amp;gt;&amp;lt;U+2587&amp;gt;&amp;lt;U+2587&amp;gt;&amp;lt;U+2587&amp;gt;&amp;lt;U+2583&amp;gt;&amp;lt;U+2582&amp;gt;&amp;lt;U+2581&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s start with a simple visualization. The code below builds out a scatterplot with marginal histograms which I think is a nice, clean way to evaluate scatter data.&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; These data seem plausible since the impedance will typically drop as the tissue heats up during the procedure. In reality the impedance goes asymptotic but we’ll work over a limited range of time where the behavior might reasonably be linear.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scatter_1_fig &amp;lt;- ablation_dta_tbl %&amp;gt;% ggplot(aes(x = time, y = temp)) +
  geom_point(
    colour = &amp;quot;#2c3e50&amp;quot;,
    fill = &amp;quot;#2c3e50&amp;quot;,
    size = 2,
    alpha = 0.4
  ) +
  labs(
    x = &amp;quot;Ablation Time (seconds)&amp;quot;,
    y = &amp;quot;Tissue Temperature (deg C)&amp;quot;,
    title = &amp;quot;Ablation Time vs. Tissue Temperature&amp;quot;,
    subtitle = &amp;quot;Simulated Catheter RF Ablation&amp;quot;
  )

scatter_hist_1_fig &amp;lt;- ggMarginal(scatter_1_fig,
  type = &amp;quot;histogram&amp;quot;,
  color = &amp;quot;white&amp;quot;,
  alpha = 0.7,
  fill = &amp;quot;#2c3e50&amp;quot;,
  xparams = list(binwidth = 1),
  yparams = list(binwidth = 2.5)
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# ggExtra needs these explit calls to display in Markdown docs *shrug*
grid::grid.newpage()
grid::grid.draw(scatter_hist_1_fig)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-01-creating-and-using-a-simple-bayesian-linear-model-in-brms-and-r_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It helps to have a plan. If I can create a posterior distribution that captures reasonable values for the model parameters and confirm that the model makes reasonable predictions then I will be happy. Here’s the workflow that hopefully will get me there.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grViz(&amp;quot;digraph flowchart {
      # node definitions with substituted label text
      node [fontname = Helvetica, shape = rectangle, fillcolor = yellow]        
      tab1 [label = &amp;#39;Step 1: Propose a distribution for the response variable \n Choose a maximum entropy distribution given the constraints you understand&amp;#39;]
      tab2 [label = &amp;#39;Step 2: Parameterize the mean \n The mean of the response distribution will vary linearly across the range of predictor values&amp;#39;]
      tab3 [label = &amp;#39;Step 3: Set priors \n Simulate what the model knows before seeing the data.  Use domain knowledge as constraints.&amp;#39;]
      tab4 [label = &amp;#39;Step 4: Define the model \n Create the model using the observed data, the likelihood function, and the priors&amp;#39;]
      tab5 [label = &amp;#39;Step 5: Draw from the posterior \n Plot plausible lines using parameters visited by the Markov chains&amp;#39;]
      tab6 [label = &amp;#39;Step 6: Push the parameters back through the model \n Simulate real data from plausible combinations of mean and sigma&amp;#39;]
      # edge definitions with the node IDs
      tab1 -&amp;gt; tab2 -&amp;gt; tab3 -&amp;gt; tab4 -&amp;gt; tab5 -&amp;gt; tab6;
      }
      &amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:500px;&#34; class=&#34;grViz html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;diagram&#34;:&#34;digraph flowchart {\n      # node definitions with substituted label text\n      node [fontname = Helvetica, shape = rectangle, fillcolor = yellow]        \n      tab1 [label = \&#34;Step 1: Propose a distribution for the response variable \n Choose a maximum entropy distribution given the constraints you understand\&#34;]\n      tab2 [label = \&#34;Step 2: Parameterize the mean \n The mean of the response distribution will vary linearly across the range of predictor values\&#34;]\n      tab3 [label = \&#34;Step 3: Set priors \n Simulate what the model knows before seeing the data.  Use domain knowledge as constraints.\&#34;]\n      tab4 [label = \&#34;Step 4: Define the model \n Create the model using the observed data, the likelihood function, and the priors\&#34;]\n      tab5 [label = \&#34;Step 5: Draw from the posterior \n Plot plausible lines using parameters visited by the Markov chains\&#34;]\n      tab6 [label = \&#34;Step 6: Push the parameters back through the model \n Simulate real data from plausible combinations of mean and sigma\&#34;]\n      # edge definitions with the node IDs\n      tab1 -&gt; tab2 -&gt; tab3 -&gt; tab4 -&gt; tab5 -&gt; tab6;\n      }\n      &#34;,&#34;config&#34;:{&#34;engine&#34;:&#34;dot&#34;,&#34;options&#34;:null}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;div id=&#34;step-1-propose-a-distribution-for-the-response-variable&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Step 1: Propose a distribution for the response variable&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;A Gaussian model is reasonable for the outcome variable Temperature as we know it is a measured from the thermocouples on the distal end of the catheter. According to McElreath (pg 75):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Measurement errors, variations in growth, and the velocities of molecules all tend towards Gaussian distributions. These processes do this because at their heart, these processes add together fluctuations. And repeatedly adding finite fluctuations results in a distribution of sums that have shed all information about the underlying process, aside from mean and spread.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here’s us formally asserting Temperature as a normal distribution with mean mu and standard deviation sigma. These two parameters are all that is needed to completely describe the distribution and also pin down the likelihood function.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(T_i \sim \text{Normal}(\mu_i, \sigma)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-parameterize-the-mean&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Step 2: Parameterize the mean&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;If we further parameterize the mean we can do some neat things like move it around with the predictor variable. This is a pretty key concept - &lt;em&gt;you move the mean of the outcome variable around by parameterizing it. If we make it a line then it will move linearly with the predictor variable.&lt;/em&gt; The real data will still have a spread once the sigma term is folded back in, but we can think of the whole distribution shifting up and down based on the properties of the line.&lt;/p&gt;
&lt;p&gt;Here’s us asserting we want mu to move linearly with changes in the predictor variable (time). Subtracting the mean from each value of the predictor variable “centers” the data which McElreath recommends in most cases. I will explore the differences between centered and un-centered later on.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_i = \alpha + \beta (x_i - \bar{x})\)&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-set-priors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Step 3: Set priors&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;We know some things about these data and we should use it to help regularize to model through the priors.&lt;/p&gt;
&lt;p&gt;Temperature is a continuous variable so we want a continuous distribution. We also know from the nature of the treatment that there isn’t really any physical mechanism within the device that would be expected to cool down the tissue below normal body temperature. Since only heating is expected, the slope should be positive or zero.&lt;/p&gt;
&lt;p&gt;McElreath emphasizes simulating from the priors to visualize “what the model knows before it sees the data”. Here are some priors to consider. Let’s evaluate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Set seed for repeatability
set.seed(1999)

# number of sims
n &amp;lt;- 150

# random draws from the specified prior distributions
# lognormal distribution is used to constrain slopes to positive values
a &amp;lt;- rnorm(n, 75, 15)

b &amp;lt;- rnorm(n, 0, 1)
b_ &amp;lt;- rlnorm(n, 0, 0.8)

# calc mean of time and temp for later use
mean_temp &amp;lt;- mean(ablation_dta_tbl$temp)
mean_time &amp;lt;- mean(ablation_dta_tbl$time)

# dummy tibble to feed ggplot()
empty_tbl &amp;lt;- tibble(x = 0)

# y = b(x - mean(var_1)) + a is equivalent to:
# y = bx + (a - b * mean(var_1))

# in this fig we use the uninformed prior that generates some unrealistic values
prior_fig_1 &amp;lt;- empty_tbl %&amp;gt;% ggplot() +
  geom_abline(
    intercept = a - b * mean_time,
    slope = b,
    color = &amp;quot;#2c3e50&amp;quot;,
    alpha = 0.3,
    size = 1
  ) +
  ylim(c(0, 150)) +
  xlim(c(0, 150)) +
  labs(
    x = &amp;quot;time (sec)&amp;quot;,
    y = &amp;quot;Temp (C)&amp;quot;,
    title = &amp;quot;Prior Predictive Simulations&amp;quot;,
    subtitle = &amp;quot;Uninformed Prior&amp;quot;
  )

# in this fig we confine the slopes to broad ranges informed by what we know about the domain
prior_fig_2 &amp;lt;- empty_tbl %&amp;gt;% ggplot() +
  geom_abline(
    intercept = a - b_ * mean_time,
    slope = b_,
    color = &amp;quot;#2c3e50&amp;quot;,
    alpha = 0.3,
    size = 1
  ) +
  ylim(c(0, 150)) +
  xlim(c(0, 150)) +
  labs(
    x = &amp;quot;time (sec)&amp;quot;,
    y = &amp;quot;Temp (C)&amp;quot;,
    title = &amp;quot;Prior Predictive Simulations&amp;quot;,
    subtitle = &amp;quot;Mildly Informed Prior&amp;quot;
  )

plot_grid(prior_fig_1, prior_fig_2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-01-creating-and-using-a-simple-bayesian-linear-model-in-brms-and-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The plots above show what the model thinks before seeing the data for two different sets of priors. In both cases, I have centered the data by subtracting the mean of the time from each individual value of time. This means the intercept has the meaning of the expected temperature at the mean of time. The family of lines on the right seem a lot more realistic despite having some slopes that predict strange values out of sample (blood coagulates at ~90C). Choosing a log normal distribution for time ensures positives slopes. You could probably go even tighter on these priors but for this exercise I’m feeling good about proceeding.&lt;/p&gt;
&lt;p&gt;Looking only at the time window of the original observations and the Temp window bounded by body temperature (lower bound) and water boiling (upper bound).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;empty_tbl %&amp;gt;% ggplot() +
  geom_abline(
    intercept = a - b_ * mean_time,
    slope = b_,
    color = &amp;quot;#2c3e50&amp;quot;,
    alpha = 0.3,
    size = 1
  ) +
  ylim(c(37, 100)) +
  xlim(c(15, 40)) +
  labs(
    x = &amp;quot;time (sec)&amp;quot;,
    y = &amp;quot;Temp (C)&amp;quot;,
    title = &amp;quot;Prior Predictive Simulations&amp;quot;,
    subtitle = &amp;quot;Mildly Informed Prior, Original Data Range&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-01-creating-and-using-a-simple-bayesian-linear-model-in-brms-and-r_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here are the prior distributions selected to go forward.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha \sim \text{Normal}(75, 15)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta \sim \text{LogNormal}(0, .8)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Uniform}(0, 30)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4-define-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Step 4: Define the model&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Here I use the brm() function in brms to build what I’m creatively calling: “model_1”. This one uses the un-centered data for time. This function uses Markov Chain Monte Carlo to survey the parameter space. After the warm up cycles, the relative amount of time the chains spend at each parameter value is a good approximation of the true posterior distribution. I’m using a lot of warm up cycles because I’ve heard chains for the uniform priors on sigma can take a long time to converge. This model still takes a bit of time to chug through the parameter space on my modest laptop.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#model_1 &amp;lt;-
#  brm(
#    data = ablation_dta_tbl, family = gaussian,
#    temp ~ 1 + time,
#    prior = c(
#      prior(normal(75, 15), class = Intercept),
#      prior(lognormal(0, .8), class = b),
#      prior(uniform(0, 30), class = sigma)
#    ),
#    iter = 41000, warmup = 40000, chains = 4, cores = 4,
#    seed = 4
#  )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-5-draw-from-the-posterior&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Step 5: Draw from the posterior&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The fruits of all my labor! The posterior holds credible combinations for sigma and the slope and intercept (which together describe the mean of the outcome variable we care about). Let’s take a look.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post_samplesM1_tbl &amp;lt;-
  posterior_samples(model_1) %&amp;gt;%
  select(-lp__) %&amp;gt;%
  round(digits = 3)

post_samplesM1_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;b_Intercept&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;b_time&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sigma&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;58.509&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.841&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.682&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;55.983&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.949&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.648&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;56.195&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.937&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.540&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;56.661&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.919&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.474&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;55.143&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.978&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.593&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;55.170&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.977&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.667&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;54.908&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.996&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.621&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;58.453&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.836&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.534&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;54.134&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.031&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.647&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;58.713&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.828&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.707&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The plotting function in brms is pretty sweet. I’m not expert in MCMC diagnostics but I do know the “fuzzy caterpillar” look of the trace plots is desirable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model_1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-01-creating-and-using-a-simple-bayesian-linear-model-in-brms-and-r_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Posterior_summary() can grab the model results in table form.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod_1_summary_tbl &amp;lt;-
  posterior_summary(model_1) %&amp;gt;%
  as.data.frame() %&amp;gt;%
  rownames_to_column() %&amp;gt;%
  as_tibble() %&amp;gt;%
  mutate_if(is.numeric, funs(as.character(signif(., 2)))) %&amp;gt;%
  mutate_at(.vars = c(2:5), funs(as.numeric(.)))

mod_1_summary_tbl %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 5))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;rowname&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Est.Error&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Q2.5&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Q97.5&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;b_Intercept&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;57.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;55.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;59.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;b_time&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.91&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.045&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.83&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;sigma&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.60&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.100&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.40&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;lp__&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-790.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.300&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-790.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-790.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now let’s see what changes if the time data is centered. Everything is the same here in model_2 except the time_c data which is transformed by subtracting the mean from each value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ablation_dta_tbl &amp;lt;- ablation_dta_tbl %&amp;gt;% mutate(time_c = time - mean(time))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#model_2 &amp;lt;-
#  brm(
#    data = ablation_dta_tbl, family = gaussian,
#    temp ~ 1 + time_c,
#    prior = c(
#      prior(normal(75, 15), class = Intercept),
#      prior(lognormal(0, .8), class = b),
#      prior(uniform(0, 30), class = sigma)
#    ),
#    iter = 41000, warmup = 40000, chains = 4, cores = 4,
#    seed = 4
#  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Plotting model_2 to compare with the output of model_1 above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_mod_2_fig &amp;lt;- plot(model_2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-01-creating-and-using-a-simple-bayesian-linear-model-in-brms-and-r_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The slope B and sigma are very similar. The intercept is the only difference with model_1 ranging from low to high 50’s. Model 2 is tight around 77. We should visualize the lines proposed by the parameters in the posteriors of our models to understand the uncertainty associated with the mean and also understand why the intercepts are different between models. First, store the posterior samples as a tibble in anticipation for ggplot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post_samplesM2_tbl &amp;lt;-
  posterior_samples(model_2) %&amp;gt;%
  select(-lp__) %&amp;gt;%
  round(digits = 3)

post_samplesM2_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;b_Intercept&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;b_time_c&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sigma&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;77.323&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.894&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.350&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;77.430&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.881&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.516&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;77.335&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.957&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.571&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;77.011&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.947&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.776&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;77.209&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.013&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.691&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;77.517&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.820&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.488&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;77.335&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.881&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.682&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;77.313&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.857&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.538&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;77.423&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.873&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.569&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;77.302&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.926&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.340&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Visualize the original data (centered and un-centered versions) along with plausible values for regression line of the mean:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean_regressionM1_fig &amp;lt;-
  ablation_dta_tbl %&amp;gt;%
  ggplot(aes(x = time, y = temp)) +
  geom_point(
    colour = &amp;quot;#481567FF&amp;quot;,
    size = 2,
    alpha = 0.6
  ) +
  geom_abline(aes(intercept = b_Intercept, slope = b_time),
    data = post_samplesM1_tbl,
    alpha = 0.1, color = &amp;quot;gray50&amp;quot;
  ) +
  geom_abline(
    slope = mean(post_samplesM1_tbl$b_time),
    intercept = mean(post_samplesM1_tbl$b_Intercept),
    color = &amp;quot;blue&amp;quot;, size = 1
  ) +
  labs(
    title = &amp;quot;Regression Line Representing Mean of Slope&amp;quot;,
    subtitle = &amp;quot;Data is As-Observed (No Centering of Predictor)&amp;quot;,
    x = &amp;quot;Time (s)&amp;quot;,
    y = &amp;quot;Temperature (C)&amp;quot;
  )

mean_regressionM2_fig &amp;lt;-
  ablation_dta_tbl %&amp;gt;%
  ggplot(aes(x = time_c, y = temp)) +
  geom_point(
    color = &amp;quot;#55C667FF&amp;quot;,
    size = 2,
    alpha = 0.6
  ) +
  geom_abline(aes(intercept = b_Intercept, slope = b_time_c),
    data = post_samplesM2_tbl,
    alpha = 0.1, color = &amp;quot;gray50&amp;quot;
  ) +
  geom_abline(
    slope = mean(post_samplesM2_tbl$b_time_c),
    intercept = mean(post_samplesM2_tbl$b_Intercept),
    color = &amp;quot;blue&amp;quot;, size = 1
  ) +
  labs(
    title = &amp;quot;Regression Line Representing Mean of Slope&amp;quot;,
    subtitle = &amp;quot;Predictor Data (Time) is Centered&amp;quot;,
    x = &amp;quot;Time (Difference from Mean Time in seconds)&amp;quot;,
    y = &amp;quot;Temperature (C)&amp;quot;
  )


combined_mean_fig &amp;lt;-
  ablation_dta_tbl %&amp;gt;%
  ggplot(aes(x = time, y = temp)) +
  geom_point(
    colour = &amp;quot;#481567FF&amp;quot;,
    size = 2,
    alpha = 0.6
  ) +
  geom_point(
    data = ablation_dta_tbl, aes(x = time_c, y = temp),
    colour = &amp;quot;#55C667FF&amp;quot;,
    size = 2,
    alpha = 0.6
  ) +
  geom_abline(aes(intercept = b_Intercept, slope = b_time),
    data = post_samplesM1_tbl,
    alpha = 0.1, color = &amp;quot;gray50&amp;quot;
  ) +
  geom_abline(
    slope = mean(post_samplesM1_tbl$b_time),
    intercept = mean(post_samplesM1_tbl$b_Intercept),
    color = &amp;quot;blue&amp;quot;, size = 1
  ) +
  geom_abline(aes(intercept = b_Intercept, slope = b_time_c),
    data = post_samplesM2_tbl,
    alpha = 0.1, color = &amp;quot;gray50&amp;quot;
  ) +
  geom_abline(
    slope = mean(post_samplesM2_tbl$b_time_c),
    intercept = mean(post_samplesM2_tbl$b_Intercept),
    color = &amp;quot;blue&amp;quot;, size = 1
  ) +
  labs(
    title = &amp;quot;Regression Line Representing Mean of Slope&amp;quot;,
    subtitle = &amp;quot;Centered and Un-Centered Predictor Data&amp;quot;,
    x = &amp;quot;Time (s)&amp;quot;,
    y = &amp;quot;Temperature (C)&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;combined_predicts_fig &amp;lt;- combined_mean_fig + 
  ylim(c(56,90)) +
  labs(title = &amp;quot;Points Represent Observed Data (Green is Centered)&amp;quot;,
       subtitle = &amp;quot;Regression Line Represents Rate of Change of Mean (Grey Bands are Uncertainty)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/combined_predicts_fig.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now everything is clear. The slopes are exactly the same (as we saw in the density plots between model_1 and model_2 in summary()). The intercepts are different because in the centered data (green) the intercept occurs when the predictor equals 0 (its new mean). The outcome variable temp must therefore also be at its mean value in the “knot” of the bow-tie.&lt;/p&gt;
&lt;p&gt;For the un-centered data (purple), the intercept is the value of Temperature when the un-adjusted time is at 0. The range of possible intercepts is much more uncertain here.&lt;/p&gt;
&lt;p&gt;Another way to look at the differences is as a map of the plausible parameter space. We need a plot that can represent 3 parameters: intercept, slope, and sigma. Each point will be a credible combination of the three parameters as observed in 1 row of the posterior distribution tibble(s).&lt;/p&gt;
&lt;p&gt;First, the un-centered model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_spaceM1_fig &amp;lt;- 
  post_samplesM1_tbl[1:1000, ] %&amp;gt;%
  ggplot(aes(x = b_time, y = b_Intercept, color = sigma)) +
  geom_point(alpha = 0.5) +
  geom_density2d(color = &amp;quot;gray30&amp;quot;) +
  scale_color_viridis_c() +
  labs(
    title = &amp;quot;Parameter Space - Model 1 (Un-Centered)&amp;quot;,
    subtitle = &amp;quot;Intercept Represents the Expected Temp at Time = 0&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/p_spaceM1_fig.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now the centered version:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_spaceM2_fig &amp;lt;- 
  post_samplesM2_tbl[1:1000, ] %&amp;gt;%
  ggplot(aes(x = b_time_c, y = b_Intercept, color = sigma)) +
  geom_point(alpha = 0.5) +
  geom_density2d(color = &amp;quot;gray30&amp;quot;) +
  scale_color_viridis_c() +
  labs(
    title = &amp;quot;Parameter Space - Model 2 (Centered)&amp;quot;,
    subtitle = &amp;quot;Intercept Represents the Expected Temp at Mean Time&amp;quot;
  )

#p_spaceM2_fig 
#ggsave(filename = &amp;quot;p_spaceM2_fig.png&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/p_spaceM2_fig.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These look way different, but part of it is an illusion of the scaling on the y-axis. Remember how the credible values of the intercept were much tighter for the centered model? If we plot them both on the same canvas we can understand better, and it’s pretty (to my eye at least).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_spaceC_tbl &amp;lt;- 
  post_samplesM2_tbl[1:1000, ] %&amp;gt;%
  ggplot(aes(x = b_time_c, y = b_Intercept, color = sigma)) +
  geom_point(alpha = 0.5) +
  geom_point(data = post_samplesM1_tbl, aes(x = b_time, y = b_Intercept, color = sigma), alpha = 0.5) +
  scale_color_viridis_c() +
  labs(
    title = &amp;quot;Credible Parameter Values for Models 1 and 2&amp;quot;,
    subtitle = &amp;quot;Model 1 is Un-Centered, Model 2 is Centered&amp;quot;,
    x = expression(beta[&amp;quot;time&amp;quot;]),
    y = expression(alpha[&amp;quot;Intercept&amp;quot;])) +
  ylim(c(54, 80))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/p_spaceC_tbl.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we see they aren’t as different as they first seemed. They cover very similar ranges for the slope and the un-centered model covers a wider range of plausible intercepts.&lt;/p&gt;
&lt;p&gt;I’ve been looking for a good time to fire up the rayshader package and I’m not throwing away my shot here. Plotting with rayshader feels like a superpower that I shouldn’t be allowed to have. It’s silly how easy it is to make these ridiculous visuals. First, a fancy 3d plot providing some perspective on the relative “heights” of theta.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#par(mfrow = c(1, 1))
#plot_gg(p_spaceC_tbl, width = 5, height = 4, scale = 300, multicore = TRUE, windowsize = c(1200, 960),
#        fov = 70, zoom = 0.45, theta = 330, phi = 40)

#Sys.sleep(0.2)
#render_depth(focus = 0.7, focallength = 200)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/3d_params.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you want more, this code below renders a video guaranteed to impress small children and executives. I borrowed this code from Joey Stanley who borrowed it from Morgan Wall.&lt;a href=&#34;#fn4&#34; class=&#34;footnoteRef&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install.packages(&amp;quot;av&amp;quot;)
#library(av)

# Set up the camera position and angle
#phivechalf = 30 + 60 * 1/(1 + exp(seq(-7, 20, length.out = 180)/2))
#phivecfull = c(phivechalf, rev(phivechalf))
#thetavec = 0 + 60 * sin(seq(0,359,length.out = 360) * pi/180)
#zoomvec = 0.45 + 0.2 * 1/(1 + exp(seq(-5, 20, length.out = 180)))
#zoomvecfull = c(zoomvec, rev(zoomvec))

# Actually render the video.
#render_movie(filename = &amp;quot;hex_plot_fancy_2&amp;quot;, type = &amp;quot;custom&amp;quot;, 
#            frames = 360,  phi = phivecfull, zoom = zoomvecfull, theta = thetavec)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/hex_plot_fancy_2.gif&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-6-push-the-parameters-back-through-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Step 6: Push the parameters back through the model&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;After a lot of work we have finally identified the credible values for our model parameters. We now want to see what sort of predictions our posterior makes. Again, I’ll work with both the centered and un-centered data to try to understand the difference between the approaches. The first step in both cases is to create a sequence of time data to predict off of. For some reason I couldn’t get the predict() function in brms to cooperate so I wrote my own function to predict values. You enter a time value and the function makes a temperature prediction for every combination of mean and standard deviation derived from the parameters in the posterior distribution. Our goal will be to map this function over the sequence of predictor values we just set up.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#sequence of time data to predict off of.  Could use the same for both models but I created 2 for clarity
time_seq_tbl   &amp;lt;- tibble(pred_time   = seq(from = -15, to = 60, by = 1))
time_seq_tbl_2 &amp;lt;- tibble(pred_time_2 = seq(from = -15, to = 60, by = 1))

#function that takes a time value and makes a prediction using model_1 (un-centered) 
rk_predict &amp;lt;- 
function(time_to_sim){
  rnorm(n = nrow(post_samplesM1_tbl),
        mean = post_samplesM1_tbl$b_Intercept + post_samplesM1_tbl$b_time*time_to_sim,
        sd = post_samplesM1_tbl$sigma
  )
}

#function that takes a time value and makes a prediction using model_2 (centered)
rk_predict2 &amp;lt;- 
function(time_to_sim){
  rnorm(n = nrow(post_samplesM2_tbl),
        mean = post_samplesM2_tbl$b_Intercept + post_samplesM2_tbl$b_time_c*time_to_sim,
        sd = post_samplesM2_tbl$sigma
  )
}

#map the first prediction function over all values in the time sequence
#then calculate the .025 and .975 quantiles in anticipation of 95% prediction intervals
predicts_m1_tbl &amp;lt;- time_seq_tbl %&amp;gt;%
  mutate(preds_for_this_time = map(pred_time, rk_predict)) %&amp;gt;%
  mutate(percentile_2.5  = map_dbl(preds_for_this_time, ~quantile(., .025))) %&amp;gt;%
  mutate(percentile_97.5 = map_dbl(preds_for_this_time, ~quantile(., .975)))
    
#same for the 2nd prediction function
predicts_m2_tbl &amp;lt;- time_seq_tbl_2 %&amp;gt;%
  mutate(preds_for_this_time = map(pred_time_2, rk_predict2)) %&amp;gt;%
  mutate(percentile_2.5  = map_dbl(preds_for_this_time, ~quantile(., .025))) %&amp;gt;%
  mutate(percentile_97.5 = map_dbl(preds_for_this_time, ~quantile(., .975)))   

#visualize what is stored in the nested prediction cells (sanity check)
test_array &amp;lt;- predicts_m2_tbl[1, 2] %&amp;gt;% unnest(cols = c(preds_for_this_time))
test_array %&amp;gt;% 
  round(digits = 2) %&amp;gt;%
  head(5) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;preds_for_this_time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;68.13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;61.67&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;65.55&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;62.12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;64.05&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;And now the grand finale - overlay the 95% prediction intervals on the original data along with the credible values of mean. We see there is no difference between the predictions made from centered data vs. un-centered.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;big_enchilada &amp;lt;- 
  tibble(h=0) %&amp;gt;%
  ggplot() +
  geom_point(
    data = ablation_dta_tbl, aes(x = time, y = temp),
    colour = &amp;quot;#481567FF&amp;quot;,
    size = 2,
    alpha = 0.6
  ) +
  geom_point(
    data = ablation_dta_tbl, aes(x = time_c, y = temp),
    colour = &amp;quot;#55C667FF&amp;quot;,
    size = 2,
    alpha = 0.6
  ) +
  geom_abline(aes(intercept = b_Intercept, slope = b_time),
    data = post_samplesM1_tbl,
    alpha = 0.1, color = &amp;quot;gray50&amp;quot;
  ) +
  geom_abline(
    slope = mean(post_samplesM1_tbl$b_time),
    intercept = mean(post_samplesM1_tbl$b_Intercept),
    color = &amp;quot;blue&amp;quot;, size = 1
  ) +
  geom_abline(aes(intercept = b_Intercept, slope = b_time_c),
    data = post_samplesM2_tbl,
    alpha = 0.1, color = &amp;quot;gray50&amp;quot;
  ) +
  geom_abline(
    slope = mean(post_samplesM2_tbl$b_time_c),
    intercept = mean(post_samplesM2_tbl$b_Intercept),
    color = &amp;quot;blue&amp;quot;, size = 1
  ) +
  geom_ribbon(
  data = predicts_m1_tbl, aes(x = predicts_m1_tbl$pred_time, ymin = predicts_m1_tbl$percentile_2.5, ymax = predicts_m1_tbl$percentile_97.5), alpha = 0.25, fill = &amp;quot;pink&amp;quot;, color = &amp;quot;black&amp;quot;, size = .3
) +
  geom_ribbon(
  data = predicts_m2_tbl, aes(x = predicts_m2_tbl$pred_time_2, ymin = predicts_m2_tbl$percentile_2.5, ymax = predicts_m2_tbl$percentile_97.5), alpha = 0.4, fill = &amp;quot;pink&amp;quot;, color = &amp;quot;black&amp;quot;, size = .3
) +
  labs(
    title = &amp;quot;Regression Line Representing Mean of Slope&amp;quot;,
    subtitle = &amp;quot;Centered and Un-Centered Predictor Data&amp;quot;,
    x = &amp;quot;Time (s)&amp;quot;,
    y = &amp;quot;Temperature (C)&amp;quot;
  ) +
  scale_x_continuous(limits = c(-10, 37), expand = c(0, 0)) +
  scale_y_continuous(limits = c(40, 120), expand = c(0, 0))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/big_enchilada.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What a ride! This seemingly simple problem really stretched my brain. There are still a lot of question I want to go deeper on - diagnostics for the MCMC, impact of the regularizing priors, different between this workflow and frequentist at various sample sizes and priors, etc… but that will have to wait for another day.&lt;/p&gt;
&lt;p&gt;For those looking for more interpretations of McElreath’s workflows using Tidyverse tools, Solomon Kurz has a brilliant collection here.&lt;a href=&#34;#fn5&#34; class=&#34;footnoteRef&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thank you for reading.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Statistical Rethinking, &lt;a href=&#34;https://github.com/rmcelreath/statrethinking_winter2019&#34; class=&#34;uri&#34;&gt;https://github.com/rmcelreath/statrethinking_winter2019&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S1547527116001806&#34; class=&#34;uri&#34;&gt;https://www.sciencedirect.com/science/article/abs/pii/S1547527116001806&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;There’s a funky bug in ggExtra which makes you break this code into 2 chunks when working in Markdown, &lt;a href=&#34;https://cran.r-project.org/web/packages/ggExtra/vignettes/ggExtra.html&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/ggExtra/vignettes/ggExtra.html&lt;/a&gt;&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;3D Vowel Plots with Rayshader, &lt;a href=&#34;http://joeystanley.com/blog/3d-vowel-plots-with-rayshader&#34; class=&#34;uri&#34;&gt;http://joeystanley.com/blog/3d-vowel-plots-with-rayshader&lt;/a&gt;&lt;a href=&#34;#fnref4&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Statistical Rethinking with brms, ggplot2, and the tidyverse, &lt;a href=&#34;https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/&#34; class=&#34;uri&#34;&gt;https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/&lt;/a&gt;&lt;a href=&#34;#fnref5&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Confounders and Colliders - Modeling Spurious Correlations in R</title>
      <link>/post/confounders-and-colliders-modeling-spurious-correlations-in-r/</link>
      <pubDate>Tue, 29 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/confounders-and-colliders-modeling-spurious-correlations-in-r/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;/./img/dag.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Like many engineers, my first models were based on Designed Experiments in the tradition of Cox and Montgomery. I hadn’t seen anything like a causal diagram until I picked the &lt;strong&gt;The Book of Why&lt;/strong&gt; which explores all sorts of experimental relationships and structures I never imagined.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Colliders, confounders, causal diagrams, M-bias - these concepts are all relatively new to me and I want to understand them better. In this post I will attempt to create some simple structural causal models (SCMs) for myself using the Dagitty and GGDag packages and then show the potential effects of confounders and colliders on a simulated experiment adapted from here.&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It turns out that it is not as simple as identifying lurking variables and holding them constant while we conduct the experiment of interest (as I was always taught).&lt;/p&gt;
&lt;p&gt;First, load the libraries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load libraries
library(tidyverse)
library(kableExtra)
library(tidymodels)
library(viridisLite)
library(GGally)
library(dagitty)
library(ggdag)
library(visreg)
library(styler)
library(cowplot)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A structural causal model (SCM) is a type of directed acyclic graph (DAG) that maps causal assumptions onto a simple model of experimental variables. In the figure below, each node(blue dot) represents a variable. The edges(yellow lines) between nodes represent assumed causal effects.&lt;/p&gt;
&lt;p&gt;Dagitty uses the dafigy() function to create the relationships in the DAG. These are stored in a DAG object which is provided to ggplot and can then be customized and adjusted. Most of the code below the DAG object is just formatting the figure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create DAG object
g &amp;lt;- dagify(
  A ~ J,
  X ~ J,
  X ~ A
)

# tidy the dag object and supply to ggplot
set.seed(100)
g %&amp;gt;%
  tidy_dagitty() %&amp;gt;%
  mutate(x = c(0, 1, 1, 2)) %&amp;gt;%
  mutate(y = c(0, 2, 2, 0)) %&amp;gt;%
  mutate(xend = c(2, 0, 2, NA)) %&amp;gt;%
  mutate(yend = c(0, 0, 0, NA)) %&amp;gt;%
  dag_label(labels = c(
    &amp;quot;A&amp;quot; = &amp;quot;Independent\n Variable&amp;quot;,
    &amp;quot;X&amp;quot; = &amp;quot;Dependent\n Variable&amp;quot;,
    &amp;quot;J&amp;quot; = &amp;quot;The\n Confounder&amp;quot;
  )) %&amp;gt;%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges(
    edge_colour = &amp;quot;#b8de29ff&amp;quot;,
    edge_width = .8
  ) +
  geom_dag_node(
    color = &amp;quot;#2c3e50&amp;quot;,
    alpha = 0.8
  ) +
  geom_dag_text(color = &amp;quot;white&amp;quot;) +
  geom_dag_label_repel(aes(label = label),
    col = &amp;quot;white&amp;quot;,
    label.size = .4,
    fill = &amp;quot;#20a486ff&amp;quot;,
    alpha = 0.8,
    show.legend = FALSE,
    nudge_x = .7,
    nudge_y = .3
  ) +
  labs(
    title = &amp;quot; Directed Acyclic Graph&amp;quot;,
    subtitle = &amp;quot; Two Variables of Interest with a Confounder&amp;quot;
  ) +
  xlim(c(-1.5, 3.5)) +
  ylim(c(-.33, 2.2)) +
  geom_rect(
    xmin = -.5,
    xmax = 3.25,
    ymin = -.25,
    ymax = .65,
    alpha = .04,
    fill = &amp;quot;white&amp;quot;
  ) +
  theme_void() +
  theme(
    plot.background = element_rect(fill = &amp;quot;#222222&amp;quot;),
    plot.title = element_text(color = &amp;quot;white&amp;quot;),
    plot.subtitle = element_text(color = &amp;quot;white&amp;quot;)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-29-confounders-and-colliders-modeling-spurious-correlations-in-r_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; The relationship of interest is captured in the lower rectangle: we want to change the value of independent variable &lt;strong&gt;A&lt;/strong&gt; and record the effect on dependent variable &lt;strong&gt;X&lt;/strong&gt; (in epidemiology these might be called “treatment” and “outcome”). There also happens to be a confounding variable &lt;strong&gt;J&lt;/strong&gt; that has a causal effect on both &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;X&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We can set up a simulated experiment that follows the structure of the SCM above:&lt;/p&gt;
&lt;p&gt;Each variable will have n=1000 values. &lt;strong&gt;J&lt;/strong&gt; is generated by drawing randomly from a standard normal distribution. We want &lt;strong&gt;J&lt;/strong&gt; to be a cause of &lt;strong&gt;A&lt;/strong&gt; so we use &lt;strong&gt;J&lt;/strong&gt; in the creation of &lt;strong&gt;A&lt;/strong&gt; along with a random error term to represent noise. The model above shows a causal link from &lt;strong&gt;A&lt;/strong&gt; to &lt;strong&gt;X&lt;/strong&gt; but we don’t actually know if this exists - that’s the point of the experiment. It may or may not be there (from the point of view of the experimenter/engineer). For the purposes of demonstration we will structure the simulation such that there is &lt;strong&gt;no&lt;/strong&gt; causal relationship between &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;X&lt;/strong&gt; (&lt;strong&gt;A&lt;/strong&gt; will not be used in the creation of the variable &lt;strong&gt;J&lt;/strong&gt;). Again we need &lt;strong&gt;J&lt;/strong&gt; as a cause of &lt;strong&gt;X&lt;/strong&gt; so we use &lt;strong&gt;J&lt;/strong&gt; in the creation of the &lt;strong&gt;dependent_var_X&lt;/strong&gt; object along with a random noise component.&lt;/p&gt;
&lt;p&gt;The simulation is now set up to model an experiment where the experimenter/engineer wants to understand the effect of &lt;strong&gt;A&lt;/strong&gt; on &lt;strong&gt;X&lt;/strong&gt; but the true effect is zero. Meanwhile, there is a confounding variable &lt;strong&gt;J&lt;/strong&gt; that is a parent to both &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;X&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set seed for repeatability
set.seed(805)

# n = 1000 points for the simulation
n &amp;lt;- 1000

# create variables
# J is random draws from standard normal (mean = 0, stdev = 1)
confounding_var_J &amp;lt;- rnorm(n)

# J is used in creation of A since it is a cause of A (confounder)
independent_var_A &amp;lt;- 1.1 * confounding_var_J + rnorm(n)

# J is used in creation of X since it is a cause of X (confounder)
dependent_var_X &amp;lt;- 1.9 * confounding_var_J + rnorm(n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In reality, the experimenter may or may not be aware of the parent confounder &lt;strong&gt;J&lt;/strong&gt;. We will create two different regression models below. In the first, denoted &lt;strong&gt;crude_model&lt;/strong&gt;, we will assume the experimenter was unaware of the confounder. The model is then created with &lt;strong&gt;A&lt;/strong&gt; as the only predictor variable of &lt;strong&gt;X&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the second, denoted &lt;strong&gt;confounder_model&lt;/strong&gt;, we will assume the experimenter was aware of the confounder and chose to include it in their model. This version is created with &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;J&lt;/strong&gt; as predictors of &lt;strong&gt;X&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create crude regression model with A predicting X.  J is omitted
crude_model &amp;lt;- lm(dependent_var_X ~ independent_var_A)

# create confounder model with A and J predicting X
confounder_model &amp;lt;- lm(dependent_var_X ~ independent_var_A + confounding_var_J)

# tidy the crude model and examine it
crude_model_tbl &amp;lt;- summary(crude_model) %&amp;gt;% tidy()
crude_model_kbl &amp;lt;- summary(crude_model) %&amp;gt;%
  tidy() %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 5), digits = 3)
crude_model_kbl&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.007
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.051
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.135
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.893
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_A
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.967
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.034
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
28.415
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Tidy the confounder model and examine it
confounder_model_tbl &amp;lt;- summary(confounder_model) %&amp;gt;% tidy()
confounder_model_kbl &amp;lt;- summary(confounder_model) %&amp;gt;%
  tidy() %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 5), digits = 3)
confounder_model_kbl&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.005
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.151
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.880
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_A
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.005
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.033
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.153
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.878
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
confounding_var_J
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.860
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.048
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
38.460
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add column for labels
crude_model_tbl &amp;lt;- crude_model_tbl %&amp;gt;% mutate(model = &amp;quot;crude_model: no confounder&amp;quot;)
confounder_model_tbl &amp;lt;- confounder_model_tbl %&amp;gt;% mutate(model = &amp;quot;confounder_model: with confounder&amp;quot;)

# combine into a single kable
confounder_model_summary_tbl &amp;lt;- bind_rows(crude_model_tbl, confounder_model_tbl)
confounder_model_summary_tbl &amp;lt;- confounder_model_summary_tbl %&amp;gt;% select(model, everything())
confounder_model_summary_tbl %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 6), digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
model
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
crude_model: no confounder
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.007
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.051
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.135
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.893
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
crude_model: no confounder
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_A
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.967
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.034
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
28.415
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
confounder_model: with confounder
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.005
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.151
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.880
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
confounder_model: with confounder
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_A
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.005
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.033
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.153
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.878
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
confounder_model: with confounder
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
confounding_var_J
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.860
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.048
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
38.460
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The combined summary table above provides the effect sizes and the difference between the two models is striking. Conditional plots are a way to visualize regression models. The visreg package creates conditional plots by supplying a model object and a predictor variable to the visreg() function. The x-axis shows the value of the predictor variable and the y-axis shows change in the response variable. All other variables are held constant at their medians.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# visualize conditional plot of A vs X, crude model
v1 &amp;lt;- visreg(crude_model,
  &amp;quot;independent_var_A&amp;quot;,
  gg = TRUE,
  line = list(col = &amp;quot;#E66101&amp;quot;)
) +
  labs(
    title = &amp;quot;Relationship Between A and X&amp;quot;,
    subtitle = &amp;quot;Neglecting Confounder Variable J&amp;quot;
  ) +
  ylab(&amp;quot;Change in Response X&amp;quot;) +
  ylim(-6, 6) +
  theme(plot.subtitle = element_text(face = &amp;quot;bold&amp;quot;, color = &amp;quot;#404788FF&amp;quot;))

# visualize conditional plot of A vs X, confounder model
v2 &amp;lt;- visreg(confounder_model,
  &amp;quot;independent_var_A&amp;quot;,
  gg = TRUE,
  line = list(col = &amp;quot;#E66101&amp;quot;)
) +
  labs(
    title = &amp;quot;Relationship Between A and X&amp;quot;,
    subtitle = &amp;quot;Considering Confounder Variable J&amp;quot;
  ) +
  ylab(&amp;quot;Change in Response X&amp;quot;) +
  ylim(-6, 6) +
  theme(plot.subtitle = element_text(face = &amp;quot;bold&amp;quot;, color = &amp;quot;#20a486ff&amp;quot;))

plot_grid(v1, v2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-29-confounders-and-colliders-modeling-spurious-correlations-in-r_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We know from creating the simulated data that &lt;strong&gt;A&lt;/strong&gt; has no real effect on the outcome &lt;strong&gt;X&lt;/strong&gt;. &lt;strong&gt;X&lt;/strong&gt; was created using only &lt;strong&gt;J&lt;/strong&gt; and some noise. But the left plot shows a large, positive slope and significant coefficient! How can this be? This faulty estimate of the true effect is biased; more specifically we are seeing “confounder bias” or “omitted variable bias”. Adding &lt;strong&gt;J&lt;/strong&gt; to the regression model has the effect of conditioning on &lt;strong&gt;J&lt;/strong&gt; and revealing the true relationship between &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;X&lt;/strong&gt;: no effect of &lt;strong&gt;A&lt;/strong&gt; on &lt;strong&gt;X&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Confounding is pretty easy to understand. “Correlation does not imply causation” has been drilled into my brain effectively. Still, confounders that aren’t anticipated can derail studies and confuse observers. For example, the first generation of drug eluting stents was released in the early 2000’s. They showed great promise but their long-term risk profile was not well understood. Observational studies indicated an improved mortality rate for drug-eluting stents relative to their bare-metal counterparts. However, the performance benefit could not be replicated in randomized controlled trials.&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The disconnect was eventually linked (at least in part) to a confounding factor. Outside of a RCT, clinicians took into account the health of the patient going into the procedure. Specifically, if the patient was scheduled for a pending surgery or had a history of clotting then the clinician would hedge towards a bare-metal stent (since early gen DES tended to have thrombotic events at a greater frequency than BMS). Over the long term, these sicker patients were assigned BMS disproportionately, biasing the effect of stent type on long-term mortality via patient health as a confounder.&lt;/p&gt;
&lt;p&gt;So we always want to include every variable we know about in our regression models, right? Wrong. Here is a case that looks similar to the confounder scenario but is slightly different. The question of interest is the same: evaluate the effect of predictor &lt;strong&gt;B&lt;/strong&gt; on the outcome &lt;strong&gt;Y&lt;/strong&gt;. Again, there is a 3rd variable at play. But this time, the third variable is caused by both &lt;strong&gt;B&lt;/strong&gt; and &lt;strong&gt;Y&lt;/strong&gt; rather than being itself the common cause.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# assign DAG object
h &amp;lt;- dagify(
  K ~ B + Y,
  Y ~ B
)

# tidy the dag object and suppply to ggplot
set.seed(100)
h %&amp;gt;%
  tidy_dagitty() %&amp;gt;%
  mutate(x = c(0, 0, 2, 1)) %&amp;gt;%
  mutate(y = c(0, 0, 0, 2)) %&amp;gt;%
  mutate(xend = c(1, 2, 1, NA)) %&amp;gt;%
  mutate(yend = c(2, 0, 2, NA)) %&amp;gt;%
  dag_label(labels = c(
    &amp;quot;B&amp;quot; = &amp;quot;Independent\n Variable&amp;quot;,
    &amp;quot;Y&amp;quot; = &amp;quot;Dependent\n Variable&amp;quot;,
    &amp;quot;K&amp;quot; = &amp;quot;The\n Collider&amp;quot;
  )) %&amp;gt;%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges(
    edge_colour = &amp;quot;#b8de29ff&amp;quot;,
    edge_width = .8
  ) +
  geom_dag_node(
    color = &amp;quot;#2c3e50&amp;quot;,
    alpha = 0.8
  ) +
  geom_dag_text(color = &amp;quot;white&amp;quot;) +
  geom_dag_label_repel(aes(label = label),
    col = &amp;quot;white&amp;quot;,
    label.size = .4,
    fill = &amp;quot;#20a486ff&amp;quot;,
    alpha = 0.8,
    show.legend = FALSE,
    nudge_x = .7,
    nudge_y = .3
  ) +
  labs(
    title = &amp;quot; Directed Acyclic Graph&amp;quot;,
    subtitle = &amp;quot; Two Variables of Interest with a Collider&amp;quot;
  ) +
  xlim(c(-1.5, 3.5)) +
  ylim(c(-.33, 2.2)) +
  geom_rect(
    xmin = -.5,
    xmax = 3.25,
    ymin = -.25,
    ymax = .65,
    alpha = .04,
    fill = &amp;quot;white&amp;quot;
  ) +
  theme_void() +
  theme(
    plot.background = element_rect(fill = &amp;quot;#222222&amp;quot;),
    plot.title = element_text(color = &amp;quot;white&amp;quot;),
    plot.subtitle = element_text(color = &amp;quot;white&amp;quot;)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-29-confounders-and-colliders-modeling-spurious-correlations-in-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A variable like this is called a collider because the causal arrows from from &lt;strong&gt;B&lt;/strong&gt; and &lt;strong&gt;Y&lt;/strong&gt; collide at &lt;strong&gt;K&lt;/strong&gt;. &lt;strong&gt;K&lt;/strong&gt; is created in the simulation below using both &lt;strong&gt;B&lt;/strong&gt; and &lt;strong&gt;Y&lt;/strong&gt; plus random noise. This time, the outcome &lt;strong&gt;Y&lt;/strong&gt; is created using &lt;strong&gt;B&lt;/strong&gt; as an input, thereby assigning a causal relation with an effect size of 0.3.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create variables
# B is random draws from standard normal (mean = 0, stdev = 1)
independent_var_B &amp;lt;- rnorm(n)

# Y is created with B and noise. Effect size of B on Y is 0.3
dependent_var_Y &amp;lt;- .3 * independent_var_B + rnorm(n)

# K (collider) is created with B and Y + noise
collider_var_K &amp;lt;- 1.2 * independent_var_B + 0.9 * dependent_var_Y + rnorm(n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s assume that the experimenter knows about possible collider variable &lt;strong&gt;K&lt;/strong&gt;. What should they do with it when they go to create their regression model? Let’s create two models again to compare results. Following the nomenclature from before: &lt;strong&gt;crude_model_b&lt;/strong&gt; uses only &lt;strong&gt;B&lt;/strong&gt; to predict &lt;strong&gt;Y&lt;/strong&gt; and &lt;strong&gt;collider_model&lt;/strong&gt; uses both &lt;strong&gt;B&lt;/strong&gt; and &lt;strong&gt;K&lt;/strong&gt; to predict &lt;strong&gt;Y&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create crude regression model with B predicting Y.  K is omitted
crude_model_b &amp;lt;- lm(dependent_var_Y ~ independent_var_B)

# create collider model with B and K predicting Y
collider_model &amp;lt;- lm(dependent_var_Y ~ independent_var_B + collider_var_K)

# tidy the crude model and examine it
crude_model_b_kbl &amp;lt;- summary(crude_model_b) %&amp;gt;%
  tidy() %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 5), digits = 3)
crude_model_b_tbl &amp;lt;- summary(crude_model_b) %&amp;gt;% tidy()
crude_model_b_kbl&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.021
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.666
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.506
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_B
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.247
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7.820
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# tidy the collider model and examine it
collider_model_kbl &amp;lt;- summary(collider_model) %&amp;gt;%
  tidy() %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 5), digits = 3)
collider_model_tbl &amp;lt;- summary(collider_model) %&amp;gt;% tidy()
collider_model_kbl&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.011
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.023
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.453
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.651
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_B
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.481
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.034
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-14.250
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
collider_var_K
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.519
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.018
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
29.510
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add label column
crude_model_b_tbl &amp;lt;- crude_model_b_tbl %&amp;gt;% mutate(model = &amp;quot;crude_model_b: no collider&amp;quot;)
collider_model_tbl &amp;lt;- collider_model_tbl %&amp;gt;% mutate(model = &amp;quot;collider_model: with collider&amp;quot;)

# combine and examine
collider_model_summary_tbl &amp;lt;- bind_rows(crude_model_b_tbl, collider_model_tbl)
collider_model_summary_tbl &amp;lt;- collider_model_summary_tbl %&amp;gt;% select(model, everything())
collider_model_summary_tbl %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 6), digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
model
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
crude_model_b: no collider
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.021
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.666
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.506
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
crude_model_b: no collider
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_B
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.247
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7.820
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
collider_model: with collider
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.011
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.023
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.453
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.651
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
collider_model: with collider
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_B
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.481
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.034
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-14.250
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
collider_model: with collider
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
collider_var_K
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.519
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.018
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
29.510
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This time, omitting the collider variable is the proper way to recover the true effect of &lt;strong&gt;B&lt;/strong&gt; on &lt;strong&gt;Y&lt;/strong&gt;. Let’s verify with conditional plots as before. Again, we know the true slope should be around 0.3.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create conditional plot with crude_model_b and B
v3 &amp;lt;- visreg(crude_model_b,
  &amp;quot;independent_var_B&amp;quot;,
  gg = TRUE,
  line = list(col = &amp;quot;#E66101&amp;quot;)
) +
  labs(
    title = &amp;quot;Relationship Between B and Y&amp;quot;,
    subtitle = &amp;quot;Neglecting Collider Variable K&amp;quot;
  ) +
  ylab(&amp;quot;Change in Response Y&amp;quot;) +
  ylim(-6, 6) +
  theme(plot.subtitle = element_text(face = &amp;quot;bold&amp;quot;, color = &amp;quot;#f68f46b2&amp;quot;))

# create conditional plot with collider_model and B
v4 &amp;lt;- visreg(collider_model,
  &amp;quot;independent_var_B&amp;quot;,
  gg = TRUE,
  line = list(col = &amp;quot;#E66101&amp;quot;)
) +
  labs(
    title = &amp;quot;Relationship Between B and Y&amp;quot;,
    subtitle = &amp;quot;Considering Collider Variable K&amp;quot;
  ) +
  ylab(&amp;quot;Change in Response Y&amp;quot;) +
  ylim(-6, 6) +
  theme(plot.subtitle = element_text(face = &amp;quot;bold&amp;quot;, color = &amp;quot;#403891b2&amp;quot;))

plot_grid(v3, v4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-29-confounders-and-colliders-modeling-spurious-correlations-in-r_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; Incredibly, the conclusion one draws about the relationship between &lt;strong&gt;B&lt;/strong&gt; and &lt;strong&gt;Y&lt;/strong&gt; completely reverses depending upon which model is used. The true effect is positive (we only know this for sure because we created the data) but by including the collider variable in the model we observe it as negative. &lt;strong&gt;We should not control for a collider variable!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Controlling for a confounder reduces bias but controlling for a collider increases it - a simple summary that I will try to remember as I design future experiments or attempt to derive meaning from observational studies. These are the simple insights that make learning this stuff really fun (for me at least)!&lt;/p&gt;
&lt;p&gt;Thanks for reading.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://bayes.cs.ucla.edu/WHY/&#34; class=&#34;uri&#34;&gt;http://bayes.cs.ucla.edu/WHY/&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://scholar.harvard.edu/files/malf/files/ijeluquecollider.pdf&#34; class=&#34;uri&#34;&gt;https://scholar.harvard.edu/files/malf/files/ijeluquecollider.pdf&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3681250/&#34; class=&#34;uri&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3681250/&lt;/a&gt;&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>JAGS for Bayesian Reliability Estimation</title>
      <link>/post/jags-for-bayesian-reliability-estimation/</link>
      <pubDate>Fri, 25 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/jags-for-bayesian-reliability-estimation/</guid>
      <description>


&lt;p&gt;Intro&lt;/p&gt;
&lt;p&gt;Load the libraries to be used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Load libraries
library(tidyverse)
library(kableExtra)
library(rsample)
library(recipes)
library(parsnip)
library(yardstick)
library(viridisLite)
library(GGally)&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Heart Disease Prediction From Patient Data in R</title>
      <link>/post/heart-disease-prediction-from-patient-data-in-r/</link>
      <pubDate>Sun, 29 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/heart-disease-prediction-from-patient-data-in-r/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In this post I’ll be attempting to leverage the parsnip package in R to run through some straightforward predictive analytics/machine learning. Parsnip provides a flexible and consistent interface to apply common regression and classification algorithms in R. I’ll be working with the Cleveland Clinic Heart Disease dataset which contains 13 variables related to patient diagnostics and one outcome variable indicating the presence or absence of heart disease.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; The data was accessed from the UCI Machine Learning Repository in September 2019.&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. The goal is to be able to accurately classify as having or not having heart disease based on diagnostic test data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/cda.jpg&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Load the libraries to be used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Load libraries
library(tidyverse)
library(kableExtra)
library(rsample)
library(recipes)
library(parsnip)
library(yardstick)
library(viridisLite)
library(GGally)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first part of the analysis is to read in the data set and clean the column names up a bit.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Read in data
heart_disease_dataset &amp;lt;- read.csv(file = &amp;quot;processed.cleveland.data&amp;quot;, header = F)

#Prepare column names
names &amp;lt;- c(&amp;quot;Age&amp;quot;,
           &amp;quot;Sex&amp;quot;,
           &amp;quot;Chest_Pain_Type&amp;quot;,
           &amp;quot;Resting_Blood_Pressure&amp;quot;,
           &amp;quot;Serum_Cholesterol&amp;quot;,
           &amp;quot;Fasting_Blood_Sugar&amp;quot;,
           &amp;quot;Resting_ECG&amp;quot;,
           &amp;quot;Max_Heart_Rate_Achieved&amp;quot;,
           &amp;quot;Exercise_Induced_Angina&amp;quot;,
           &amp;quot;ST_Depression_Exercise&amp;quot;,
           &amp;quot;Peak_Exercise_ST_Segment&amp;quot;,
           &amp;quot;Num_Major_Vessels_Flouro&amp;quot;,
           &amp;quot;Thalassemia&amp;quot;,
           &amp;quot;Diagnosis_Heart_Disease&amp;quot;)

#Apply column names to the dataframe
colnames(heart_disease_dataset) &amp;lt;- names

#Glimpse data to verify new column names are in place
heart_disease_dataset %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 303
## Variables: 14
## $ Age                      &amp;lt;dbl&amp;gt; 63, 67, 67, 37, 41, 56, 62, 57, 63, 5...
## $ Sex                      &amp;lt;dbl&amp;gt; 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1...
## $ Chest_Pain_Type          &amp;lt;dbl&amp;gt; 1, 4, 4, 3, 2, 2, 4, 4, 4, 4, 4, 2, 3...
## $ Resting_Blood_Pressure   &amp;lt;dbl&amp;gt; 145, 160, 120, 130, 130, 120, 140, 12...
## $ Serum_Cholesterol        &amp;lt;dbl&amp;gt; 233, 286, 229, 250, 204, 236, 268, 35...
## $ Fasting_Blood_Sugar      &amp;lt;dbl&amp;gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1...
## $ Resting_ECG              &amp;lt;dbl&amp;gt; 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2...
## $ Max_Heart_Rate_Achieved  &amp;lt;dbl&amp;gt; 150, 108, 129, 187, 172, 178, 160, 16...
## $ Exercise_Induced_Angina  &amp;lt;dbl&amp;gt; 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1...
## $ ST_Depression_Exercise   &amp;lt;dbl&amp;gt; 2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0....
## $ Peak_Exercise_ST_Segment &amp;lt;dbl&amp;gt; 3, 2, 2, 3, 1, 1, 3, 1, 2, 3, 2, 2, 2...
## $ Num_Major_Vessels_Flouro &amp;lt;fct&amp;gt; 0.0, 3.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0....
## $ Thalassemia              &amp;lt;fct&amp;gt; 6.0, 3.0, 7.0, 3.0, 3.0, 3.0, 3.0, 3....
## $ Diagnosis_Heart_Disease  &amp;lt;int&amp;gt; 0, 2, 1, 0, 0, 0, 3, 0, 2, 1, 0, 0, 2...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are 14 variables provided in the data set and the last one is the dependent variable that we want to be able to predict. Here is a summary of what the other variables mean:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Age&lt;/strong&gt;: Age of subject&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Sex&lt;/strong&gt;: Gender of subject:&lt;br /&gt;
0 = female 1 = male&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Chest-pain type&lt;/strong&gt;: Type of chest-pain experienced by the individual:&lt;br /&gt;
1 = typical angina&lt;br /&gt;
2 = atypical angina&lt;br /&gt;
3 = non-angina pain&lt;br /&gt;
4 = asymptomatic angina&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Resting Blood Pressure&lt;/strong&gt;: Resting blood pressure in mm Hg&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Serum Cholesterol&lt;/strong&gt;: Serum cholesterol in mg/dl&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Fasting Blood Sugar&lt;/strong&gt;: Fasting blood sugar level relative to 120 mg/dl: 0 = fasting blood sugar &amp;lt;= 120 mg/dl&lt;br /&gt;
1 = fasting blood sugar &amp;gt; 120 mg/dl&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Resting ECG&lt;/strong&gt;: Resting electrocardiographic results&lt;br /&gt;
0 = normal&lt;br /&gt;
1 = ST-T wave abnormality&lt;br /&gt;
2 = left ventricle hyperthrophy&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Max Heart Rate Achieved&lt;/strong&gt;: Max heart rate of subject&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Exercise Induced Angina&lt;/strong&gt;:&lt;br /&gt;
0 = no 1 = yes&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;ST Depression Induced by Exercise Relative to Rest&lt;/strong&gt;: ST Depression of subject&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Peak Exercise ST Segment&lt;/strong&gt;:&lt;br /&gt;
1 = Up-sloaping&lt;br /&gt;
2 = Flat&lt;br /&gt;
3 = Down-sloaping&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Number of Major Vessels (0-3) Visible on Flouroscopy&lt;/strong&gt;: Number of visible vessels under flouro&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Thal&lt;/strong&gt;: Form of thalassemia: &lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;br /&gt;
3 = normal&lt;br /&gt;
6 = fixed defect&lt;br /&gt;
7 = reversible defect&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Diagnosis of Heart Disease&lt;/strong&gt;: Indicates whether subject is suffering from heart disease or not:&lt;br /&gt;
0 = absence&lt;br /&gt;
1, 2, 3, 4 = heart disease present&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A closer look at the data identifies some NA and “?” values that will need to be addressed in the cleaning step. We also want to know the number of observations in the dependent variable column to understand if the dataset is relatively balanced.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Determine the number of values in each level of dependent variable
heart_disease_dataset %&amp;gt;% 
  drop_na() %&amp;gt;%
  group_by(Diagnosis_Heart_Disease) %&amp;gt;%
  count() %&amp;gt;% 
  ungroup() %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2)) %&amp;gt;% kable_styling(&amp;quot;full_width&amp;quot; = F)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Diagnosis_Heart_Disease
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
n
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
164
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
55
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
35
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
13
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Identify the different levels of Thalassemia
heart_disease_dataset %&amp;gt;% 
  drop_na() %&amp;gt;%
  group_by(Thalassemia) %&amp;gt;%
  count() %&amp;gt;% 
  ungroup() %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2)) %&amp;gt;% kable_styling(&amp;quot;full_width&amp;quot; = F)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Thalassemia
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
n
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
?
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
166
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
18
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
117
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Since any value above 0 in ‘Diagnosis_Heart_Disease’ (column 14) indicates the presence of heart disease, we can lump all levels &amp;gt; 0 together so the classification predictions are binary - Yes or No (1 or 0). The total count of positive heart disease results is less than the number of negative results so the fct_lump() call with default arguments will convert that variable from 4 levels to 2.&lt;/p&gt;
&lt;p&gt;The data cleaning pipeline below deals with NA values, converts some variables to factors, lumps the dependent variable into two buckets, removes the rows that had “?” for observations, and reorders the variables within the dataframe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Drop NA&amp;#39;s, convert to factors, lump target variable to 2 levels, remove &amp;quot;?&amp;quot;, reorder variables
heart_dataset_clean_tbl &amp;lt;- heart_disease_dataset %&amp;gt;% 
    drop_na() %&amp;gt;%
    mutate_at(c(&amp;quot;Resting_ECG&amp;quot;, 
                &amp;quot;Fasting_Blood_Sugar&amp;quot;, 
                &amp;quot;Sex&amp;quot;, 
                &amp;quot;Diagnosis_Heart_Disease&amp;quot;, 
                &amp;quot;Exercise_Induced_Angina&amp;quot;,
                &amp;quot;Peak_Exercise_ST_Segment&amp;quot;, 
                &amp;quot;Chest_Pain_Type&amp;quot;), as_factor) %&amp;gt;%
    mutate(Num_Major_Vessels_Flouro = as.numeric(Num_Major_Vessels_Flouro)) %&amp;gt;%
    mutate(Diagnosis_Heart_Disease = fct_lump(Diagnosis_Heart_Disease, other_level = &amp;quot;1&amp;quot;)) %&amp;gt;% 
    filter(Thalassemia != &amp;quot;?&amp;quot;) %&amp;gt;%
    select(Age, 
           Resting_Blood_Pressure, 
           Serum_Cholesterol, 
           Max_Heart_Rate_Achieved, 
           ST_Depression_Exercise,
           Num_Major_Vessels_Flouro,
           everything())

#Glimpse data
heart_dataset_clean_tbl %&amp;gt;%
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 301
## Variables: 14
## $ Age                      &amp;lt;dbl&amp;gt; 63, 67, 67, 37, 41, 56, 62, 57, 63, 5...
## $ Resting_Blood_Pressure   &amp;lt;dbl&amp;gt; 145, 160, 120, 130, 130, 120, 140, 12...
## $ Serum_Cholesterol        &amp;lt;dbl&amp;gt; 233, 286, 229, 250, 204, 236, 268, 35...
## $ Max_Heart_Rate_Achieved  &amp;lt;dbl&amp;gt; 150, 108, 129, 187, 172, 178, 160, 16...
## $ ST_Depression_Exercise   &amp;lt;dbl&amp;gt; 2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0....
## $ Num_Major_Vessels_Flouro &amp;lt;dbl&amp;gt; 2, 5, 4, 2, 2, 2, 4, 2, 3, 2, 2, 2, 3...
## $ Sex                      &amp;lt;fct&amp;gt; 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1...
## $ Chest_Pain_Type          &amp;lt;fct&amp;gt; 1, 4, 4, 3, 2, 2, 4, 4, 4, 4, 4, 2, 3...
## $ Fasting_Blood_Sugar      &amp;lt;fct&amp;gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1...
## $ Resting_ECG              &amp;lt;fct&amp;gt; 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2...
## $ Exercise_Induced_Angina  &amp;lt;fct&amp;gt; 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1...
## $ Peak_Exercise_ST_Segment &amp;lt;fct&amp;gt; 3, 2, 2, 3, 1, 1, 3, 1, 2, 3, 2, 2, 2...
## $ Thalassemia              &amp;lt;fct&amp;gt; 6.0, 3.0, 7.0, 3.0, 3.0, 3.0, 3.0, 3....
## $ Diagnosis_Heart_Disease  &amp;lt;fct&amp;gt; 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Time for some basic exploratory data analysis. The workflow below breaks out the categorical variables and visualizes them on a faceted bar plot. I’m recoding the factors levels from numeric back to text-based so the labels are easy to interpret on the plots and stripping the y-axis labels since the relative differences are what matters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Select categorical vars, recode them to their character values, convert to long format
hd_long_fact_tbl &amp;lt;- heart_dataset_clean_tbl  %&amp;gt;%
  select(Sex,
         Chest_Pain_Type,
         Fasting_Blood_Sugar,
         Resting_ECG,
         Exercise_Induced_Angina,
         Peak_Exercise_ST_Segment,
         Thalassemia,
         Diagnosis_Heart_Disease) %&amp;gt;%
  mutate(Sex = recode_factor(Sex, `0` = &amp;quot;female&amp;quot;, 
                                  `1` = &amp;quot;male&amp;quot; ),
         Chest_Pain_Type = recode_factor(Chest_Pain_Type, `1` = &amp;quot;typical&amp;quot;,   
                                                          `2` = &amp;quot;atypical&amp;quot;,
                                                          `3` = &amp;quot;non-angina&amp;quot;, 
                                                          `4` = &amp;quot;asymptomatic&amp;quot;),
         Fasting_Blood_Sugar = recode_factor(Fasting_Blood_Sugar, `0` = &amp;quot;&amp;lt;= 120 mg/dl&amp;quot;, 
                                                                  `1` = &amp;quot;&amp;gt; 120 mg/dl&amp;quot;),
         Resting_ECG = recode_factor(Resting_ECG, `0` = &amp;quot;normal&amp;quot;,
                                                  `1` = &amp;quot;ST-T abnormality&amp;quot;,
                                                  `2` = &amp;quot;LV hypertrophy&amp;quot;),
         Exercise_Induced_Angina = recode_factor(Exercise_Induced_Angina, `0` = &amp;quot;no&amp;quot;,
                                                                          `1` = &amp;quot;yes&amp;quot;),
         Peak_Exercise_ST_Segment = recode_factor(Peak_Exercise_ST_Segment, `1` = &amp;quot;up-sloaping&amp;quot;,
                                                                            `2` = &amp;quot;flat&amp;quot;,
                                                                            `3` = &amp;quot;down-sloaping&amp;quot;),
         Thalassemia = recode_factor(Thalassemia, `3` = &amp;quot;normal&amp;quot;,
                                                  `6` = &amp;quot;fixed defect&amp;quot;,
                                                  `7` = &amp;quot;reversible defect&amp;quot;)) %&amp;gt;%
  gather(key = &amp;quot;key&amp;quot;, value = &amp;quot;value&amp;quot;, -Diagnosis_Heart_Disease)

#Visualize with bar plot
hd_long_fact_tbl %&amp;gt;% 
  ggplot(aes(value)) +
    geom_bar(aes(x        = value, 
                 fill     = Diagnosis_Heart_Disease), 
                 alpha    = .6, 
                 position = &amp;quot;dodge&amp;quot;, 
                 color    = &amp;quot;black&amp;quot;,
                 width    = .8
             ) +
    labs(x = &amp;quot;&amp;quot;,
         y = &amp;quot;&amp;quot;,
         title = &amp;quot;Scaled Effect of Categorical Variables&amp;quot;) +
    theme(
         axis.text.y  = element_blank(),
         axis.ticks.y = element_blank()) +
    facet_wrap(~ key, scales = &amp;quot;free&amp;quot;, nrow = 4) +
    scale_fill_manual(
         values = c(&amp;quot;#fde725ff&amp;quot;, &amp;quot;#20a486ff&amp;quot;),
         name   = &amp;quot;Heart\nDisease&amp;quot;,
         labels = c(&amp;quot;No HD&amp;quot;, &amp;quot;Yes HD&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-29-heart-disease-prediction-from-patient-data-in-r_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I prefer boxplots for evaluating the numeric variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Must gather() data first in order to facet wrap by key 
#(default gather call puts all var names into new key col)
hd_long_cont_tbl &amp;lt;- heart_dataset_clean_tbl  %&amp;gt;%
  select(Age,
         Resting_Blood_Pressure,
         Serum_Cholesterol,
         Max_Heart_Rate_Achieved,
         ST_Depression_Exercise,
         Num_Major_Vessels_Flouro,
         Diagnosis_Heart_Disease) %&amp;gt;% 
  gather(key   = &amp;quot;key&amp;quot;, 
         value = &amp;quot;value&amp;quot;,
         -Diagnosis_Heart_Disease)

#Visualize numeric variables as boxplots
hd_long_cont_tbl %&amp;gt;% 
  ggplot(aes(y = value)) +
       geom_boxplot(aes(fill = Diagnosis_Heart_Disease),
                      alpha  = .6,
                      fatten = .7) +
        labs(x = &amp;quot;&amp;quot;,
             y = &amp;quot;&amp;quot;,
             title = &amp;quot;Boxplots for Numeric Variables&amp;quot;) +
      scale_fill_manual(
            values = c(&amp;quot;#fde725ff&amp;quot;, &amp;quot;#20a486ff&amp;quot;),
            name   = &amp;quot;Heart\nDisease&amp;quot;,
            labels = c(&amp;quot;No HD&amp;quot;, &amp;quot;Yes HD&amp;quot;)) +
      theme(
         axis.text.x  = element_blank(),
         axis.ticks.x = element_blank()) +
      facet_wrap(~ key, 
                 scales = &amp;quot;free&amp;quot;, 
                 ncol   = 2) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-29-heart-disease-prediction-from-patient-data-in-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; The faceted plots for categorical and numeric variables suggest the following conditions are associated with increased prevalence of heart disease (note: this does not mean the relationship is causal).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Asymptomatic angina chest pain (relative to typical angina chest pain, atypical angina pain, or non-angina pain)&lt;/li&gt;
&lt;li&gt;Presence of exercise induced angina&lt;/li&gt;
&lt;li&gt;Lower fasting blood sugar&lt;/li&gt;
&lt;li&gt;Flat or down-sloaping peak exercise ST segment&lt;/li&gt;
&lt;li&gt;Presence of left ventricle hypertrophy&lt;/li&gt;
&lt;li&gt;Male&lt;/li&gt;
&lt;li&gt;Higher thelassemia score&lt;/li&gt;
&lt;li&gt;Higher age&lt;/li&gt;
&lt;li&gt;Lower max heart rate achieved&lt;/li&gt;
&lt;li&gt;Higher resting blood pressure&lt;/li&gt;
&lt;li&gt;Higher cholesterol&lt;/li&gt;
&lt;li&gt;Higher ST depression induced by exercise relative to rest&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can’t all be cardiologists but these do seem to pass the eye check. Particularly: age, blood pressure, cholesterol, and sex all point in the right direction based on what we generally know about the world around us. This provides a nice phase gate to let us proceed with the analysis.&lt;/p&gt;
&lt;p&gt;Highly correlated variables can lead to overly complicated models or wonky predictions. The ggcorr() function from GGally package provides a nice, clean correlation matrix of the numeric variables. The default method is Pearson which I use here first. Pearson isn’t ideal if the data is skewed or has a lot of outliers so I’ll check using the rank-based Kendall method as well.&lt;a href=&#34;#fn4&#34; class=&#34;footnoteRef&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Correlation matrix using Pearson method, default method is Pearson
heart_dataset_clean_tbl %&amp;gt;% ggcorr(high       = &amp;quot;#20a486ff&amp;quot;,
                                   low        = &amp;quot;#fde725ff&amp;quot;,
                                   label      = TRUE, 
                                   hjust      = .75, 
                                   size       = 3, 
                                   label_size = 3,
                                   nbreaks    = 5
                                              ) +
  labs(title = &amp;quot;Correlation Matrix&amp;quot;,
  subtitle = &amp;quot;Pearson Method Using Pairwise Obervations&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-29-heart-disease-prediction-from-patient-data-in-r_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Correlation matrix using Kendall method
heart_dataset_clean_tbl %&amp;gt;% ggcorr(method     = c(&amp;quot;pairwise&amp;quot;, &amp;quot;kendall&amp;quot;),
                                   high       = &amp;quot;#20a486ff&amp;quot;,
                                   low        = &amp;quot;#fde725ff&amp;quot;,
                                   label      = TRUE, 
                                   hjust      = .75, 
                                   size       = 3, 
                                   label_size = 3,
                                   nbreaks    = 5
                                   ) +
  labs(title = &amp;quot;Correlation Matrix&amp;quot;,
  subtitle = &amp;quot;Kendall Method Using Pairwise Observations&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-29-heart-disease-prediction-from-patient-data-in-r_files/figure-html/unnamed-chunk-8-2.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are very minor differences between the Pearson and Kendall results. No variables appear to be highly correlated. As such, it seems reasonable to stay with the original 14 variables as we proceed into the modeling section.&lt;/p&gt;
&lt;p&gt;The plan is to split up the original data set to form a training group and testing group. The training group will be used to fit the model while the testing group will be used to evaluate predictions. The initial_split() function creates a split object which is just an efficient way to store both the training and testing sets. The training() and testing() functions are used to extract the appropriate dataframes out of the split object when needed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#set seed for repeatability
set.seed(1333)

#create split object 
train_test_split &amp;lt;- heart_dataset_clean_tbl %&amp;gt;% initial_split(prop = .8, strata = &amp;quot;Diagnosis_Heart_Disease&amp;quot;)

#pipe split obj to training() fcn to create training set
train_tbl &amp;lt;- train_test_split %&amp;gt;% training()

#pipe split obj to testing() fcn to create test set
test_tbl &amp;lt;- train_test_split %&amp;gt;% testing()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We chose to do our data preparation early on during the cleaning phase. For more complicated modeling operations it may be desirable to set up a recipe to do the pre-processing in a repeatable and reversible fashion and I chose here to leave some placeholder lines commented out and available for future work. The recipe is the spot to transform, scale, or binarize the data. We have to tell the recipe() function what we want to model: Diagnosis_Heart_Disease as a function of all the other variables (not needed here since we took care of the necessary conversions). The training data should be used exclusively to train the recipe to avoid data leakage. After giving the model syntax to the recipe, the data is piped into the prep() function which will extract all the processing parameters (if we had implemented processing steps here). The trained recipe is stored as an object and bake function is used to apply the trained recipe to a new (test) data set.&lt;/p&gt;
&lt;p&gt;Juice() is a shortcut to extract the finalized training set which is already embedded in the recipe by default. Calling the bake() function and providing the recipe and a new data set will apply the processing steps to that dataframe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set up recipe (use training data here to avoid leakage)
the_recipe &amp;lt;- recipe(Diagnosis_Heart_Disease ~ . , data = train_tbl) %&amp;gt;%
              #[Processing Step 1]
              #[Processing Step 2]
              prep(train_tbl, retain = TRUE)

#Apply recipe to training data to create processed training_data_obj (already populated in the recipe object)
train_processed_data &amp;lt;- juice(the_recipe)

#Apply recipe to test data to create processed test_data_obj
test_processed_data &amp;lt;- bake(the_recipe, new_data = test_tbl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the training and testing data have been processed and stored, the logistic regression model can be set up using the parsnip workflow. Parsnip uses a 3-step process:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;specify the model and its arguments&lt;/li&gt;
&lt;li&gt;set the engine (how the model is created)&lt;/li&gt;
&lt;li&gt;fit the model to the processed training data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Logistic regression is a convenient first model to work with since it is relatively easy to implement and yields results that have intuitive meaning. It can be easily interpreted when the odds ratio is calculated from the model structure. &lt;a href=&#34;#fn5&#34; class=&#34;footnoteRef&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set up and train the model using processed training_data_obj
set.seed(100)
log_regr_hd_model &amp;lt;- logistic_reg(mode = &amp;quot;classification&amp;quot;) %&amp;gt;%
                     set_engine(&amp;quot;glm&amp;quot;) %&amp;gt;% 
                     fit(Diagnosis_Heart_Disease ~ ., data = train_processed_data)

#Take a look at model coefficients and add odds ratio for interpretability
broom::tidy(log_regr_hd_model$fit) %&amp;gt;%
  arrange(desc(estimate)) %&amp;gt;% 
  mutate(odds_ratio = exp(estimate)) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 5), digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
odds_ratio
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Thalassemia7.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.932
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.519
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.726
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6.906
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Chest_Pain_Type4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.694
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.770
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.201
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.028
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
5.443
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sex1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.473
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.648
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.274
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.023
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4.364
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Num_Major_Vessels_Flouro
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.264
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.307
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4.119
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.538
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Chest_Pain_Type2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.255
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.874
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.436
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.151
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.507
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Resting_ECG2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.022
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.447
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.287
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.022
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.780
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Peak_Exercise_ST_Segment3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.003
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.984
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.020
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.308
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.727
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Peak_Exercise_ST_Segment2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.833
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.551
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.512
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.130
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.300
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Exercise_Induced_Angina1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.704
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.526
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.339
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.181
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.023
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Resting_ECG1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.675
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.314
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.204
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.839
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.965
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
ST_Depression_Exercise
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.340
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.268
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.267
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.205
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.405
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Thalassemia6.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.127
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.882
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.144
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.885
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.136
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Resting_Blood_Pressure
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.036
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.014
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.535
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.011
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.037
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Serum_Cholesterol
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.003
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.005
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.644
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.520
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.003
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Max_Heart_Rate_Achieved
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.014
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-2.271
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.023
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.969
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Age
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.035
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.029
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-1.198
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.231
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.966
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Chest_Pain_Type3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.282
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.770
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.366
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.714
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.755
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fasting_Blood_Sugar1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.684
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.718
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.953
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.341
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.504
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-6.350
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.439
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-1.846
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.065
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.002
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In the above code I’ve converted the estimate of the coefficient into the odds ratio. The odds ratio represents the odds that an outcome will occur given the presence of a specific predictor, compared to the odds of the outcome occurring in the absence of that predictor, assuming all other predictors remain constant. The odds ratio is calculated from the exponential function of the coefficient estimate based on a unit increase in the predictor. An example with a numeric variable: for 1 mm Hg increased in resting blood pressure rest_bp, the odds of having heart disease increases by a factor of 1.04.&lt;/p&gt;
&lt;p&gt;Now let’s feed the model the testing data that we held out from the fitting process. It’s the first time the model will have seen these data so we should get a fair assessment (absent of over-fitting). The new_data argument in the predict() function is used to supply the test data to the model and have it output a vector of predictions, one for each observation in the testing data. The results vector can be added as a column into the original dataframe to append the predictions next to the true values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Make predictions using testing set
first_training_prediction &amp;lt;- predict(log_regr_hd_model, 
                                     new_data = test_tbl, 
                                     type     = &amp;quot;class&amp;quot;)

#Add predictions as new column in heart data set
first_training_prediction_full_tbl &amp;lt;- test_processed_data %&amp;gt;% 
  mutate(Predicted_Heart_Disease = first_training_prediction$.pred_class)

#Glimpse data
first_training_prediction_full_tbl %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 59
## Variables: 15
## $ Age                      &amp;lt;dbl&amp;gt; 56, 63, 56, 52, 54, 60, 64, 43, 65, 4...
## $ Resting_Blood_Pressure   &amp;lt;dbl&amp;gt; 120, 130, 140, 172, 140, 117, 140, 12...
## $ Serum_Cholesterol        &amp;lt;dbl&amp;gt; 236, 254, 294, 199, 239, 230, 335, 17...
## $ Max_Heart_Rate_Achieved  &amp;lt;dbl&amp;gt; 178, 147, 153, 162, 160, 160, 158, 12...
## $ ST_Depression_Exercise   &amp;lt;dbl&amp;gt; 0.8, 1.4, 1.3, 0.5, 1.2, 1.4, 0.0, 2....
## $ Num_Major_Vessels_Flouro &amp;lt;dbl&amp;gt; 2, 3, 2, 2, 2, 4, 2, 2, 5, 2, 2, 2, 2...
## $ Sex                      &amp;lt;fct&amp;gt; 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1...
## $ Chest_Pain_Type          &amp;lt;fct&amp;gt; 2, 4, 2, 3, 4, 4, 3, 4, 4, 1, 4, 3, 3...
## $ Fasting_Blood_Sugar      &amp;lt;fct&amp;gt; 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1...
## $ Resting_ECG              &amp;lt;fct&amp;gt; 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2...
## $ Exercise_Induced_Angina  &amp;lt;fct&amp;gt; 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0...
## $ Peak_Exercise_ST_Segment &amp;lt;fct&amp;gt; 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3...
## $ Thalassemia              &amp;lt;fct&amp;gt; 3.0, 7.0, 3.0, 7.0, 3.0, 7.0, 3.0, 7....
## $ Diagnosis_Heart_Disease  &amp;lt;fct&amp;gt; 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0...
## $ Predicted_Heart_Disease  &amp;lt;fct&amp;gt; 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A confusion matrix is a visual way to display the results of the model’s predictions. It’s not just the ability to predict the presence of heart disease that is of interest - we also want to know the number of times the model successfully predicts the absence of heart disease. Likewise, we want to know the number of false positives and false negatives. The confusion matrix captures all these metrics nicely.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Use predictions col and truth col to make a confusion matrix object
conf_mat_obj &amp;lt;- first_training_prediction_full_tbl %&amp;gt;% 
  conf_mat(truth    = Diagnosis_Heart_Disease, 
           estimate = Predicted_Heart_Disease)

#Call conf_mat and supply columns for truth, prediction
#Pluck() to extract the conf_matrix data into cols and convert to tibble for plotting
conf_matrix_plt_obj &amp;lt;- first_training_prediction_full_tbl %&amp;gt;% 
  conf_mat(truth    = Diagnosis_Heart_Disease, 
           estimate = Predicted_Heart_Disease) %&amp;gt;%
  pluck(1) %&amp;gt;%
  as_tibble() %&amp;gt;%
  mutate(&amp;quot;outcome&amp;quot; = c(&amp;quot;true_negative&amp;quot;,
                       &amp;quot;false_positive&amp;quot;,
                       &amp;quot;false_negative&amp;quot;,
                       &amp;quot;true_positive&amp;quot;)) %&amp;gt;%
  mutate(Prediction = recode(Prediction, &amp;quot;0&amp;quot; = &amp;quot;No Heart Disease&amp;quot;,
                                         &amp;quot;1&amp;quot; = &amp;quot;Heart Disease&amp;quot;)) %&amp;gt;%
  mutate(Truth = recode(Truth,  &amp;quot;0&amp;quot; = &amp;quot;No Heart Disease&amp;quot;,
                                &amp;quot;1&amp;quot; = &amp;quot;Heart Disease&amp;quot;))

#Convert to kable format
conf_matrix_plt_obj %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 4))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Prediction
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Truth
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
n
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
outcome
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
No Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
No Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
true_negative
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
No Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
false_positive
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
No Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
false_negative
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
true_positive
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Plot confusion matrix
p1 &amp;lt;- conf_matrix_plt_obj %&amp;gt;% ggplot(aes(x = Truth, y = Prediction)) +
  geom_tile(aes(fill = n), alpha = .8) +
  geom_text(aes(label = n), color = &amp;quot;white&amp;quot;) +
  scale_fill_viridis_c() +
  theme(legend.title = element_blank()) +
  labs(
    title    = &amp;quot;Confusion Matrix&amp;quot;,
    subtitle = &amp;quot;Heart Disease Prediction Using Logistic Regression&amp;quot;
  )
  
p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-29-heart-disease-prediction-from-patient-data-in-r_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Calling summary() on the confusion_matrix_obj gives all the performance measures
#Filter to the ones we care about
log_reg_performance_tbl &amp;lt;- summary(conf_mat_obj) %&amp;gt;% filter(
                                 .metric == &amp;quot;accuracy&amp;quot; | 
                                 .metric == &amp;quot;sens&amp;quot; |
                                 .metric == &amp;quot;spec&amp;quot; |
                                 .metric == &amp;quot;ppv&amp;quot;  |
                                 .metric == &amp;quot;npv&amp;quot;  |
                                 .metric == &amp;quot;f_meas&amp;quot;) %&amp;gt;%
  select(-.estimator) %&amp;gt;%
  rename(&amp;quot;metric&amp;quot; = .metric, 
         &amp;quot;estimate&amp;quot; = .estimate) %&amp;gt;%
  mutate(&amp;quot;estimate&amp;quot; = estimate %&amp;gt;% signif(digits = 3)) %&amp;gt;%
  mutate(metric = recode(metric, &amp;quot;sens&amp;quot; = &amp;quot;sensitivity&amp;quot;),
         metric = recode(metric, &amp;quot;spec&amp;quot; = &amp;quot;specificity&amp;quot;),
         metric = recode(metric, &amp;quot;ppv&amp;quot;  = &amp;quot;positive predictive value&amp;quot;),
         metric = recode(metric, &amp;quot;npv&amp;quot;  = &amp;quot;negative predictive value&amp;quot;)) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 3))
  
#Display perfomance summary as kable
log_reg_performance_tbl &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
metric
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.847
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
sensitivity
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.906
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
specificity
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.778
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
positive predictive value
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.829
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
negative predictive value
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.875
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
f_meas
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.866
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Other common performance metrics are summarized above. Accuracy represents the percentage of correct predictions. Descriptions for each can be found at this link.&lt;a href=&#34;#fn6&#34; class=&#34;footnoteRef&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The initial split of the data set into training/testing was done randomly so a replicate of the procedure would yield slightly different results. V-fold cross validation is a resampling technique that allows for repeating the process of splitting the data, training the model, and assessing the results many times from the same data set. Each stop in the CV process is annotated in the comments within the code below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create multiple split objects w/ vfold cross-validation resampling
set.seed(925)
hd_cv_split_objects &amp;lt;- heart_dataset_clean_tbl %&amp;gt;% vfold_cv(strata = Diagnosis_Heart_Disease)
hd_cv_split_objects&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 2
##    splits           id    
##    &amp;lt;named list&amp;gt;     &amp;lt;chr&amp;gt; 
##  1 &amp;lt;split [270/31]&amp;gt; Fold01
##  2 &amp;lt;split [270/31]&amp;gt; Fold02
##  3 &amp;lt;split [270/31]&amp;gt; Fold03
##  4 &amp;lt;split [271/30]&amp;gt; Fold04
##  5 &amp;lt;split [271/30]&amp;gt; Fold05
##  6 &amp;lt;split [271/30]&amp;gt; Fold06
##  7 &amp;lt;split [271/30]&amp;gt; Fold07
##  8 &amp;lt;split [271/30]&amp;gt; Fold08
##  9 &amp;lt;split [272/29]&amp;gt; Fold09
## 10 &amp;lt;split [272/29]&amp;gt; Fold10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#I want a big function that takes a split object and an id
make_cv_predictions_fcn &amp;lt;- function(split, id){
  #extract data for analysis set from split obj
  #prep(train) the recipe and return updated recipe
  #bake(apply) trained recipe to new data  
  analysis_tbl &amp;lt;- analysis(split)
  trained_analysis_recipe &amp;lt;- prep(the_recipe ,training = analysis_tbl)
  baked_analysis_data_tbl &amp;lt;- bake(trained_analysis_recipe, new_data = analysis_tbl)
  
  #define model in parsnip syntax
  model &amp;lt;- logistic_reg(mode = &amp;quot;classification&amp;quot;) %&amp;gt;%
    set_engine(&amp;quot;glm&amp;quot;) %&amp;gt;%
    fit(Diagnosis_Heart_Disease ~ ., data = baked_analysis_data_tbl)
  
  #same as above but for assessment set (like the test set but for resamples)
  assessment_tbl &amp;lt;- assessment(split)
  trained_assessment_recipe &amp;lt;- prep(the_recipe, training = assessment_tbl)
  baked_assessment_data_tbl &amp;lt;- bake(trained_assessment_recipe, new_data = assessment_tbl)
  
  #make a tibble with the results
  tibble(&amp;quot;id&amp;quot;         = id,
         &amp;quot;truth&amp;quot;      = baked_assessment_data_tbl$Diagnosis_Heart_Disease,
         &amp;quot;prediction&amp;quot; = unlist(predict(model, new_data = baked_assessment_data_tbl))
  )
}

#map the big function to every split obj / id in the initial cv split tbl
cv_predictions_tbl &amp;lt;- map2_df(.x = hd_cv_split_objects$splits,
                              .y = hd_cv_split_objects$id,
                              ~make_cv_predictions_fcn(split = .x, id = .y))

#see results 
cv_predictions_tbl %&amp;gt;% head(10) %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
id
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
truth
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
prediction
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#define desired metrics
desired_metrics &amp;lt;- metric_set(accuracy,
                              sens,
                              spec,
                              ppv,
                              npv,
                              f_meas)

#group by fold and use get desired metrics [metric_set fcn is from yardstick]
cv_metrics_long_tbl &amp;lt;- cv_predictions_tbl %&amp;gt;% 
                       group_by(id) %&amp;gt;% 
                       desired_metrics(truth = truth, estimate = prediction) 

#see results
cv_metrics_long_tbl %&amp;gt;% head(10) %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 4))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
id
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
.metric
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
.estimator
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
.estimate
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8709677
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold02
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9354839
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold03
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8387097
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold04
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.7666667
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold06
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold07
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold08
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.7333333
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold09
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.7931034
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold10
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9310345
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#visualize results
cv_metrics_long_tbl %&amp;gt;% ggplot(aes(x = .metric, y = .estimate)) +
  geom_boxplot(aes(fill = .metric), 
               alpha = .6, 
               fatten = .7) +
  geom_jitter(alpha = 0.2, width = .05) +
  labs(x = &amp;quot;&amp;quot;,
       y = &amp;quot;&amp;quot;,
       title = &amp;quot;Boxplots for Logistic Regression&amp;quot;,
       subtitle = &amp;quot;Model Metrics, 10-Fold Cross Validation&amp;quot;) +
  scale_fill_viridis_d() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1) ) +
  theme(legend.title = element_blank(),
        axis.text.x  = element_blank(),
        axis.ticks.x = element_blank()) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-29-heart-disease-prediction-from-patient-data-in-r_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#calculate the mean from all the folds for each metric
cv_mean_metrics_tbl &amp;lt;- cv_metrics_long_tbl %&amp;gt;%
                       group_by(.metric) %&amp;gt;%
                       summarize(&amp;quot;Avg&amp;quot; = mean(.estimate)) %&amp;gt;%
                       ungroup()
  
cv_mean_metrics_tbl %&amp;gt;% 
  mutate(Average = Avg %&amp;gt;% signif(digits = 3)) %&amp;gt;% 
  select(.metric,
         Average) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
.metric
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Average
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.837
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
f_meas
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.853
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
npv
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.852
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
ppv
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.839
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
sens
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.876
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
spec
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.790
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Got there! Average of .837 accuracy after 10-fold cross-validation. Not bad for a basic logistic regression. It is certainly possible that .837 is not sufficient for our purposes given that we are in the domain of health care where false classifications have dire consequences. Evaluating other algorithms would be a logical next step for improving the accuracy and reducing patient risk.&lt;/p&gt;
&lt;p&gt;Thanks for reading.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Image Credit: Shutterstock/Crevis&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;UCI Machine Learning Repository, &lt;a href=&#34;https://archive.ics.uci.edu/ml/datasets/Heart+Disease&#34; class=&#34;uri&#34;&gt;https://archive.ics.uci.edu/ml/datasets/Heart+Disease&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Nuclear stress testing requires the injection of a tracer, commonly technicium 99M (Myoview or Cardiolyte), which is then taken up by healthy, viable myocardial cells. A camera (detector) is used afterwards to image the heart and compare segments. A coronary stenosis is detected when a myocardial segment takes up the nuclear tracer at rest, but not during cardiac stress. This is called a “reversible defect.” Scarred myocardium from prior infarct will not take up tracer at all and is referred to as a “fixed defect.”&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/3730/pearsons-or-spearmans-correlation-with-non-normal-data&#34; class=&#34;uri&#34;&gt;https://stats.stackexchange.com/questions/3730/pearsons-or-spearmans-correlation-with-non-normal-data&lt;/a&gt;&lt;a href=&#34;#fnref4&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://notast.netlify.com/post/explaining-predictions-interpretable-models-logistic-regression/&#34; class=&#34;uri&#34;&gt;https://notast.netlify.com/post/explaining-predictions-interpretable-models-logistic-regression/&lt;/a&gt;&lt;a href=&#34;#fnref5&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2019/08/11-important-model-evaluation-error-metrics/&#34; class=&#34;uri&#34;&gt;https://www.analyticsvidhya.com/blog/2019/08/11-important-model-evaluation-error-metrics/&lt;/a&gt;&lt;a href=&#34;#fnref6&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Modeling Particulate Counts as a Poisson Process in R</title>
      <link>/post/modeling-particulate-counts-as-a-poisson-process-in-r/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/modeling-particulate-counts-as-a-poisson-process-in-r/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I’ve never really worked much with Poisson data and wanted to get my hands dirty. I thought that for this project I might combine a Poisson data set with the simple Bayesian methods that I’ve explored before since it turns out the Poisson rate parameter lambda also has a nice conjugate prior (more on that later). Poisson distributed data are counts per unit time or space - they are events that arrive at random intervals but that have a characteristic rate parameter which also equals the variance. This rate parameter is usually denoted as lambda. No-hitters in baseball are often modeled as Poisson data, as are certain types of processing defects in electronics and medical devices. A particularly relevant application is in particulate testing for implantable devices. Particulate shed is an unassuming but potentially costly and dangerous phenomenon.&lt;/p&gt;
&lt;p&gt;Particulate can be shed from the surface of medical devices even when the manufacturing environment is diligently controlled. The source of the particulate can vary: light particulate is attracted to the surface of sheaths and luers due to static charge; hydrophilic coatings may delaminate from the surface during delivery; therapeutic coating on the implant’s surface may degrade over time in the presence of blood.&lt;/p&gt;
&lt;p&gt;The clinical harms that the patient may face due to particulate shed include neurological events if the particulate migrates cranially or embolism it migrates caudally. The occurrence and severity of symptoms are understood to be functions of both size and quantity of particulate. In recent years, FDA and friends have been more stringent in requiring manufacturers to quantify and understand the nature of the particulate burden associated with their devices. In the analysis below, I’m going to simulate an experiment in which particulate data are collected for 20 devices.&lt;/p&gt;
&lt;p&gt;Before I get there, I want to remind myself of what Poisson data look like for different rate parameters. I set up a function to make a Poisson pdf based on number of events n and rate parameter lambda. The function then converts the information to a tibble for use with ggplot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Load libraries
library(tidyverse)
library(knitr)
library(kableExtra)
library(tolerance)
library(ggrepel)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Sequence from 0 to 24 by 1 (x-axis of plot)
number_of_events &amp;lt;- seq(0, 24, by = 1)

#Function to make a Poisson density vector from n and lambda, convert into tibble
pois_fcn &amp;lt;- function(lambda){
            pois_vector &amp;lt;- dpois(x = number_of_events, lambda = lambda, log = FALSE)
            pois_tbl    &amp;lt;- tibble(&amp;quot;num_of_events&amp;quot; = number_of_events,
                                  &amp;quot;prob&amp;quot;          = pois_vector,
                                  &amp;quot;lambda&amp;quot;        = lambda)
            }
#Objects to hold tibbles for different Poisson rates
pois_dist_1_tbl &amp;lt;-  pois_fcn(lambda = 1)
pois_dist_5_tbl &amp;lt;-  pois_fcn(lambda = 5)
pois_dist_15_tbl &amp;lt;- pois_fcn(lambda = 15)

#Combine in one df
pois_total_tbl &amp;lt;- bind_rows(pois_dist_1_tbl,
                            pois_dist_5_tbl,
                            pois_dist_15_tbl)

#Convert lambda front int to factor so ggplot maps aesthetics as levels, not gradient
pois_total_int_tbl &amp;lt;- pois_total_tbl %&amp;gt;% 
  mutate(lambda = as_factor(lambda))

#Make and store ggplot obj
h1 &amp;lt;- pois_total_int_tbl %&amp;gt;% ggplot(aes(x = num_of_events, y = prob)) +
  geom_col(aes(y = prob, fill = lambda), position = &amp;quot;dodge&amp;quot;, color = &amp;quot;black&amp;quot;) +
  scale_fill_manual(values = c(&amp;quot;#2C728EFF&amp;quot;, &amp;quot;#75D054FF&amp;quot;, &amp;quot;#FDE725FF&amp;quot;)) +
  labs(x        = &amp;quot;Number of Events&amp;quot;, 
       y        = &amp;quot;Probability&amp;quot;,
       title    = &amp;quot;Probability Mass Function&amp;quot;,
       subtitle = &amp;quot;Poisson Distributions with Different Rates (Lambda)&amp;quot;)

h1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-18-modeling-device-particulate-counts-as-a-poisson-process_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Cool - so when the rate is low it looks sort of like the discrete version of an exponential curve. It’s still not symmetric at lambda = 5 but by lambda = 15 it looks a lot like a binomial distribution.&lt;/p&gt;
&lt;p&gt;The data I simulate below are intended to represent the fluid collected during bench-top simulated use testing in a clean “flow loop” or vascular deployment model. The fluid would generally be passed through light obscuration censors to quantify the size and counts of particulate relative to a control. Particulate requirements for many endovascular devices are borrowed from USP &amp;lt;788&amp;gt;. According to that standard, no more than 60 particles greater than 25 micron effective diameter are acceptable. I want to know the probability of passing the test but don’t know the rate parameter lambda. The end goal is to understand what the most credible values for lambda are based on the bench-top data from multiple devices. First I’ll try to quantify the uncertainty in the rate parameter lambda. Each lambda can then be used to estimate a reliability. The large number of simulated lamdas will make a large set of simulated reliabilities. From there I should be able to extract any information needed regarding the uncertainty of the device reliability as it relates to particulate shed. That’s the plan! Note: I’m trying out knitr::kable() which generates html tables nicely. I’m not too good at it yet so bare with me please.&lt;/p&gt;
&lt;p&gt;Take a look at the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Peek at some data
particulate_data %&amp;gt;% head(5) %&amp;gt;%
  kable() %&amp;gt;% kable_styling(&amp;quot;full_width&amp;quot; = F)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
x
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
58
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
62
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I’m using a Bayesian approach again - partially because I need practice and partially because the Poisson parameter lambda has a convenient conjugate prior: the gamma distribution. This means that some simple math can get me from the prior to the posterior. I love simple math. Using the gamma distribution to describe the prior belief in lambda, the posterior distribution for lambda is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox{prior:  lambda ~ Gamma}(a, b)\]&lt;/span&gt; As a reminder to myself, this is read as “lambda is distributed as a Gamma distribution with parameters a and b”.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox{posterior:  lambda ~ Gamma}(a + \sum_{i=1}^{n} x_i\ , b + n)\]&lt;/span&gt; It is reasonable to use an relatively uninformed prior for lambda since I don’t have much preliminary knowledge about particulate data for my device design. Setting the shape a to 1 and the rate b to 0.1 provides allocates the credibility across a wide range of lambdas to start. To go from prior to posterior we need only sum up all the particulate counts in the data set and add the total to the shape a, then add the total number of devices tested (sample size n) to the rate b.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set parameters and constants
a &amp;lt;- 1
b &amp;lt;- 0.1
n &amp;lt;- length(particulate_data)
total_particulate_count &amp;lt;- sum(particulate_data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I like to peek at the prior and posterior distributions of lambda since they are easy to visualize via the relationships above. We are back into continuous distribution mode because the rate parameter lambda can be any positive value even though the particulate counts the come from the process are discrete.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set sequence of x values; generate prior using a,b; generate posterior 
x_values  &amp;lt;- seq(0, 60, length.out = 1000)
prior     &amp;lt;- dgamma(x_values, shape = 1, rate = 0.1)
posterior &amp;lt;- dgamma(x_values, shape = a + total_particulate_count, rate = b + n)

#Prior in tibble format
prior_tbl &amp;lt;- tibble(
  &amp;quot;x_values&amp;quot; = x_values,
  &amp;quot;prob&amp;quot;     = prior,
  &amp;quot;config&amp;quot;   = &amp;quot;prior&amp;quot;
)

#Posterior in tibble format
posterior_tbl &amp;lt;- tibble(
  &amp;quot;x_values&amp;quot; = x_values,
  &amp;quot;prob&amp;quot;     = posterior,
  &amp;quot;config&amp;quot;   = &amp;quot;posterior&amp;quot;
)

#Combine prior and posterior in 1 tibble
prior_post_tbl &amp;lt;- bind_rows(prior_tbl, posterior_tbl)

#Visualize 
prior_post_tbl %&amp;gt;% ggplot(aes(x = x_values, y = prob)) +
  geom_line(aes(color = config), size = 1.5, alpha = 0.8) +
  scale_y_continuous(name=&amp;quot;Density&amp;quot;, limits=c(0, 0.3)) +
  scale_color_manual(values = c(&amp;quot;#75D054FF&amp;quot;, &amp;quot;#2C728EFF&amp;quot;)) +
  labs(
    title    = &amp;quot;Rate Parameter Lambda For Particle Counts&amp;quot;,
    subtitle = &amp;quot;Modeled as Poisson Process&amp;quot;,
    x        = &amp;quot;Lambda&amp;quot;,
    color    = &amp;quot;&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-18-modeling-device-particulate-counts-as-a-poisson-process_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Having access to the posterior distribution of lambda enables simulation of possible values of lambda by drawing random values from the distributions. The probability of drawing any particular value of lambda is based on the density shown on the y-axis (although the probability of any particular point is zero; we must calculate over a span of x via integration). Each of the values randomly drawn from the posterior can be used to simulate a distribution of particulate counts for comparison with the spec. The workflow is essentially a series of questions:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;What might the values of the rate parameter lambda be based on the data? -&amp;gt; Combine data with conjugate prior to generate the posterior distribution of credible lambdas. (Done and shown above)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If a random value of lambda is pulled from the posterior distribution , what would we expect regarding the uncertainty of the original experiment? -&amp;gt; Draw random values lambda and then evaluate what percentage of the cdf lies above the spec (could also run simulations for each random lambda and then count the number of simulated runs above the spec but this is time consuming (10,000 lambdas x 10,000 simulations to build out the particle count distribution for each one…)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Combine each of these tail areas into a new distribution. This new distribution represents the uncertainty in the reliability estimate based on uncertainty in lambda. How to estimate the reliability of the real device while taking uncertainty into account? -&amp;gt; Calculate the lower bound of the 95% credible interval by finding the .05 quantile from the set of simulated reliability values.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s do this!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Sample and store 10000 random lambda values from posterior 
n_posterior_samples &amp;lt;- 10000
sampled_posterior_lambda &amp;lt;- rgamma(n_posterior_samples, shape = a + total_particulate_count, rate = b + n)

#Initialize empty vector to hold reliability data
reliability_vector &amp;lt;- rep(NA, n_posterior_samples)

#For each lambda value, calc cumulative probability of less than or equal to q particles shed from 1 sample?
for(i in 1:n_posterior_samples){
  reliability_vector[i] &amp;lt;- ppois(q = 60, lambda = sampled_posterior_lambda[i])
}

#Visualize
reliability_vector %&amp;gt;% head() %&amp;gt;% 
  kable(align=rep(&amp;#39;c&amp;#39;)) %&amp;gt;% kable_styling(&amp;quot;full_width&amp;quot; = F)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
x
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9147028
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9506510
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9431756
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9700806
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9546490
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9540933
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Checking what the simulated reliabilities are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Convert reliability vector to tibble
reliability_tbl &amp;lt;- reliability_vector %&amp;gt;% 
  as_tibble() %&amp;gt;%
  mutate(&amp;quot;reliability&amp;quot; = value) %&amp;gt;%
  select(reliability)

#Visualize with histogram
reliability_tbl %&amp;gt;% ggplot(aes(reliability)) +
  geom_histogram(fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, binwidth = .01, alpha = 0.8) +
    labs(
        x        = &amp;quot;Reliability&amp;quot;,
        title    = &amp;quot;Estimated Reliability Range for Particulate Shed Performance&amp;quot;,
        subtitle = &amp;quot;Requirement: 60 or less of 25 um or larger&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-18-modeling-device-particulate-counts-as-a-poisson-process_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The 95% credible interval for the reliability (conformance rate) is the .05 quantile of this distribution since the spec is 1-sided:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Calculate .05 quantile
reliability_tbl$reliability %&amp;gt;% 
  quantile(probs = .05)     %&amp;gt;% 
  signif(digits = 3)    &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    5% 
## 0.893&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, the answer! The lowest reliability expected is 89.3 % based on a 95% credible interval. This would likely not meet the product requirements (assigned based on risk of the harms that come from this particular failure mode) and we would likely need to improve our design or processes to reduce particulate shed from the product.&lt;/p&gt;
&lt;p&gt;This concludes the Bayesian inference of reliability in Poisson distributed particle counts. But hey, since we’re here… one of the things I love about R is the ability to easily check sensitivities, assumptions, and alternatives easily. What would this analysis look like using the conventional frequentist approach? I admit I’m not sure exactly but I assume we would extend the standard tolerance interval approach that is common in Class III medical device submissions. Tolerance intervals are easy to pull from tables or software but actually pretty tricky (for me at least) to derive. They involve uncertainty in both the mean and the variance. For simplicity (and because I’m not confident enough to derive the formula), I’ll use the tolerance package in R to calculate tolerance intervals for Poisson data. It turns out that there are 8 methods and I’ll use them all because I’m feeling a little wild and I want to see if they result in different results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## 95%/95% 1-sided Poisson tolerance limits for future
## occurrences in a period of length 1 part. All eight methods
## are presented for comparison.
tl_tab &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;TAB&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;TAB&amp;quot;) %&amp;gt;% as_tibble() 

tl_ls &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;LS&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;LS&amp;quot;) %&amp;gt;% as_tibble() 

tl_sc &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;SC&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;SC&amp;quot;) %&amp;gt;% as_tibble() 

tl_cc &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;CC&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;CC&amp;quot;) %&amp;gt;% as_tibble()

tl_vs &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;VS&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;VS&amp;quot;) %&amp;gt;% as_tibble() 

tl_rvs &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;RVS&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;RVS&amp;quot;) %&amp;gt;% as_tibble() 

tl_ft &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;FT&amp;quot;) %&amp;gt;%mutate(method = &amp;quot;FT&amp;quot;) %&amp;gt;% as_tibble() 

tl_csc &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;CSC&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;CSC&amp;quot;) %&amp;gt;% as_tibble() 

tl_all_tbl &amp;lt;-  bind_rows(tl_tab,
                         tl_ls,
                         tl_sc,
                         tl_cc,
                         tl_vs,
                         tl_rvs,
                         tl_ft,
                         tl_csc)

tl_all_tbl %&amp;gt;% kable(align=rep(&amp;#39;c&amp;#39;, 5)) &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
alpha
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
P
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
lambda.hat
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
1-sided.lower
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
1-sided.upper
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
method
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
TAB
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
LS
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
SC
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
CC
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
VS
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
RVS
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
FT
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
CSC
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For this data set it can be seen that all 8 methods produce the same 1-sided 95/95 upper tolerance interval 64 counts per device. N=60 was the requirement - since the edge of our tolerance interval lies above the 1-sided spec we would fail this test. This conclusion is consistent with the Bayesian method that estimates the reliability below the 95% requirement.&lt;/p&gt;
&lt;p&gt;But what sort of reliability claim could our data support? For the Bayesian approach we concluded that the answer was 89.3% (lower bound of 1-sided 95% credible interval). For the frequentist method, we don’t have a posterior distribution to examine. We could try using the tolerance interval function above with various values of P to impute the value of P which coincides with the spec limit of 60.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Sequence of reliability values for which to use as P 
reliability_freq_tbl &amp;lt;- tibble(
  &amp;quot;proportion_covered_P&amp;quot; = seq(.40, .99, .01)
)

#Function that is just like poistol.int but extracts and reports only the upper limit
#of the tolerance interval
tol_interval_fcn &amp;lt;- function(data_vec = sum_part_data, n=20, m=1, alpha=.05, P=.95, side=1, method=&amp;quot;TAB&amp;quot;){
  holder &amp;lt;- poistol.int(data_vec, n, m, alpha, P, side, method)
  holder_2 &amp;lt;- holder[1,5]
}

#Test the function
test_1 &amp;lt;- tol_interval_fcn(data_vec = sum_part_data, n=n, m=1, alpha = .05, P = .95, side = 1, method = &amp;quot;TAB&amp;quot;)

#Test the function
test_2 &amp;lt;- tol_interval_fcn(P = .95)

#Map the function across a vector of proportions
#Note to future self: map() arguments are: the list of values map the fn over, the fn
#itself, then all the additional arguments of the fn that you aren&amp;#39;t mapping over (odd syntax)
upper_tol_tbl &amp;lt;- reliability_freq_tbl %&amp;gt;% mutate(
  particles_per_part = map(proportion_covered_P, tol_interval_fcn, data_vec = sum_part_data, n=n, m=1, alpha = .05, side = 1, method = &amp;quot;TAB&amp;quot;) %&amp;gt;% as.integer() 
)

#View haead and tail of data
upper_tol_tbl %&amp;gt;% head(20) %&amp;gt;% kable(align=rep(&amp;#39;c&amp;#39;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
proportion_covered_P
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
particles_per_part
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.40
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.41
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.42
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.44
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.45
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.46
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.47
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.48
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.49
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.50
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.51
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.52
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.54
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.55
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
53
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.56
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
53
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.57
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
53
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.58
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
53
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.59
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
53
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;upper_tol_tbl %&amp;gt;% tail(20) %&amp;gt;% kable(align=rep(&amp;#39;c&amp;#39;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
proportion_covered_P
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
particles_per_part
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.80
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
58
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.81
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
58
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.82
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
58
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.83
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
59
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.84
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
59
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.85
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
59
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.86
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
60
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.87
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
60
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.88
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
60
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.89
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
61
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.90
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
61
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.91
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
62
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.92
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
62
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.93
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
63
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.94
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
63
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.96
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
65
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.97
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
66
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.98
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
67
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.99
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
69
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#need this data to feed to gg_label_repel to tell it where to attach label
point_tbl &amp;lt;- tibble(x = .65, y = 60)

#visualize 
upper_tol_tbl %&amp;gt;% ggplot(aes(x = proportion_covered_P, y = particles_per_part)) +
  geom_line(color = &amp;quot;#2c3e50&amp;quot;,
            size = 2.5) +
    labs(x = &amp;quot;Estimated Reliability at .95 Confidence Level&amp;quot;,
         y = &amp;quot;Edge of 1-Sided Tolerance Interval (Particles per Device)&amp;quot;,
         title = &amp;quot;Edge of Tolerance Interval vs. Specified Reliability&amp;quot;,
         subtitle = &amp;quot;95% Confidence Level Using TAB Tolerance Technique&amp;quot;) +
  scale_y_continuous(breaks = seq(40, 70, 5)) +
  geom_vline(xintercept = .88) +
  geom_hline(yintercept = 60) +
  geom_point(x = .65, y = 60, size = 0, alpha = 0) +
  geom_label_repel(data = point_tbl, aes(x, y), 
                   label = &amp;quot;Spec Limit: 60 Particles Max&amp;quot;,
                   fill = &amp;quot;#2c3e50&amp;quot;, 
                   color = &amp;quot;white&amp;quot;,
                   segment.color = &amp;quot;#2c3e50&amp;quot;,
                   segment.size = 1,
                   min.segment.length = unit(1, &amp;quot;lines&amp;quot;),
                   nudge_y = 2,
                   nudge_x = .05)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-18-modeling-device-particulate-counts-as-a-poisson-process_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here’s a plot that I’ve never made or seen before. For given set of data (in this case: particulate_data from earlier with n=20 from a Poisson distribution, lambda = 50), the x-axis shows the estimated reliability and the y-axis represents the number of particles at the edge the calculated tolerance interval using the TAB method. That is to say: the standard approaches to calculate the edge of the relevant tolerance interval for a specified proportion at a specified confidence level. For example, we could state we want to know the estimate for the 95th percentile at 95% confidence level - the answer would be 64 particles per device. Since the requirement for clinical safety is set at 60 particles max, we would not pass the test because we could not state with high confidence that 95 or more (out of 100) would pass. Usually it’s just a binary pass/fail decision.&lt;/p&gt;
&lt;p&gt;It’s obvious that the 95/95 edge of the tolerance interval is out of spec… but what would be the greatest reliability we could claim at 95% confidence? It ends up being .88 or 88% - very close to the predicted lower bound of the 95% credible interval calculated from the Bayesian method (which was 89.3%, from above)! In this case, the frequentist and Bayesian methods happen to be similar (even though they aren’t measuring the same thing). Interesting stuff!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stopping Rules for Significance Testing in R</title>
      <link>/post/stopping-rules-for-significance-testing-in-r/</link>
      <pubDate>Fri, 06 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/stopping-rules-for-significance-testing-in-r/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;When doing comparative testing it can be tempting to stop when we see the result that we hoped for. In the case of null hypothesis significance testing (NHST), the desired outcome is often a p-value of &amp;lt; .05. In the medical device industry, bench top testing can cost a lot of money. Why not just recalculate the p-value after every test and stop when the p-value reaches .05? The reason is that the confidence statement attached to your testing is only valid for a specific stopping rule. In other words, to achieve the desired false positive rate we must continue testing speciments until the pre-determined sample size is reached. Evaluating the p-value as you proceed through the testing is known as “peeking” and it’s a statistical no-no.&lt;/p&gt;
&lt;p&gt;Suppose we are attempting to demonstrate that a raw material provided by a new vendor results in better corrosion resistance in finished stents relative to the standard supplier. A bench top test is set up to measure the breakdown potential of each sample in a cyclic potentiodynamic polarization (CPP) test. Our goal is to compare the means of the CPP data from the old supplier and the new supplier. The null hypothesis is that the means are equivalent and if the t-test results in a p-value of .05 or lower then we will reject the null and claim improved performance. What happens to the p-value over the course of the testing? We can run a simulation to monitor the p-value and calculate the effect of peeking on the long-term false positive rate. For the test to perform as intended, the long-term false positive rate should be controlled at a level equal to (1 - confidence level).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(knitr)
library(kableExtra)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, initialize the objects to hold the data and establish any constants we might need later.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Initial offset constant to keep minimum group size at n=6
INITIAL_OFFSET &amp;lt;- 5

#Initial values for number of inner and outer loop iterations
n_inner_loop &amp;lt;- 50
n_inner_data &amp;lt;- n_inner_loop + INITIAL_OFFSET
n_outer &amp;lt;- 100

#Initialize empty vector to store p values
store_p_values_vec &amp;lt;- rep(NA, n_inner_loop)

#Initialize a tibble with placeholder column
many_runs_tbl &amp;lt;-  tibble(
  V1 = rep(NA,  n_inner_loop)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The simulation requires 2 for loops. The inner loop performs a series of t-test adding 1 more experimental observation to each group after each iteration. The p-value for that iteration is extracted and stored. In the outer loop, the initial data for the 2 groups are generated randomly from normal distributions. Since we can’t really run a t-test on groups with very low sample sizes, we use an initial offset value so that the t-test loops don’t start until both groups have a few observations from which to calculate the means.&lt;/p&gt;
&lt;p&gt;The p-value for a traditional t-test should be an indication of the long-term false positive rate. In other words: if we ran a t-test on samples drawn from 2 identical populations many times we would see a few large differences in means simply due to chance draws. Among all such simulations, the value at the 95% quantile represents the p-value of .05.&lt;/p&gt;
&lt;p&gt;We can gut-check our simulation in this way by setting the two populations identical to each other and drawing random values in the outer loop as mentioned above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set seed for repeatability
set.seed(1234)

#Outer loop: replicates a t-test between 2 groups
for(l in 1:n_outer) {
    
    #Generate simulated data for each group.  The parameters are set the same to represent 1 population
    example_group_1 &amp;lt;- rnorm(n = n_inner_data, mean = 10, sd = 4)
    example_group_2 &amp;lt;- rnorm(n = n_inner_data, mean = 10, sd = 4)
    
    #Inner loop: subset the first (i + initial offset) values from grp 1 and grp 2 (y)
    #Perform t-test, extract p-value, store in a vector
    #Increment each group&amp;#39;s size by 1 after each iteration
    for (i in 1:n_inner_loop) {
    t_test_obj &amp;lt;- t.test(x = example_group_1[1:(INITIAL_OFFSET + i)], y = example_group_2[1:(INITIAL_OFFSET + i)])
    store_p_values_vec[i] = t_test_obj$p.value
  }
  
    #Store each vector of n_inner_loop p-values to a column in the many_runs_tbl
    many_runs_tbl[,l] &amp;lt;- store_p_values_vec
}

#visualize tibble 
many_runs_tbl[,1:12] %&amp;gt;% 
  signif(digits = 3) %&amp;gt;%
  head(10) %&amp;gt;% 
  kable(align=rep(&amp;#39;c&amp;#39;, 100))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V1
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V2
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V3
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V4
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V5
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V6
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V7
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V8
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V9
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V10
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V11
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V12
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3960
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0990
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.204
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.412
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0686
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1450
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.894
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.360
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.721
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.897
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0535
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.668
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1700
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0628
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.106
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.951
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2240
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0834
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.802
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.614
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.750
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.886
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3170
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.517
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1410
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0929
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.057
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.618
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1360
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0296
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.499
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.561
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.846
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.809
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1740
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.410
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1560
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.4050
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.146
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.800
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1690
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0625
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.724
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.700
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.857
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.687
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3620
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.338
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1140
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2610
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.104
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.992
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2550
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1860
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.548
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.846
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.727
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.911
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.4270
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.334
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0540
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3400
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.143
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.889
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3180
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1740
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.775
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.768
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.795
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.666
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.5630
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.229
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0693
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.4030
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.125
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.871
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.7340
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0757
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.826
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.792
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.704
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.755
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.4810
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.694
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0324
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.4050
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.181
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.930
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8630
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0617
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.738
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.564
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.501
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.611
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3930
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.472
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0206
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.4550
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.112
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.912
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.7560
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0958
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.644
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.708
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.265
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.687
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2520
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.638
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0294
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.6690
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.103
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.777
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8680
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1700
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.664
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.703
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.284
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.912
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2450
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.441
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Each column above represents n=50 p-values, with each successive value calculated after observing the newest data point in the simulated test sequence. These are the p-values we see if we peek at the calculation every time.&lt;/p&gt;
&lt;p&gt;We need to convert data into tidy format for better visualization. In the tidy format, every column should be a unique variable. The gather() function converts data from wide to long by adding a new variable called “rep_sim_number” and combining all the various runs from 1 to 100 in a single column. In total, we’ll have only 3 columns in the tidy version.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#add new column with row id numbers
final_runs_tbl &amp;lt;- many_runs_tbl %&amp;gt;% 
    mutate(row_id = row_number()) %&amp;gt;%
    select(row_id, everything())

#convert from wide format (untidy) to long (tidy) using gather()
final_runs_tidy_tbl &amp;lt;- final_runs_tbl %&amp;gt;% gather(key = &amp;quot;rep_sim_number&amp;quot;, value = &amp;quot;p_value&amp;quot;, -row_id)

#visualize tidy data structure
final_runs_tidy_tbl %&amp;gt;% 
  head(10) %&amp;gt;% 
  kable(align=rep(&amp;#39;c&amp;#39;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
row_id
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
rep_sim_number
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p_value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3963352
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1704697
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1414021
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1557261
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1141854
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0539595
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0693410
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0324232
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0205511
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0293952
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;final_runs_tidy_tbl %&amp;gt;% 
  tail(10) %&amp;gt;% 
  kable(align=rep(&amp;#39;c&amp;#39;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
row_id
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
rep_sim_number
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p_value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
41
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0515933
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0509430
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
43
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0386845
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
44
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0567804
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0762953
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0933081
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
47
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0755494
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0558263
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0731072
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
50
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0496300
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;From here it is straightforward to visualize the trajectory of the p-values through the course of the testing for all 100 simulations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#visualize history of n_outer p-values across n_inner_loop consecutive data points as lineplot
lp_1 &amp;lt;- final_runs_tidy_tbl %&amp;gt;% ggplot(aes(x = row_id, y = p_value, group = rep_sim_number)) +
  geom_line(show.legend = &amp;quot;none&amp;quot;,
            color       = &amp;quot;grey&amp;quot;,
            alpha       = 0.7) +
  labs(x        = &amp;quot;Sequential Benchtop Test Observations&amp;quot;,
       title    = &amp;quot;P-Value History for Difference in Means, Standard T-Test&amp;quot;,
       subtitle = &amp;quot;Both Groups Sampled From Same Population&amp;quot;
       )

lp_1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-06-stopping-rules-for-significance-testing_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The p-values are all over the place! It makes sense that at the pre-determined stopping point (n=50) we would have a spread of p-values since the population parameters for the two groups were identical and p should only rarely land below .05. However, this visualization makes it clear that prior to the stopping point, the path of any particular p-value fluctuates wildly. This is the reason why we can’t stop early or peek!&lt;/p&gt;
&lt;p&gt;Let’s take a look at the false positives, defined here as the runs where the p-value ended up less than or equal to .05 at the pre-determined stopping point of n=50.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#filter for runs that ended in false positives (p &amp;lt; .05) at the last data point
filtered_endpoint_tbl &amp;lt;- final_runs_tidy_tbl %&amp;gt;% 
    filter(row_id == 50,
           p_value &amp;lt;= 0.05) %&amp;gt;%
    select(rep_sim_number) %&amp;gt;%
    rename(&amp;quot;false_positives&amp;quot; = rep_sim_number)

filtered_endpoint_tbl %&amp;gt;% 
  head(10) %&amp;gt;% 
  kable(align=&amp;#39;c&amp;#39;) %&amp;gt;%
  kable_styling(full_width = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
false_positives
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V23
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V48
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V54
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V77
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V86
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V89
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So 8 out of 100 simulations have p-values &amp;lt; .05. This is about as expected since the long term false positive rate should be 5%. Having now identified the false positives, we can visualize the trajectory of their p-values after obtaining each successive data point. This is what happens when we peek early or stop the test when we first see a desired outcome. The following code pulls the full history of the false positive test sequences so we can see their paths before the stopping point.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#extract full false positive test histories.  %in% filters rows that match anything in the false_positives vector
full_low_runs_tbl &amp;lt;- final_runs_tidy_tbl %&amp;gt;%
    filter(rep_sim_number %in% filtered_endpoint_tbl$false_positives)

#visualize trajectory of false positives by highlighting their traces
lp_2 &amp;lt;- final_runs_tidy_tbl %&amp;gt;% 
    ggplot(aes(x = row_id, y = p_value, group = rep_sim_number)) +
    geom_line(alpha = 0.7, show.legend = FALSE, color = &amp;quot;grey&amp;quot;) +
    geom_line(aes(color = rep_sim_number), data = full_low_runs_tbl, show.legend = FALSE, size = .8, alpha = 0.7) +
    labs(x       = &amp;quot;Sequential Benchtop Test Observations&amp;quot;,
        title    = &amp;quot;P-Value History for Difference in Means, Standard T-Test&amp;quot;,
        subtitle = &amp;quot;Highlighted Traces Represent Sequences with p &amp;lt; .05 at n=50&amp;quot;
        )

lp_2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-06-stopping-rules-for-significance-testing_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; Indeed, the p-values that end up less than .05 do not take a straight line path to get there. Likewise, there may be tests that dip below p=.05 at some point but culminate well above .05 at the pre-determined stopping point. These represent additional false-positives we invite when we peek or stop early. Let’s identify and count these:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#filter for all run who&amp;#39;s p-value ever dipped to .05 or lower at any point 
low_p_tbl &amp;lt;- final_runs_tidy_tbl %&amp;gt;% 
    filter(p_value &amp;lt;= .05) %&amp;gt;% 
    distinct(rep_sim_number)

#visualize
low_p_tbl %&amp;gt;% 
  head(10) %&amp;gt;% 
  kable(align=&amp;#39;c&amp;#39;) %&amp;gt;% 
  kable_styling(full_width = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
rep_sim_number
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V6
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V7
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V16
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V17
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V20
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V21
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V23
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V30
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V33
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#count total number of false positives with peeking
low_p_tbl %&amp;gt;% nrow() %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;) %&amp;gt;% 
  kable_styling(full_width = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
x
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
37
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The false positives go from 8 to 37!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#filter for only the rows where rep_sim_number here matches at least 1 value from low_p_tbl$rep_sim_number
#this extracts the full history of runs who&amp;#39;s p-value dipped to .05 or lower at any point 
any_low_runs_tbl &amp;lt;- final_runs_tidy_tbl %&amp;gt;%
    filter(rep_sim_number %in% low_p_tbl$rep_sim_number)

#visualize
any_low_runs_tbl %&amp;gt;% 
  head(10) %&amp;gt;% 
  kable(align = rep(&amp;quot;c&amp;quot;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
row_id
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
rep_sim_number
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p_value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3963352
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1704697
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1414021
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1557261
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1141854
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0539595
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0693410
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0324232
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0205511
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0293952
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#visualize the trajectory or runs that dipped to .05 or below
lp_3 &amp;lt;- final_runs_tidy_tbl %&amp;gt;% 
    ggplot(aes(x = row_id, y = p_value, group = rep_sim_number)) +
    geom_line(alpha = 0.7, show.legend = FALSE, color = &amp;quot;grey&amp;quot;) +
    geom_line(aes(color = rep_sim_number), data = any_low_runs_tbl, show.legend = FALSE, size = .8, alpha = 0.7) +
    labs(x       = &amp;quot;Sequential Benchtop Test Observations&amp;quot;,
        title    = &amp;quot;P-Value History for Difference in Means, Standard T-Test&amp;quot;,
        subtitle = &amp;quot;Highlighted Runs Represent p &amp;lt; .05 at Any Point&amp;quot;
        )

lp_3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-06-stopping-rules-for-significance-testing_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;All these differences in means would be considered significant if we don’t observe our pre-determined stopping rule. This could be a big deal. We might claim a performance benefit when there is none, or waste precious time and money trying to figure out why we can’t replicate an earlier experiment!&lt;/p&gt;
&lt;p&gt;Thanks for reading.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Assessing Design Verification Risk with Bayesian Estimation in R</title>
      <link>/post/assessing-dv-risk-w-bayesian-estimation-in-r/</link>
      <pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/assessing-dv-risk-w-bayesian-estimation-in-r/</guid>
      <description>


&lt;p&gt;Suppose our team is preparing to freeze a new implant design. In order to move into the next phase of the PDP, it is common to perform a suite of formal “Design Freeze” testing. If the results of the Design Freeze testing are acceptable, the project can advance from Design Freeze (DF) into Design Verification (DV). DV is an expensive and resource intensive phase culminating in formal reports that are included in the regulatory submission. One key goal of DF is therefore to burn down enough risk to feel confident going into DV. Despite the high stakes, I haven’t ever seen a quantitative assessment of residual risk at the phase review. In this post we’ll attempt to use some simple Bayesian methods to quantify the DV risk as a function of DF sample size for a single, high-risk test.&lt;/p&gt;
&lt;p&gt;Consider the requirement for accelerated durability (sometimes called fatigue resistance). In this test, the device is subjected to cyclic loading for a number of cycles equal to the desired service life. For 10 years of loading due to systolic - diastolic pressure cycles, vascular implants must survive approximately 400 million cycles. Accelerated durability is usually treated as attribute type data because the results can be only pass (if no fractures observed) or fail (if fractures are observed). Each test specimen can therefore be considered a Bernoulli trial and the number of passing units in n samples can be modeled with the binomial.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/fatigue.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;How many samples should we include in DF? We’ll set up some simulations to find out. In order to incorporate the outcome of the DF data into a statement about the probability of success for DV, we’ll need to apply Bayesian methods.&lt;/p&gt;
&lt;p&gt;First, load the libraries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(cowplot)
library(gghighlight)
library(knitr)
library(kableExtra)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The simulation should start off before we even execute Design Freeze testing. If we’re going to use Bayesian techniques we need to express our uncertainty about the parameters in terms of probability. In this case, the parameter we care about is the reliability. Before seeing any DF data we might know very little about what the true reliability is for this design. If we were asked to indicate what we thought the reliability might be, we should probably state a wide range of possibilities. The design might be good but it might be quite poor. Our belief about the reliability before we do any testing at all is called the prior and we expess it as a probability density function, not a point estimate. We need a mathematical function to describe how we want to spread out our belief in the true reliability.&lt;/p&gt;
&lt;p&gt;The beta is a flexible distribution that can be adjusted to take a variety of different forms. By tweaking the two shape factors of the beta we can customize the probability density curve in many different ways. If we were super confident that every part we ever made would pass the durability testing, we could put a “spike” prior right on 1.0. This is like saying “there’s no way any part could ever fail”. But the whole point is to communicate uncertainty and in reality there is always a chance the reliability might only be 97%, or 94%, etc. Since we haven’t really seen any DF data, we should probably drop some of our credibility into many different possible values of the reliability. Let’s be very conservative here and just use the flat prior. By evenly binning all of our credibility across the full range of reliability from 0 to 1, we’re saying we don’t want our pre-conceived notions to influence the final estimated reliability much. We’ll instead use the DF data themselves to re-allocate the credibility across the range of reliabilities appropriately according to Bayes’ rule after looking at the Design Freeze results. The more DF data we observe, the more precise the posterior estimate.&lt;/p&gt;
&lt;p&gt;The mathematical way to turn the beta distribution into a straight line (flat prior) is to set the shape parameters alpha and beta to (1,1). Note the area under the curve must always sum to 1. The image on the left shows a flat prior generated from a beta density with parameters (1,1).&lt;/p&gt;
&lt;p&gt;Another way to display the prior is to build out the visualization manually by drawing random values from the beta(1,1) distribution and constructing a histogram. This method isn’t terribly useful since we already know the exact distribution we want to use but I like to include it to emphasize the idea of “binning” the credibility across different values of reliability. It’s also nice to see the uncertainty we might see when we start to randomly draw from the distribution (full disclosure: I also just to practice my coding).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Plot flat prior using stat_function and ggplot
p_1 &amp;lt;- tibble(x_canvas=c(0,1)) %&amp;gt;% ggplot(aes(x=x_canvas)) +
    stat_function(fun   = dbeta,
                  args  = list(1, 1),
                  color = &amp;quot;#2c3e50&amp;quot;, 
                  size  = 1,
                  alpha = .8) +
    ylim(c(0,1.5)) +
    labs(
        y = &amp;quot;Density of Beta&amp;quot;,
        x = &amp;quot;Reliability&amp;quot;,
        title = &amp;quot;Credibility Allocation, Start of DF&amp;quot;,
        subtitle = &amp;quot;Uninformed Prior with Beta (1,1)&amp;quot;
    )

#Set the number of random draws from beta(1,1) to construct histogram flat prior
set.seed(123)
n_draws &amp;lt;- 100000

#Draw random values from beta(1,1), store in object
prior_dist_sim &amp;lt;- rbeta(n = n_draws, shape1 = 1, shape2 = 1)

#Convert from vector to tibble
prior_dist_sim_tbl &amp;lt;- prior_dist_sim %&amp;gt;% as_tibble()

#Visualize with ggplot
p_2 &amp;lt;- prior_dist_sim_tbl %&amp;gt;% ggplot(aes(x = value)) +
    geom_histogram(
        boundary = 1, 
        binwidth = .05, 
        color    = &amp;quot;white&amp;quot;,
        fill     = &amp;quot;#2c3e50&amp;quot;,
        alpha    = 0.8
        ) +
    xlim(c(-0.05, 1.05)) +
    ylim(c(0, 7500)) +
    labs(
        y = &amp;quot;Count&amp;quot;,
        title = &amp;quot;Credibility Simulation , Start of DF&amp;quot;,
        subtitle = &amp;quot;Uninformed Prior with Beta (1,1)&amp;quot;,
        x = &amp;quot;Reliability&amp;quot;
    
    ) 

plot_grid(p_1,p_2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-23-assessing-dv-risk-w-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;OK now the fun stuff. There is a cool, mathematical shortcut we can take to combine our simulated Design Freeze data with our flat prior to create the posterior distribution. It’s very simple: we just add the number of passing DF units to our alpha parameter and the number of failing DF units to our beta parameter. The reason why this works so well is beyond the scope of this post, but the main idea is that when the functional form of the prior (beta function in our case) is similar to the functional form of the likelihood function (Bernoulli in our case), then you can multiply them together easily and the product also takes a similar form. When this happens, the prior is said to be the “conjugate prior” of the likelihood function &lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; The beta and binomial are a special case that go together like peanut butter and jelly.&lt;/p&gt;
&lt;p&gt;Again, to understand how our belief in the reliability should be allocated after observing the DF data, all we need to do is update the beta function by adding the number of passing units from DF testing to alpha (Shape1 parameter) and the number of failing units to beta (Shape2 parameter).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox{Beta}(\alpha_0+\mbox{passes}, \beta_0+\mbox{fails})\]&lt;/span&gt; We’re going to assume all units pass DF, so we only need to adjust the alpha parameter. The resulting beta distribution that we get after updating the alpha parameter represents our belief in where the true reliability may lie after observing the DF data. Remember, even though every unit passed, we can’t just say the reliability is 100% because we’re smart enough to know that if the sample size was, for example, n=15 - there is a reasonable chance that a product with true reliability of 97% could run off n=15 in a row without failing. Even 90% reliability might hit 15 straight every once in a while but it would be pretty unlikely.&lt;/p&gt;
&lt;p&gt;The code below looks at four different possible sample size options for DF: n=15, n=30, n=45, and a full n=59 (just like we plan for DV).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Draw radomly from 4 different beta distributions. Alpha parameter is adjusted based on DF sample size
posterior_dist_sim_15 &amp;lt;- rbeta(n_draws, 16, 1)
posterior_dist_sim_30 &amp;lt;- rbeta(n_draws, 31, 1)
posterior_dist_sim_45 &amp;lt;- rbeta(n_draws, 46, 1)
posterior_dist_sim_59 &amp;lt;- rbeta(n_draws, 60, 1)

#Function to convert vectors above into tibbles and add column for Sample Size 
pds_clean_fcn &amp;lt;- function(pds, s_size){
    pds %&amp;gt;% as_tibble() %&amp;gt;% mutate(Sample_Size = s_size) %&amp;gt;%
    mutate(Sample_Size = factor(Sample_Size, levels = unique(Sample_Size)))}

#Apply function to 4 vectors above
posterior_dist_sim_15_tbl &amp;lt;- pds_clean_fcn(posterior_dist_sim_15, 15)
posterior_dist_sim_30_tbl &amp;lt;- pds_clean_fcn(posterior_dist_sim_30, 30)
posterior_dist_sim_45_tbl &amp;lt;- pds_clean_fcn(posterior_dist_sim_45, 45)
posterior_dist_sim_59_tbl &amp;lt;- pds_clean_fcn(posterior_dist_sim_59, 59)

#Combine the tibbles in a tidy format for visualization
full_post_df_tbl &amp;lt;- bind_rows(
            posterior_dist_sim_15_tbl,
            posterior_dist_sim_30_tbl, 
            posterior_dist_sim_45_tbl, 
            posterior_dist_sim_59_tbl
            )

#Visualize with density plot
df_density_plt &amp;lt;- full_post_df_tbl %&amp;gt;% ggplot(aes(x = value, fill = Sample_Size)) +
    geom_density(alpha = .6) +
    xlim(c(0.85,1)) +
    labs(x = &amp;quot;&amp;quot;,
         y = &amp;quot;Density of Beta&amp;quot;,
         title = &amp;quot;Credibility Simulation, After Design Freeze&amp;quot;,
         subtitle = &amp;quot;Updated Belief Modeled with Beta(1 + n,1)&amp;quot;) +
    scale_fill_manual(values = c(&amp;quot;#2C728EFF&amp;quot;, &amp;quot;#20A486FF&amp;quot;, &amp;quot;#75D054FF&amp;quot;, &amp;quot;#FDE725FF&amp;quot;)) 

#Visualize with histogram 
df_hist_plt &amp;lt;- full_post_df_tbl %&amp;gt;% ggplot(aes(x = value, fill = Sample_Size)) +
    geom_histogram(alpha = .9,
                   position = &amp;quot;dodge&amp;quot;,
                   boundary = 1,
                   color = &amp;quot;black&amp;quot;) +
    xlim(c(0.85,1)) +
    labs(x = &amp;quot;Reliability&amp;quot;,
         y = &amp;quot;Count&amp;quot;) +
    scale_fill_manual(values = c(&amp;quot;#2C728EFF&amp;quot;, &amp;quot;#20A486FF&amp;quot;, &amp;quot;#75D054FF&amp;quot;, &amp;quot;#FDE725FF&amp;quot;))

plot_grid(df_density_plt, df_hist_plt, ncol = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-23-assessing-dv-risk-w-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we unpack these charts a bit, we can see that if we only do n=15 in Design Freeze, we still need to allocate some credibility to reliability parameters below .90. For a full n=59, anything below .95 reliability is very unlikely, yet the 59 straight passing units could have very well come from a product with reliability = .98 or .97.&lt;/p&gt;
&lt;p&gt;We now have a good feel for our uncertainty about the reliability after DF, but what we really want to know is our likelihood of passing Design Verification. To answer this question, we’ll extend our simulation to perform many replicates of n=59 Bernoulli trials, each representing a round of Design Verification testing. The probability of failure will be randomly drawn from the distributions via Monte Carlo. Let’s see how many of these virtual DV tests end with 59/59 passing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Perform many sets of random binom runs, each with n=59 trials. p is taken from the probs previously generated 
DV_acceptable_units_15 &amp;lt;- rbinom(size = 59, n = n_draws, 
                                 prob = (posterior_dist_sim_15_tbl$value))
DV_acceptable_units_30 &amp;lt;- rbinom(size = 59, n = n_draws, 
                                 prob = (posterior_dist_sim_30_tbl$value))
DV_acceptable_units_45 &amp;lt;- rbinom(size = 59, n = n_draws, 
                                 prob = (posterior_dist_sim_45_tbl$value))
DV_acceptable_units_59 &amp;lt;- rbinom(size = 59, n = n_draws, 
                                 prob = (posterior_dist_sim_59_tbl$value))

#Function to convert vectors to tibbles and add col for sample size
setup_fcn &amp;lt;- function(vec, ss){
    vec %&amp;gt;% as_tibble() %&amp;gt;% mutate(DF_Sample_Size = ss) %&amp;gt;%
    mutate(DF_Sample_Size = factor(DF_Sample_Size, levels = unique(DF_Sample_Size)))}

#Apply function
DV_acceptable_units_15_tbl &amp;lt;- setup_fcn(DV_acceptable_units_15, 15)
DV_acceptable_units_30_tbl &amp;lt;- setup_fcn(DV_acceptable_units_30, 30)
DV_acceptable_units_45_tbl &amp;lt;- setup_fcn(DV_acceptable_units_45, 45)
DV_acceptable_units_59_tbl &amp;lt;- setup_fcn(DV_acceptable_units_59, 59)

#Combine the tibbles in a tidy format for visualization
DV_acceptable_full_tbl &amp;lt;- bind_rows(DV_acceptable_units_15_tbl,
                                    DV_acceptable_units_30_tbl,
                                    DV_acceptable_units_45_tbl,
                                    DV_acceptable_units_59_tbl)

#Visualize with ggplot.  Apply gghighlight where appropriate
g1 &amp;lt;- DV_acceptable_full_tbl %&amp;gt;%
   ggplot(aes(x = value)) +
   geom_histogram(aes(fill = DF_Sample_Size),binwidth = 1, color = &amp;quot;black&amp;quot;, position = &amp;quot;dodge&amp;quot;, alpha = .9) +
    xlim(c(45, 60)) +
    scale_x_continuous(limits = c(45, 60), breaks=seq(45, 60, 1)) +
    scale_fill_manual(values = c(&amp;quot;#2C728EFF&amp;quot;, &amp;quot;#20A486FF&amp;quot;, &amp;quot;#75D054FF&amp;quot;, &amp;quot;#FDE725FF&amp;quot;)) +
    labs(
        x = &amp;quot;Passing Parts out of 59 total&amp;quot;,
        title = &amp;quot;Simulated Design Verification Testing&amp;quot;,
        subtitle = &amp;quot;100,000 Simulated DV Runs of n=59&amp;quot;
    )

g2 &amp;lt;- g1 +
    gghighlight(value == 59, use_direct_label = FALSE) +
    labs(
        title = &amp;quot;Simulations that PASSED Design Verification&amp;quot;
     )
    
g3 &amp;lt;- g1 +
    gghighlight(value &amp;lt; 59, use_direct_label = FALSE) +
    labs(
        title = &amp;quot;Simulations that FAILED Design Verification&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-23-assessing-dv-risk-w-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;img src=&#34;/post/2019-08-23-assessing-dv-risk-w-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;img src=&#34;/post/2019-08-23-assessing-dv-risk-w-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-5-3.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Taking into consideration the uncertainty of the true reliability after the DF testing, the percentage of times we expect to pass Design Verification is shown below. These percentages are calculated as the number of simulated DV runs that achieved 59/59 passing units divided by the total number of simulated DV runs. Any simulation with 58 or less passing units would have failed DV.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox{expected probability of passing DV  = (number of sims with n=59 pass) / (total sims) }\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Function to calculate how many DV simulations resulted in 59/59 passing units
pct_pass_fct &amp;lt;- function(tbl, n){
    pct_dv_pass &amp;lt;- tbl %&amp;gt;% filter(value == 59) %&amp;gt;% nrow() / n_draws
    paste(&amp;quot;DF with n = &amp;quot;,n, &amp;quot;(all pass): &amp;quot;, pct_dv_pass %&amp;gt;% scales::percent(), &amp;quot;expected probability of next 59/59 passing DV&amp;quot;)}&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
DF with n = 15 (all pass): 21.3% expected probability of next 59/59 passing DV
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
DF with n = 30 (all pass): 34.5% expected probability of next 59/59 passing DV
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
DF with n = 45 (all pass): 43.5% expected probability of next 59/59 passing DV
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
DF with n = 59 (all pass): 50.3% expected probability of next 59/59 passing DV
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The percentage of time we expect to pass Design Verification is shockingly low! Even when we did a full n=59 in Design Freeze, we still only be able to predict 50% success in DV! This is because even with 59/59 passes, we still must account for the possibility that the reliability isn’t 100%. We don’t have enough DF data to shift the credibility all the way near 100%, and when the credibility is spread to include possible reliabilities in the mid .90’s we should always be prepared for the possibility of failing Design Verification.&lt;/p&gt;
&lt;p&gt;We could just leave it at that but I have found that when discussing risk, stakeholders want more than just an estimation of the rate of bad outcomes. They want a recommendation and a mitigation plan. Here are a few ideas; can you think of any more?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Maintain multiple design configurations as long as possible (often not feasible, but provides an out if 1 design fails)&lt;/li&gt;
&lt;li&gt;Perform durability testing as “fatigue-to-failure”. In this methodology, the devices are run to failure and the cycles to failure are treated as variable data. By varying the amplitude of the loading cycles, we can force the devices to fail and understand the uncertainty within the failure envelope. &lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Fold in information from pre-DF testing, predicate testing, etc to inform the prior better. I will look at the sensitivity of the reliability estimations to the prior in a future post.&lt;/li&gt;
&lt;li&gt;Build redundant design cycles into the project schedule to accomodate additional design turns without falling behind the contracted timeline&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Kruschke, Doing Bayesian Data Analysis, &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34; class=&#34;uri&#34;&gt;https://sites.google.com/site/doingbayesiandataanalysis/&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Fatigue-to Fracture ASTM Standard: &lt;a href=&#34;https://www.astm.org/Standards/F3211.htm&#34; class=&#34;uri&#34;&gt;https://www.astm.org/Standards/F3211.htm&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Permutation Test for NHST of 2 Samples in R</title>
      <link>/post/permutation-test-for-nhst-of-2-samples-in-r/</link>
      <pubDate>Sat, 10 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/permutation-test-for-nhst-of-2-samples-in-r/</guid>
      <description>


&lt;p&gt;As engineers, it is not uncommon to be asked to determine whether or not two different configurations of a product perform the same. Perhaps we are asked to compare the durability of a next-generation prototype to the current generation. Sometimes we are testing the flexibility of our device versus a competitor for marketing purposes. Maybe we identify a new vendor for a raw material but must first understand whether the resultant finished product will perform any differently than when built using material from the standard supplier. All of these situations call for a comparison between two groups culminating in a statistically supported recommendation.&lt;/p&gt;
&lt;p&gt;There are a lot of interesting ways to do this: regions of practical equivalence, Bayes Factors, etc. The most common method is still null hypothesis significance testing (NHST) and that’s what I want to explore in this first post. Frequentist methods yield the least useful inferences but have the advantage of a long usage history. Most medical device professionals will be looking for a p-value, so a p-value we must provide.&lt;/p&gt;
&lt;p&gt;In NHST, the plan is usually to calculate a test statistic from our data and use a table of reference values or a statistical program to tell us how surprising our derived statistic would be in a world where the null hypothesis was true. We generally do this by comparing our statistic to a reference distribution or table of tabulated values. Unfortunately, whenever our benchtop data violates an assumption of the reference model, we are no longer comparing apples-to-apples. We must make tweaks and adjustments to try to compensate. It is easy to get overwhelmed in a decision tree of test names and use cases.&lt;/p&gt;
&lt;p&gt;A more robust and intuitive approach to NHST is to replace the off-the-shelf distributions and tables with a simulation built right from our dataset. The workflow any such test is shown below. &lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/workflow.png&#34; width=&#34;75%&#34; height=&#34;75%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The main difference here is that we create the distribution of the data under the null hypothesis using simulation instead of relying on a reference distribution. It’s intuitive, powerful, and fun.&lt;/p&gt;
&lt;p&gt;Imagine we have just designed a benchtop experiment in which we intend to measure the pressure (in mm Hg) at which a pair of overlapped stent grafts started to migrate or disconnect when deployed in a large thoracic aneurysm. &lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/migration_model.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A common null hypothesis for comparing groups is that there is no difference between them. Under this model, &lt;strong&gt;we can treat all the experimental data as one big group instead of 2 different groups&lt;/strong&gt;. We therefore pool the data from our completed experiment into one big group, shuffle it, and randomly assign data points into two groups of the original size. This is our generative model. After each round of permutation and assignment, we calculate and store the test statistic for the observed effect (difference in means between the two groups). Once many simulations have been completed, we’ll see where our true data falls relative to the virtual data.&lt;/p&gt;
&lt;p&gt;One way to setup and execute a simulation-based NHST for comparing two groups in R is as follows (note: there are quicker shortcuts to executing this type of testing but the long version below allows for customization, visualization, and adjust-ability):&lt;/p&gt;
&lt;p&gt;First, we read in the libraries and transcribe the benchtop data into R and evaluate sample size&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(cowplot)
library(knitr)
library(kableExtra)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Migration pressure for predicate device
predicate &amp;lt;-  c(186, 188, 189, 189, 192, 193, 194, 194, 194, 195, 195, 196, 196, 197, 197, 198, 198, 199, 199, 201, 206, 207, 210, 213, 216, 218)

#Migration pressure for next_gen device
next_gen &amp;lt;-  c(189, 190, 192, 193, 193, 196, 199, 199, 199, 202, 203, 204, 205, 206, 206, 207, 208, 208, 210, 210, 212, 214, 216, 216, 217, 218)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sample Size of Predicate Device Data: 26
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sample Size of Next-Gen Device Data: 26
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So we have slightly uneven groups and relatively small sample sizes. No problem - assign each group to a variable and convert to tibble format:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Assign variables for each group and convert to tibble
predicate_tbl &amp;lt;- tibble(Device = &amp;quot;Predicate&amp;quot;,
                        Pressure = predicate)

next_gen_tbl &amp;lt;- tibble(Device = &amp;quot;Next_Gen&amp;quot;,
                        Pressure = next_gen)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Combine predicate and next_gen data into a single, pooled group called results_tbl. Taking a look at the first few and last few rows in the pooled tibble confirm it was combined appropriately.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Combine in tibble
results_tbl &amp;lt;- bind_rows(predicate_tbl, next_gen_tbl)
results_tbl %&amp;gt;% 
  head() %&amp;gt;% 
  kable(align = rep(&amp;quot;c&amp;quot;,2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Device
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Pressure
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Predicate
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
186
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Predicate
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
188
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Predicate
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
189
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Predicate
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
189
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Predicate
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
192
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Predicate
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
193
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results_tbl %&amp;gt;% tail() %&amp;gt;% 
  head() %&amp;gt;% 
  kable(align = rep(&amp;quot;c&amp;quot;,2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Device
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Pressure
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Next_Gen
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
212
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Next_Gen
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
214
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Next_Gen
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
216
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Next_Gen
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
216
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Next_Gen
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
217
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Next_Gen
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
218
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now we do some exploratory data analysis to identify general shape and distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Visualize w/ basic boxplot
boxplot_eda &amp;lt;- results_tbl %&amp;gt;% 
    ggplot(aes(x=Device, y=Pressure)) +
    geom_boxplot(
        alpha  = .6,
        width  = .4,
        size   = .8,
        fatten = .5,
        fill   = c(&amp;quot;#FDE725FF&amp;quot;,&amp;quot;#20A486FF&amp;quot;)) +
    labs(
        y        = &amp;quot;Pressure (mm Hg)&amp;quot;,
        title    = &amp;quot;Predicate and Next-Gen Data&amp;quot;,
        subtitle = &amp;quot;Modular Disconnect Pressure&amp;quot;
    )

boxplot_eda&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-10-simple-permutation-test-for-nhst-of-2-samples_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Visualize with density plot
density_eda &amp;lt;- results_tbl %&amp;gt;% 
    ggplot(aes(x = Pressure)) +
    geom_density(aes(fill = Device),
        color = &amp;quot;black&amp;quot;,
        alpha = 0.6
        ) +
    scale_fill_manual(values = c(&amp;quot;#FDE725FF&amp;quot;,&amp;quot;#20A486FF&amp;quot;)) +
    labs(
        x        = &amp;quot;Pressure (mm Hg)&amp;quot;,
        title    = &amp;quot;Predicate and Next-Gen Data&amp;quot;,
        subtitle = &amp;quot;Modular Disconnect Pressure&amp;quot;
    )

density_eda&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-10-simple-permutation-test-for-nhst-of-2-samples_files/figure-html/unnamed-chunk-7-2.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yikes! These data do not look normal. Fortunately, the permutation test does not need the data to take on any particular distribution. The main assumption is exchangability, meaning it must be reasonable that the labels could be arbitrarily permuted under the null hypothesis. Provided the sample size is approximately equal, the permutation test is robust against unequal variances.&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; This gives us an attractive option for data shaped as shown above.&lt;/p&gt;
&lt;p&gt;To get started with our permutation test we create a function that accepts 3 arguments: the pooled data from all trials in our benchtop experiment (x), the number of observations taken from Group 1 (n1), and the number of observations taken from Group 2 (n2). The function creates an object containing indices 1:n, then randomly assigns indices into two Groups A and B with sizes to match the original group sizes. It then uses the randomly assigned indices to splice the dataset x producing 2 “shuffled” groups from the original data. Finally, it computes and returns the mean between the 2 randomly assigned groups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Function to permute vector indices and then compute difference in group means
perm_fun &amp;lt;- function(x, n1, n2){
  n &amp;lt;- n1 + n2
  group_B &amp;lt;- sample(1:n, n1)
  group_A &amp;lt;- setdiff(1:n, group_B)
  mean_diff &amp;lt;- mean(x[group_B] - mean(x[group_A]))
  return(mean_diff)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we initialize an dummy vector called perm_diffs to hold the results of the loop we are about to use. It’ll have all 0’s to start and then we’ll assign values from each iteration of the for loop.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set number of simulations to run
n_sims &amp;lt;- 10000

#Initialize empty vector
perm_diffs &amp;lt;- rep(0,n_sims)
perm_diffs %&amp;gt;% head()  %&amp;gt;% 
  kable(align = &amp;quot;c&amp;quot;, col.names = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Set up a simple for loop to execute the same evaluation using perm_fun() 10,000 times. On each iteration, we’ll store the results into the corresponding index within perm_diffs that we initialized above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set seed for reproducibility
set.seed(2015)

#Iterate over desired number of simulations using permutation function
for (i in 1:n_sims)
  perm_diffs[i] = perm_fun(results_tbl$Pressure, 26, 26)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have 10,000 replicates of our permutation test stored in perm_diffs. We want to visualize the data with ggplot so we convert it into a tibble frame using tibble().&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Convert results to a tibble and look at it
perm_diffs_df &amp;lt;- tibble(perm_diffs)
perm_diffs_df %&amp;gt;% head()  %&amp;gt;% 
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
perm_diffs
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.6153846
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-3.3076923
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.6923077
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-2.3846154
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.3076923
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.1538462
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Visualize the difference in means as a histogram and density plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Visualize difference in means as a histogram
diffs_histogram_plot &amp;lt;- perm_diffs_df %&amp;gt;% ggplot(aes(perm_diffs)) +
  geom_histogram(fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, binwidth = .3, alpha = 0.8) +
    labs(
        x = &amp;quot;Pressure (mm Hg)&amp;quot;,
        title = &amp;quot;Histogram of Difference in Means&amp;quot;,
        subtitle = &amp;quot;Generated Under Null Hypothesis&amp;quot;
    )

#Visualize difference in means as a density plot
diffs_density_plot &amp;lt;-  perm_diffs_df %&amp;gt;% ggplot(aes(perm_diffs)) +
  geom_density(fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = 0.8) +
     labs(
        x = &amp;quot;Pressure (mm Hg)&amp;quot;,
        title = &amp;quot;Density Plot of Difference in Means&amp;quot;,
        subtitle = &amp;quot;Generated Under Null Hypothesis&amp;quot;
    )

plot_grid(diffs_histogram_plot, diffs_density_plot)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-10-simple-permutation-test-for-nhst-of-2-samples_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We just simulated many tests from the null hypothesis. These virtual data give us a good understanding of what sort of difference in means we might observe if there truly was no difference between the groups. As expected, most of the time the difference is around 0. But occasionally there is a noticeable difference in means just due to chance.&lt;/p&gt;
&lt;p&gt;But how big was the difference in means from our real world dataset? We’ll call this “baseline difference”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Evaluate difference in means from true data set
predicate_pressure_mean &amp;lt;- mean(predicate_tbl$Pressure)
next_gen_pressure_mean &amp;lt;- mean(next_gen_tbl$Pressure)

baseline_difference &amp;lt;- predicate_pressure_mean - next_gen_pressure_mean
baseline_difference  %&amp;gt;% 
  signif(digits = 3) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;, col.names = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-5.85
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So our real, observed data show a difference in means of -5.85. Is this large or small? With the context of the shuffle testing we already performed, we know exactly how extreme our observed data is and can visualize it with a vertical line.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Visualize real data in context of simulations
g1 &amp;lt;- diffs_histogram_plot + 
  geom_vline(xintercept = baseline_difference, 
             linetype   = &amp;quot;dotted&amp;quot;, 
             color      = &amp;quot;#2c3e50&amp;quot;, 
             size       = 1
             ) 

g2 &amp;lt;- diffs_density_plot + 
  geom_vline(xintercept = baseline_difference, 
             linetype   =&amp;quot;dotted&amp;quot;, 
             color      = &amp;quot;#2c3e50&amp;quot;, 
             size       = 1
             ) 

plot_grid(g1,g2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-10-simple-permutation-test-for-nhst-of-2-samples_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It looks like the our benchtop data was pretty extreme relative to the null. We should start to consider the possibility that this effect was not due solely to chance alone. 0.05 is a commonly used threshold for declaring statistical significance. Let’s see if our data is more or less extreme than 0.05 (solid line).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Calculate the 5% quantile of the simulated distribution for difference in means
the_five_percent_quantile &amp;lt;- quantile(perm_diffs_df$perm_diffs, probs = 0.05)
the_five_percent_quantile&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        5% 
## -4.153846&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Visualize the 5% quantile on the histogram and density plots
g3 &amp;lt;- g1 +
         geom_vline(xintercept = the_five_percent_quantile, 
             color      = &amp;quot;#2c3e50&amp;quot;, 
             size       = 1
             )

g4 &amp;lt;- g2 +
        geom_vline(xintercept = the_five_percent_quantile, 
             color      = &amp;quot;#2c3e50&amp;quot;, 
             size       = 1
             )

plot_grid(g3,g4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-10-simple-permutation-test-for-nhst-of-2-samples_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see here that our data is more extreme than the 5% quantile which means our p-value is less than 0.05. This satisfies the traditional, frequentist definition of statistically significant. If we want to actual p-value, we have to determine the percentage of simulated data that are as extreme or more extreme than our observed data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Calculate percentage of simulations as extreme or more extreme than the observed data (p-value)
p_value &amp;lt;- perm_diffs_df %&amp;gt;% 
    filter(perm_diffs &amp;lt;= baseline_difference) %&amp;gt;%
    nrow() / n_sims

paste(&amp;quot;The empirical p-value is: &amp;quot;, p_value)  %&amp;gt;% 
  kable(align = &amp;quot;c&amp;quot;, col.names = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
The empirical p-value is: 0.0096
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Our p-value is well below 0.05. This is likely enough evidence for us to claim that there was a statistically significant difference observed between the Next Gen device and the predicate device.&lt;/p&gt;
&lt;p&gt;Our marketing team will be thrilled, but we should always be wary that statistically significant does not mean practically important. Domain knowledge should provide the context to interpret the relevance of the observed difference. A difference in mean Pressure of a few mm Hg seems to be enough to claim a statistically significant improvement in our new device vs. the predicate, but is it enough for our marketing team to make a meaningful campaign? In reality, a few mm Hg is noticeable on the bench but is likely lost in the noise of anatomical variation within real patient anatomies.&lt;/p&gt;
&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Probably Overthinking It, &lt;a href=&#34;http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html&#34; class=&#34;uri&#34;&gt;http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;J ENDOVASC THER 2011;18:559-568, open access &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3163409/&#34; class=&#34;uri&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3163409/&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Simulations and Explanation of Unequal Variance and Sample Sizes, &lt;a href=&#34;https://stats.stackexchange.com/questions/87215/does-a-big-difference-in-sample-sizes-together-with-a-difference-in-variances-ma&#34; class=&#34;uri&#34;&gt;https://stats.stackexchange.com/questions/87215/does-a-big-difference-in-sample-sizes-together-with-a-difference-in-variances-ma&lt;/a&gt;&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>