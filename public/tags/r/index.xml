<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on [R]eliability</title>
    <link>/tags/r/</link>
    <description>Recent content in R on [R]eliability</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019. All rights reserved.</copyright>
    <lastBuildDate>Fri, 02 Dec 2022 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Gaussian Process Regression for FEA Designed Experiments - Building the Basics in R</title>
      <link>/post/gaussian-process-regression-for-fea-designed-experiments-building-the-basics-in-r/</link>
      <pubDate>Fri, 02 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/gaussian-process-regression-for-fea-designed-experiments-building-the-basics-in-r/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;A Google search for ‘Gaussian Process Regression’ returns some intimidating material for a non-statistician. After filtering away the obscure stuff I’ll never understand and digging around within the code that makes GPR happen, I’m proud to say that I feel I’ve gotten my arms around the basics of GPR. The only way to confirm if this is true or not is for me to try to explain it - so that’s what I plan to do in this post. For reference, the educational resource that resonated most with my style of learning is the wonderful text “Surrogates - Gaussian process modeling, design and optimization for the applied sciences” by Robert B. Gramacy.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; My thanks go out to the author for making his work freely available on bookdown.org. Much of this post is a Tidyverse-centric re-framing and expansion of ideas presented in Chapter 5 of Surrogates.&lt;/p&gt;
&lt;p&gt;But this isn’t just a whimsical exploration of a random algorithm - GPR has an elegant use-case right here in the medical device development domain: fitting predictive models for designed experiments (DOE) in which Finite Element Analysis (FEA) is used to make predictions about an output of interest. Essentially, GPR can replace and improve upon the traditional regression techniques used in Response Surface Modeling (RSM).&lt;/p&gt;
&lt;p&gt;Why would GPR be a good choice for modeling data produced by FEA? Well FEA is a deterministic modeling process - the prediction for any set of inputs (boundary conditions) is unique and repeatable. There is no noise or experimental error. This means a transfer function that passes through every point in the training data would be preferred. With a traditional regression model, the flexibility needed hit every data point would require many high order terms, sabotaging the model’s predictive ability on new data. But GPR has the amazing ability to swerve gently and fluidly between data points, meeting each one perfectly on its way to the next. This allows GPR to make perfect predictions on the training data while providing sound predictions in the areas in between the training points.&lt;/p&gt;
&lt;p&gt;As if that wasn’t enough, GPR is consistent with a Bayesian framework whereby priors and are asserted (informed by domain knowledge where applicable) and a posterior distribution is generated after conditioning on the observed training data. And just like any Bayesian posterior, uncertainty intervals are easily available and their meaning is intuitive.&lt;/p&gt;
&lt;p&gt;Please note - I won’t actually be working through an example of fitting FEA data from a DOE here today - I’ll get to that in a follow up post. Today it’s just the basics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#libraries&#34;&gt;Libraries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plan-and-background&#34;&gt;Plan and Background&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#consider-many-possible-functions&#34;&gt;Consider Many Possible Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#from-randomly-drawn-points-to-traces&#34;&gt;From Randomly Drawn Points to Traces&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#priors---random-traces-with-a-few-built-in-assumptions&#34;&gt;Priors - Random Traces with a Few Built in Assumptions&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#uniform-to-gaussian&#34;&gt;Uniform to Gaussian&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#calculate-distance-between-any-combination-of-points&#34;&gt;Calculate Distance Between any combination of points&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#interlude:--a-little-nudge&#34;&gt;Interlude: A little nudge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#get-covariance-matrix-sigma&#34;&gt;Get Covariance Matrix Sigma&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#draw-y-values&#34;&gt;Draw Y-Values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#combine-the-x&amp;#39;s-and-the-y&amp;#39;s&#34;&gt;Combine the x’s and the y’s&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plot-1-realization&#34;&gt;Plot 1 Realization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#define-function-to-make-a-random-trace&#34;&gt;Define Function to Make a Random Trace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#map-the-function-over-a-setup-tbl-to-create-multiple-traces&#34;&gt;Map the Function Over a Setup Tbl to Create Multiple Traces&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conditioning-and-predicting&#34;&gt;Conditioning and Predicting&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#the-data-points&#34;&gt;The Data Points&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#calculating-the-necessary-distances-and-covariance-matrices&#34;&gt;Calculating the Necessary Distances and Covariance Matrices&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#calculate:-inverse-of-covariance-matrix-between-x-values-in-vector-of-training-data-(observed-datapoints):&#34;&gt;Calculate: Inverse of Covariance matrix between x values in vector of training data (observed datapoints):&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#calculate:--covariance-matrix-between-x-values-in-vector-of-desired-test-points-(the-x-range-of-interest-where-the-gaussians-are-positioned):&#34;&gt;Calculate: Covariance matrix between x values in vector of desired test points (the x range of interest where the Gaussians are positioned):&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#calculate:-covariance-matrix-between-x-values-in-vector-of-training-data-(observed-datapoints)-and-x-values-in-vector-of-desired-test-points-(the-x-range-of-interest-where-the-gaussians-are-positioned-):&#34;&gt;Calculate: Covariance matrix between x values in vector of training data (observed datapoints) and x values in vector of desired test points (the x range of interest where the Gaussians are positioned ):&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#combine-per-the-conditioning-equations-above&#34;&gt;Combine Per the Conditioning Equations Above&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#draw-from-the-updated-gaussians&#34;&gt;Draw from the Updated Gaussians&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plot-the-draws&#34;&gt;Plot the Draws&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#function-for-many-posterior-draws&#34;&gt;Function for Many Posterior Draws&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#generate-many-draws-for-posterior-traces&#34;&gt;Generate Many Draws for Posterior Traces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualize&#34;&gt;Visualize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#more-visualize&#34;&gt;More Visualize&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sessioninfo&#34;&gt;sessionInfo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;libraries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Libraries&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(here)
library(gt)
library(plgp) #to calculate distance between points
library(mvtnorm) #to draw from multivariate normal 
library(tidybayes)
library(patchwork)

theme_set(theme_classic())&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plan-and-background&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plan and Background&lt;/h1&gt;
&lt;p&gt;The plan for setting up Gaussian Process Regression sounds pretty absurd until you actually see it work, so bear with me. In this example, we’ll consider the scenario where we have one input variable x and we wish to predict the output y.&lt;/p&gt;
&lt;div id=&#34;consider-many-possible-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Consider Many Possible Functions&lt;/h2&gt;
&lt;p&gt;Rather than assuming some parametric model and then fitting parameters to it, in GPR we start by considering many possible functions that could occupy the x-y space. In our case, we can think of the functions as squiggly traces on a 2d plot. Before seeing any data, our possible functions could take just about any course or path in the space. Our first goal in GPR is to find a way to construct a bunch of random squiggly functions across a range of interest for x and over an assumed scale of y.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;from-randomly-drawn-points-to-traces&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;From Randomly Drawn Points to Traces&lt;/h2&gt;
&lt;p&gt;One way to construct a trace from left to right in 2d space would be to partition the x range up in to discrete intervals, draw a random y value at each x interval, and then connect the resulting points with lines. This would provide traces across the 2d space, but if the random draws were from a grid of y values or a uniform distribution in y, each draw’s position in y would be random and our trace would swing wildly up and down, displaying none of the cohesion or “smoothness” that we think of in functions. It would look like random noise.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_uniforms &amp;lt;- 50
x_tbl &amp;lt;- tibble(x = seq(from = 0, to = 10, length = n_uniforms))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function draws y values from a uniform [-3, 3] distribution at any specified x location. We then plot and take a look.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;centered_unif_draws_fcn &amp;lt;- function(x_loc, n_draws){
  temp &amp;lt;- tibble(x = x_loc, y = runif(n_draws, -3, 3))
  return(temp)
}

unif_tbl &amp;lt;- x_tbl %&amp;gt;%
  mutate(y_draws = map(.x = x, .f = centered_unif_draws_fcn, n_draws = 600)) %&amp;gt;%
  select(-x) %&amp;gt;%
  unnest()

single_set &amp;lt;- x_tbl %&amp;gt;%
  mutate(y_draws = map(.x = x, .f = centered_unif_draws_fcn, n_draws = 1)) %&amp;gt;%
  select(-x) %&amp;gt;%
  unnest()

unif_tbl %&amp;gt;%
  ggplot(aes(x = x, y = y)) +
  geom_jitter(size = .1, alpha = .4, width = .02, color = &amp;quot;#2c3e50&amp;quot;) +
  geom_point(data = single_set, aes(x = x, y = y), size = 2, color = &amp;quot;firebrick&amp;quot;) +
  geom_line(data = single_set, aes(x = x, y = y), size = 1.5, color = &amp;quot;firebrick&amp;quot;, alpha = .8) +
  labs(title = &amp;quot;Draws from Uniform Distributions&amp;quot;,
       subtitle = &amp;quot;Positioned at x intervals&amp;quot;,
       caption = &amp;quot;red line represents trace created by connecting a single draw from each distribtion&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-12-02-gaussian-process-regression-for-fea-designed-experiments-building-the-basics-in-r_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now here’s the amazing part - suppose that instead of drawing the y values from uniform distributions and creating noise, we use a normal (Gaussian) distribution instead. If we then asserted the Gaussians were actually part of a multi-variate normal distribution with a shared covariance matrix, we could control the nature of the draws such that points nearby each other (on the x axis) were highly correlated but points far from each other (on the x axis) were not highly correlated. It turns out that random points drawn and connected under these conditions yield a smooth trace.&lt;/p&gt;
&lt;p&gt;A 2nd draw from the MVN produces another set of points that connect to form a 2nd random trace with a different path but similar smoothness and scale to the first. In this way, the stacking of normal curves in the x dimension allows random draws to produce random curves of specified scale and smoothness. We tailor the covariance matrix to give us the scale and smoothness to produce a range of various possible curves that could plausibly be the function that we want. These are our priors.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;priors---random-traces-with-a-few-built-in-assumptions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Priors - Random Traces with a Few Built in Assumptions&lt;/h1&gt;
&lt;p&gt;We choose 50 Gaussians, 1 for each of the 50 desired partitions of the x range [0,10] that spans the region of interest.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_gaussians &amp;lt;- 50&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Partition the x range of interest with the number of partitions equal to the number of specified Gaussians.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x_tbl &amp;lt;- tibble(x = seq(from = 0, to = 10, length = n_gaussians))
x_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;ajikturiiq&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#ajikturiiq .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ajikturiiq .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ajikturiiq .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ajikturiiq .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ajikturiiq .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ajikturiiq .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ajikturiiq .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ajikturiiq .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ajikturiiq .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ajikturiiq .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ajikturiiq .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ajikturiiq .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#ajikturiiq .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ajikturiiq .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#ajikturiiq .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#ajikturiiq .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ajikturiiq .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#ajikturiiq .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ajikturiiq .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#ajikturiiq .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ajikturiiq .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ajikturiiq .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ajikturiiq .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ajikturiiq .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ajikturiiq .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#ajikturiiq .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ajikturiiq .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#ajikturiiq .gt_left {
  text-align: left;
}

#ajikturiiq .gt_center {
  text-align: center;
}

#ajikturiiq .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ajikturiiq .gt_font_normal {
  font-weight: normal;
}

#ajikturiiq .gt_font_bold {
  font-weight: bold;
}

#ajikturiiq .gt_font_italic {
  font-style: italic;
}

#ajikturiiq .gt_super {
  font-size: 65%;
}

#ajikturiiq .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;x&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0000000&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.2040816&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.4081633&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6122449&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.8163265&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..49&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;50&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;10.0000000&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;uniform-to-gaussian&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Uniform to Gaussian&lt;/h2&gt;
&lt;p&gt;This function draws y values from a standard normal distribution at any specified x location. We then plot and take a look.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;centered_norm_draws_fcn &amp;lt;- function(x_loc){
  temp &amp;lt;- tibble(x = x_loc, y = rnorm(600, 0, 1))
  return(temp)
}

pretty_norm_tbl &amp;lt;- x_tbl %&amp;gt;%
  mutate(y_draws = map(.x = x, .f = centered_norm_draws_fcn)) %&amp;gt;%
  select(-x) %&amp;gt;%
  unnest() 

pp1 &amp;lt;- pretty_norm_tbl %&amp;gt;%
  ggplot(aes(x = x, y = y)) +
  geom_jitter(size = .1, alpha = .4, width = .02, color = &amp;quot;limegreen&amp;quot;) 

pp2 &amp;lt;- pretty_norm_tbl %&amp;gt;%
  ggplot(aes(x = x, y = y)) +
  stat_halfeye(fill = &amp;quot;limegreen&amp;quot;, alpha = .5)

pp1 / pp2 + plot_annotation(
  title = &amp;#39;(Multivariate) Normal Distributions Positioned at Intervals on the X Axis&amp;#39;,
  subtitle = &amp;#39;Each Normal Distribution has mean = 0 and sd = 1&amp;#39;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-12-02-gaussian-process-regression-for-fea-designed-experiments-building-the-basics-in-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-distance-between-any-combination-of-points&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculate Distance Between any combination of points&lt;/h2&gt;
&lt;p&gt;The key idea to creating functions from random draws of a MVN is that points nearby each other are highly correlated while points farther away are less so. The distance() function (plgp library) calculates the distance of the partitioned x-range points from each other and outputs a matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_mat &amp;lt;- distance(x_tbl)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;interlude-a-little-nudge&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Interlude: A little nudge&lt;/h2&gt;
&lt;p&gt;We need to create a very small (negligible) numerical value to eventually add to the diagonal. This is a mathematical formality and things work fine without it in our simple case, but we add it here to be consistent with the reference materials. Don’t think too much about it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diag_jitter &amp;lt;- sqrt(.Machine$double.eps) 
diag_jitter&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.490116e-08&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;get-covariance-matrix-sigma&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get Covariance Matrix Sigma&lt;/h2&gt;
&lt;p&gt;We exponentiate the distances to give use the relationship between proximity of points to each other and their correlation. That’s all that is needed to make the covariance matrix!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sigma &amp;lt;- exp(-d_mat) + diag(diag_jitter, n_gaussians)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;draw-y-values&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Draw Y-Values&lt;/h2&gt;
&lt;p&gt;Draw 1 value each from a bunch of normal distributions linked by the covariance matrix described above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y_tbl &amp;lt;- tibble(y_draws = as.vector(rmvnorm(n = 1, mean = rep(0, length = nrow(x_tbl)), sigma = sigma))) 
y_tbl&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 50 x 1
##    y_draws
##      &amp;lt;dbl&amp;gt;
##  1   1.56 
##  2   1.49 
##  3   1.31 
##  4   1.08 
##  5   0.902
##  6   0.816
##  7   0.818
##  8   0.822
##  9   0.712
## 10   0.422
## # ... with 40 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;combine-the-xs-and-the-ys&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Combine the x’s and the y’s&lt;/h2&gt;
&lt;p&gt;Make a tibble to facilitate plotting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp_prior_tbl &amp;lt;- x_tbl %&amp;gt;%
  bind_cols(y_tbl)

gp_prior_tbl&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 50 x 2
##        x y_draws
##    &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 0       1.56 
##  2 0.204   1.49 
##  3 0.408   1.31 
##  4 0.612   1.08 
##  5 0.816   0.902
##  6 1.02    0.816
##  7 1.22    0.818
##  8 1.43    0.822
##  9 1.63    0.712
## 10 1.84    0.422
## # ... with 40 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-1-realization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot 1 Realization&lt;/h2&gt;
&lt;p&gt;By overlaying our randomly drawn points on the underlying Gaussians and connecting the dots, we see how the correlation matrix, based on distance in x, ensures that the points form a smooth but bumpy curve. The diagonal of the covariance matrix is 1, corresponding to ~95% of the green y values being between -2 and +2.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp_prior_tbl %&amp;gt;%
  ggplot(aes(x = x, y = y_draws)) +
  geom_jitter(data = pretty_norm_tbl, aes(x = x, y = y), size = .1, alpha = .4, width = .02, color = &amp;quot;limegreen&amp;quot;) +
  geom_point(size = 1, color = &amp;quot;black&amp;quot;, alpha = .7) +
  geom_line(color = &amp;quot;black&amp;quot;)+
  theme_classic() +
  labs(title = &amp;quot;Single Random Curve&amp;quot;,
        subtitle = &amp;quot;Created Using Random Draw From MVN Distribution&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-12-02-gaussian-process-regression-for-fea-designed-experiments-building-the-basics-in-r_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;define-function-to-make-a-random-trace&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Define Function to Make a Random Trace&lt;/h2&gt;
&lt;p&gt;The above steps are converted to a function so that we can repeat our draws easily and create many traces.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;generate_y_fcn &amp;lt;- function(sim_number){
  
x &amp;lt;- seq(from = 0, to = 10, length = n_gaussians)
d &amp;lt;- distance(x)
dj &amp;lt;- sqrt(.Machine$double.eps) 
sig &amp;lt;- exp(-d) + diag(dj, n_gaussians)
y &amp;lt;- tibble(x = x,
            y_draws = as.vector(rmvnorm(n = 1, mean = rep(0, length = length(x)), sigma = sig)),
            sim_number = sim_number)
return(y)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;map-the-function-over-a-setup-tbl-to-create-multiple-traces&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Map the Function Over a Setup Tbl to Create Multiple Traces&lt;/h2&gt;
&lt;p&gt;Generate and plot 12 instances of random curves over the background of Gaussians.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_sim_traces &amp;lt;- 12

multi_trace_prior_tbl &amp;lt;- tibble(trace_num = seq(from = 1, to = n_sim_traces, by = 1) %&amp;gt;% as_factor()) %&amp;gt;%
  mutate(dat = map(.x = trace_num, .f = generate_y_fcn)) %&amp;gt;%
  unnest() 

multi_trace_prior_tbl %&amp;gt;% 
  ggplot(aes(x = x, y = y_draws)) +
  geom_jitter(data = pretty_norm_tbl, aes(x = x, y = y), size = .1, alpha = .9, width = .02, color = &amp;quot;grey&amp;quot;) +
  geom_line(aes(color = trace_num), size = 1.3, alpha = .7) +
  geom_point(size = 1) +
  theme_classic() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  scale_color_viridis_d(option = &amp;quot;Plasma&amp;quot;) +
  labs(title = &amp;quot;Multiple Curves Representing Prior Possibilities&amp;quot;,
       subtitle = &amp;quot;Created Using Random Draw From MVN Distribution&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-12-02-gaussian-process-regression-for-fea-designed-experiments-building-the-basics-in-r_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Cool! We explored a clever way to create random functions from multi-normal draws and we specified a covariance matrix the controls the bumpiness and y-scale. Our priors are in place.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conditioning-and-predicting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conditioning and Predicting&lt;/h1&gt;
&lt;p&gt;There’s one important aspect of drawing the random points this way that I haven’t yet discussed: by using a multivariate normal distribution, we make available a formal way of conditioning on the data and updating the parameters of our normal curves based on their location in x.&lt;/p&gt;
&lt;p&gt;Put another way, the model has a way to learn from the data and modify the mean and variance of each normal distribution in the MVN. This does the job of reducing the range of credible curves that are consistent with the data. This process is consistent with the Bayesian workflow of starting with priors, conditioning on data, and producing a posterior of jointly credible possibilities.&lt;/p&gt;
&lt;p&gt;The derivations for how this works are beyond the scope of this post (and I wouldn’t be a good candidate to explain them well), but they are available &lt;a href=&#34;https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Conditional_distributions&#34;&gt;HERE&lt;/a&gt;. The TLDR is this: we need the following component parts to be able to update our estimates of the mean and variance of each Gaussian, which in turn decreases the dispersion of our randomly generated traces and thereby increases the precision of our predictions.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-12-02-gaussian-process-regression-for-fea-designed-experiments-building-the-basics-in-r_files/joint_predictive_equations_annotated.png&#34; style=&#34;width:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The code that follows goes about constructing each of the component parts in the above equations that will facilitate our predictions.&lt;/p&gt;
&lt;div id=&#34;the-data-points&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Data Points&lt;/h2&gt;
&lt;p&gt;Generate a set of n=8 data point. In practice these would be supplied to us via an experiment or some other means.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_dat &amp;lt;- 8
x_dat &amp;lt;- matrix(seq(0, 2*pi, length=n_dat), ncol=1)
y_dat &amp;lt;- sin(x_dat)

data_tbl &amp;lt;- tibble(x = x_dat, 
                   y = y_dat)

data_tbl %&amp;gt;%
  gt()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;rsxfjhkhtr&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#rsxfjhkhtr .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#rsxfjhkhtr .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#rsxfjhkhtr .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#rsxfjhkhtr .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#rsxfjhkhtr .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rsxfjhkhtr .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#rsxfjhkhtr .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#rsxfjhkhtr .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#rsxfjhkhtr .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#rsxfjhkhtr .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#rsxfjhkhtr .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#rsxfjhkhtr .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#rsxfjhkhtr .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#rsxfjhkhtr .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#rsxfjhkhtr .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#rsxfjhkhtr .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#rsxfjhkhtr .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#rsxfjhkhtr .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#rsxfjhkhtr .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#rsxfjhkhtr .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#rsxfjhkhtr .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#rsxfjhkhtr .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#rsxfjhkhtr .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rsxfjhkhtr .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#rsxfjhkhtr .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#rsxfjhkhtr .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#rsxfjhkhtr .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#rsxfjhkhtr .gt_left {
  text-align: left;
}

#rsxfjhkhtr .gt_center {
  text-align: center;
}

#rsxfjhkhtr .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#rsxfjhkhtr .gt_font_normal {
  font-weight: normal;
}

#rsxfjhkhtr .gt_font_bold {
  font-weight: bold;
}

#rsxfjhkhtr .gt_font_italic {
  font-style: italic;
}

#rsxfjhkhtr .gt_super {
  font-size: 65%;
}

#rsxfjhkhtr .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;x&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;y&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_center&#34;&gt;0.0000000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;0.000000e+00&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_center&#34;&gt;0.8975979&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;7.818315e-01&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_center&#34;&gt;1.7951958&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;9.749279e-01&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_center&#34;&gt;2.6927937&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;4.338837e-01&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_center&#34;&gt;3.5903916&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;-4.338837e-01&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_center&#34;&gt;4.4879895&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;-9.749279e-01&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_center&#34;&gt;5.3855874&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;-7.818315e-01&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_center&#34;&gt;6.2831853&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;-2.449213e-16&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;calculating-the-necessary-distances-and-covariance-matrices&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculating the Necessary Distances and Covariance Matrices&lt;/h2&gt;
&lt;div id=&#34;calculate-inverse-of-covariance-matrix-between-x-values-in-vector-of-training-data-observed-datapoints&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Calculate: Inverse of Covariance matrix between x values in vector of training data (observed datapoints):&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_dat &amp;lt;- distance(x_dat) 
sigma_dat &amp;lt;- exp(-d_dat) + diag(diag_jitter, ncol(d_dat))
inv_sigma_dat &amp;lt;- solve(sigma_dat) #solve() finds inverse&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-covariance-matrix-between-x-values-in-vector-of-desired-test-points-the-x-range-of-interest-where-the-gaussians-are-positioned&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Calculate: Covariance matrix between x values in vector of desired test points (the x range of interest where the Gaussians are positioned):&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x_pred_range &amp;lt;- matrix(seq(-0.5, 2*pi + 0.5, length=100), ncol=1)

d_x_pred_range &amp;lt;- distance(x_pred_range)
sigma_x_pred_range &amp;lt;- exp(-d_x_pred_range) + diag(diag_jitter, ncol(d_x_pred_range))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-covariance-matrix-between-x-values-in-vector-of-training-data-observed-datapoints-and-x-values-in-vector-of-desired-test-points-the-x-range-of-interest-where-the-gaussians-are-positioned&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Calculate: Covariance matrix between x values in vector of training data (observed datapoints) and x values in vector of desired test points (the x range of interest where the Gaussians are positioned ):&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_x_dat &amp;lt;- distance(x_pred_range, x_dat)
sigma_x_dat &amp;lt;- exp(-d_x_dat) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;combine-per-the-conditioning-equations-above&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Combine Per the Conditioning Equations Above&lt;/h2&gt;
&lt;p&gt;Bring it together by combining the above inputs into the predictive equations. The output will be trained means and (reduced) variances from which to draw new points to create new traces.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mu_pred &amp;lt;- sigma_x_dat %*% inv_sigma_dat %*% y_dat

sigma_pred &amp;lt;- sigma_x_pred_range - sigma_x_dat %*% inv_sigma_dat %*% t(sigma_x_dat)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;draw-from-the-updated-gaussians&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Draw from the Updated Gaussians&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y_draws &amp;lt;- rmvnorm(1, mu_pred, sigma_pred)

y_draws %&amp;gt;% as.vector()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1] -0.11135178 -0.13414543 -0.14125646 -0.13384335 -0.11310097 -0.08032221
##   [7] -0.03869301  0.01008520  0.06426747  0.12167776  0.18125818  0.24235780
##  [13]  0.30473905  0.36878655  0.43483034  0.50286496  0.57276290  0.64341048
##  [19]  0.71394154  0.78186652  0.84577472  0.90297749  0.95168825  0.99017006
##  [25]  1.01800993  1.03518813  1.04214564  1.04042284  1.03171212  1.01776905
##  [31]  0.99957608  0.97924481  0.95714576  0.93327439  0.90739967  0.87885348
##  [37]  0.84624283  0.80916023  0.76606525  0.71690098  0.66145810  0.59996973
##  [43]  0.53349461  0.46304360  0.38937083  0.31415990  0.23807037  0.16243279
##  [49]  0.08706189  0.01247238 -0.06049590 -0.13256227 -0.20299983 -0.27120336
##  [55] -0.33690887 -0.39869342 -0.45653362 -0.50974602 -0.55842531 -0.60249705
##  [61] -0.64369848 -0.68291472 -0.72150414 -0.76086850 -0.80247216 -0.84637868
##  [67] -0.89223759 -0.93883876 -0.98369467 -1.02455925 -1.05798305 -1.08237703
##  [73] -1.09435116 -1.09289825 -1.07770612 -1.04977391 -1.00965956 -0.96046396
##  [79] -0.90481696 -0.84427854 -0.78205657 -0.71951229 -0.65718008 -0.59550566
##  [85] -0.53379511 -0.47180457 -0.40834782 -0.34347059 -0.27688415 -0.20952401
##  [91] -0.14200053 -0.07558342 -0.01236511  0.04618189  0.09857431  0.14360497
##  [97]  0.18013374  0.20735434  0.22425309  0.23046425&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-the-draws&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot the Draws&lt;/h2&gt;
&lt;p&gt;Plot the single trace drawn from posterior.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = x_pred_range,
       y = as.vector(y_draws)) %&amp;gt;%
  ggplot(aes(x = x, y = y)) +
  geom_point(color = &amp;quot;purple&amp;quot;) +
  geom_line(color = &amp;quot;purple&amp;quot;) +
  labs(title = &amp;quot;Single Trace Generated from Draws of Posterior&amp;quot;,
       subtitle = &amp;quot;Gaussians conditioned on n=8 data points&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-12-02-gaussian-process-regression-for-fea-designed-experiments-building-the-basics-in-r_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;function-for-many-posterior-draws&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Function for Many Posterior Draws&lt;/h2&gt;
&lt;p&gt;Now that we’ve shown how to create a set of draws to construct a posterior trace, let’s make it a function so that we can plot many traces. The function below is just all the same steps of the last section but combined into a tibble as the last step. This let’s us map the function easily as we expand the simulation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;generate_ypred_fcn &amp;lt;- function(sim_number){

#distance and sigma
d_dat &amp;lt;- distance(x_dat) 
sigma_dat &amp;lt;- exp(-d_dat) + diag(diag_jitter, ncol(d_dat))

#x range
x_pred_range &amp;lt;- matrix(seq(-0.5, 2*pi + 0.5, length=50), ncol=1)

#x point distance and sigma
d_x_pred_range &amp;lt;- distance(x_pred_range)
sigma_x_pred_range &amp;lt;- exp(-d_x_pred_range) + diag(diag_jitter, ncol(d_x_pred_range))

#distance and sigma between x points and x data points
d_x_dat &amp;lt;- distance(x_pred_range, x_dat)
sigma_x_dat &amp;lt;- exp(-d_x_dat) 

#inverse sigma for distance between x data points
inv_sigma_dat &amp;lt;- solve(sigma_dat)

#mu and sigma pred
mu_pred &amp;lt;- sigma_x_dat %*% inv_sigma_dat %*% y_dat
sigma_pred &amp;lt;- sigma_x_pred_range - sigma_x_dat %*% inv_sigma_dat %*% t(sigma_x_dat)

#y preds at x pred range points
y_draws &amp;lt;- rmvnorm(1, mu_pred, sigma_pred)

y &amp;lt;- tibble(x = x_pred_range,
            mu_y_pred = as.vector(mu_pred),
            y_draws = as.vector(rmvnorm(n = 1, mean = mu_pred, sigma = sigma_pred)),
            sim_number = sim_number)
return(y)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;generate-many-draws-for-posterior-traces&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Generate Many Draws for Posterior Traces&lt;/h2&gt;
&lt;p&gt;Simply specify the number of desired traces and use the newly created function to start drawing that many from the MVN.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_sim_traces &amp;lt;- 500

multi_trace_post_tbl &amp;lt;- tibble(trace_num = seq(from = 1, to = n_sim_traces, by = 1) %&amp;gt;% as_factor()) %&amp;gt;%
  mutate(dat = map(.x = trace_num, .f = generate_ypred_fcn)) %&amp;gt;%
  unnest() %&amp;gt;%
  select(-sim_number)

multi_trace_post_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;emmwxbyhsn&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#emmwxbyhsn .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#emmwxbyhsn .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#emmwxbyhsn .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#emmwxbyhsn .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#emmwxbyhsn .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#emmwxbyhsn .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#emmwxbyhsn .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#emmwxbyhsn .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#emmwxbyhsn .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#emmwxbyhsn .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#emmwxbyhsn .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#emmwxbyhsn .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#emmwxbyhsn .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#emmwxbyhsn .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#emmwxbyhsn .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#emmwxbyhsn .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#emmwxbyhsn .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#emmwxbyhsn .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#emmwxbyhsn .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#emmwxbyhsn .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#emmwxbyhsn .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#emmwxbyhsn .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#emmwxbyhsn .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#emmwxbyhsn .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#emmwxbyhsn .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#emmwxbyhsn .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#emmwxbyhsn .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#emmwxbyhsn .gt_left {
  text-align: left;
}

#emmwxbyhsn .gt_center {
  text-align: center;
}

#emmwxbyhsn .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#emmwxbyhsn .gt_font_normal {
  font-weight: normal;
}

#emmwxbyhsn .gt_font_bold {
  font-weight: bold;
}

#emmwxbyhsn .gt_font_italic {
  font-style: italic;
}

#emmwxbyhsn .gt_super {
  font-size: 65%;
}

#emmwxbyhsn .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;trace_num&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;x&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;mu_y_pred&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;y_draws&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;-0.50000000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-0.15088553&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-0.41433594&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;-0.35136357&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-0.13638869&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-0.23805775&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;-0.20272713&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-0.09766208&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-0.10048631&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;-0.05409070&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-0.03122685&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-0.01702983&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;0.09454574&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.06321976&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.01810016&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..24999&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;25000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;500&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;6.78318531&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.15088553&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.45732248&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualize&lt;/h2&gt;
&lt;p&gt;Structuring the data this way allows for plotting many traces of the posterior draws. In the figure below, the black line represents predictions, the red points are the training data, and the “bubbles” represent uncertainty. Notice how the uncertainty collapses near the observed data - just like we would want for FEA!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;multi_trace_post_tbl %&amp;gt;% 
  ggplot(aes(x = x, y = y_draws)) +
  geom_line(aes(color = trace_num)) +
  geom_line(aes(x = x, y = mu_y_pred), size = 2) +
  geom_point(size = .5) +
  geom_point(dat = data_tbl, aes(x = x, y = y), size = 4, color = &amp;quot;firebrick&amp;quot;) +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  scale_color_viridis_d() +
  labs(title = &amp;quot;Credible Posterior Traces&amp;quot;,
       subtitle = &amp;quot;Gaussians trained on n=8 data points&amp;quot;,
       caption = &amp;quot;Red points are observed data\nBlack line is predictions&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-12-02-gaussian-process-regression-for-fea-designed-experiments-building-the-basics-in-r_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;more-visualize&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;More Visualize&lt;/h2&gt;
&lt;p&gt;Just for fun, let’s just observe how the Gaussians collapse from prior to posterior, based on the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x_pred_range_new &amp;lt;- matrix(seq(-0.5, 2*pi + 0.5, length=50), ncol=1)

pretty_norm_tbl_2 &amp;lt;- tibble(x = x_pred_range_new) %&amp;gt;%
  mutate(y_draws = map(.x = x, .f = centered_norm_draws_fcn)) %&amp;gt;%
  select(-x) %&amp;gt;%
  unnest() 

prior_gaussians &amp;lt;- pretty_norm_tbl_2 %&amp;gt;% 
  ggplot(aes(x = x, y = y)) +
  geom_jitter(size = .1, alpha = .4, width = .01, color = &amp;quot;limegreen&amp;quot;) 


post_gaussians &amp;lt;- multi_trace_post_tbl %&amp;gt;% 
  ggplot(aes(x = x, y = y_draws)) +
  geom_jitter(size = .1, alpha = .4, width = .01, color = &amp;quot;firebrick&amp;quot;) +
  geom_point(dat = data_tbl, aes(x = x, y = y), size = 2, color = &amp;quot;black&amp;quot;) 

prior_gaussians / post_gaussians +
  plot_annotation(title = &amp;quot;Gaussian Process Regression&amp;quot;,
                  subtitle = &amp;quot;Image represents stacking of multivariate normal dimensions across an X-range of interest&amp;quot;,
                  caption = &amp;quot;Upper Panel: Prior\nLower Panel: Posterior&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-12-02-gaussian-process-regression-for-fea-designed-experiments-building-the-basics-in-r_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In this walk through we built up a Gaussian Process Regression model from scratch and showed how to train it and use it for predictions. I hope I was able to communicate the unique features of this model type: specifying priors over a range of many different functions, building and training a large multi-variate normal distribution to create credible functions across a range of interest, and representing uncertainty while still collapsing on the observed data. In a future post I promise we’ll circle back to the unique use-case that was the motivation for my learning in the first place: fitting a GPR to FEA generated DOE data. If you’ve made it this far, thank you for your attention.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sessioninfo&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;sessionInfo&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.3 (2020-10-10)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18363)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] patchwork_1.1.1 tidybayes_3.0.2 plgp_1.1-10     tgp_2.4-18     
##  [5] mvtnorm_1.1-3   gt_0.3.1        here_1.0.1      forcats_0.5.1  
##  [9] stringr_1.4.0   dplyr_1.0.7     purrr_0.3.4     readr_2.1.1    
## [13] tidyr_1.1.4     tibble_3.1.6    ggplot2_3.3.5   tidyverse_1.3.1
## 
## loaded via a namespace (and not attached):
##  [1] fs_1.5.2             lubridate_1.8.0      httr_1.4.2          
##  [4] rprojroot_2.0.2      tensorA_0.36.2       tools_4.0.3         
##  [7] backports_1.4.1      bslib_0.3.1          utf8_1.2.2          
## [10] R6_2.5.1             rpart_4.1-15         DBI_1.1.2           
## [13] colorspace_2.0-2     ggdist_3.0.1         withr_2.4.3         
## [16] tidyselect_1.1.1     compiler_4.0.3       cli_3.1.0           
## [19] rvest_1.0.2          arrayhelpers_1.1-0   xml2_1.3.3          
## [22] labeling_0.4.2       bookdown_0.21        posterior_1.2.0     
## [25] sass_0.4.0           scales_1.1.1         checkmate_2.0.0     
## [28] digest_0.6.28        rmarkdown_2.11       pkgconfig_2.0.3     
## [31] htmltools_0.5.2      highr_0.9            dbplyr_2.1.1        
## [34] fastmap_1.1.0        rlang_0.4.11         readxl_1.3.1        
## [37] rstudioapi_0.13      jquerylib_0.1.4      farver_2.1.0        
## [40] generics_0.1.1       svUnit_1.0.6         jsonlite_1.7.2      
## [43] distributional_0.3.0 magrittr_2.0.1       Rcpp_1.0.7          
## [46] munsell_0.5.0        fansi_0.5.0          maptree_1.4-8       
## [49] abind_1.4-5          lifecycle_1.0.1      stringi_1.7.4       
## [52] yaml_2.2.1           grid_4.0.3           crayon_1.4.2        
## [55] lattice_0.20-45      haven_2.4.3          hms_1.1.1           
## [58] knitr_1.34           pillar_1.6.4         reprex_2.0.1        
## [61] glue_1.6.0           evaluate_0.14        blogdown_0.15       
## [64] modelr_0.1.8         vctrs_0.3.8          tzdb_0.2.0          
## [67] cellranger_1.1.0     gtable_0.3.0         assertthat_0.2.1    
## [70] xfun_0.29            broom_0.7.11         coda_0.19-4         
## [73] viridisLite_0.4.0    cluster_2.1.2        ellipsis_0.3.2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://bookdown.org/rbg/surrogates/&#34; class=&#34;uri&#34;&gt;https://bookdown.org/rbg/surrogates/&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Power Analysis for a DV Test - Frequentist and Bayesian Estimation in R </title>
      <link>/post/power-analysis-for-a-dv-test-frequentist-and-bayesian-estimation-in-r/</link>
      <pubDate>Thu, 17 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/power-analysis-for-a-dv-test-frequentist-and-bayesian-estimation-in-r/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;When testing is costly or resource intensive, it’s not uncommon for management to ask an engineer “what are the chances that we pass?”. The answer will depend on the team’s collection of domain knowledge around the product and requirement but also in how the question is interpreted. It will also be sensitive to sample size considerations. In this post, I will show how to conduct an analysis to inform the response from both a Frequentist and Bayesian perspective. Simulation will be used whenever possible to avoid the need for external references and the predictions will be used to inform a recommendation of sample size.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#libraries&#34;&gt;Libraries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#background-and-requirements&#34;&gt;Background and Requirements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#assumptions-and-plan&#34;&gt;Assumptions and Plan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#predicate-data&#34;&gt;Predicate Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#frequentist&#34;&gt;Frequentist&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#simulated-experiments-with-a-single-set-of-assumed-parameters&#34;&gt;Simulated experiments with a single set of assumed parameters&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#simulate-the-data&#34;&gt;Simulate the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#calculate-frequency-of-success&#34;&gt;Calculate Frequency of Success&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualize&#34;&gt;Visualize&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#nested-simulation-with-many-sets-of-parameters&#34;&gt;Nested Simulation with Many Sets of Parameters&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#simulated-the-data&#34;&gt;Simulated the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#calculate-frequency-of-success&#34;&gt;Calculate Frequency of Success&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualize---power-curves&#34;&gt;Visualize - Power Curves&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bayesian&#34;&gt;Bayesian&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#priors&#34;&gt;Priors&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#specify-priors&#34;&gt;Specify Priors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualize-prior-pred&#34;&gt;Visualize Prior Pred&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data&#34;&gt;Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#specify-data&#34;&gt;Specify Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#likelihood-and-model-fitting&#34;&gt;Likelihood and Model Fitting&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#fit-model-with-brms&#34;&gt;Fit Model with brms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualize-chains-and-posterior&#34;&gt;Visualize Chains and Posterior&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#examine-posterior-draws&#34;&gt;Examine Posterior Draws&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#use-posterior-to-estimate-probability-of-passing-with-various-sample-sizes&#34;&gt;Use Posterior to Estimate Probability of Passing with Various Sample Sizes&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#simulate-the-data&#34;&gt;Simulate the Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#aggregate-probability-of-passing-by-sample-size&#34;&gt;Aggregate Probability of Passing by Sample Size&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sessioninfo&#34;&gt;SessionInfo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;libraries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Libraries&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(tolerance)
library(patchwork)
library(ggrepel)
library(gt)
library(ggExtra)
library(brms)
library(here)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;background-and-requirements&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background and Requirements&lt;/h2&gt;
&lt;p&gt;We need some sort of performance test for this toy problem so let’s consider pitting corrosion resistance. Specifically, we are interested in data generated during cyclic potentiodynamic polarization (CPP) testing of a nitinol stent. The data is expressed as the difference between the breakdown potential Eb the rest potential Er, both relative to a reference electrode. The magnitude of this difference corresponds to the expected corrosion resistance in the body with larger values being better.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions-and-plan&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions and Plan&lt;/h2&gt;
&lt;p&gt;We’ll assume that our device has 1-sided, lower spec limit of &lt;em&gt;+300 mV&lt;/em&gt; as a requirement. We’ll also assume that based on our risk analysis procedure, pitting corrosion falls in a zone mandating that at least 90% of the population will meet the requirement with 90% confidence. Thus, we need to use our test data to create a 1-sided, 90/90 tolerance interval to compare against the requirements. If you are unfamiliar with tolerance intervals, refer to &lt;a href=&#34;https://rileyking.netlify.app/post/exploring-frequentist-and-bayesian-tolerance-intervals-in-r/&#34;&gt;this older post of mine&lt;/a&gt;. We’ll also assume that the default sample size would be n=9, chosen somewhat arbitrarily (we’ll consider other sample sizes later on).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;predicate-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Predicate Data&lt;/h2&gt;
&lt;p&gt;We would never go into any late-stage testing without some directional data from pilot studies or predicate devices. These data are usually sparse and they come with caveats, but they inform the range or possible expectations. In this example, let’s assume we have n=3 data points from early feasibility testing of a early prototype for our product. We’ll throw them into a table and then quickly check some summary stats. From testing other products and reviewing literature, we also know that the population of Eb - Er data for a particular configuration tend to be normally distributed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;legacy_data_tbl &amp;lt;- tibble(eb_minus_er = c(424, 543, 571))

sum_data &amp;lt;- legacy_data_tbl %&amp;gt;%
  summarize(mean = mean(eb_minus_er),
            sd = sd(eb_minus_er)) %&amp;gt;%
  mutate(across(is.numeric, round, digits = 1))

sum_data %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;cxrtutiaur&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#cxrtutiaur .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#cxrtutiaur .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#cxrtutiaur .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#cxrtutiaur .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#cxrtutiaur .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#cxrtutiaur .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#cxrtutiaur .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#cxrtutiaur .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#cxrtutiaur .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#cxrtutiaur .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#cxrtutiaur .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#cxrtutiaur .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#cxrtutiaur .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#cxrtutiaur .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#cxrtutiaur .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#cxrtutiaur .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#cxrtutiaur .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#cxrtutiaur .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#cxrtutiaur .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#cxrtutiaur .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#cxrtutiaur .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#cxrtutiaur .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#cxrtutiaur .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#cxrtutiaur .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#cxrtutiaur .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#cxrtutiaur .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#cxrtutiaur .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#cxrtutiaur .gt_left {
  text-align: left;
}

#cxrtutiaur .gt_center {
  text-align: center;
}

#cxrtutiaur .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#cxrtutiaur .gt_font_normal {
  font-weight: normal;
}

#cxrtutiaur .gt_font_bold {
  font-weight: bold;
}

#cxrtutiaur .gt_font_italic {
  font-style: italic;
}

#cxrtutiaur .gt_super {
  font-size: 65%;
}

#cxrtutiaur .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;mean&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sd&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;512.7&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;78.1&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;frequentist&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Frequentist&lt;/h2&gt;
&lt;div id=&#34;simulated-experiments-with-a-single-set-of-assumed-parameters&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Simulated experiments with a single set of assumed parameters&lt;/h3&gt;
&lt;p&gt;For the Frequentist simulation, our plan is to specify the parameters of the assumed population and then repeat a simulated experiment may times. For each rep of the sim we assess the resultant tolerance limit against the requirement. This tells us the long-run frequency (interpreted as probability in the frequentist framework) of passing the test based on our experimental setup and the assumed parameters. Later on, we can adjust the sample size or the assumed population parameters to see how our chance of passing is affected.&lt;/p&gt;
&lt;p&gt;Let’s do 1 full simulation using a sample size of n=9 and a mean and sd taken from our predicate data shown above.&lt;/p&gt;
&lt;div id=&#34;simulate-the-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Simulate the Data&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reps &amp;lt;- 1000
set.seed(127)
n &amp;lt;- 9


single_sim_tbl &amp;lt;- 
  tibble(
  n = n,
  mean = sum_data$mean, #mean from predicate data
  sd = sum_data$sd) %&amp;gt;% #ds from predicate data
  slice(rep(1:n(), each = reps)) %&amp;gt;%
  mutate(replicate = seq(from = 1, to = reps)) %&amp;gt;%
  mutate(sim_data = pmap(.l = list(n = n, mean = mean, sd = sd), .f = rnorm)) %&amp;gt;% #create the random data points, n=9 per sim
  unnest() %&amp;gt;%
  group_by(mean, sd, replicate) %&amp;gt;%
  summarize(ltl = normtol.int(sim_data, P = .9, alpha = .1)) %&amp;gt;% #calculate 90/90 tolerance interval
  unnest() %&amp;gt;%
  ungroup() %&amp;gt;%
  rename(ltl = &amp;quot;1-sided.lower&amp;quot;) %&amp;gt;%
  select(1:7) %&amp;gt;%
  mutate(fail = case_when( 
    ltl &amp;lt;= 300 ~ 1,
    TRUE ~ 0)) %&amp;gt;% #flag failures
  mutate(across(c(x.bar, ltl), round, digits = 1))


single_sim_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;pdrxpyqqcj&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#pdrxpyqqcj .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#pdrxpyqqcj .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#pdrxpyqqcj .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#pdrxpyqqcj .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#pdrxpyqqcj .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#pdrxpyqqcj .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#pdrxpyqqcj .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#pdrxpyqqcj .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#pdrxpyqqcj .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#pdrxpyqqcj .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#pdrxpyqqcj .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#pdrxpyqqcj .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#pdrxpyqqcj .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#pdrxpyqqcj .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#pdrxpyqqcj .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#pdrxpyqqcj .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#pdrxpyqqcj .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#pdrxpyqqcj .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#pdrxpyqqcj .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#pdrxpyqqcj .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#pdrxpyqqcj .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#pdrxpyqqcj .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#pdrxpyqqcj .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#pdrxpyqqcj .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#pdrxpyqqcj .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#pdrxpyqqcj .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#pdrxpyqqcj .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#pdrxpyqqcj .gt_left {
  text-align: left;
}

#pdrxpyqqcj .gt_center {
  text-align: center;
}

#pdrxpyqqcj .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#pdrxpyqqcj .gt_font_normal {
  font-weight: normal;
}

#pdrxpyqqcj .gt_font_bold {
  font-weight: bold;
}

#pdrxpyqqcj .gt_font_italic {
  font-style: italic;
}

#pdrxpyqqcj .gt_super {
  font-size: 65%;
}

#pdrxpyqqcj .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;mean&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sd&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;replicate&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;alpha&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;P&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;x.bar&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;ltl&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;fail&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;512.7&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;78.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;522.5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;410.0&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;512.7&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;78.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;515.5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;437.0&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;512.7&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;78.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;480.4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;283.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;512.7&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;78.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;518.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;315.8&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;512.7&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;78.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;510.8&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;353.5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..999&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;512.7&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;78.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;493.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;286.8&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-frequency-of-success&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Calculate Frequency of Success&lt;/h4&gt;
&lt;p&gt;Having generated and stored the above simulation, it is straightforward to calculate the predicted success rate. We see that the long run frequency of success is 84%, conditional on all of our strict assumptions about population parameters and fixed sample size:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;single_sim_tbl %&amp;gt;%
  summarize(total_simulated_experiments = n(),
            sum_pass = n() - sum(fail)) %&amp;gt;%
  mutate(prop_pass = sum_pass/total_simulated_experiments) %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;ssgcfuqezb&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#ssgcfuqezb .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ssgcfuqezb .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ssgcfuqezb .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ssgcfuqezb .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ssgcfuqezb .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ssgcfuqezb .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ssgcfuqezb .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ssgcfuqezb .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ssgcfuqezb .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ssgcfuqezb .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ssgcfuqezb .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ssgcfuqezb .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#ssgcfuqezb .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ssgcfuqezb .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#ssgcfuqezb .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#ssgcfuqezb .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ssgcfuqezb .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#ssgcfuqezb .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ssgcfuqezb .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#ssgcfuqezb .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ssgcfuqezb .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ssgcfuqezb .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ssgcfuqezb .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ssgcfuqezb .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ssgcfuqezb .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#ssgcfuqezb .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ssgcfuqezb .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#ssgcfuqezb .gt_left {
  text-align: left;
}

#ssgcfuqezb .gt_center {
  text-align: center;
}

#ssgcfuqezb .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ssgcfuqezb .gt_font_normal {
  font-weight: normal;
}

#ssgcfuqezb .gt_font_bold {
  font-weight: bold;
}

#ssgcfuqezb .gt_font_italic {
  font-style: italic;
}

#ssgcfuqezb .gt_super {
  font-size: 65%;
}

#ssgcfuqezb .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;total_simulated_experiments&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sum_pass&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;prop_pass&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;844&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.844&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Visualize&lt;/h4&gt;
&lt;p&gt;Here we look at the means and lower tolerance limits (LTLs) from the simulation to help us gut check the conclusions and further understand what is going on.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;single_sim_tbl %&amp;gt;% 
  pivot_longer(cols = c(x.bar, ltl), names_to = &amp;quot;param&amp;quot;, values_to = &amp;quot;value&amp;quot;) %&amp;gt;%
  mutate(param = case_when(param == &amp;quot;x.bar&amp;quot; ~ &amp;quot;mean&amp;quot;,
                           TRUE ~ &amp;quot;lower_tolerance_limit&amp;quot;)) %&amp;gt;%
  ggplot(aes(x = param, y = value)) +
  geom_line(aes(group = replicate), size = .1, alpha = .1) +
  geom_jitter(aes(color = param), size = .4, alpha = .4, width = .01) +
  geom_hline(yintercept = 300, color = &amp;quot;firebrick&amp;quot;, linetype = 2) +
  theme_classic() +
  theme(legend.title=element_blank()) +
  labs(title = &amp;quot;Means and Lower Tolerance Limits for 1000 Simulated Experiments&amp;quot;,
       subtitle = &amp;quot;Each sim: n=9 data points draws from a normal distribution&amp;quot;,
       x = &amp;quot;&amp;quot;,
       y = &amp;quot;Eb - Er [mV SCE]&amp;quot;,
       caption = &amp;quot;red dotted line indicates lower spec limit&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-11-17-power-analysis-for-a-dv-test-frequentist-and-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And here we look by simulation run number and add the marginal distributions for mean and sd.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;int_plot &amp;lt;- single_sim_tbl %&amp;gt;%
  ggplot(aes(group = replicate)) +
  geom_segment(aes(x = replicate, y = x.bar, xend = replicate, yend = ltl), size = .2, alpha = .2) +
  geom_point(data = single_sim_tbl %&amp;gt;% 
               pivot_longer(cols = c(x.bar, ltl), names_to = &amp;quot;param&amp;quot;, values_to = &amp;quot;value&amp;quot;) %&amp;gt;%
               mutate(param = case_when(param == &amp;quot;x.bar&amp;quot; ~ &amp;quot;Sample Mean&amp;quot;, TRUE ~ &amp;quot;1-Sided Lower Tolerance Limit&amp;quot;)), 
               aes(x = replicate, y = value, color = param), size = .6) +
  geom_hline(yintercept = 300, linetype = 2, color = &amp;quot;firebrick&amp;quot;) +
  theme_classic() +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  labs(y = &amp;quot;Eb - Er (mV SCE)&amp;quot;,
       x = &amp;quot;Simulated Experiment Replicate Number&amp;quot;,
       title = &amp;quot;Means and Lower Tolerance Limits for 1000 Simulated Experiments&amp;quot;,
       subtitle = &amp;quot;Each sim: n=9 data points draws from a normal distribution&amp;quot;) +
  theme(legend.title=element_blank())

ggMarginal(int_plot,
  groupColour = TRUE,
  groupFill = TRUE,
  type = &amp;quot;density&amp;quot;,
  alpha = 0.7,
  margins = &amp;quot;y&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-11-17-power-analysis-for-a-dv-test-frequentist-and-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;nested-simulation-with-many-sets-of-parameters&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Nested Simulation with Many Sets of Parameters&lt;/h3&gt;
&lt;p&gt;The simulation above makes strict assumptions about the population parameters and uses only a single fixed sample size. we know intuitively that there is lot-to-lot variability and we have our choice of sample size, within reason, when we proceed with our eventual real-world test. Thus, what we really want to understand is the probability of success for a wide range of parameter assumptions and sample sizes. For that, we’ll need a more complex simulation.&lt;/p&gt;
&lt;p&gt;In the code below, a grid of possibilities is explored for potential values of mean, sd, and sample size. Each permutation is a nested simulation of n=1000. Ranges explored (the range for mean goes mostly lower and the range for sd goes mostly higher as we really want to understand what happens if our predicate data was overly optimistic):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mean: 300 to 500 mV&lt;/li&gt;
&lt;li&gt;sd: 75 to 179 mV&lt;/li&gt;
&lt;li&gt;n: 5 to 17 parts&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;simulated-the-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Simulated the Data&lt;/h4&gt;
&lt;p&gt;The workflow below is very similar to the single simulation section with a few exceptions. The expand_grid() function is what generated all combinations of the specified sequences for mean, sd, and n. slice() is used to copy and append rows, and a “scenario” column is added to track each permutation of the 3 variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2015)
reps &amp;lt;-  1000

mean = c(seq(from = 300, to = 500, by = 50), sum_data$mean)
sd = c(seq(from = 75, to = 175, by = 25), sum_data$sd)
n = seq(from = 5, to = 17, by = 2)

full_even_sim_tbl &amp;lt;-  expand_grid(mean, sd, n) %&amp;gt;%
  mutate(mean = mean %&amp;gt;% round(0),
         sd = sd %&amp;gt;% round(0)) %&amp;gt;%
  mutate(scenario = seq(from = 1, to = nrow(.))) %&amp;gt;%
  slice(rep(1:n(), each = reps)) %&amp;gt;%
  mutate(replicate_number = rep(seq(from = 1, to = reps), nrow(.)/reps)) %&amp;gt;%
  mutate(sim_data = pmap(.l = list(n = n, mean = mean, sd=sd), .f = rnorm)) %&amp;gt;%
  unnest(cols = everything()) %&amp;gt;%
  group_by(mean, sd, scenario, replicate_number, n) %&amp;gt;%
  summarize(ltl = normtol.int(sim_data, P = .9, alpha = .1)) %&amp;gt;%
  unnest(cols = everything()) %&amp;gt;%
  ungroup() %&amp;gt;%
  rename(ltl = &amp;#39;1-sided.lower&amp;#39;,
         utl = &amp;#39;1-sided.upper&amp;#39;) %&amp;gt;%
  mutate(fail = case_when(ltl &amp;lt;= 300 ~ 1,
         TRUE ~ 0))

full_even_sim_tbl %&amp;gt;% 
  mutate(across(c(x.bar, ltl, utl), round, digits = 1)) %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;teihcoazgx&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#teihcoazgx .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#teihcoazgx .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#teihcoazgx .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#teihcoazgx .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#teihcoazgx .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#teihcoazgx .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#teihcoazgx .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#teihcoazgx .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#teihcoazgx .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#teihcoazgx .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#teihcoazgx .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#teihcoazgx .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#teihcoazgx .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#teihcoazgx .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#teihcoazgx .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#teihcoazgx .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#teihcoazgx .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#teihcoazgx .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#teihcoazgx .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#teihcoazgx .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#teihcoazgx .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#teihcoazgx .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#teihcoazgx .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#teihcoazgx .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#teihcoazgx .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#teihcoazgx .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#teihcoazgx .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#teihcoazgx .gt_left {
  text-align: left;
}

#teihcoazgx .gt_center {
  text-align: center;
}

#teihcoazgx .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#teihcoazgx .gt_font_normal {
  font-weight: normal;
}

#teihcoazgx .gt_font_bold {
  font-weight: bold;
}

#teihcoazgx .gt_font_italic {
  font-style: italic;
}

#teihcoazgx .gt_super {
  font-size: 65%;
}

#teihcoazgx .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;mean&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sd&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;scenario&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;replicate_number&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;n&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;alpha&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;P&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;x.bar&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;ltl&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;utl&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;fail&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;300&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;75&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;258.4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;97.0&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;419.8&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;300&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;75&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;294.2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;58.8&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;529.6&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;300&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;75&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;323.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;172.7&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;473.4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;300&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;75&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;270.5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;90.4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;450.6&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;300&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;75&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;302.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;231.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;372.2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..251999&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;252000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;513&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;175&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;245&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;17&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;532.5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;191.6&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;873.4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-frequency-of-success-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Calculate Frequency of Success&lt;/h4&gt;
&lt;p&gt;Now, each scenario (combination of assumed mean, sd, and sample size) has its own probability (long run frequency) of passing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary_tbl &amp;lt;- full_even_sim_tbl %&amp;gt;%
  group_by(mean, sd, n, max(replicate_number)) %&amp;gt;%
  summarize(number_fail = sum(fail)) %&amp;gt;%
  rename(reps = &amp;#39;max(replicate_number)&amp;#39;) %&amp;gt;%
  mutate(avg = stringr::str_glue(&amp;quot;mean Eb-Er = {as_factor(mean)} mV [SCE]&amp;quot;)) %&amp;gt;%
  mutate(prop_pass = 1-(number_fail / reps)) %&amp;gt;%
  ungroup()

summary_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;vkukobschs&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#vkukobschs .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#vkukobschs .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vkukobschs .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#vkukobschs .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#vkukobschs .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vkukobschs .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vkukobschs .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#vkukobschs .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#vkukobschs .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#vkukobschs .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#vkukobschs .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#vkukobschs .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#vkukobschs .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#vkukobschs .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#vkukobschs .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#vkukobschs .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#vkukobschs .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#vkukobschs .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vkukobschs .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#vkukobschs .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vkukobschs .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#vkukobschs .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#vkukobschs .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vkukobschs .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vkukobschs .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#vkukobschs .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vkukobschs .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#vkukobschs .gt_left {
  text-align: left;
}

#vkukobschs .gt_center {
  text-align: center;
}

#vkukobschs .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#vkukobschs .gt_font_normal {
  font-weight: normal;
}

#vkukobschs .gt_font_bold {
  font-weight: bold;
}

#vkukobschs .gt_font_italic {
  font-style: italic;
}

#vkukobschs .gt_super {
  font-size: 65%;
}

#vkukobschs .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;mean&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sd&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;n&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;reps&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;number_fail&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;avg&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;prop_pass&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;300&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;75&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;997&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;mean Eb-Er = 300 mV [SCE]&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.003&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;300&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;75&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;7&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;mean Eb-Er = 300 mV [SCE]&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.000&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;300&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;75&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;mean Eb-Er = 300 mV [SCE]&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.000&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;300&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;75&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;11&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;mean Eb-Er = 300 mV [SCE]&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.000&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;300&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;75&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;13&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;mean Eb-Er = 300 mV [SCE]&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.000&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..251&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;252&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;513&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;175&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;17&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;938&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;mean Eb-Er = 513 mV [SCE]&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.062&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize---power-curves&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Visualize - Power Curves&lt;/h4&gt;
&lt;p&gt;Plotting these data produce so-called power curves from which we can easily see trends for probability of passing based on the parameter assumptions and our choice of sample size. Constructing these curves provide a principled way to select a reasonable sample size.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary_tbl %&amp;gt;%
  ggplot(aes(x = sd, y = prop_pass)) +
  geom_point(aes(color = as_factor(n))) +
  geom_line(aes(color = as_factor(n))) +
  geom_vline(xintercept = sum_data$sd, color = &amp;quot;firebrick&amp;quot;, linetype = 2) +
  facet_wrap(~ avg) +
  lims(x = c(75, 175)) +
  scale_color_discrete(name = &amp;quot;Sample Size&amp;quot;) +
#scale_color_viridis_d(option = &amp;quot;C&amp;quot;, end = .8) +
  labs(x = &amp;quot;Standard Deviation (mV [SCE])&amp;quot;,
       y = str_glue(&amp;quot;Passing Proportion\nBased on n={reps} simulations each&amp;quot;)) +
  theme_bw() +
  labs(title = &amp;quot;Predicted Power Curves for Simulated Corrosion Experiments&amp;quot;,
       subtitle = &amp;quot;as a function of mean, standard deviation, and sample size&amp;quot;,
       caption = &amp;quot;513 mV facet represents predicate mean, red dotted line represents predicate sd&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-11-17-power-analysis-for-a-dv-test-frequentist-and-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;
We note that at the lower means and higher sds we would have very low chance of passing.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bayesian&lt;/h2&gt;
&lt;p&gt;As engineers, we can look through the range of possible inputs and think about how plausible they might be based on our understanding of the product and domain. But there is no formal way to leverage that knowledge in the frequentist framework. For that, we need a Bayesian approach.&lt;/p&gt;
&lt;div id=&#34;priors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Priors&lt;/h3&gt;
&lt;p&gt;In the code below, we want to ask ourselves what values are reasonable for the parameters of interest. We happen to know from other devices and literature that the mean tends to fall in the 200-800 range. We select a t distribution on this parameter centered at 500 with a few degrees of freedom. This is conservative since it spreads our “belief” wider than a normal distribution, including more options in the tails. For the sd, we apply a uniform distribution over a generous range, making sure to keep all values positive.&lt;/p&gt;
&lt;div id=&#34;specify-priors&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Specify Priors&lt;/h4&gt;
&lt;p&gt;We put these into this table form because we’ll want to plot these curves to confirm visually that our assumptions make sense.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prior_pred_tbl &amp;lt;- tibble(
  mu = rstudent_t(n = 300, df = 3, mu = 500, sigma = 100),
  sig = runif(300, min = 20, max = 200) %&amp;gt;% abs()
) %&amp;gt;%
  mutate(row_id = row_number()) %&amp;gt;%
  select(row_id, everything()) %&amp;gt;%
  mutate(plotted_y_data = map2(mu, sig, ~ tibble(
    x = seq(-200, 1000, length.out = 10000),
    y = dnorm(x, .x, .y)
  ))) %&amp;gt;%
#  slice(1) %&amp;gt;%
  unnest() %&amp;gt;%
  mutate(model = &amp;quot;mu ~ student(3, 500, 100), sigma ~ unif(20,200)&amp;quot;)

prior_pred_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;mhnwryimjo&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#mhnwryimjo .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#mhnwryimjo .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#mhnwryimjo .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#mhnwryimjo .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#mhnwryimjo .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#mhnwryimjo .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#mhnwryimjo .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#mhnwryimjo .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#mhnwryimjo .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#mhnwryimjo .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#mhnwryimjo .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#mhnwryimjo .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#mhnwryimjo .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#mhnwryimjo .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#mhnwryimjo .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#mhnwryimjo .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#mhnwryimjo .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#mhnwryimjo .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#mhnwryimjo .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#mhnwryimjo .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#mhnwryimjo .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#mhnwryimjo .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#mhnwryimjo .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#mhnwryimjo .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#mhnwryimjo .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#mhnwryimjo .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#mhnwryimjo .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#mhnwryimjo .gt_left {
  text-align: left;
}

#mhnwryimjo .gt_center {
  text-align: center;
}

#mhnwryimjo .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#mhnwryimjo .gt_font_normal {
  font-weight: normal;
}

#mhnwryimjo .gt_font_bold {
  font-weight: bold;
}

#mhnwryimjo .gt_font_italic {
  font-style: italic;
}

#mhnwryimjo .gt_super {
  font-size: 65%;
}

#mhnwryimjo .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;row_id&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;mu&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sig&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;x&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;y&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;model&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;399.9662&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;134.5556&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-200.00&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.428195e-07&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;mu ~ student(3, 500, 100), sigma ~ unif(20,200)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;399.9662&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;134.5556&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-199.88&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.433886e-07&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;mu ~ student(3, 500, 100), sigma ~ unif(20,200)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;399.9662&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;134.5556&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-199.76&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.439598e-07&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;mu ~ student(3, 500, 100), sigma ~ unif(20,200)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;399.9662&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;134.5556&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-199.64&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.445331e-07&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;mu ~ student(3, 500, 100), sigma ~ unif(20,200)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;399.9662&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;134.5556&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;-199.52&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.451087e-07&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;mu ~ student(3, 500, 100), sigma ~ unif(20,200)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..2999999&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3000000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;300&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;585.2949&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;29.1041&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000.00&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.118222e-46&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;mu ~ student(3, 500, 100), sigma ~ unif(20,200)&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize-prior-pred&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Visualize Prior Pred&lt;/h4&gt;
&lt;p&gt;This vis shows a variety of possible outcomes for Eb-Er before seeing the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prior_pred_tbl %&amp;gt;%
  ggplot(aes(x = x, y = y, group = row_id)) +
  geom_line(aes(x, y), size = .5, alpha = .2, color = &amp;quot;#2c3e50&amp;quot;) +
  labs(
    x = &amp;quot;mV [SCE]&amp;quot;,
    y = &amp;quot;&amp;quot;,
    title = &amp;quot;Prior Predictive Simulations&amp;quot;
  ) +
  theme_minimal() + theme(
  axis.text.y = element_blank(),
  axis.ticks.y = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-11-17-power-analysis-for-a-dv-test-frequentist-and-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data&lt;/h3&gt;
&lt;div id=&#34;specify-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Specify Data&lt;/h4&gt;
&lt;p&gt;We re-enter our legacy data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_tbl &amp;lt;- tibble(p = c(424, 543, 571))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;likelihood-and-model-fitting&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Likelihood and Model Fitting&lt;/h3&gt;
&lt;div id=&#34;fit-model-with-brms&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Fit Model with brms&lt;/h4&gt;
&lt;p&gt;Having specified our data and priors, we can assume a likelihood and brms can do the rest. Here we assume Gaussian (normal) for the likelihood of the data and copy our priors from the previous section. Once fit, we’ll have access to a posterior in table form comprised of credible values for the mean and sd for many possible normal distributions. This is similar to the grid of values we build manually in the frequentist section to generate power curve, but now now they are weighted by plausibility.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pa_mod_1 &amp;lt;-
 brm(
   data = p_tbl, family = gaussian,
   p ~ 1,
  prior = c(
    prior(student_t(3, 500, 100), class = Intercept),
    prior(uniform(1, 200), class = sigma)),
  iter = 41000, warmup = 40000, chains = 4, cores = 4,
  seed = 4
)

summary(pa_mod_1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: p ~ 1 
##    Data: p_tbl (Number of observations: 3) 
##   Draws: 4 chains, each with iter = 41000; warmup = 40000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   508.58     50.22   402.45   608.44 1.00     1314      988
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma   105.34     40.47    44.68   190.13 1.00     1198     1360
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize-chains-and-posterior&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Visualize Chains and Posterior&lt;/h4&gt;
&lt;p&gt;This section provided diagnostic plots for the Markov Chain Monte Carlo. Chains look well dispersed and relatively similar (good) with a “fuzzy caterpillar” look that we want.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(pa_mod_1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2022-11-17-power-analysis-for-a-dv-test-frequentist-and-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;examine-posterior-draws&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Examine Posterior Draws&lt;/h4&gt;
&lt;p&gt;Let’s take a peek at the table of samples from the posterior. They look reasonable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pa_mod_1_post_tbl &amp;lt;- posterior_samples(pa_mod_1) %&amp;gt;%
  select(-lp__) %&amp;gt;%
  rename(&amp;quot;mu&amp;quot; = b_Intercept)

pa_mod_1_post_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;scenvywpoa&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#scenvywpoa .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#scenvywpoa .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#scenvywpoa .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#scenvywpoa .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#scenvywpoa .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#scenvywpoa .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#scenvywpoa .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#scenvywpoa .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#scenvywpoa .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#scenvywpoa .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#scenvywpoa .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#scenvywpoa .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#scenvywpoa .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#scenvywpoa .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#scenvywpoa .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#scenvywpoa .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#scenvywpoa .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#scenvywpoa .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#scenvywpoa .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#scenvywpoa .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#scenvywpoa .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#scenvywpoa .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#scenvywpoa .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#scenvywpoa .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#scenvywpoa .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#scenvywpoa .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#scenvywpoa .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#scenvywpoa .gt_left {
  text-align: left;
}

#scenvywpoa .gt_center {
  text-align: center;
}

#scenvywpoa .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#scenvywpoa .gt_font_normal {
  font-weight: normal;
}

#scenvywpoa .gt_font_bold {
  font-weight: bold;
}

#scenvywpoa .gt_font_italic {
  font-style: italic;
}

#scenvywpoa .gt_super {
  font-size: 65%;
}

#scenvywpoa .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;mu&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sigma&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;474.3346&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;124.91147&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;570.3584&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;102.00744&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;625.1128&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;98.52465&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;598.0249&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;110.21080&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;521.2838&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;88.29519&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..3999&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;593.9553&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;87.95511&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;use-posterior-to-estimate-probability-of-passing-with-various-sample-sizes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use Posterior to Estimate Probability of Passing with Various Sample Sizes&lt;/h3&gt;
&lt;p&gt;Now that we have the posterior, we can repeat a series of simulations using parameters from each row of the sampled posterior. This will preserve the uncertainty captured in the posterior and allow us to estimate the probability of passing, weighted by our beliefs and the informed by the data.&lt;/p&gt;
&lt;div id=&#34;simulate-the-data-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Simulate the Data&lt;/h4&gt;
&lt;p&gt;Knowing that the posterior draws represent credible values population mean and sd, our goal is to produce a new simulation that conducts and a simulated experiment over every credible combination. This is very similar to our frequentist version above, but instead of just copying arbitrary combinations of parameters over a grid, here the posterior draws have already selected credible values for the parameters. This is sort of like a “weighted” version of the frequentist simulation that is compatible with our pre-existing beliefs as established by the priors and then updated though the predicate data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2015)
reps &amp;lt;-  1000

n = seq(from = 5, to = 17, by = 2)

b_sim_tbl &amp;lt;- pa_mod_1_post_tbl %&amp;gt;%
  rename(mean = mu,
         sd = sigma) %&amp;gt;%
  mutate(scenario = seq(from = 1, to = nrow(.))) %&amp;gt;%
  slice(rep(1:n(), each = length(n))) %&amp;gt;%
  mutate(num_draws = rep(x = n, times = nrow(.)/length(n))) %&amp;gt;%
  mutate(dat = pmap(.l = list(n = num_draws, mean = mean, sd=sd), .f = rnorm)) %&amp;gt;%
  unnest(cols = everything()) %&amp;gt;%
  group_by(mean, sd, scenario, num_draws) %&amp;gt;%
  summarize(ltl = normtol.int(dat, P = .9, alpha = .1)) %&amp;gt;%
  unnest(cols = everything()) %&amp;gt;%
  ungroup() %&amp;gt;%
  arrange(scenario) %&amp;gt;%
  rename(ltl = &amp;#39;1-sided.lower&amp;#39;,
         utl = &amp;#39;1-sided.upper&amp;#39;) %&amp;gt;%
  mutate(fail = case_when(ltl &amp;lt;= 300 ~ 1,
         TRUE ~ 0)) %&amp;gt;%
  select(-utl) %&amp;gt;%
  mutate(across(is.numeric, round, digits = 1))
  
b_sim_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;mnbyzravio&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#mnbyzravio .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#mnbyzravio .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#mnbyzravio .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#mnbyzravio .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#mnbyzravio .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#mnbyzravio .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#mnbyzravio .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#mnbyzravio .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#mnbyzravio .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#mnbyzravio .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#mnbyzravio .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#mnbyzravio .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#mnbyzravio .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#mnbyzravio .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#mnbyzravio .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#mnbyzravio .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#mnbyzravio .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#mnbyzravio .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#mnbyzravio .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#mnbyzravio .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#mnbyzravio .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#mnbyzravio .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#mnbyzravio .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#mnbyzravio .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#mnbyzravio .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#mnbyzravio .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#mnbyzravio .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#mnbyzravio .gt_left {
  text-align: left;
}

#mnbyzravio .gt_center {
  text-align: center;
}

#mnbyzravio .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#mnbyzravio .gt_font_normal {
  font-weight: normal;
}

#mnbyzravio .gt_font_bold {
  font-weight: bold;
}

#mnbyzravio .gt_font_italic {
  font-style: italic;
}

#mnbyzravio .gt_super {
  font-size: 65%;
}

#mnbyzravio .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;mean&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sd&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;scenario&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;num_draws&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;alpha&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;P&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;x.bar&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;ltl&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;fail&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;474.3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;124.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;405.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;136.3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;474.3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;124.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;7&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;462.0&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;168.3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;474.3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;124.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;466.8&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;241.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;474.3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;124.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;11&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;493.6&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;183.8&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;474.3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;124.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;13&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;477.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;224.4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..27999&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;28000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;594.0&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;88.0&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;4000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;17&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;541.4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;392.9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;aggregate-probability-of-passing-by-sample-size&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Aggregate Probability of Passing by Sample Size&lt;/h2&gt;
&lt;p&gt;Count the number of simulations that pass/fail at each sample size condition:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;agg_tbl &amp;lt;- b_sim_tbl %&amp;gt;%
  group_by(num_draws) %&amp;gt;%
  summarize(total_fail = sum(fail),
            total_trials = 4000) %&amp;gt;%
  ungroup() %&amp;gt;%
  rename(sample_size = num_draws) %&amp;gt;%
  mutate(prob_passing = 1-(total_fail / total_trials)) %&amp;gt;%
  mutate(prob_passing = scales::percent(prob_passing, accuracy = 1))

agg_tbl %&amp;gt;%
  select(sample_size, prob_passing) %&amp;gt;%
  gt()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;pfqjmlckth&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#pfqjmlckth .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#pfqjmlckth .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#pfqjmlckth .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#pfqjmlckth .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#pfqjmlckth .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#pfqjmlckth .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#pfqjmlckth .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#pfqjmlckth .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#pfqjmlckth .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#pfqjmlckth .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#pfqjmlckth .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#pfqjmlckth .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#pfqjmlckth .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#pfqjmlckth .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#pfqjmlckth .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#pfqjmlckth .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#pfqjmlckth .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#pfqjmlckth .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#pfqjmlckth .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#pfqjmlckth .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#pfqjmlckth .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#pfqjmlckth .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#pfqjmlckth .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#pfqjmlckth .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#pfqjmlckth .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#pfqjmlckth .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#pfqjmlckth .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#pfqjmlckth .gt_left {
  text-align: left;
}

#pfqjmlckth .gt_center {
  text-align: center;
}

#pfqjmlckth .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#pfqjmlckth .gt_font_normal {
  font-weight: normal;
}

#pfqjmlckth .gt_font_bold {
  font-weight: bold;
}

#pfqjmlckth .gt_font_italic {
  font-style: italic;
}

#pfqjmlckth .gt_super {
  font-size: 65%;
}

#pfqjmlckth .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sample_size&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;prob_passing&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_right&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;42%&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_right&#34;&gt;7&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;51%&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_right&#34;&gt;9&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;54%&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_right&#34;&gt;11&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;58%&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_right&#34;&gt;13&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;60%&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_right&#34;&gt;15&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;63%&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_right&#34;&gt;17&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;63%&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Based on this estimate, the increase in probability of passing by going from, for example, n=9 to n=13 is 6% which does not seem significant enough to recommend the associated increase in cost and time for the larger sample size. However, if testing is cheap and easy, then going from, for example, n=9 to n=15 provides an estimated 9% increase in probability of passing.&lt;/p&gt;
&lt;p&gt;The Bayesian version of the workflow has allowed us to answer the question concisely: ‘what are our chances of passing?’. The Frequentist version gives a survey of possibilities but forces you to apply your domain knowledge after the fact in an unprincipled way to arrive at a decision.&lt;/p&gt;
&lt;p&gt;Both are useful - and I hope this post was useful to somebody too! Thank you for reading.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sessioninfo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;SessionInfo&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.3 (2020-10-10)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18363)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] here_1.0.1      brms_2.16.3     Rcpp_1.0.7      ggExtra_0.9    
##  [5] gt_0.3.1        ggrepel_0.9.1   patchwork_1.1.1 tolerance_2.0.0
##  [9] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.7     purrr_0.3.4    
## [13] readr_2.1.1     tidyr_1.1.4     tibble_3.1.6    ggplot2_3.3.5  
## [17] tidyverse_1.3.1
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.4.1      plyr_1.8.6          
##   [4] igraph_1.2.11        splines_4.0.3        crosstalk_1.2.0     
##   [7] rstantools_2.1.1     inline_0.3.19        digest_0.6.28       
##  [10] htmltools_0.5.2      rsconnect_0.8.25     fansi_0.5.0         
##  [13] magrittr_2.0.1       checkmate_2.0.0      memoise_2.0.1       
##  [16] tzdb_0.2.0           modelr_0.1.8         extrafont_0.17      
##  [19] RcppParallel_5.1.5   matrixStats_0.61.0   xts_0.12.1          
##  [22] extrafontdb_1.0      pkgdown_2.0.1        prettyunits_1.1.1   
##  [25] colorspace_2.0-2     rvest_1.0.2          haven_2.4.3         
##  [28] xfun_0.29            callr_3.7.0          crayon_1.4.2        
##  [31] jsonlite_1.7.2       lme4_1.1-27.1        zoo_1.8-9           
##  [34] glue_1.6.0           gtable_0.3.0         emmeans_1.7.2       
##  [37] V8_4.0.0             distributional_0.3.0 pkgbuild_1.3.1      
##  [40] Rttf2pt1_1.3.9       rstan_2.26.4         abind_1.4-5         
##  [43] scales_1.1.1         mvtnorm_1.1-3        DBI_1.1.2           
##  [46] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.0.3        
##  [49] StanHeaders_2.26.4   DT_0.20              htmlwidgets_1.5.4   
##  [52] httr_1.4.2           threejs_0.3.3        posterior_1.2.0     
##  [55] ellipsis_0.3.2       pkgconfig_2.0.3      loo_2.4.1           
##  [58] farver_2.1.0         sass_0.4.0           dbplyr_2.1.1        
##  [61] utf8_1.2.2           labeling_0.4.2       tidyselect_1.1.1    
##  [64] rlang_0.4.11         reshape2_1.4.4       later_1.3.0         
##  [67] munsell_0.5.0        cellranger_1.1.0     tools_4.0.3         
##  [70] cachem_1.0.6         cli_3.1.0            generics_0.1.1      
##  [73] broom_0.7.11         ggridges_0.5.3       evaluate_0.14       
##  [76] fastmap_1.1.0        yaml_2.2.1           processx_3.5.2      
##  [79] knitr_1.34           fs_1.5.2             rgl_0.108.3         
##  [82] nlme_3.1-153         projpred_2.0.2       mime_0.12           
##  [85] xml2_1.3.3           compiler_4.0.3       bayesplot_1.8.1     
##  [88] shinythemes_1.2.0    rstudioapi_0.13      gamm4_0.2-6         
##  [91] curl_4.3.2           reprex_2.0.1         bslib_0.3.1         
##  [94] stringi_1.7.4        highr_0.9            ps_1.6.0            
##  [97] blogdown_0.15        Brobdingnag_1.2-6    lattice_0.20-45     
## [100] Matrix_1.4-0         nloptr_1.2.2.3       markdown_1.1        
## [103] shinyjs_2.1.0        tensorA_0.36.2       vctrs_0.3.8         
## [106] pillar_1.6.4         lifecycle_1.0.1      jquerylib_0.1.4     
## [109] bridgesampling_1.1-2 estimability_1.3     httpuv_1.6.5        
## [112] R6_2.5.1             bookdown_0.21        promises_1.2.0.1    
## [115] gridExtra_2.3        codetools_0.2-18     boot_1.3-28         
## [118] colourpicker_1.1.1   MASS_7.3-54          gtools_3.9.2        
## [121] assertthat_0.2.1     rprojroot_2.0.2      withr_2.4.3         
## [124] shinystan_2.5.0      mgcv_1.8-38          parallel_4.0.3      
## [127] hms_1.1.1            grid_4.0.3           minqa_1.2.4         
## [130] coda_0.19-4          rmarkdown_2.11       shiny_1.7.1         
## [133] lubridate_1.8.0      base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;For additional details about this testing, refer to ASTM F2129&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Real World Use Case for a Bayesian Reliability Model - How to Incorporate FEA into Risk Estimates</title>
      <link>/post/a-real-world-use-case-for-a-bayesian-reliability-model/</link>
      <pubDate>Wed, 29 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/a-real-world-use-case-for-a-bayesian-reliability-model/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Frequentist statistical methods, despite their flaws, are generally serviceable for a large suite of practical problems faced by engineers during product development of medical devices. But even in domains where simple models usually do the trick, there remain instances where a Bayesian approach is the best (and perhaps only logical) way to tackle a problem.&lt;/p&gt;
&lt;p&gt;In the rest of this post, I will lay out a technical use-case and associated modeling workflow that is based on a real business problem encountered in the medical device industry. Note: specifics have been changed to respect the privacy of the company and the product. Here we go.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#libraries&#34;&gt;Libraries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#background&#34;&gt;Background&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#analysis&#34;&gt;Analysis&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#data-for-probability-of-fracture-occurring-(p1)&#34;&gt;Data for Probability of Fracture Occurring (P1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-for-probability-of-fracture-leading-to-harm-(p2)&#34;&gt;Data for Probability of Fracture Leading to Harm (P2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modeling&#34;&gt;Modeling&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#model-for-p1&#34;&gt;Model for P1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-for-p2&#34;&gt;Model for P2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-for-ph&#34;&gt;Model for Ph&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sessioninfo&#34;&gt;SessionInfo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;libraries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Libraries&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(gt)
library(tidybayes)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;background&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Background&lt;/h1&gt;
&lt;p&gt;The problem background is this:&lt;/p&gt;
&lt;p&gt;Vascular implants like stents and heart valves are tested extensively on the bench prior to approval for clinical use. When fractures (failures) occur, it is the job of the engineering team to determine if the failure was due to the design of the implant itself or a special cause and also assess the potential risk to the patient.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assume that we have observed an &lt;em&gt;unanticipated fracture&lt;/em&gt; late in the design process - during the 3rd of 3 planned rounds of testing.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;An investigation is unable to identify a special cause beyond the design of the implant. Management therefore wishes the understand the risk of a &lt;strong&gt;harm&lt;/strong&gt; occurring in a patient implanted with this product based solely on the test data available, plus any additional information that may help inform the analysis, assuming no special cause for the fracture.&lt;/p&gt;
&lt;p&gt;The probability of a patient harm occurring due to a fracture can be broken down into two components as follows:&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox P_1 = \mbox{Probability of Fracture Occurring}\\\mbox P_2 = \mbox{Probability of Fracture Leading to a Harm}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Assuming independence, the probability of harm from the fracture is then:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox P_h = \mathrm{P}(P_1 \cap P_2) = \mbox P_1 \mbox{ x }\mbox P_2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Our challenge is: how to develop an estimate of &lt;span class=&#34;math inline&#34;&gt;\(\mbox P_1 \mbox{ , }\mbox P_2 \mbox{ , and }\mbox P_h\)&lt;/span&gt; that incorporates the benchtop test data and our domain knowledge while also propagating uncertainty throughout the calculation.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;First, lets see what data and information we have available. Assume the following benchtop data and/or computer simulation (FEA) data are available to inform each estimate:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Analysis&lt;/h1&gt;
&lt;div id=&#34;data-for-probability-of-fracture-occurring-p1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data for Probability of Fracture Occurring (P1)&lt;/h2&gt;
&lt;p&gt;To estimate &lt;span class=&#34;math inline&#34;&gt;\(\mbox P_1\)&lt;/span&gt; we have 3 rounds of benchtop data, where each outcome is a pass/fail representing fracture or no fracture.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Round 1: 6 parts tested and all 6 passed (0 failures)&lt;/li&gt;
&lt;li&gt;Round 2: 5 parts tested and all 5 passed (0 failures)&lt;/li&gt;
&lt;li&gt;Round 3: 12 parts tested and 11 passed (1 failure). This is the failure that triggered the investigation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;data-for-probability-of-fracture-leading-to-harm-p2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data for Probability of Fracture Leading to Harm (P2)&lt;/h2&gt;
&lt;p&gt;To simplify the problem, we’ll only consider one patient harm: embolism due to broken pieces of the implant migrating within the body. In order for this to happen, the first fracture (as observed on the bench in part 1, round 3) must cascade into additional fractures and eventual loss of overall implant integrity. In order to assess this &lt;span class=&#34;math inline&#34;&gt;\(\mbox P_2\)&lt;/span&gt; risk, we have 2 inputs:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Input 1: A finite element analysis (FEA) simulation concluding that when 1 fracture occurs, the strain levels at other locations in the implant are not expected to rise to levels where we would anticipate additional fractures and loss of overall implant integrity&lt;/li&gt;
&lt;li&gt;Input 2: A benchtop study in which 6 parts were intentionally fractured at the location of interest continued to cycle; none of the 6 showed any additional fractures after the first (0 failures)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note: FEA is a way to simulate stresses and strain in a model under specific assumptions of boundary conditions, geometries, material properties, etc. See below for an example of predicted strain amplitudes in a nitinol component via FEA.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-29-a-real-world-use-case-for-a-bayesian-reliability-model_files/superelastic%20nitinol.png&#34; style=&#34;width:100.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modeling&lt;/h2&gt;
&lt;p&gt;We want a model that can use all the available information which includes several rounds of benchtop data and a computer simulation. A beta-binomial Bayesian model is a reasonable choice for both technical and business reasons, a few of which are shown below:&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;The model is simple, with an analytic solution available (to avoid needing to validate an MCMC sampler and supporting code)&lt;/li&gt;
&lt;li&gt;There is domain knowledge (FEA moel) available that needs to be incorporated into the analysis&lt;/li&gt;
&lt;li&gt;The outcome can be easily understood by a general audience&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;To generate the posterior probabilities for &lt;span class=&#34;math inline&#34;&gt;\(\mbox P_1\)&lt;/span&gt; we need nothing more than addition. The two parameters in the model are the cumulative sum of the 1+passes and 1+fails, respectively.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox P_1 \sim \mbox{Beta}(\alpha_0+\mbox{fails}, \beta_0+\mbox{passes})\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;model-for-p1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model for P1&lt;/h3&gt;
&lt;p&gt;For &lt;span class=&#34;math inline&#34;&gt;\(\mbox P_1\)&lt;/span&gt; we can choose to start with a flat prior where &lt;span class=&#34;math inline&#34;&gt;\(\alpha_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; are 1. This implies we don’t know anything about whether or not the part may fracture.&lt;/p&gt;
&lt;div id=&#34;before-seeing-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Before Seeing Data&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_1 &amp;lt;- tibble(x_canvas = c(0, 1))

alpha &amp;lt;- 1
beta &amp;lt;- 1

plot_p1_fcn &amp;lt;- function(a, b) {
  p_1 %&amp;gt;%
    ggplot(aes(x = x_canvas)) +
    stat_function(
      fun = dbeta,
      args = list(a, b),
      color = &amp;quot;#2c3e50&amp;quot;,
      size = 1,
      alpha = .8
    ) +
    #  ylim(c(0, 1.5)) +
    labs(
      y = &amp;quot;&amp;quot;,
      x = &amp;quot;P1: Probability of Fracture&amp;quot;,
      title = &amp;quot;Credible Estimates for P1&amp;quot;,
      subtitle = str_glue(&amp;quot;Beta ({a}, {b})&amp;quot;)
    ) +
    theme_bw() +
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank()
    )
}

plot_p1_fcn(a = alpha, b = beta)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-29-a-real-world-use-case-for-a-bayesian-reliability-model_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;add-round-1-benchtop-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Add Round 1 Benchtop Data&lt;/h4&gt;
&lt;p&gt;Recall from above:&lt;/p&gt;
&lt;p&gt;Round 1: 6 parts tested and all 6 passed (0 failures). So we add 6 to the cumulative sum for b and nothing to a.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;alpha &amp;lt;- 1
beta &amp;lt;- 7

plot_p1_fcn(a = alpha, b = beta)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-29-a-real-world-use-case-for-a-bayesian-reliability-model_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;add-round-2-benchtop-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Add Round 2 Benchtop Data&lt;/h4&gt;
&lt;p&gt;Recall from above:&lt;/p&gt;
&lt;p&gt;Round 2: 5 parts tested and all 5 passed (0 failures). So we add 5 to the cumulative sum for b and nothing to a.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;alpha &amp;lt;- 1
beta &amp;lt;- 12

plot_p1_fcn(a = alpha, b = beta)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-29-a-real-world-use-case-for-a-bayesian-reliability-model_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;add-round-3-benchtop-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Add Round 3 Benchtop Data&lt;/h4&gt;
&lt;p&gt;Recall from above:&lt;/p&gt;
&lt;p&gt;Round 3: 12 parts tested and all 11 passed (1 failure). So we add 11 to the cumulative sum for b and 1 to the cumulative sum for a.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;alpha &amp;lt;- 2
beta &amp;lt;- 23

plot_p1_fcn(a = alpha, b = beta)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-29-a-real-world-use-case-for-a-bayesian-reliability-model_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Pausing here to assess, we can see a wide range of values for P1 that are still consistent with the data, ranging from close to 0 up to around .25.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-for-p2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model for P2&lt;/h3&gt;
&lt;p&gt;Now we consider a model for &lt;span class=&#34;math inline&#34;&gt;\(\mbox P_2\)&lt;/span&gt;, the probability of a fracture resulting in a harm (embolism). We can use the same methodology but now we consider additional inputs that are not benchtop data - they are FEA simulations. &lt;strong&gt;FEA cannot be thought of as coming from a sampling distribution&lt;/strong&gt; - if we were to run the FEA simultaion a second time we would get the exact same results (recall that the FEA model suggested no cascading fractures we be expected as a result of the first). &lt;strong&gt;Yet this is important knowledge that must inform our risk assessment.&lt;/strong&gt; So do we give it the impact of a single benchtop data point? No, this would be too little respect for an engineering analysis of this type.&lt;/p&gt;
&lt;p&gt;A way that we could incorporate the FEA output is to consider, as subject matter experts, how much weight we intend to place in the FEA simulation. On the one hand we know that FEA can sometimes yield strange predictions due to mesh sensitivities, material model inaccuracies, or assumptions about the boundary conditions. On the other hand, it is a rigorous piece of engineering information coming from validated software that we would be foolish to ignore.&lt;/p&gt;
&lt;p&gt;Assume our team of risk modelers meets with the FEA simulation engineers, discusses potential limitations of the FEA, and aligns on a risk estimate centered around .05 but allowing for credible values down to around .2i ish. We could convert this domain knowledge, coming from our FEA, into a prior that reflects this uncertainty. Something like Beta(1,20) should work well.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Combining this knowledge of the FEA along with our benchtop results is how a Bayesian workflow can really shine in ways that our traditional ways can’t.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;prior-probability-based-on-fea-input-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Prior Probability based on FEA (Input 1)&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_2 &amp;lt;- tibble(x_canvas = c(0, 1))

alpha &amp;lt;- 1
beta &amp;lt;- 20

plot_p2_fcn &amp;lt;- function(a, b) {
  p_2 %&amp;gt;%
    ggplot(aes(x = x_canvas)) +
    stat_function(
      fun = dbeta,
      args = list(a, b),
      color = &amp;quot;firebrick&amp;quot;,
      size = 1,
      alpha = .8
    ) +
    #  ylim(c(0, 1.5)) +
    labs(
      y = &amp;quot;&amp;quot;,
      x = &amp;quot;P2: Probability of Fracture resulting in Harm&amp;quot;,
      title = &amp;quot;Credible Estimates for P2&amp;quot;,
      subtitle = str_glue(&amp;quot;Beta ({a}, {b})&amp;quot;)
    ) +
    theme_bw() +
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank()
    )
}

plot_p2_fcn(a = alpha, b = beta) +
  labs(caption = &amp;quot;prior probabilities assessed primarily from FEA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-29-a-real-world-use-case-for-a-bayesian-reliability-model_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;add-input-2-benchtop-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Add Input 2 (Benchtop Data)&lt;/h4&gt;
&lt;p&gt;Now we add our study where we looked at 6 parts that were intentionally fractured and saw no propagation or cascading failures. So we add 6 to the cumulative sum for b and nothing to a.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;alpha &amp;lt;- 1
beta &amp;lt;- 26

plot_p2_fcn(alpha, beta)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-29-a-real-world-use-case-for-a-bayesian-reliability-model_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-for-ph&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model for Ph&lt;/h3&gt;
&lt;p&gt;We now have posterior distributions for both &lt;span class=&#34;math inline&#34;&gt;\(\mbox P_1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\mbox P_2\)&lt;/span&gt;, and we need to multiply them together to estimate &lt;span class=&#34;math inline&#34;&gt;\(\mbox P_h\)&lt;/span&gt;. There is probably a way to do this analytically, but most engineers won’t know how beyond multiplying the point estimates. Fortunately we can sample from each of these distributions, multiply the samples together row-wise, and produce an estimate of the posterior for &lt;span class=&#34;math inline&#34;&gt;\(\mbox P_h\)&lt;/span&gt; that reflects the uncertainty in &lt;span class=&#34;math inline&#34;&gt;\(\mbox P_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mbox P_2\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;sample-from-p1-posterior-and-visualize&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Sample from P1 Posterior and Visualize&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
n_draws &amp;lt;- 500000

p1_post_draws_tbl &amp;lt;- tibble(draws = rbeta(n = n_draws, shape1 = 2, shape2 = 23))

p1_post_draws_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;hiigomxvmh&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#hiigomxvmh .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#hiigomxvmh .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#hiigomxvmh .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#hiigomxvmh .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#hiigomxvmh .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hiigomxvmh .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#hiigomxvmh .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#hiigomxvmh .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#hiigomxvmh .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#hiigomxvmh .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#hiigomxvmh .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#hiigomxvmh .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#hiigomxvmh .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#hiigomxvmh .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#hiigomxvmh .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#hiigomxvmh .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#hiigomxvmh .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#hiigomxvmh .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#hiigomxvmh .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#hiigomxvmh .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#hiigomxvmh .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#hiigomxvmh .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#hiigomxvmh .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hiigomxvmh .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#hiigomxvmh .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#hiigomxvmh .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#hiigomxvmh .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#hiigomxvmh .gt_left {
  text-align: left;
}

#hiigomxvmh .gt_center {
  text-align: center;
}

#hiigomxvmh .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#hiigomxvmh .gt_font_normal {
  font-weight: normal;
}

#hiigomxvmh .gt_font_bold {
  font-weight: bold;
}

#hiigomxvmh .gt_font_italic {
  font-style: italic;
}

#hiigomxvmh .gt_super {
  font-size: 65%;
}

#hiigomxvmh .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;draws&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.04862055&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.06549307&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.30463148&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.08498940&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.08936808&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..499999&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;500000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.02849358&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1_post_draws_tbl %&amp;gt;%
  ggplot(aes(x = draws)) +
  geom_histogram(
    binwidth = .002,
    color = &amp;quot;white&amp;quot;,
    fill = &amp;quot;#2c3e50&amp;quot;,
    alpha = 0.8
  ) +
  xlim(c(-0.05, .5)) +
  labs(
    y = &amp;quot;&amp;quot;,
    title = &amp;quot;Samples from P1 Posterior&amp;quot;,
    subtitle = &amp;quot;Current State of Belief&amp;quot;,
    x = &amp;quot;P1: Probability of Fracture&amp;quot;
  ) +
  theme_bw() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-29-a-real-world-use-case-for-a-bayesian-reliability-model_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sample-from-p2-posterior-and-visualize&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Sample from P2 Posterior and Visualize&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
n_draws &amp;lt;- 500000

p2_post_draws_tbl &amp;lt;- tibble(draws = rbeta(n = n_draws, shape1 = 1, shape2 = 26))

p2_post_draws_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;ewlaiusdsg&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#ewlaiusdsg .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ewlaiusdsg .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ewlaiusdsg .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ewlaiusdsg .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ewlaiusdsg .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ewlaiusdsg .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ewlaiusdsg .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ewlaiusdsg .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ewlaiusdsg .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ewlaiusdsg .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ewlaiusdsg .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ewlaiusdsg .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#ewlaiusdsg .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ewlaiusdsg .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#ewlaiusdsg .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#ewlaiusdsg .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ewlaiusdsg .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#ewlaiusdsg .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ewlaiusdsg .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#ewlaiusdsg .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ewlaiusdsg .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ewlaiusdsg .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ewlaiusdsg .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ewlaiusdsg .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ewlaiusdsg .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#ewlaiusdsg .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ewlaiusdsg .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#ewlaiusdsg .gt_left {
  text-align: left;
}

#ewlaiusdsg .gt_center {
  text-align: center;
}

#ewlaiusdsg .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ewlaiusdsg .gt_font_normal {
  font-weight: normal;
}

#ewlaiusdsg .gt_font_bold {
  font-weight: bold;
}

#ewlaiusdsg .gt_font_italic {
  font-style: italic;
}

#ewlaiusdsg .gt_super {
  font-size: 65%;
}

#ewlaiusdsg .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;draws&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0526550965&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0024287487&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0332258372&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0303373980&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0017321513&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..499999&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;500000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0002236549&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2_post_draws_tbl %&amp;gt;%
  ggplot(aes(x = draws)) +
  geom_histogram(
    binwidth = .002,
    color = &amp;quot;white&amp;quot;,
    fill = &amp;quot;firebrick&amp;quot;,
    alpha = 0.8
  ) +
  xlim(c(-0.05, .5)) +
  labs(
    y = &amp;quot;&amp;quot;,
    title = &amp;quot;Samples from P2 Posterior&amp;quot;,
    subtitle = &amp;quot;Current State of Belief&amp;quot;,
    x = &amp;quot;P2: Probability of a Fracture Resulting in a Harm&amp;quot;
  ) +
  theme_bw() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-29-a-real-world-use-case-for-a-bayesian-reliability-model_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;combine-to-estimate-ph&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Combine to Estimate Ph&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;joint_post_tbl &amp;lt;- p1_post_draws_tbl %&amp;gt;%
  bind_cols(p2_post_draws_tbl) %&amp;gt;%
  rename(
    p1_draws = draws...1,
    p2_draws = draws...2
  ) %&amp;gt;%
  mutate(p1_x_p2 = p1_draws * p2_draws)

joint_post_tbl %&amp;gt;%
  ggplot(aes(x = p1_x_p2)) +
  geom_histogram(
    binwidth = .0001,
    color = &amp;quot;white&amp;quot;,
    fill = &amp;quot;purple&amp;quot;,
    alpha = 0.8
  ) +
  labs(
    y = &amp;quot;&amp;quot;,
    title = &amp;quot;Ph - Probabilty Model of Fracture Occurring AND Resulting in Harm&amp;quot;,
    subtitle = &amp;quot;Current State&amp;quot;,
    x = &amp;quot;Ph: Probabilty of Fracture Occurring AND Resulting in Harm&amp;quot;
  ) +
  theme_bw() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  ) +
  xlim(c(-.001, .03))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-29-a-real-world-use-case-for-a-bayesian-reliability-model_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above plot can also be summarized in tabular form.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;joint_post_tbl %&amp;gt;%
  select(p1_x_p2) %&amp;gt;%
  mutate_if(is.numeric, round, 4) %&amp;gt;%
  median_qi(.width = .95) %&amp;gt;%
  gt() %&amp;gt;%
  cols_align(&amp;quot;center&amp;quot;) %&amp;gt;%
  opt_row_striping(row_striping = TRUE) %&amp;gt;%
  tab_header(
    title = &amp;quot;Summary of Ph Posterior&amp;quot;,
    subtitle = &amp;quot;Based on Bayesian Beta/Binomial Model&amp;quot;
  ) %&amp;gt;%
  cols_width(everything() ~ px(100)) %&amp;gt;%
  tab_style(
    style = list(
      cell_text(weight = &amp;quot;bold&amp;quot;)
    ),
    locations = cells_column_labels(columns = everything())
  )&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;iobhrrvdid&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#iobhrrvdid .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#iobhrrvdid .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#iobhrrvdid .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#iobhrrvdid .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#iobhrrvdid .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#iobhrrvdid .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#iobhrrvdid .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#iobhrrvdid .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#iobhrrvdid .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#iobhrrvdid .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#iobhrrvdid .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#iobhrrvdid .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#iobhrrvdid .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#iobhrrvdid .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#iobhrrvdid .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#iobhrrvdid .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#iobhrrvdid .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#iobhrrvdid .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#iobhrrvdid .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#iobhrrvdid .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#iobhrrvdid .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#iobhrrvdid .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#iobhrrvdid .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#iobhrrvdid .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#iobhrrvdid .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#iobhrrvdid .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#iobhrrvdid .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#iobhrrvdid .gt_left {
  text-align: left;
}

#iobhrrvdid .gt_center {
  text-align: center;
}

#iobhrrvdid .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#iobhrrvdid .gt_font_normal {
  font-weight: normal;
}

#iobhrrvdid .gt_font_bold {
  font-weight: bold;
}

#iobhrrvdid .gt_font_italic {
  font-style: italic;
}

#iobhrrvdid .gt_super {
  font-size: 65%;
}

#iobhrrvdid .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34; style=&#34;table-layout: fixed;; width: 0px&#34;&gt;
  &lt;colgroup&gt;
    &lt;col style=&#34;width:100px;&#34;/&gt;
    &lt;col style=&#34;width:100px;&#34;/&gt;
    &lt;col style=&#34;width:100px;&#34;/&gt;
    &lt;col style=&#34;width:100px;&#34;/&gt;
    &lt;col style=&#34;width:100px;&#34;/&gt;
    &lt;col style=&#34;width:100px;&#34;/&gt;
  &lt;/colgroup&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;6&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;Summary of Ph Posterior&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;6&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;Based on Bayesian Beta/Binomial Model&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34; style=&#34;font-weight: bold;&#34;&gt;p1_x_p2&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34; style=&#34;font-weight: bold;&#34;&gt;.lower&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34; style=&#34;font-weight: bold;&#34;&gt;.upper&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34; style=&#34;font-weight: bold;&#34;&gt;.width&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34; style=&#34;font-weight: bold;&#34;&gt;.point&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34; style=&#34;font-weight: bold;&#34;&gt;.interval&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_center&#34;&gt;0.0016&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;0&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;0.014&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;0.95&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;median&lt;/td&gt;
&lt;td class=&#34;gt_row gt_center&#34;&gt;qi&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;We have arrived at an estimate for Ph, the probability of the fracture occurring and resulting in a harm. A point estimate is .0016 or 16 out of 1000. A decision made off this single value may result in pushing a product that seems relatively safe. But the 95% credible interval covers up to .014 or 1.4 in 100 which would not be acceptable in most circumstances. The Bayesian approach has allowed us to carry that uncertainty all the way through the calculations to make a more informed decision.&lt;/p&gt;
&lt;p&gt;This is the distillation of a lot of work to prepare the problem for a business decision: do nothing, initiate a redesign, or proceed with more testing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In this hypothetical example, credible risk values above 1% are likely too high to proceed without design changes or additional testing.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you’ve made it this far, I thank you for your attention.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;sessioninfo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;SessionInfo&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.3 (2020-10-10)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18363)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.3.1 gt_0.2.2        forcats_0.5.0   stringr_1.4.0  
##  [5] dplyr_1.0.7     purrr_0.3.4     readr_1.4.0     tidyr_1.1.3    
##  [9] tibble_3.1.4    ggplot2_3.3.5   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.7           lattice_0.20-41      lubridate_1.7.9.2   
##  [4] assertthat_0.2.1     digest_0.6.28        utf8_1.2.2          
##  [7] plyr_1.8.6           R6_2.5.1             cellranger_1.1.0    
## [10] backports_1.2.0      reprex_0.3.0         evaluate_0.14       
## [13] coda_0.19-4          highr_0.9            httr_1.4.2          
## [16] blogdown_0.15        pillar_1.6.2         rlang_0.4.11        
## [19] readxl_1.3.1         rstudioapi_0.13      jquerylib_0.1.4     
## [22] checkmate_2.0.0      rmarkdown_2.11       labeling_0.4.2      
## [25] munsell_0.5.0        broom_0.7.8          compiler_4.0.3      
## [28] modelr_0.1.8         xfun_0.26            pkgconfig_2.0.3     
## [31] htmltools_0.5.2      tidyselect_1.1.1     bookdown_0.21       
## [34] arrayhelpers_1.1-0   fansi_0.5.0          crayon_1.4.1        
## [37] dbplyr_2.0.0         withr_2.4.2          distributional_0.2.1
## [40] ggdist_2.3.0         grid_4.0.3           jsonlite_1.7.2      
## [43] gtable_0.3.0         lifecycle_1.0.1      DBI_1.1.0           
## [46] magrittr_2.0.1       scales_1.1.1         cli_3.0.1           
## [49] stringi_1.7.4        farver_2.1.0         fs_1.5.0            
## [52] xml2_1.3.2           bslib_0.3.0          ellipsis_0.3.2      
## [55] generics_0.1.0       vctrs_0.3.8          tools_4.0.3         
## [58] svUnit_1.0.3         glue_1.4.2           hms_0.5.3           
## [61] fastmap_1.1.0        yaml_2.2.1           colorspace_2.0-2    
## [64] rvest_0.3.6          knitr_1.34           haven_2.3.1         
## [67] sass_0.4.0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.greenlight.guru/blog/en-iso-149712012-risk-assessment-explained&#34; class=&#34;uri&#34;&gt;https://www.greenlight.guru/blog/en-iso-149712012-risk-assessment-explained&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;We will ignore the Severity adjustment typically involved in risk calculations per EN ISO 14971 for simplicity&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://nitinol.com/wp-content/uploads/2017/11/a666400cdba78b589ce578e17fc2c3fd.pdf&#34; class=&#34;uri&#34;&gt;https://nitinol.com/wp-content/uploads/2017/11/a666400cdba78b589ce578e17fc2c3fd.pdf&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.bayesrulesbook.com/chapter-3.html&#34; class=&#34;uri&#34;&gt;https://www.bayesrulesbook.com/chapter-3.html&lt;/a&gt;&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Exploring Frequentist and Bayesian Tolerance Intervals in R</title>
      <link>/post/exploring-frequentist-and-bayesian-tolerance-intervals-in-r/</link>
      <pubDate>Tue, 22 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/exploring-frequentist-and-bayesian-tolerance-intervals-in-r/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Tolerance intervals are used to specify coverage of a population of data. In the frequentist framework, the width of the interval is dependent on the desired coverage proportion and the specified confidence level. They are widely used in the medical device industry because they can be compared directly vs. product specifications, allowing the engineer to make a judgment about what percentage of the parts would meet the spec taking into account sampling uncertainty.&lt;/p&gt;
&lt;p&gt;In this post I wanted to dive a bit deeper into the frequentist version of tolerance intervals to verify that they provide the correct coverage in a straight-forward use case. Then I will explore a Bayesian version which uses the posterior draws from a fitted model to calculate the Bayesian analogue of a tolerance interval.&lt;/p&gt;
&lt;div id=&#34;libraries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Libraries&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(here)
library(brms)
library(broom)
library(tidybayes)
library(tolerance)
library(wesanderson)
library(patchwork)
library(gt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As with any frequentist simulation looking at coverage of a p-value, we can start with the population parameters known. From there we simulate many draws from that population and calculate the desired statistic (in this case the tolerance interval limits). By comparing each calculated tolerance interval to the true population coverage, we can determine the number of simulations that do not meet the specified coverage. If that number, as a fraction of the total number of sims, is less than or equal to the p-value, then the tolerance interval procedure is working as intended and provided the specified coverage, on average, over many simulated experiments.&lt;/p&gt;
&lt;p&gt;This block sets up the parameters and identifies the specified quantiles of the true population.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulated-experiments&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simulated Experiments&lt;/h1&gt;
&lt;div id=&#34;true-population-parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;True Population Parameters&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(9989)

n_sims &amp;lt;- 10000
true_population_mean &amp;lt;- 40
true_population_sd &amp;lt;- 4
alpha &amp;lt;- 0.1
p &amp;lt;- .95

upper_97.5 &amp;lt;- qnorm(p = .975, mean = true_population_mean, sd = true_population_sd)
lower_02.5 &amp;lt;- qnorm(p = .025, mean = true_population_mean, sd = true_population_sd)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the simulation, replicating many “experiments” of n=15, calculating a 90% confidence, 2-sided tolerance interval for 95% of the population each time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;run-the-simulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Run the Simulation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_summary_tbl &amp;lt;- tibble(sim_id = seq(from = 1, to = n_sims, by = 1)) %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(
    test_sample_size = 15,
    sim_test_data = list(rnorm(n = test_sample_size, mean = true_population_mean, sd = true_population_sd))
  ) %&amp;gt;%
  summarize(
    sim_id = sim_id,
    #   sim_test_data = sim_test_data,
    norm_tol = list(normtol.int(sim_test_data, alpha = alpha, P = p, side = 2)),
    sample_sd = sd(sim_test_data)
  ) %&amp;gt;%
  unnest(norm_tol) %&amp;gt;%
  rename(
    lower_bound_ltl = &amp;quot;2-sided.lower&amp;quot;,
    upper_bound_utl = &amp;quot;2-sided.upper&amp;quot;,
    sample_mean = x.bar,
    p = P
  ) %&amp;gt;%
  ungroup() %&amp;gt;%
  select(sim_id, alpha, p, sample_mean, sample_sd, everything()) %&amp;gt;%
  mutate(
    true_lower_2.5 = lower_02.5,
    true_upper_97.5 = upper_97.5
  )

sim_summary_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;moscublyzf&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#moscublyzf .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#moscublyzf .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#moscublyzf .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#moscublyzf .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#moscublyzf .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#moscublyzf .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#moscublyzf .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#moscublyzf .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#moscublyzf .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#moscublyzf .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#moscublyzf .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#moscublyzf .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#moscublyzf .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#moscublyzf .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#moscublyzf .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#moscublyzf .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#moscublyzf .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#moscublyzf .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#moscublyzf .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#moscublyzf .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#moscublyzf .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#moscublyzf .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#moscublyzf .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#moscublyzf .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#moscublyzf .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#moscublyzf .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#moscublyzf .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#moscublyzf .gt_left {
  text-align: left;
}

#moscublyzf .gt_center {
  text-align: center;
}

#moscublyzf .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#moscublyzf .gt_font_normal {
  font-weight: normal;
}

#moscublyzf .gt_font_bold {
  font-weight: bold;
}

#moscublyzf .gt_font_italic {
  font-style: italic;
}

#moscublyzf .gt_super {
  font-size: 65%;
}

#moscublyzf .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sim_id&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;alpha&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;p&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sample_mean&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sample_sd&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;lower_bound_ltl&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;upper_bound_utl&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;true_lower_2.5&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;true_upper_97.5&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.95&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;36.19320&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;3.243531&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;27.35493&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;45.03147&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;32.16014&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;47.83986&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.95&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;40.56155&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;3.766514&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;30.29821&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;50.82489&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;32.16014&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;47.83986&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.95&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;40.23154&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;4.268292&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;28.60091&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;51.86217&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;32.16014&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;47.83986&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.95&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;40.24057&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;4.175918&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;28.86165&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;51.61949&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;32.16014&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;47.83986&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.95&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;40.41020&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;3.880094&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;29.83737&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;50.98303&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;32.16014&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;47.83986&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..9999&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;10000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;10000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.95&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;38.69646&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;4.780010&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;25.67145&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;51.72147&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;32.16014&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;47.83986&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualize&lt;/h2&gt;
&lt;p&gt;Plot the resulting upper and lower bounds of the 90/95 tolerance interval. The red lines are the true population quantiles.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_summary_tbl %&amp;gt;%
  pivot_longer(cols = everything(), names_to = &amp;quot;param&amp;quot;, values_to = &amp;quot;value&amp;quot;) %&amp;gt;%
  filter(param == &amp;quot;lower_bound_ltl&amp;quot; | param == &amp;quot;upper_bound_utl&amp;quot;) %&amp;gt;%
  mutate(param = as_factor(param)) %&amp;gt;%
  ggplot(aes(x = value, y = param)) +
  geom_jitter(aes(color = param), width = .1, height = .1, size = .3, alpha = .05) +
  stat_halfeye(aes(fill = param), alpha = .7, position = position_nudge(y = .2)) +
  geom_vline(xintercept = mean(sim_summary_tbl$true_lower_2.5), color = &amp;quot;firebrick&amp;quot;, linetype = 2) +
  geom_vline(xintercept = mean(sim_summary_tbl$true_upper_97.5), color = &amp;quot;firebrick&amp;quot;, linetype = 2) +
  scale_color_manual(values = wes_palette(&amp;quot;Moonrise2&amp;quot;)) +
  scale_fill_manual(values = wes_palette(&amp;quot;Moonrise2&amp;quot;)) +
  #  scale_color_manual(values = c(&amp;quot;purple&amp;quot;, &amp;quot;limegreen&amp;quot;)) +
  #  scale_fill_manual(values = c(&amp;quot;purple&amp;quot;, &amp;quot;limegreen&amp;quot;)) +
  labs(
    x = &amp;quot;&amp;quot;,
    y = &amp;quot;&amp;quot;,
    title = &amp;quot;Distribution of Calculated Upper and Lower Tolerance Limits&amp;quot;,
    subtitle = &amp;quot;10,000 Simulations of n=15 parts with 2-sided normal Tolerance Intervals&amp;quot;,
    caption = &amp;quot;pink vertical lines represent true population quantiles, .025 and .975&amp;quot;
  ) +
  theme(
    legend.title = element_blank(),
    legend.position = &amp;quot;bottom&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-06-22-exploring-frequentist-and-bayesian-tolerance-intervals-in-r_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To see if the tolerance interval procedure is providing the desired coverage, we have to look at each set of lower and upper limits from each simulation. The code below converts the calculated tolerance bounds from each sim into quantiles of the true population, then calculates the difference to determine the true population coverage of the simulated experiment. If the coverage is less than intended, a flag of 1 is assigned in the “unacceptable_coverage” col, else 0.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluate-true-coverage-of-each-simulated-experiment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Evaluate True Coverage of Each Simulated Experiment&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coverage_summary_tbl &amp;lt;- sim_summary_tbl %&amp;gt;%
  mutate(
    ltl_coverage_true = map_dbl(lower_bound_ltl, pnorm, true_population_mean, true_population_sd),
    utl_coverage_true = map_dbl(upper_bound_utl, pnorm, true_population_mean, true_population_sd)
  ) %&amp;gt;%
  mutate(total_tl_coverage_true = utl_coverage_true - ltl_coverage_true) %&amp;gt;%
  mutate(unacceptable_coverage = case_when(
    total_tl_coverage_true &amp;gt;= p ~ 0,
    TRUE ~ 1
  )) %&amp;gt;%
  select(-c(alpha, p, true_lower_2.5, true_upper_97.5))

coverage_summary_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;ixrqpuauby&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#ixrqpuauby .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ixrqpuauby .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ixrqpuauby .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ixrqpuauby .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ixrqpuauby .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ixrqpuauby .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ixrqpuauby .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ixrqpuauby .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ixrqpuauby .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ixrqpuauby .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ixrqpuauby .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ixrqpuauby .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#ixrqpuauby .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ixrqpuauby .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#ixrqpuauby .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#ixrqpuauby .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ixrqpuauby .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#ixrqpuauby .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ixrqpuauby .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#ixrqpuauby .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ixrqpuauby .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ixrqpuauby .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ixrqpuauby .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ixrqpuauby .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ixrqpuauby .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#ixrqpuauby .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ixrqpuauby .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#ixrqpuauby .gt_left {
  text-align: left;
}

#ixrqpuauby .gt_center {
  text-align: center;
}

#ixrqpuauby .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ixrqpuauby .gt_font_normal {
  font-weight: normal;
}

#ixrqpuauby .gt_font_bold {
  font-weight: bold;
}

#ixrqpuauby .gt_font_italic {
  font-style: italic;
}

#ixrqpuauby .gt_super {
  font-size: 65%;
}

#ixrqpuauby .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sim_id&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sample_mean&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sample_sd&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;lower_bound_ltl&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;upper_bound_utl&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;ltl_coverage_true&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;utl_coverage_true&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;total_tl_coverage_true&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;unacceptable_coverage&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;36.19320&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;3.243531&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;27.35493&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;45.03147&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0007854236&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.8957802&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.8949948&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;40.56155&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;3.766514&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;30.29821&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;50.82489&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0076447723&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9965973&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9889526&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;40.23154&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;4.268292&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;28.60091&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;51.86217&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0021875221&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9984893&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9963017&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;40.24057&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;4.175918&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;28.86165&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;51.61949&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0026797862&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9981630&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9954832&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;40.41020&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;3.880094&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;29.83737&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;50.98303&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0055321969&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9969814&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9914492&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..9999&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;10000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;10000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;38.69646&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;4.780010&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;25.67145&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;51.72147&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0001703976&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9983072&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.9981368&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;count-false-positives&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Count False Positives&lt;/h2&gt;
&lt;p&gt;For the coverage to be correct, the percentage of false positives (simulated experiments that covered less than p% of the true population) should be less than or equal to alpha (10%). That would mean less than .1(10000) = 1000 cases where the tolerance interval covered less than 95% of the true population.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coverage_summary_tbl %&amp;gt;%
  summarize(
    false_positives = sum(unacceptable_coverage),
    false_positive_limit = alpha * n_sims
  ) %&amp;gt;%
  mutate(
    alpha_level = alpha,
    total_trials = n_sims,
    false_positive_rate = false_positives / n_sims,
    &amp;quot;tol_limit_procedure_working?&amp;quot; = case_when(
      false_positives &amp;lt; false_positive_limit ~ &amp;quot;heck_yes&amp;quot;,
      TRUE ~ &amp;quot;boo&amp;quot;
    )
  ) %&amp;gt;%
  select(total_trials, alpha_level, false_positive_limit, everything()) %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;hblnhaayca&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#hblnhaayca .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#hblnhaayca .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#hblnhaayca .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#hblnhaayca .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#hblnhaayca .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hblnhaayca .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#hblnhaayca .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#hblnhaayca .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#hblnhaayca .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#hblnhaayca .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#hblnhaayca .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#hblnhaayca .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#hblnhaayca .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#hblnhaayca .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#hblnhaayca .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#hblnhaayca .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#hblnhaayca .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#hblnhaayca .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#hblnhaayca .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#hblnhaayca .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#hblnhaayca .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#hblnhaayca .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#hblnhaayca .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hblnhaayca .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#hblnhaayca .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#hblnhaayca .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#hblnhaayca .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#hblnhaayca .gt_left {
  text-align: left;
}

#hblnhaayca .gt_center {
  text-align: center;
}

#hblnhaayca .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#hblnhaayca .gt_font_normal {
  font-weight: normal;
}

#hblnhaayca .gt_font_bold {
  font-weight: bold;
}

#hblnhaayca .gt_font_italic {
  font-style: italic;
}

#hblnhaayca .gt_super {
  font-size: 65%;
}

#hblnhaayca .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;total_trials&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;alpha_level&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;false_positive_limit&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;false_positives&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;false_positive_rate&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;tol_limit_procedure_working?&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;10000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;958&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.0958&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;heck_yes&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Because .0958 is less than .1 (10%) we can say that the tolerance interval procedure is capturing the desired population proportion (95%) with an acceptable false positive rate (&amp;lt;= 10%). Neat!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-2-sided-tolerance-interval&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bayesian 2-sided Tolerance Interval&lt;/h1&gt;
&lt;p&gt;Now let’s look at the Bayesian approach. Note that this is completely different example from above, not a continuation. The desired coverage for this case is a little bit different - 95%, and we’ll aim for a 90% confidence level (for the frequentist version that comes later) and we’ll try to capture the 90% most credible estimates for the Bayesian version.&lt;/p&gt;
&lt;div id=&#34;load-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load the Data&lt;/h2&gt;
&lt;p&gt;The dataset and example used for this section is adapted from &lt;a href=&#34;https://nvlpubs.nist.gov/nistpubs/jres/126/jres.126.004.pdf&#34;&gt;this excellent paper on coverage intervals&lt;/a&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; The values represent measurements of mass fraction of iron made by the National Institute of Standards and Technology (NIST). Units of measurement are percentages, or cg/g.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;w_tbl &amp;lt;- tibble(w = c(
  67.43, 66.97, 67.65, 66.84, 67.05, 66.57, 67.16, 68.3,
  67.01, 67.07, 67.23, 66.51, 66.46, 67.54, 67.09, 66.77
)) %&amp;gt;%
  mutate(w_pct = w / 100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In preparation for the Bayesian tolerance interval calculations we should run some prior predictive checks. I know Beta(1,1) is a flat prior on mu, but I am not experienced enough with the cauchy to mentally visualize what its parameters mean with respect to the outcome variable. I adjusted the scale parameter for sigma manually and did this visual check each time until I saw a nice cloud of curves of varying but reasonable widths at scale = .025. Bonus - it is so satisfying to make the code for these curves using map2 and dplyr in the prep and then ggplot for the vis - incredibly smooth, readable, and efficient. I remain grateful for these core packages, especially as I start to mess around with other languages.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;prior-predictive-simulations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prior Predictive Simulations&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2005)

prior_pred_tbl &amp;lt;- tibble(
  mu = rbeta(300, 1, 1),
  sig = rcauchy(300, 0, 0.025) %&amp;gt;% abs()
) %&amp;gt;%
  mutate(row_id = row_number()) %&amp;gt;%
  select(row_id, everything()) %&amp;gt;%
  mutate(plotted_y_data = map2(mu, sig, ~ tibble(
    x = seq(0, 1, length.out = 100),
    y = dnorm(x, .x, .y)
  ))) %&amp;gt;%
  unnest() %&amp;gt;%
  mutate(model = &amp;quot;mu ~ beta(1,1), sigma ~ cauchy(0,0.025)&amp;quot;)

prior_pred_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;spvhicbjem&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#spvhicbjem .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#spvhicbjem .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#spvhicbjem .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#spvhicbjem .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#spvhicbjem .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#spvhicbjem .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#spvhicbjem .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#spvhicbjem .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#spvhicbjem .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#spvhicbjem .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#spvhicbjem .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#spvhicbjem .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#spvhicbjem .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#spvhicbjem .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#spvhicbjem .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#spvhicbjem .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#spvhicbjem .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#spvhicbjem .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#spvhicbjem .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#spvhicbjem .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#spvhicbjem .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#spvhicbjem .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#spvhicbjem .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#spvhicbjem .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#spvhicbjem .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#spvhicbjem .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#spvhicbjem .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#spvhicbjem .gt_left {
  text-align: left;
}

#spvhicbjem .gt_center {
  text-align: center;
}

#spvhicbjem .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#spvhicbjem .gt_font_normal {
  font-weight: normal;
}

#spvhicbjem .gt_font_bold {
  font-weight: bold;
}

#spvhicbjem .gt_font_italic {
  font-style: italic;
}

#spvhicbjem .gt_super {
  font-size: 65%;
}

#spvhicbjem .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;row_id&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;mu&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sig&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;x&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;y&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;model&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1675134&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;2.18178615&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.00000000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.823131e-01&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;mu ~ beta(1,1), sigma ~ cauchy(0,0.025)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1675134&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;2.18178615&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.01010101&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.823759e-01&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;mu ~ beta(1,1), sigma ~ cauchy(0,0.025)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1675134&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;2.18178615&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.02020202&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.824349e-01&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;mu ~ beta(1,1), sigma ~ cauchy(0,0.025)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1675134&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;2.18178615&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.03030303&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.824900e-01&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;mu ~ beta(1,1), sigma ~ cauchy(0,0.025)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.1675134&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;2.18178615&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.04040404&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.825412e-01&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;mu ~ beta(1,1), sigma ~ cauchy(0,0.025)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..29999&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;30000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;300&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.5856645&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.01596839&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.00000000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;1.589627e-145&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;mu ~ beta(1,1), sigma ~ cauchy(0,0.025)&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;j &amp;lt;- prior_pred_tbl %&amp;gt;%
  ggplot(aes(x = x, y = y, group = row_id)) +
  geom_line(aes(x, y), alpha = .5, color = &amp;quot;#2c3e50&amp;quot;) +
  labs(
    x = &amp;quot;x&amp;quot;,
    y = &amp;quot;dnorm(x)&amp;quot;
  ) +
  ylim(c(0, 10)) +
  theme_minimal()

k &amp;lt;- j +
  ylim(c(0, 50))

(k + j) + plot_annotation(
  title = &amp;quot;Prior Predictions: n=300 Possible Distibutions According to Priors:&amp;quot;,
  subtitle = &amp;quot;mu ~ Beta(1,1), sigma ~ cauchy(0, .025)&amp;quot;,
  caption = &amp;quot;same data, 2 different y-axis scales&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-06-22-exploring-frequentist-and-bayesian-tolerance-intervals-in-r_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-the-model-with-brms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit the model with brms&lt;/h2&gt;
&lt;p&gt;Use the priors that were just identified to fit a model in brms and visualize the output. The fuzzy caterpillar is not plotted because its very slow with to render with so many iterations. Don’t worry - it’s fuzzy.&lt;/p&gt;
&lt;div id=&#34;non-informative-priors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Non-Informative Priors&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;w_mod &amp;lt;-
  brm(
    data = w_tbl, family = gaussian(),
    w_pct ~ 1,
    prior = c(
      prior(beta(1, 1), class = Intercept),
      prior(cauchy(0, .025), class = sigma)
    ),
    iter = 400000, warmup = 50000, chains = 4, cores = 2,
    seed = 10
  )


w_mod %&amp;gt;% summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: w_pct ~ 1 
##    Data: w_tbl (Number of observations: 16) 
## Samples: 4 chains, each with iter = 4e+05; warmup = 50000; thin = 1;
##          total post-warmup samples = 1400000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.67      0.00     0.67     0.67 1.00   858299   757467
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.01      0.00     0.00     0.01 1.00   792388   740061
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Peek at the posterior tbl for mu and sigma.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;w_post_tbl &amp;lt;-
  posterior_samples(w_mod) %&amp;gt;%
  select(-lp__) %&amp;gt;%
  rename(&amp;quot;mu&amp;quot; = b_Intercept)

w_post_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;keeocegnnv&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#keeocegnnv .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#keeocegnnv .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#keeocegnnv .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#keeocegnnv .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#keeocegnnv .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#keeocegnnv .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#keeocegnnv .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#keeocegnnv .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#keeocegnnv .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#keeocegnnv .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#keeocegnnv .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#keeocegnnv .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#keeocegnnv .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#keeocegnnv .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#keeocegnnv .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#keeocegnnv .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#keeocegnnv .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#keeocegnnv .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#keeocegnnv .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#keeocegnnv .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#keeocegnnv .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#keeocegnnv .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#keeocegnnv .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#keeocegnnv .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#keeocegnnv .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#keeocegnnv .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#keeocegnnv .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#keeocegnnv .gt_left {
  text-align: left;
}

#keeocegnnv .gt_center {
  text-align: center;
}

#keeocegnnv .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#keeocegnnv .gt_font_normal {
  font-weight: normal;
}

#keeocegnnv .gt_font_bold {
  font-weight: bold;
}

#keeocegnnv .gt_font_italic {
  font-style: italic;
}

#keeocegnnv .gt_super {
  font-size: 65%;
}

#keeocegnnv .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;mu&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sigma&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6704184&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.004895014&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6685570&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.005720891&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6708761&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.003932762&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6713238&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.004217306&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6689520&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.005191162&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..1399999&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1400000&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6720105&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.005901202&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-2-sided-bayesian-tolerance-interval-from-the-posterior---non-informative-priors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Calculate 2-Sided Bayesian Tolerance Interval from the Posterior - Non-Informative Priors&lt;/h3&gt;
&lt;p&gt;Our goal is to calculate the 95/90 tolerance limit. The Bayesian analogue involves doing a row-wise calculation for each posterior draw where the equivalent of a tolerance interval is calculated using the standard formula: x +/- ks, where x is mu and s is sigma. The k factor is taken as the .95 quantile of a unit normal distribution (thus excluding the top and bottom 5% for 90% coverage). Doing this for every row in the posterior produces a distribution of upper and lower tolerance bounds - 1 observation for each credible set of mu and sigma. The 95% “confidence” analogue is done by excluding the 2.5% most extreme values from the low end of the lower bound distribution and the 2.5% most extreme values from the high end of the upper bound distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bt_lower &amp;lt;- quantile(w_post_tbl$mu - qnorm(0.95) * w_post_tbl$sigma, 0.025)
bt_upper &amp;lt;- quantile(w_post_tbl$mu + qnorm(0.95) * w_post_tbl$sigma, 0.975)

bt_tbl &amp;lt;- tibble(
  lower_coverage_limit = bt_lower * 100 %&amp;gt;% round(4),
  upper_coverage_limit = bt_upper * 100 %&amp;gt;% round(4),
  method = as_factor(&amp;quot;Bayesian&amp;quot;)
)

bt_tbl %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;cpqafktvfr&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#cpqafktvfr .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#cpqafktvfr .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#cpqafktvfr .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#cpqafktvfr .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#cpqafktvfr .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#cpqafktvfr .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#cpqafktvfr .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#cpqafktvfr .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#cpqafktvfr .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#cpqafktvfr .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#cpqafktvfr .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#cpqafktvfr .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#cpqafktvfr .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#cpqafktvfr .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#cpqafktvfr .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#cpqafktvfr .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#cpqafktvfr .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#cpqafktvfr .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#cpqafktvfr .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#cpqafktvfr .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#cpqafktvfr .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#cpqafktvfr .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#cpqafktvfr .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#cpqafktvfr .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#cpqafktvfr .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#cpqafktvfr .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#cpqafktvfr .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#cpqafktvfr .gt_left {
  text-align: left;
}

#cpqafktvfr .gt_center {
  text-align: center;
}

#cpqafktvfr .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#cpqafktvfr .gt_font_normal {
  font-weight: normal;
}

#cpqafktvfr .gt_font_bold {
  font-weight: bold;
}

#cpqafktvfr .gt_font_italic {
  font-style: italic;
}

#cpqafktvfr .gt_super {
  font-size: 65%;
}

#cpqafktvfr .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;lower_coverage_limit&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;upper_coverage_limit&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;method&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;65.75688&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;68.44929&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;Bayesian&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;So the Bayesian version of a tolerance interval for those relatively vague priors is [65.84, 68.37] after back transforming the percentages to cg/g.&lt;/p&gt;
&lt;p&gt;The frequentist version for the same data is calculated as follows with the tolerance package (assuming normality of the experimental data):&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;frequentist-2-sided-tolerance-interval&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Frequentist 2-sided Tolerance Interval&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fr_tbl &amp;lt;- tidy(normtol.int(w_tbl$w, alpha = .05, P = .9, side = 2, method = &amp;quot;EXACT&amp;quot;)) %&amp;gt;%
  select(column, mean) %&amp;gt;%
  pivot_wider(
    names_from = &amp;quot;column&amp;quot;,
    values_from = &amp;quot;mean&amp;quot;
  ) %&amp;gt;%
  select(&amp;quot;2-sided.lower&amp;quot;, &amp;quot;2-sided.upper&amp;quot;) %&amp;gt;%
  mutate(method = as_factor(&amp;quot;Frequentist&amp;quot;)) %&amp;gt;%
  rename(
    lower_coverage_limit = &amp;quot;2-sided.lower&amp;quot;,
    upper_coverage_limit = &amp;quot;2-sided.upper&amp;quot;
  ) %&amp;gt;%
  select(method, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;combining-and-comparing-to-the-bayesian-version&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Combining and comparing to the Bayesian version:&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fr_tbl %&amp;gt;%
  bind_rows(bt_tbl) %&amp;gt;%
  mutate_if(is.numeric, round, digits = 2) %&amp;gt;%
  mutate(priors = c(&amp;quot;non_informative (implied)&amp;quot;, &amp;quot;non-informative&amp;quot;)) %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;div id=&#34;blgxhrurex&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#blgxhrurex .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#blgxhrurex .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#blgxhrurex .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#blgxhrurex .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#blgxhrurex .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#blgxhrurex .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#blgxhrurex .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#blgxhrurex .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#blgxhrurex .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#blgxhrurex .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#blgxhrurex .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#blgxhrurex .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#blgxhrurex .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#blgxhrurex .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#blgxhrurex .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#blgxhrurex .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#blgxhrurex .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#blgxhrurex .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#blgxhrurex .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#blgxhrurex .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#blgxhrurex .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#blgxhrurex .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#blgxhrurex .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#blgxhrurex .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#blgxhrurex .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#blgxhrurex .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#blgxhrurex .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#blgxhrurex .gt_left {
  text-align: left;
}

#blgxhrurex .gt_center {
  text-align: center;
}

#blgxhrurex .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#blgxhrurex .gt_font_normal {
  font-weight: normal;
}

#blgxhrurex .gt_font_bold {
  font-weight: bold;
}

#blgxhrurex .gt_font_italic {
  font-style: italic;
}

#blgxhrurex .gt_super {
  font-size: 65%;
}

#blgxhrurex .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;method&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;lower_coverage_limit&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;upper_coverage_limit&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;priors&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;Frequentist&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;65.95&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;68.25&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;non_informative (implied)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;Bayesian&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;65.76&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;68.45&lt;/td&gt;
&lt;td class=&#34;gt_row gt_left&#34;&gt;non-informative&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
These are quite close! The Bayesian version does remain bit wider. Perhaps with more iterations of MCMC or with slightly less vague priors, the Bayesian version would creep tighter until they converge.&lt;/p&gt;
&lt;p&gt;Plotting the upper and lower tolerance limits from the Bayesian version we see that the distribution (upper and lower bounds) are not normal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;w_post_tbl %&amp;gt;%
  mutate(
    upper_95 = qnorm(p = .95, mean = mu, sd = sigma),
    lower_95 = qnorm(p = .05, mean = mu, sd = sigma),
    id = as_factor(&amp;quot;posterior&amp;quot;)
  ) %&amp;gt;%
  sample_n(size = 10000) %&amp;gt;%
  pivot_longer(cols = c(upper_95, lower_95), names_to = &amp;quot;quantile&amp;quot;, values_to = &amp;quot;value&amp;quot;) %&amp;gt;%
  mutate(quantile = as_factor(quantile)) %&amp;gt;%
  ggplot(aes(x = value, y = id)) +
  geom_jitter(aes(color = quantile), width = .001, height = .1, size = .3, alpha = .05) +
  stat_halfeye(aes(fill = quantile), alpha = .7, position = position_nudge(y = .2)) +
  scale_color_manual(values = wes_palette(&amp;quot;Moonrise2&amp;quot;)) +
  scale_fill_manual(values = wes_palette(&amp;quot;Moonrise2&amp;quot;)) +
  #  scale_color_manual(values = c(&amp;quot;purple&amp;quot;, &amp;quot;limegreen&amp;quot;)) +
  #  scale_fill_manual(values = c(&amp;quot;purple&amp;quot;, &amp;quot;limegreen&amp;quot;)) +
  labs(
    x = &amp;quot;&amp;quot;,
    y = &amp;quot;&amp;quot;,
    title = &amp;quot;Distribution of Calculated Upper and Lower Tolerance Limits&amp;quot;,
    subtitle = &amp;quot;Calculated using Bayesian Method&amp;quot;,
    caption = &amp;quot;10,000 Predictions Sampled from Posterior (400,000 total)&amp;quot;
  ) +
  theme(
    legend.title = element_blank(),
    legend.position = &amp;quot;bottom&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-06-22-exploring-frequentist-and-bayesian-tolerance-intervals-in-r_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But the upper and lower bounds come in pairs. Plotting the pairs&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2345)

w_post_tbl %&amp;gt;%
  mutate(
    upper_95 = qnorm(p = .95, mean = mu, sd = sigma),
    lower_95 = qnorm(p = .05, mean = mu, sd = sigma)
  ) %&amp;gt;%
  sample_n(10000) %&amp;gt;%
  ggplot(aes(y = lower_95, x = upper_95)) +
  geom_point(alpha = .1, color = &amp;quot;#2c3e50&amp;quot;) +
  geom_hline(yintercept = bt_lower, linetype = 2) +
  geom_vline(xintercept = bt_upper, linetype = 2) +
  theme_minimal() %&amp;gt;%
  labs(
    x = &amp;quot;Predicted upper tolerance bound&amp;quot;,
    y = &amp;quot;Predicted lower tolerance bound&amp;quot;,
    title = &amp;quot;Credible Values for Upper and Lower 95% Bounds&amp;quot;,
    subtitle = &amp;quot;Based on Credible Posterior Draws&amp;quot;,
    caption = &amp;quot;10,000 Predictions Sampled from Posterior (400,000 total)&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-06-22-exploring-frequentist-and-bayesian-tolerance-intervals-in-r_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we can calculate the number of tolerance bounds that are both:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Above (within) the lower 95% tolerance bound for 90% coverage&lt;/li&gt;
&lt;li&gt;Below (within) the upper 95% tolerance bound for 90% coverage&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This number should be less than 500 if the coverage interval is doing its job of capturing &amp;gt;= 95% of the credible range, since this is a subset of 10,000 draws from the full posterior (which wouldn’t display well).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2345)

w_post_tbl %&amp;gt;%
  mutate(
    upper_95 = qnorm(p = .95, mean = mu, sd = sigma),
    lower_95 = qnorm(p = .05, mean = mu, sd = sigma)
  ) %&amp;gt;%
  sample_n(10000) %&amp;gt;%
  filter(
    lower_95 &amp;gt; bt_lower,
    upper_95 &amp;lt; bt_upper
  ) %&amp;gt;%
  gt_preview()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;div id=&#34;mrrkjpguhd&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#mrrkjpguhd .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#mrrkjpguhd .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#mrrkjpguhd .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#mrrkjpguhd .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#mrrkjpguhd .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#mrrkjpguhd .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#mrrkjpguhd .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#mrrkjpguhd .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#mrrkjpguhd .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#mrrkjpguhd .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#mrrkjpguhd .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#mrrkjpguhd .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#mrrkjpguhd .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#mrrkjpguhd .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#mrrkjpguhd .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#mrrkjpguhd .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#mrrkjpguhd .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#mrrkjpguhd .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#mrrkjpguhd .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#mrrkjpguhd .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#mrrkjpguhd .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#mrrkjpguhd .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#mrrkjpguhd .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#mrrkjpguhd .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#mrrkjpguhd .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#mrrkjpguhd .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#mrrkjpguhd .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#mrrkjpguhd .gt_left {
  text-align: left;
}

#mrrkjpguhd .gt_center {
  text-align: center;
}

#mrrkjpguhd .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#mrrkjpguhd .gt_font_normal {
  font-weight: normal;
}

#mrrkjpguhd .gt_font_bold {
  font-weight: bold;
}

#mrrkjpguhd .gt_font_italic {
  font-style: italic;
}

#mrrkjpguhd .gt_super {
  font-size: 65%;
}

#mrrkjpguhd .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;mu&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;sigma&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;upper_95&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;lower_95&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;1&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6734567&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.005124883&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6818864&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6650271&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;2&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6705619&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.004108660&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6773200&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6638037&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;3&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6704661&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.005681679&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6798116&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6611206&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;4&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6709579&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.003404294&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6765575&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6653584&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;5&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6706663&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.004703547&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6784029&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6629296&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier; font-size: x-small; background-color: #E4E4E4;&#34;&gt;6..9541&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #E4E4E4;&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td class=&#34;gt_row gt_left gt_stub&#34; style=&#34;font-family: Courier;&#34;&gt;9542&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6713993&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.004295096&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6784641&lt;/td&gt;
&lt;td class=&#34;gt_row gt_right&#34;&gt;0.6643345&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;
&lt;/div&gt;
9,542 rows means 458 of the least probable values excluded from this interval - this is acceptable coverage for the Bayesian interval.&lt;/p&gt;
&lt;p&gt;If you’ve made it this far, thank you for your attention.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session Info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.3 (2020-10-10)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18363)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] gt_0.2.2          patchwork_1.1.0   wesanderson_0.3.6 tolerance_2.0.0  
##  [5] tidybayes_2.3.1   broom_0.7.2       brms_2.14.4       Rcpp_1.0.5       
##  [9] here_1.0.0        forcats_0.5.0     stringr_1.4.0     dplyr_1.0.2      
## [13] purrr_0.3.4       readr_1.4.0       tidyr_1.1.2       tibble_3.0.4     
## [17] ggplot2_3.3.2     tidyverse_1.3.0  
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1            backports_1.2.0         plyr_1.8.6             
##   [4] igraph_1.2.6            splines_4.0.3           svUnit_1.0.3           
##   [7] crosstalk_1.1.0.1       rstantools_2.1.1        inline_0.3.16          
##  [10] digest_0.6.27           htmltools_0.5.0         rsconnect_0.8.16       
##  [13] fansi_0.4.1             checkmate_2.0.0         magrittr_2.0.1         
##  [16] modelr_0.1.8            RcppParallel_5.0.2      matrixStats_0.57.0     
##  [19] xts_0.12.1              prettyunits_1.1.1       colorspace_2.0-0       
##  [22] rvest_0.3.6             ggdist_2.3.0            haven_2.3.1            
##  [25] xfun_0.19               callr_3.5.1             crayon_1.3.4           
##  [28] jsonlite_1.7.1          lme4_1.1-25             zoo_1.8-8              
##  [31] glue_1.4.2              gtable_0.3.0            emmeans_1.5.2-1        
##  [34] webshot_0.5.2           V8_3.4.0                distributional_0.2.1   
##  [37] pkgbuild_1.1.0          rstan_2.21.2            abind_1.4-5            
##  [40] scales_1.1.1            mvtnorm_1.1-1           DBI_1.1.0              
##  [43] miniUI_0.1.1.1          xtable_1.8-4            stats4_4.0.3           
##  [46] StanHeaders_2.21.0-6    DT_0.16                 htmlwidgets_1.5.2      
##  [49] httr_1.4.2              threejs_0.3.3           arrayhelpers_1.1-0     
##  [52] ellipsis_0.3.1          farver_2.0.3            pkgconfig_2.0.3        
##  [55] loo_2.3.1               sass_0.3.1              dbplyr_2.0.0           
##  [58] labeling_0.4.2          manipulateWidget_0.10.1 tidyselect_1.1.0       
##  [61] rlang_0.4.9             reshape2_1.4.4          later_1.1.0.1          
##  [64] munsell_0.5.0           cellranger_1.1.0        tools_4.0.3            
##  [67] cli_2.2.0               generics_0.1.0          ggridges_0.5.2         
##  [70] evaluate_0.14           fastmap_1.0.1           yaml_2.2.1             
##  [73] processx_3.4.4          knitr_1.30              fs_1.5.0               
##  [76] rgl_0.103.5             nlme_3.1-150            mime_0.9               
##  [79] projpred_2.0.2          xml2_1.3.2              compiler_4.0.3         
##  [82] bayesplot_1.7.2         shinythemes_1.1.2       rstudioapi_0.13        
##  [85] gamm4_0.2-6             curl_4.3                reprex_0.3.0           
##  [88] statmod_1.4.35          stringi_1.5.3           ps_1.4.0               
##  [91] blogdown_0.15           Brobdingnag_1.2-6       lattice_0.20-41        
##  [94] Matrix_1.2-18           nloptr_1.2.2.2          markdown_1.1           
##  [97] shinyjs_2.0.0           vctrs_0.3.5             pillar_1.4.7           
## [100] lifecycle_0.2.0         bridgesampling_1.0-0    estimability_1.3       
## [103] httpuv_1.5.4            R6_2.5.0                bookdown_0.21          
## [106] promises_1.1.1          gridExtra_2.3           codetools_0.2-18       
## [109] boot_1.3-25             colourpicker_1.1.0      MASS_7.3-53            
## [112] gtools_3.8.2            assertthat_0.2.1        rprojroot_2.0.2        
## [115] withr_2.3.0             shinystan_2.5.0         mgcv_1.8-33            
## [118] parallel_4.0.3          hms_0.5.3               grid_4.0.3             
## [121] coda_0.19-4             minqa_1.2.4             rmarkdown_2.5          
## [124] shiny_1.5.0             lubridate_1.7.9.2       base64enc_0.1-3        
## [127] dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Stoudt S, Pintar A, Possolo A (2021) Coverage Intervals. J Res Natl Inst Stan 126:126004. &lt;a href=&#34;https://doi.org/10.6028/jres.126.004&#34; class=&#34;uri&#34;&gt;https://doi.org/10.6028/jres.126.004&lt;/a&gt;. &lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Boundary Conditions and Anatomy - Correlated Data and Kernel Density Estimation in R</title>
      <link>/post/boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/viz/viz.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/DiagrammeR-styles/styles.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/grViz-binding/grViz.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Measurements taken from patient anatomy are often correlated. For example, larger blood vessels might tend to have less curvature. Additionally, data are rarely Gaussian, favoring skewed shapes with some very large values and a lower bound of zero. These properties can make simulation and inference hard. In this post I will walk through a workflow for an engineering problem that might be presented in my industry. It involves simulating a population of patients and identifying a subset of interest.&lt;/p&gt;
&lt;p&gt;Imagine we have been assigned the task of identifying boundary conditions for a benchtop durability test of an implantable, artificial heart valve. In other words, we need to identify credible parameters for a physical test such that our test engineers can challenge the device under severe but realistic geometries and loads. To facilitate this task our clinical team has analyzed images and extracted measurements for the features of interest in a subset of n=300 patients. There are two main challenges when working with these data:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;How do we use our sample to simulate the full population?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;How do we use the simulated, full population to identify groups of interest and recommend boundary conditions for the test&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;The rest of this post explores what we should do with these data to resolve these challenges and identify appropriate and realistic test conditions.&lt;/p&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Data&lt;/h1&gt;
&lt;p&gt;Suppose the three parameters our team cares about are the &lt;strong&gt;&lt;em&gt;ellipticity&lt;/em&gt;&lt;/strong&gt; of the vessel cross section, &lt;strong&gt;&lt;em&gt;curvature&lt;/em&gt;&lt;/strong&gt; of the vessel in the vessel region of interest, and the blood &lt;strong&gt;&lt;em&gt;pressure&lt;/em&gt;&lt;/strong&gt;. Features such as these are important because they influence both the equilibrium geometry and the magnitude of forces acting on the implantable valve (in other words: the boundary conditions). The image below shows a schematic/example of ellipticity and vessel curvature in the LVOT and aortic valve annulus as observed in CT imaging.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/ellipticity_angulation.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I enjoy the tidyverse toolset for exploring and working with data so let’s get that loaded up along with some other packages that will help in the analysis to come.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(readxl)
library(knitr)
library(DiagrammeR)
library(fitdistrplus)
library(MASS)
library(ggrepel)
library(readxl)
library(ks)
library(broom)
library(ggExtra)
library(GGally)
library(car)
library(rgl)
library(anySim)
library(tidyverse)
library(plotly)&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#the-data&#34;&gt;The Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#correlations-in-the-original-dataset&#34;&gt;Correlations in the Original Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#anysim---generate-simulated-population-of-correlated-patient-data&#34;&gt;AnySim - Generate Simulated Population of Correlated Patient Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kernel-density-estimation---map-density-contours-to-data&#34;&gt;Kernel Density Estimation - Map Density Contours to Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#naive-method---apply-default-kde-to-lognormal-data&#34;&gt;Naive Method - Apply Default KDE to Lognormal Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#estimate-kde&#34;&gt;Estimate kde&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#density-proportions-from-kde-estimate&#34;&gt;Density proportions from kde estimate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kde-estimates-in-the-range-of-the-variables&#34;&gt;KDE estimates in the range of the variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#density-plot-with-probability-contours-in-3d&#34;&gt;Density Plot with Probability Contours in 3d&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fit-kde-to-normal-data-transform-later&#34;&gt;Fit KDE to normal data transform later&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#density-proportions-from-kde-estimate&#34;&gt;Density proportions from kde estimate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kde-estimates-in-the-range-of-the-variables&#34;&gt;KDE estimates in the range of the variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#density-plot-with-probability-contours-in-3d&#34;&gt;Density Plot with Probability Contours in 3d&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#transform-data-and-kde-contour-to-original-scale&#34;&gt;Transform data and kde contour to original scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plot-back-transformed-data-with-plotly&#34;&gt;Plot Back-Transformed Data with Plotly&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#filter-extreme-points-and-assess-points-on-95-5-contour&#34;&gt;Filter extreme points and assess points on 95-5 contour&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix-a---simulating-a-multivariate-distribution-with-mass-mvnorm&#34;&gt;Appendix A - simulating a multivariate distribution with mass mvnorm&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#step-1---fit-distributions-to-each-variable&#34;&gt;Step 1 - Fit Distributions to Each Variable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-2---transform-all-variables-to-normal&#34;&gt;Step 2 - Transform all variables to normal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-3---fit-normal-distributions-to-each-transformed-variable&#34;&gt;Step 3 - Fit normal distributions to each transformed variable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-4---draw-joint-distribution-using-mvrnorm()-or-equivalent-function&#34;&gt;Step 4 - Draw joint distribution using mvrnorm() or equivalent function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-5---back-transform-simulated-data-to-original-distribution&#34;&gt;Step 5 - Back-transform simulated data to original distribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#step-6---evaluate-parameters-and-marginal-distributions-of-the-back-transfomed-data&#34;&gt;Step 6 - Evaluate parameters and marginal distributions of the back-transfomed data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#compare-original-data-to-simulated-data&#34;&gt;Compare Original Data to Simulated Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix-b---2d-kde-plot-with-probability-traces&#34;&gt;Appendix B - 2d kde plot with probability traces&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Start by reading in the data and taking a look at the format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_data &amp;lt;- readRDS(file = &amp;quot;sim_anatomy_data.rds&amp;quot;)
sample_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 300 x 3
##    ellip  curv pressure
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1  1.26  4.51     92.7
##  2  1.28  5.02    183. 
##  3  1.29  4.03    154. 
##  4  1.23  2.14    109. 
##  5  1.13  3.67    124. 
##  6  1.22  2.37    114. 
##  7  1.10  3.06    113. 
##  8  1.04  2.31    105. 
##  9  1.11  5.31    115. 
## 10  1.09  2.04    109. 
## # ... with 290 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As expected, 300 rows with our 3 features of interest.&lt;/p&gt;
&lt;p&gt;It might seem tempting at this point to extract the maximum value from each group (or maybe something like the 95th percentile) and report those values together as a conservative worst-case. The problem with this approach is that each row of data is from a specific patient, so the variables are likely to be correlated. It could be that those severe values for each variable never occur together in the same patient. If we choose them all, we could over-test the device and over-design the device, potentially setting the program way behind. A more sophisticated approach is to consider the variables as a joint distribution and respect any correlation that may be present.&lt;/p&gt;
&lt;p&gt;Here is some code to visualize the marginal distributions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ellip_curv_plt &amp;lt;- sample_data %&amp;gt;%
  ggplot(aes(x = ellip, y = curv)) +
  geom_point(alpha = .5) +
  labs(
    title = &amp;quot;Patient Data From n=300 Scans&amp;quot;,
    subtitle = &amp;quot;Vessel Ellipticity and Vessel Curvature Joint Distribution&amp;quot;,
    x = &amp;quot;Ellipticity&amp;quot;,
    y = &amp;quot;Curvature (mm)&amp;quot;
  )

ellip_pressure_plt &amp;lt;- sample_data %&amp;gt;%
  ggplot(aes(x = ellip, y = pressure)) +
  geom_point(alpha = .5, color = &amp;quot;firebrick&amp;quot;) +
  labs(
    title = &amp;quot;Patient Data From n=300 Scans&amp;quot;,
    subtitle = &amp;quot;Vessel Ellipticity and Blood Pressure Joint Distribution&amp;quot;,
    x = &amp;quot;Ellipticity&amp;quot;,
    y = &amp;quot;Pressure (mm Hg)&amp;quot;
  )

curv_pressure_plt &amp;lt;- sample_data %&amp;gt;%
  ggplot(aes(x = curv, y = pressure)) +
  geom_point(alpha = .5, color = &amp;quot;limegreen&amp;quot;) +
  labs(
    title = &amp;quot;Patient Data From n=300 Scans&amp;quot;,
    subtitle = &amp;quot;Vessel Curvature and Blood Pressure Joint Distribution&amp;quot;,
    x = &amp;quot;Curvature (mm)&amp;quot;,
    y = &amp;quot;Pressure (mm Hg&amp;quot;
  )

ellip_curv_mplt &amp;lt;- ggExtra::ggMarginal(ellip_curv_plt, type = &amp;quot;density&amp;quot;, fill = &amp;quot;#2c3e50&amp;quot;, alpha = .5)
ellip_pressure_mplt &amp;lt;- ggExtra::ggMarginal(ellip_pressure_plt, type = &amp;quot;density&amp;quot;, fill = &amp;quot;firebrick&amp;quot;, alpha = .5)
curv_pressure_mplt &amp;lt;- ggExtra::ggMarginal(curv_pressure_plt, type = &amp;quot;density&amp;quot;, fill = &amp;quot;limegreen&amp;quot;, alpha = .5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The variables are strictly positive and show some skew. Let’s assume that from domain knowledge we know these variables to be well described by a lognormal. The visuals would be consistent with this assumption.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;correlations-in-the-original-dataset&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Correlations in the Original Dataset&lt;/h1&gt;
&lt;p&gt;ggcorr() from the GGally package is very convenient for visualizing correlations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_data %&amp;gt;% ggcorr(
  high = &amp;quot;#20a486ff&amp;quot;,
  low = &amp;quot;#fde725ff&amp;quot;,
  label = TRUE,
  hjust = .75,
  size = 3,
  label_size = 3,
  label_round = 3,
  nbreaks = 3
) +
  labs(
    title = &amp;quot;Correlation Matrix - n=300 Patient Set&amp;quot;,
    subtitle = &amp;quot;Pearson Method Using Pairwise Observations&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;
We see that there are some positive correlations in this dataset.&lt;/p&gt;
&lt;p&gt;To build out the sample into a simulated population we will fit a MLE estimate and use the model to push out a lot of predictions.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; If the variables were not correlated, we could just execute a few rlnorm()’s and bind them together. The job is more challenging when the variables are correlated because they must be simulated all at once.&lt;/p&gt;
&lt;p&gt;I know of 2 convenient engines in R to generate an arbitrary number of random values from a correlated, multivariate distribution:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AnySim::SimCorrRVs&lt;/strong&gt; : For this method you specify the parameters of the marginal distributions and correlation matrix.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;mass::mvnorm()&lt;/strong&gt; : For this method you transform each distribution to normal and supply the mean and sd of each variable along with the covariance matrix.&lt;/p&gt;
&lt;p&gt;My personal preference is for the AnySim method which I’ll show below. The code for executing a similar simulation with mass::mvnorm() is shown in Appendix A.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;anysim---generate-simulated-population-of-correlated-patient-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;AnySim - Generate Simulated Population of Correlated Patient Data&lt;/h1&gt;
&lt;p&gt;The AnySim workflow:&lt;/p&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:500px;&#34; class=&#34;grViz html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;diagram&#34;:&#34;digraph flowchart {\n      # node definitions with substituted label text\n      node [fontname = Helvetica, shape = rectangle, fillcolor = yellow]        \n      tab1 [label = \&#34;Step 1: Specify desired distributions for each variable and store as object\&#34;]\n      tab2 [label = \&#34;Step 2: Specify parameters for each variable and store as object\&#34;]\n      tab3 [label = \&#34;Step 3: Specify desired correlation matrix and store as object\&#34;]\n      tab4 [label = \&#34;Step 4: Provide the above information to EstCorrRVs() to estimate\n parameters of auxiliary Gaussian model\&#34;]\n      tab5 [label = \&#34;Step 5: Generate simulated values using SimcorrRVs()\&#34;]\n      # edge definitions with the node IDs\n      tab1 -&gt; tab2 -&gt; tab3 -&gt; tab4 -&gt; tab5;\n      }\n      &#34;,&#34;config&#34;:{&#34;engine&#34;:&#34;dot&#34;,&#34;options&#34;:null}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;First: fit distributions to the original data and calculate correlations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ellip_fit &amp;lt;- fitdist(sample_data$ellip, &amp;quot;lnorm&amp;quot;)
curv_fit &amp;lt;- fitdist(sample_data$curv, &amp;quot;lnorm&amp;quot;)
pressure_fit &amp;lt;- fitdist(sample_data$pressure, &amp;quot;lnorm&amp;quot;)

# store lognormal parameters of original data
ellip_meanlog &amp;lt;- ellip_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
ellip_sdlog &amp;lt;- ellip_fit$estimate[[&amp;quot;sdlog&amp;quot;]]
curv_meanlog &amp;lt;- curv_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
curv_sdlog &amp;lt;- curv_fit$estimate[[&amp;quot;sdlog&amp;quot;]]
pressure_meanlog &amp;lt;- pressure_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
pressure_sdlog &amp;lt;- pressure_fit$estimate[[&amp;quot;sdlog&amp;quot;]]

# store correlations in original data
cor_ec &amp;lt;- cor(x = sample_data$ellip, y = sample_data$curv)
cor_ep &amp;lt;- cor(x = sample_data$ellip, y = sample_data$pressure)
cor_cp &amp;lt;- cor(x = sample_data$curv, y = sample_data$pressure)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apply the AnySim workflow. Note that this too goes through an auxiliary normal intermediate step.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)

# Define the target distribution functions (ICDFs) of each random variable.

ellip_dist &amp;lt;- &amp;quot;qlnorm&amp;quot;
curv_dist &amp;lt;- &amp;quot;qlnorm&amp;quot;
pressure_dist &amp;lt;- &amp;quot;qlnorm&amp;quot;

# store the 3 ICDFs in a vector
dist_vec &amp;lt;- c(ellip_dist, curv_dist, pressure_dist)

# Define the parameters of the target distribution functions - store them in a list
ellip_params &amp;lt;- list(meanlog = ellip_meanlog, sdlog = ellip_sdlog)
curv_params &amp;lt;- list(meanlog = curv_meanlog, sdlog = curv_sdlog)
pressure_params &amp;lt;- list(meanlog = pressure_meanlog, sdlog = pressure_sdlog)

# this is a weird way to do it but I&amp;#39;m following along with an example from AnySim vignette :)
params_list &amp;lt;- list(NULL)
params_list[[1]] &amp;lt;- ellip_params
params_list[[2]] &amp;lt;- curv_params
params_list[[3]] &amp;lt;- pressure_params

# Define the target correlation matrix.
corr_matrix &amp;lt;- matrix(c(
  1, 0.268, 0.369,
  0.268, 1, .213,
  0.369, 0.213, 1
),
ncol = 3,
nrow = 3,
byrow = T
)
# Estimate the parameters of the auxiliary Gaussian model.
aux_gaussion_param_tbl &amp;lt;- EstCorrRVs(
  R = corr_matrix, dist = dist_vec, params = params_list,
  NatafIntMethod = &amp;quot;GH&amp;quot;, NoEval = 9, polydeg = 8
)


# Generate 10000 synthetic realizations of the 3 correlated RVs.
correlated_ln_draws_tbl &amp;lt;- as_tibble(SimCorrRVs(n = 10000, paramsRVs = aux_gaussion_param_tbl)) %&amp;gt;%
  rename(
    ellip = V1,
    curv = V2,
    pressure = V3
  )

correlated_ln_draws_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;ellip&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.123496&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.674471&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;78.14516&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.234755&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.927320&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;104.53631&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.299794&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.071074&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;116.55043&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.045001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.721336&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;106.23896&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.246727&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.091741&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;102.83055&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.252843&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.869394&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.24030&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.169606&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.613312&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;125.12784&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.171699&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.921069&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;156.06701&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.170371&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.672507&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;145.82545&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.146382&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.030319&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;89.91766&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Evaluate recovered marginal distributions with some helper functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extract_params_sim_fcn &amp;lt;- function(var, fit_to) {
  tidy(fitdistr(correlated_ln_draws_tbl %&amp;gt;% pull(var), fit_to)) %&amp;gt;%
    mutate(
      var = {
        var
      },
      dataset = &amp;quot;sim_draws&amp;quot;
    )
}

extract_params_pat_fcn &amp;lt;- function(var, fit_to) {
  tidy(fitdistr(sample_data %&amp;gt;% pull(var), fit_to)) %&amp;gt;%
    mutate(
      var = {
        var
      },
      dataset = &amp;quot;patient_set&amp;quot;
    )
}

sim_results_tbl &amp;lt;- tibble(
  var = c(&amp;quot;ellip&amp;quot;, &amp;quot;curv&amp;quot;, &amp;quot;pressure&amp;quot;),
  fit_to = rep(&amp;quot;lognormal&amp;quot;, 3)
) %&amp;gt;%
  mutate(params = map2(.x = var, .y = fit_to, .f = extract_params_sim_fcn)) %&amp;gt;%
  unnest() %&amp;gt;%
  dplyr::select(-var1)

pat_results_tbl &amp;lt;- tibble(
  var = c(&amp;quot;ellip&amp;quot;, &amp;quot;curv&amp;quot;, &amp;quot;pressure&amp;quot;),
  fit_to = rep(&amp;quot;lognormal&amp;quot;, 3)
) %&amp;gt;%
  mutate(params = map2(.x = var, .y = fit_to, .f = extract_params_pat_fcn)) %&amp;gt;%
  unnest() %&amp;gt;%
  dplyr::select(-var1)

sim_results_tbl %&amp;gt;%
  bind_rows(pat_results_tbl) %&amp;gt;%
  select(-std.error) %&amp;gt;%
  pivot_wider(id_cols = everything(), names_from = &amp;quot;dataset&amp;quot;, values_from = &amp;quot;estimate&amp;quot;) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;var&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;fit_to&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sim_draws&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;patient_set&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;lognormal&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1936145&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1932254&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;lognormal&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0628128&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0636092&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;lognormal&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1561942&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1579793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;lognormal&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.3114360&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.3091606&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;lognormal&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.7841496&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.7831767&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;lognormal&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1896585&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1910081&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Evaluate recovered correlations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;correlated_ln_draws_tbl %&amp;gt;% ggcorr(
  high = &amp;quot;#20a486ff&amp;quot;,
  low = &amp;quot;#fde725ff&amp;quot;,
  label = TRUE,
  hjust = .75,
  size = 3,
  label_size = 3,
  label_round = 3,
  nbreaks = 3
) +
  labs(
    title = &amp;quot;Correlation Matrix - n=10000 Simulation Set&amp;quot;,
    subtitle = &amp;quot;Pearson Method Using Pairwise Observations&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s take a look at the simulated population:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fig &amp;lt;- plotly::plot_ly()

fig &amp;lt;- fig %&amp;gt;% add_trace(x = correlated_ln_draws_tbl$ellip, y = correlated_ln_draws_tbl$curv, z = correlated_ln_draws_tbl$pressure, type = &amp;quot;scatter3d&amp;quot;, opacity = .4, hoverinfo = &amp;quot;none&amp;quot;, size = .1)

fig &amp;lt;- fig %&amp;gt;%
  layout(scene = list(
    xaxis = list(title = &amp;quot;ellip&amp;quot;),
    yaxis = list(title = &amp;quot;curv&amp;quot;),
    zaxis = list(title = &amp;quot;pressure&amp;quot;)
  )) %&amp;gt;%
  layout(scene = list(
    xaxis = list(showspikes = FALSE),
    yaxis = list(showspikes = FALSE),
    zaxis = list(showspikes = FALSE)
  ))

# fig&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/j1.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/j2.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;
&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/j3.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;kernel-density-estimation---map-density-contours-to-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Kernel Density Estimation - Map Density Contours to Data&lt;/h1&gt;
&lt;p&gt;The above tables and figures confirm the simulated population maintains the correlation structure and marginal distributions from the original sample as intended. The next step will be to build out some density estimates using a non-parametric, kernel density estimator. The reason we would want to do this is to understand the regions where data points are likely to fall and we can use the reference contours to identify the most extreme patients relative to the mode or to some region of interest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Important Watch-Out&lt;/strong&gt; : The exact workflow for generating and applying the kernel density estimate may vary depending on the data type. The default kde procedures may assign probabilities to regions outside the rigid boundaries when data does not have infinite support. This will occur for our dataset, since all of our variables are lognormal and should therefore never be negative. Methods for addressing this behavior include variable bandwidth estimators, transformations of estimators, and boundary estimators. To illustrate this problem and provide an example of resolution, I will show 2 parallel workflows below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the first, I apply the default global bandwidth kde to the simulated data&lt;/li&gt;
&lt;li&gt;In the second, I transform the data from lognormal to normal, apply the kde, then backtransform to lognormal&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Towards that end, I’ll add some more variables for transformed, normal version of each variable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corr_draws_tbl &amp;lt;- correlated_ln_draws_tbl %&amp;gt;%
  mutate(
    ellip_n = log(ellip),
    curv_n = log(curv),
    pressure_n = log(pressure)
  ) %&amp;gt;%
  select(ellip_n, curv_n, pressure_n)

corr_draws_tbl %&amp;gt;%
  head(5) %&amp;gt;%
  kable(aalign = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;ellip_n&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;curv_n&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;pressure_n&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.1164450&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5154974&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.358568&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.2108725&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.3679574&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.649534&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.2622058&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.4039068&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.758324&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.0440175&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0011228&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.665691&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.2205217&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.6276199&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.633083&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Quick visual check to verify the transformed properly:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corr_draws_tbl %&amp;gt;%
  pivot_longer(cols = everything()) %&amp;gt;%
  ggplot(aes(x = value)) +
  geom_density() +
  facet_wrap(~name, scales = &amp;quot;free&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;naive-method---apply-default-kde-to-lognormal-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Naive Method - Apply Default KDE to Lognormal Data&lt;/h1&gt;
&lt;div id=&#34;estimate-kde&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Estimate kde&lt;/h2&gt;
&lt;p&gt;The kde is constructed as follows:&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This first chunk converts the data and generates the kde. The bandwidth parameters controls the “smoothness” or granularity of the estimate and can be hard to specify in multiple dimensions. Hscv() provides a method of determining a reasonable bandwidth through cross-validation; see documentation in footnotes for more information if interested.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert simulated data tibble to matrix
d3m &amp;lt;- correlated_ln_draws_tbl %&amp;gt;%
  as.matrix()

# cross-validated bandwidth for kd (takes a while to calculate)
# hscv1 &amp;lt;- Hscv(correlated_ln_draws_tbl)
# hscv1 %&amp;gt;% write_rds(here::here(&amp;quot;hscv1.rds&amp;quot;))

hscv1 &amp;lt;- read_rds(here::here(&amp;quot;hscv1.rds&amp;quot;))

# generate kernel density estimate from simulated population
kd_d3m &amp;lt;- ks::kde(d3m, H = hscv1, compute.cont = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;density-proportions-from-kde-estimate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Density proportions from kde estimate&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# see the kde&amp;#39;s calculated density thresholds for specified proportions
cont_vals_tbl &amp;lt;- tidy(kd_d3m$cont) %&amp;gt;%
  mutate(n_row = row_number()) %&amp;gt;%
  mutate(probs = 100 - n_row) %&amp;gt;%
  select(probs, x)

reference_grid_probs_tbl &amp;lt;- cont_vals_tbl %&amp;gt;%
  rename(estimate = x)

reference_grid_probs_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;probs&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0342569&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;98&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0333578&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;97&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0326260&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0318672&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;95&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0312299&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;94&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0305985&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0300632&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;92&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0293781&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;91&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0289256&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;90&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0283849&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;kde-estimates-in-the-range-of-the-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;KDE estimates in the range of the variables&lt;/h2&gt;
&lt;p&gt;By default the KDE provides density estimates for a grid of points that covers the space of the variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kd_grid_estimates &amp;lt;- kd_d3m&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we want to know the value at each point in the simulated population we use the eval.points argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_estimates &amp;lt;- ks::kde(
  x = d3m, H = hscv1,
  compute.cont = TRUE,
  eval.points = correlated_ln_draws_tbl %&amp;gt;% as.matrix()
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are a couple different ways to convert the kde object features into a tibble:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_est_tbl_10000 &amp;lt;- tibble(estimate = mc_estimates$estimate) %&amp;gt;%
  bind_cols(correlated_ln_draws_tbl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kd_grid_est_tbl_29k &amp;lt;- broom:::tidy.kde(kd_grid_estimates) %&amp;gt;%
  pivot_wider(names_from = variable, values_from = value) %&amp;gt;%
  rename(ellip = x1, curv = x2, pressure = x3) %&amp;gt;%
  select(-obs)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each data point in our population has a estimate. Each data point on the grid that covers the space of interest has an estimate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_est_tbl_10000 %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;ellip&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0032540&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.123496&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.674471&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;78.14516&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0167218&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.234755&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.927320&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;104.53631&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0114561&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.299794&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.071074&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;116.55043&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0042927&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.045001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.721336&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;106.23896&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0050883&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.246727&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.091741&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;102.83055&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0123645&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.252843&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.869394&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.24030&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0073055&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.169606&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.613312&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;125.12784&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0061654&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.171699&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.921069&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;156.06701&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0103851&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.170371&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.672507&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;145.82545&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.0158417&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.146382&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.030319&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;89.91766&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kd_grid_est_tbl_29k %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;ellip&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8949674&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0080549&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;30.51151&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9187883&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0080549&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;30.51151&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9426092&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0080549&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;30.51151&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9664302&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0080549&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;30.51151&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9902511&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0080549&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;30.51151&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0140720&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0080549&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;30.51151&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0378929&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0080549&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;30.51151&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0617138&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0080549&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;30.51151&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0855347&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0080549&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;30.51151&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1093556&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0080549&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;30.51151&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The ks package automatically stores the quantiles of the estimate variable when calculating the kde. We can access those probability boundaries by sub-setting the kd object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 5% contour line from kd grid based on 10k MC data
percentile_5 &amp;lt;- kd_d3m[[&amp;quot;cont&amp;quot;]][&amp;quot;5%&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Verify that 5% (500/10,000) values fall below the threshold:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_est_tbl_10000 %&amp;gt;% filter(estimate &amp;lt;= percentile_5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 500 x 4
##    estimate ellip  curv pressure
##       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 0.000418  1.41  4.68    184. 
##  2 0.000377  1.30  7.27    144. 
##  3 0.000951  1.06  3.32     72.1
##  4 0.000704  1.28  7.10    125. 
##  5 0.000719  1.17  2.59     62.1
##  6 0.000114  1.47  3.18    189. 
##  7 0.000905  1.01  3.21    102. 
##  8 0.000182  1.06  5.85    103. 
##  9 0.000521  1.36  4.04    200. 
## 10 0.000742  1.40  3.58     97.4
## # ... with 490 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;500 / 10,000 is the correct coverage for the 5/95 boundary.&lt;/p&gt;
&lt;p&gt;If we wanted to know the nearest probability contour line for every point we could make a function to do so.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_probs_fcn &amp;lt;- function(value) {
  t &amp;lt;- reference_grid_probs_tbl %&amp;gt;%
    mutate(value = value) %&amp;gt;%
    mutate(dif = abs(estimate - value)) %&amp;gt;%
    filter(dif == min(dif))

  t[[1, 1]]
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Map the function over each value in the dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mc_1_to_99_tbl &amp;lt;- mc_est_tbl_10000 %&amp;gt;%
#   mutate(nearest_prob = map_dbl(estimate, get_probs_fcn))

# mc_1_to_99_tbl %&amp;gt;% write_rds(here::here(&amp;quot;mc_1_to_99_tbl.rds&amp;quot;))
mc_1_to_99_tbl &amp;lt;- read_rds(here::here(&amp;quot;mc_1_to_99_tbl.rds&amp;quot;))

mc_1_to_99_tbl&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10,000 x 5
##    estimate ellip  curv pressure nearest_prob
##       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
##  1  0.0140   1.27  2.16    133.            59
##  2  0.0119   1.20  4.44    127.            52
##  3  0.00265  1.38  2.65    160.            14
##  4  0.0194   1.24  3.62    142.            75
##  5  0.0122   1.32  2.54    129.            53
##  6  0.0168   1.26  3.24    147.            68
##  7  0.00555  1.33  3.39    168.            28
##  8  0.0112   1.24  4.25    146.            50
##  9  0.00826  1.19  1.85     87.7           39
## 10  0.00197  1.32  4.14     90.5           11
## # ... with 9,990 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the data, kde estimate, and nearest probability contour region boundary are stored in one tibble.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;density-plot-with-probability-contours-in-3d&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Density Plot with Probability Contours in 3d&lt;/h2&gt;
&lt;p&gt;Honestly, this part is pretty easy thanks to a built in plot.kde method. Just use the cont argument to specify with probability contours you want.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#plot(x = kd_d3m, cont = c(45, 70, 95), drawpoints = FALSE, col.pt = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/3d_cont_1.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Add points using the points3d function. In this case I add 2 sets, 1 for the 5% most extreme and 1 for the 95% most common.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot(x = kd_d3m, cont = c(95) ,drawpoints = FALSE, col.pt = 1)
mc_lowest_5_tbl &amp;lt;- mc_1_to_99_tbl %&amp;gt;% filter(estimate &amp;lt; percentile_5)
mc_6_to_100_tbl &amp;lt;- mc_1_to_99_tbl %&amp;gt;% filter(estimate &amp;gt;= percentile_5)

# points3d(x = mc_lowest_5_tbl$ellip, y = mc_lowest_5_tbl$curv, z = mc_lowest_5_tbl$pressure, color = &amp;quot;dodgerblue&amp;quot;,  size = 3, alpha = 1)

# points3d(x = mc_6_to_100_tbl$ellip, y = mc_6_to_100_tbl$curv, z = mc_6_to_100_tbl$pressure, color = &amp;quot;black&amp;quot;,  size = 3, alpha = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/3d_cont_2.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;See the problem here? In the areas on the lower right of the middle and right-most images, the data stops but the surface keeps going. This is because the data has a boundary there due to being log-normal but the kde doesn’t know. See closeup below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/3dd3.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As previously mentioned, this can be addressed by using the normal dataset to fit the kde and then back-transforming both the data and the surface:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-kde-to-normal-data-transform-later&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fit KDE to normal data transform later&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert simulated data tibble to matrix
d3m_n &amp;lt;- corr_draws_tbl %&amp;gt;%
  as.matrix()

# cross-validated bandwidth for kd (takes a while to calculate)
# hscv1_n &amp;lt;- Hscv(corr_draws_tbl)
# hscv1_n %&amp;gt;% write_rds(here::here(&amp;quot;hscv1_n.rds&amp;quot;))

hscv1_n &amp;lt;- read_rds(here::here(&amp;quot;hscv1_n.rds&amp;quot;))

# generate kernel density estimate from simulated population
kd_d3m_n &amp;lt;- ks::kde(d3m_n, H = hscv1_n, compute.cont = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;density-proportions-from-kde-estimate-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Density proportions from kde estimate&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# see the kde&amp;#39;s calculated density thresholds for specified proportions
cont_vals_tbl_n &amp;lt;- tidy(kd_d3m_n$cont) %&amp;gt;%
  mutate(n_row = row_number()) %&amp;gt;%
  mutate(probs = 100 - n_row) %&amp;gt;%
  select(probs, x)

reference_grid_probs_tbl_n &amp;lt;- cont_vals_tbl_n %&amp;gt;%
  rename(estimate = x)

reference_grid_probs_tbl_n %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;probs&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;15.39736&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;98&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14.90526&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;97&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14.53676&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14.16539&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;95&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;13.86481&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;94&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;13.56653&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;13.26884&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;92&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12.98302&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;91&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12.72985&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;90&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12.51655&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;kde-estimates-in-the-range-of-the-variables-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;KDE estimates in the range of the variables&lt;/h2&gt;
&lt;p&gt;By default the KDE provides density estimates for a grid of points that covers the space of the variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kd_grid_estimates_n &amp;lt;- kd_d3m_n&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we want to know the value at each point in the simulated population we use the eval.points argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_estimates_n &amp;lt;- ks::kde(
  x = d3m_n, H = hscv1_n,
  compute.cont = TRUE,
  eval.points = corr_draws_tbl %&amp;gt;% as.matrix()
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are a couple different ways to convert the kde object features into a tibble:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_est_tbl_10000_n &amp;lt;- tibble(estimate = mc_estimates_n$estimate) %&amp;gt;%
  bind_cols(corr_draws_tbl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kd_grid_est_tbl_29k_n &amp;lt;- broom:::tidy.kde(kd_grid_estimates_n) %&amp;gt;%
  pivot_wider(names_from = variable, values_from = value) %&amp;gt;%
  rename(ellip_n = x1, curv_n = x2, pressure_n = x3) %&amp;gt;%
  select(-obs)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each data point in our population has a estimate. Each data point on the grid that covers the space of interest has an estimate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_est_tbl_10000_n %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;ellip_n&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv_n&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure_n&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.5480641&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1164450&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5154974&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.358568&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8.5263883&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2108725&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.3679574&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.649534&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6.8647221&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2622058&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.4039068&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.758324&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.2686865&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0440175&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0011228&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.665691&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.4062801&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2205217&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6276199&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.633083&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4.3754649&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2254152&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0541010&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.535180&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.5083333&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1566667&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.4782892&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.829336&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.3766180&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1584546&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0719497&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.050286&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5.0036132&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1573211&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9830169&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.982410&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4.9614118&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1366109&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1086680&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.498894&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kd_grid_est_tbl_29k_n %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;ellip_n&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv_n&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure_n&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0877414&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.4268598&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.811282&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0685395&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.4268598&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.811282&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0493375&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.4268598&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.811282&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0301356&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.4268598&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.811282&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.0109337&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.4268598&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.811282&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0082682&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.4268598&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.811282&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0274701&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.4268598&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.811282&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0466721&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.4268598&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.811282&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0658740&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.4268598&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.811282&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0850759&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.4268598&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.811282&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 5% contour line from kd grid based on 10k MC data
percentile_5_n &amp;lt;- kd_d3m_n[[&amp;quot;cont&amp;quot;]][&amp;quot;5%&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Verify that 5% (500/10,000) values fall below the threshold:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_est_tbl_10000_n %&amp;gt;% filter(estimate &amp;lt;= percentile_5_n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 500 x 4
##    estimate ellip_n curv_n pressure_n
##       &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1   0.437   0.347   1.54        5.21
##  2   0.218   0.0546  1.20        4.28
##  3   0.346   0.114   0.375       4.43
##  4   0.340   0.121   0.382       4.96
##  5   0.0880  0.153   0.951       4.13
##  6   0.0860  0.387   1.16        5.24
##  7   0.268   0.0116  1.17        4.62
##  8   0.0957  0.0610  1.77        4.63
##  9   0.513   0.310   1.40        5.30
## 10   0.300   0.195   0.260       4.75
## # ... with 490 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;500 / 10,000 is the correct coverage for the 5/95 boundary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_probs_fcn_n &amp;lt;- function(value) {
  t &amp;lt;- reference_grid_probs_tbl_n %&amp;gt;%
    mutate(value = value) %&amp;gt;%
    mutate(dif = abs(estimate - value)) %&amp;gt;%
    filter(dif == min(dif))

  t[[1, 1]]
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Map the function over each value in the dataset and then the grid.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mc_1_to_99_tbl_n &amp;lt;- mc_est_tbl_10000_n %&amp;gt;%
#   mutate(nearest_prob = map_dbl(estimate, get_probs_fcn_n))
# #
# mc_1_to_99_tbl_n %&amp;gt;% write_rds(here::here(&amp;quot;mc_1_to_99_tbl_n.rds&amp;quot;))
mc_1_to_99_tbl_n &amp;lt;- read_rds(here::here(&amp;quot;mc_1_to_99_tbl_n.rds&amp;quot;))

mc_1_to_99_tbl_n&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10,000 x 5
##    estimate ellip_n curv_n pressure_n nearest_prob
##       &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
##  1    0.548  0.116   0.515       4.36            5
##  2    8.53   0.211   1.37        4.65           70
##  3    6.86   0.262   1.40        4.76           58
##  4    1.27   0.0440  1.00        4.67           12
##  5    3.41   0.221   1.63        4.63           32
##  6    4.38   0.225   1.05        4.54           39
##  7    1.51   0.157   0.478       4.83           14
##  8    3.38   0.158   1.07        5.05           31
##  9    5.00   0.157   0.983       4.98           44
## 10    4.96   0.137   1.11        4.50           44
## # ... with 9,990 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grid_probs_tbl_n &amp;lt;- kd_grid_est_tbl_29k_n %&amp;gt;%
  mutate(nearest_prob = map_dbl(estimate, get_probs_fcn_n))

grid_probs_tbl_n %&amp;gt;% write_rds(here::here(&amp;quot;grid_probs_tbl_n.rds&amp;quot;))
grid_probs_tbl_n &amp;lt;- read_rds(here::here(&amp;quot;grid_probs_tbl_n.rds&amp;quot;))



grid_probs_95_n &amp;lt;- grid_probs_tbl_n %&amp;gt;%
  filter(nearest_prob == 95)

grid_probs_95_n %&amp;gt;% arrange(desc(nearest_prob))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 5
##   estimate ellip_n curv_n pressure_n nearest_prob
##      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1     13.8   0.162   1.09       4.68           95
## 2     13.8   0.200   1.20       4.68           95
## 3     13.8   0.219   1.20       4.74           95
## 4     13.8   0.219   1.09       4.80           95&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grid_probs_95_n %&amp;gt;%
  head(5) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;ellip_n&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv_n&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure_n&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;nearest_prob&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13.84582&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1618836&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.094335&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.679386&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13.75222&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2002874&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.195748&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.679386&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13.83862&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2194893&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.195748&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.741394&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13.83317&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2194893&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.094335&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.803401&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;95&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;density-plot-with-probability-contours-in-3d-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Density Plot with Probability Contours in 3d&lt;/h2&gt;
&lt;p&gt;Honestly, this part is pretty easy thanks to a built in plot.kde method. Just use the cont argument to specify with probability contours you want.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(x = kd_d3m_n, cont = c(45, 70, 95), drawpoints = FALSE, col.pt = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/pp1.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;and with points&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_lowest_5_tbl_n &amp;lt;- mc_1_to_99_tbl_n %&amp;gt;% filter(estimate &amp;lt; percentile_5_n)
mc_6_to_100_tbl_n &amp;lt;- mc_1_to_99_tbl_n %&amp;gt;% filter(estimate &amp;gt;= percentile_5_n)

plot(x = kd_d3m_n, cont = c(95), drawpoints = FALSE, col.pt = 1)


points3d(x = mc_lowest_5_tbl_n$ellip_n, y = mc_lowest_5_tbl_n$curv_n, z = mc_lowest_5_tbl_n$pressure_n, color = &amp;quot;dodgerblue&amp;quot;, size = 3, alpha = 1)

points3d(x = mc_6_to_100_tbl_n$ellip_n, y = mc_6_to_100_tbl_n$curv_n, z = mc_6_to_100_tbl_n$pressure_n, color = &amp;quot;black&amp;quot;, size = 3, alpha = 1)

points3d(x = grid_probs_tbl_n$ellip_n, y = grid_probs_tbl_n$curv_n, z = grid_probs_tbl_n$pressure_n, color = &amp;quot;firebrick&amp;quot;, size = 2, alpha = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/pp2.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;transform-data-and-kde-contour-to-original-scale&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Transform data and kde contour to original scale&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mc_lowest_5_tbl_nbt &amp;lt;- mc_lowest_5_tbl_n %&amp;gt;% mutate(
  ellip_bt = exp(ellip_n),
  curv_bt = exp(curv_n),
  pressure_bt = exp(pressure_n)
)
mc_6_to_100_tbl_nbt &amp;lt;- mc_6_to_100_tbl_n %&amp;gt;% mutate(
  ellip_bt = exp(ellip_n),
  curv_bt = exp(curv_n),
  pressure_bt = exp(pressure_n)
)

full_mc_bt_tbl &amp;lt;- mc_lowest_5_tbl_nbt %&amp;gt;%
  bind_rows(mc_6_to_100_tbl_nbt)

grid_probs_95_bt &amp;lt;- grid_probs_tbl_n %&amp;gt;%
  filter(nearest_prob == 05) %&amp;gt;%
  mutate(
    ellip_bt = exp(ellip_n),
    curv_bt = exp(curv_n),
    pressure_bt = exp(pressure_n)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-back-transformed-data-with-plotly&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot Back-Transformed Data with Plotly&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fig &amp;lt;- plotly::plot_ly()

fig &amp;lt;- fig %&amp;gt;% add_trace(x = grid_probs_95_bt$ellip_bt, y = grid_probs_95_bt$curv_bt, z = grid_probs_95_bt$pressure_bt, type = &amp;quot;mesh3d&amp;quot;, alphahull = 0, opacity = .5, hoverinfo = &amp;quot;none&amp;quot;)


fig &amp;lt;- fig %&amp;gt;% add_trace(x = mc_lowest_5_tbl_nbt$ellip_bt, y = mc_lowest_5_tbl_nbt$curv_bt, z = mc_lowest_5_tbl_nbt$pressure_bt, type = &amp;quot;scatter3d&amp;quot;, size = 30)

fig &amp;lt;- fig %&amp;gt;% add_trace(x = mc_6_to_100_tbl_nbt$ellip_bt, y = mc_6_to_100_tbl_nbt$curv_bt, z = mc_6_to_100_tbl_nbt$pressure_bt, type = &amp;quot;scatter3d&amp;quot;, size = 30)

fig &amp;lt;- fig %&amp;gt;%
  layout(scene = list(
    xaxis = list(title = &amp;quot;ellip&amp;quot;),
    yaxis = list(title = &amp;quot;curv&amp;quot;),
    zaxis = list(title = &amp;quot;pressure&amp;quot;)
  )) %&amp;gt;%
  layout(scene = list(
    xaxis = list(showspikes = FALSE),
    yaxis = list(showspikes = FALSE),
    zaxis = list(showspikes = FALSE)
  ))

# fig&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/pp3.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The new image (shown on right) looks different near the boundary. Because we transformed everything from normal, no portion of the contour goes beyond the point cloud. This is what we want!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;filter-extreme-points-and-assess-points-on-95-5-contour&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Filter extreme points and assess points on 95-5 contour&lt;/h1&gt;
&lt;p&gt;Now that our kde contour is set up to properly segregate the extreme points relative to the mode, we can filter them away and assess the remaining points which lie on the contour. We do this by pulling the grid points that make up the 95/5 surface and evaluating them as percentiles.&lt;/p&gt;
&lt;p&gt;First, the ecdfs to get the percentiles from each variable&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;e1f &amp;lt;- ecdf(full_mc_bt_tbl$ellip_bt)
e2f &amp;lt;- ecdf(full_mc_bt_tbl$curv_bt)
e3f &amp;lt;- ecdf(full_mc_bt_tbl$pressure_bt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Map ecdfs over the variables and then use the sum of the percentiles as a way to identify the largest values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_probs_95_tbl &amp;lt;- grid_probs_95_bt %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(
    percentile_e = map_dbl(ellip_bt, e1f),
    percentile_c = map_dbl(curv_bt, e2f),
    percentile_p = map_dbl(pressure_bt, e3f)
  ) %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(pct_sum = sum(c(percentile_e, percentile_c, percentile_p))) %&amp;gt;%
  ungroup() %&amp;gt;%
  arrange(desc(pct_sum)) %&amp;gt;%
  mutate(pct_sum_rank = row_number()) %&amp;gt;%
  select(ellip_bt, curv_bt, pressure_bt, percentile_e, percentile_c, percentile_p, pct_sum)

full_probs_95_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;ellip_bt&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv_bt&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure_bt&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;percentile_e&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;percentile_c&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;percentile_p&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pct_sum&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.40&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.49&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;176.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.98&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.93&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.49&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;188.19&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.97&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.92&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.08&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;166.24&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.97&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.98&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.92&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.49&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;188.19&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.95&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.90&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;188.19&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.97&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.92&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.89&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.42&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;166.24&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.92&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.88&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.32&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.08&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;176.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.91&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.98&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.98&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.87&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.32&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.49&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;188.19&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.91&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.86&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.40&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.48&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;188.19&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.86&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.84&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.42&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.48&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;176.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.86&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.98&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.84&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Finally, we can show a few of the points with large percentiles on the 95/5 surface:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;top_10 &amp;lt;- full_probs_95_tbl %&amp;gt;%
  head(10)

fig &amp;lt;- fig %&amp;gt;% add_trace(x = top_10$ellip_bt, y = top_10$curv_bt, z = top_10$pressure_bt, type = &amp;quot;scatter3d&amp;quot;, size = 30)

# fig&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/pp4.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/pp5.png&#34; style=&#34;width:100.0%;height:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And there we have it! 10 candidate points representing credible points on the edge of the 5% probability region for 3 correlated lognormal variables with proper treatment of the boundary.&lt;/p&gt;
&lt;p&gt;If you’ve made it this far, I thank you. Here are a couple appendices as a reward!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix-a---simulating-a-multivariate-distribution-with-mass-mvnorm&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix A - simulating a multivariate distribution with mass mvnorm&lt;/h1&gt;
&lt;p&gt;Workflow:&lt;/p&gt;
&lt;div id=&#34;htmlwidget-2&#34; style=&#34;width:100%;height:500px;&#34; class=&#34;grViz html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-2&#34;&gt;{&#34;x&#34;:{&#34;diagram&#34;:&#34;digraph flowchart {\n      # node definitions with substituted label text\n      node [fontname = Helvetica, shape = rectangle, fillcolor = yellow]        \n      tab1 [label = \&#34;Step 1: Fit distributions to each variable in the original dataset.\n Note parameters, correlations, covariances in original data\&#34;]\n      tab2 [label = \&#34;Step 2: Transform all variables to normal\&#34;]\n      tab3 [label = \&#34;Step 3: Fit normal distributions to each transformed variablet.\n Note parameters, correlations, covariances in transformed data\&#34;]\n      tab4 [label = \&#34;Step 4: Draw joint distribution using MASS::mvrnorm() or equivalent function.\n Use parameters and covariance matrix from normal, transformed data\&#34;]\n      tab5 [label = \&#34;Step 5: Back-transform simulated data to original distribution\&#34;]\n      tab6 [label = \&#34;Step 6: Evaluate parameters and marginal distributions of the back-transfomed data.\n Compare to raw, original data to see if marginals and correlations were recreated in the sim\&#34;]\n      # edge definitions with the node IDs\n      tab1 -&gt; tab2 -&gt; tab3 -&gt; tab4 -&gt; tab5 -&gt; tab6;\n      }\n      &#34;,&#34;config&#34;:{&#34;engine&#34;:&#34;dot&#34;,&#34;options&#34;:null}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;div id=&#34;step-1---fit-distributions-to-each-variable&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1 - Fit Distributions to Each Variable&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ellip_fit &amp;lt;- fitdist(sample_data$ellip, &amp;quot;lnorm&amp;quot;)
curv_fit &amp;lt;- fitdist(sample_data$curv, &amp;quot;lnorm&amp;quot;)
pressure_fit &amp;lt;- fitdist(sample_data$pressure, &amp;quot;lnorm&amp;quot;)

# store lognormal parameters of original data
ellip_meanlog &amp;lt;- ellip_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
ellip_sdlog &amp;lt;- ellip_fit$estimate[[&amp;quot;sdlog&amp;quot;]]
curv_meanlog &amp;lt;- curv_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
curv_sdlog &amp;lt;- curv_fit$estimate[[&amp;quot;sdlog&amp;quot;]]
pressure_meanlog &amp;lt;- pressure_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
pressure_sdlog &amp;lt;- pressure_fit$estimate[[&amp;quot;sdlog&amp;quot;]]

# store correlations in original data
cor_ec &amp;lt;- cor(x = sample_data$ellip, y = sample_data$curv)
cor_ep &amp;lt;- cor(x = sample_data$ellip, y = sample_data$pressure)
cor_cp &amp;lt;- cor(x = sample_data$curv, y = sample_data$pressure)

# store covariances in original data
cov_ellip_curv &amp;lt;- cov(x = sample_data$ellip, y = sample_data$curv)
cov_ellip_ellip &amp;lt;- cov(x = sample_data$ellip, y = sample_data$ellip)
cov_curv_curv &amp;lt;- cov(x = sample_data$curv, y = sample_data$curv)
cov_ellip_pressure &amp;lt;- cov(x = sample_data$ellip, y = sample_data$pressure)
cov_pressure_pressure &amp;lt;- cov(x = sample_data$pressure, y = sample_data$pressure)
cov_curv_pressure &amp;lt;- cov(x = sample_data$curv, y = sample_data$pressure)

# summarize the parameters and reshape a bit
original_data_param_tbl &amp;lt;- tibble(
  ellip_meanlog = ellip_meanlog,
  ellip_sdlog = ellip_sdlog,
  curv_meanlog = curv_meanlog,
  curv_sdlog = curv_sdlog,
  pressure_meanlog = pressure_meanlog,
  pressure_sdlog = pressure_sdlog,
  ellip_curv_correlation = cor_ec,
  ellip_pressure_correlation = cor_ep,
  curv_pressure_correlation = cor_cp,
  ellip_ellip_covariance = cov_ellip_ellip,
  ellip_curv_covariance = cov_ellip_curv,
  curv_curv_covariance = cov_curv_curv,
  ellip_pressure_covariance = cov_ellip_pressure,
  pressure_pressure_covariance = cov_pressure_pressure,
  curv_pressure_covariance = cov_curv_pressure
) %&amp;gt;%
  pivot_longer(cols = everything(), names_to = &amp;quot;feature&amp;quot;, values_to = &amp;quot;value&amp;quot;) %&amp;gt;%
  mutate(dataset = &amp;quot;original_data&amp;quot;) %&amp;gt;%
  mutate_if(is.character, as_factor)

# View summary table of original data
original_data_param_tbl %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;, digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;feature&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;value&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;dataset&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.193&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.064&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.158&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.309&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.783&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.191&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_curv_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.268&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_pressure_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.369&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_pressure_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.213&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_ellip_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_curv_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.022&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_curv_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.157&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.659&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;530.683&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.285&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;original_data&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2---transform-all-variables-to-normal&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2 - Transform all variables to normal&lt;/h2&gt;
&lt;p&gt;A simple log operation brings the lognormal variable to normal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# transform original, lognormal data to normal
normal_sample_data &amp;lt;- sample_data %&amp;gt;%
  mutate(
    n_ellip = log(ellip),
    n_curv = log(curv),
    n_pressure = log(pressure)
  )

normal_sample_data %&amp;gt;%
  head() %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;, digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;ellip&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_ellip&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_curv&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_pressure&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.255&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.506&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;92.739&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.228&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.505&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.530&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.285&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.019&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;182.970&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.251&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.613&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.209&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.289&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.027&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;153.858&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.254&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.393&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.036&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.234&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.139&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;108.669&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.210&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.760&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.688&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.133&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.673&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;123.633&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.125&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.301&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.817&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.219&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.373&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;113.944&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.198&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.864&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.736&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3---fit-normal-distributions-to-each-transformed-variable&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3 - Fit normal distributions to each transformed variable&lt;/h2&gt;
&lt;p&gt;We don’t actually have to formally fit normal distributions since it is convenient to obtain the mean and standard deviation at any time using the mean() or sd() functions. But we will extract and store correlations and covariances for the simulation to come.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get correlations of transformed, normal data
ncor_ec &amp;lt;- cor(
  x = normal_sample_data$n_ellip,
  normal_sample_data$n_curv
)
ncor_ep &amp;lt;- cor(
  x = normal_sample_data$n_ellip,
  normal_sample_data$n_pressure
)
ncor_cp &amp;lt;- cor(
  x = normal_sample_data$n_curv,
  normal_sample_data$n_pressure
)

# get covariance of transformed, normal data
n_cov_ellip_curv &amp;lt;- cov(
  x = normal_sample_data$n_ellip,
  y = normal_sample_data$n_curv
)
n_cov_ellip_ellip &amp;lt;- cov(
  x = normal_sample_data$n_ellip,
  y = normal_sample_data$n_ellip
)
n_cov_curv_curv &amp;lt;- cov(
  x = normal_sample_data$n_curv,
  y = normal_sample_data$n_curv
)

n_cov_ellip_pressure &amp;lt;- cov(
  x = normal_sample_data$n_ellip,
  y = normal_sample_data$n_pressure
)
n_cov_pressure_pressure &amp;lt;- cov(
  x = normal_sample_data$n_pressure,
  y = normal_sample_data$n_pressure
)
n_cov_curv_pressure &amp;lt;- cov(
  x = normal_sample_data$n_curv,
  y = normal_sample_data$n_pressure
)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4---draw-joint-distribution-using-mvrnorm-or-equivalent-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 4 - Draw joint distribution using mvrnorm() or equivalent function&lt;/h2&gt;
&lt;p&gt;Time to actually draw the correlated values. I store them here in an object called mult_norm.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# draw from multivariate normal with parameters from transformed normal distributions and correlation
set.seed(0118)

mult_norm &amp;lt;- as_tibble(MASS::mvrnorm(
  10000, c(
    mean(normal_sample_data$n_ellip),
    mean(normal_sample_data$n_curv),
    mean(normal_sample_data$n_pressure)
  ),
  matrix(c(
    n_cov_ellip_ellip,
    n_cov_ellip_curv,
    n_cov_ellip_pressure,
    n_cov_ellip_curv,
    n_cov_curv_curv,
    n_cov_curv_pressure,
    n_cov_ellip_pressure,
    n_cov_curv_pressure,
    n_cov_pressure_pressure
  ), 3, 3)
)) %&amp;gt;%
  rename(
    n_ellip_sim = V1,
    n_curv_sim = V2,
    n_pressure_sim = V3
  )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-5---back-transform-simulated-data-to-original-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 5 - Back-transform simulated data to original distribution&lt;/h2&gt;
&lt;p&gt;Exponentiating the data brings it back to lognormal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert back to lognormal
log_norm &amp;lt;- mult_norm %&amp;gt;%
  mutate(
    ellip_sim = exp(n_ellip_sim),
    curv_sim = exp(n_curv_sim),
    pressure_sim = exp(n_pressure_sim)
  )

log_norm %&amp;gt;%
  head() %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;, digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;n_ellip_sim&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_curv_sim&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_pressure_sim&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;ellip_sim&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;curv_sim&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;pressure_sim&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.254&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.600&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.248&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.290&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.952&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;190.266&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.233&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.038&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.107&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.262&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.823&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;165.178&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.236&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.152&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.812&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.266&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.165&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;123.018&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.313&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.003&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.048&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.368&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.727&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;155.636&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.224&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.622&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.192&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.251&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.066&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;179.912&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.197&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.486&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.822&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.218&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.422&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;124.185&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;step-6---evaluate-parameters-and-marginal-distributions-of-the-back-transfomed-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 6 - Evaluate parameters and marginal distributions of the back-transfomed data&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# evaluate the marginal distributions of the simulated data
ellip_sim_fit &amp;lt;- fitdistrplus::fitdist(log_norm$ellip_sim, &amp;quot;lnorm&amp;quot;)
curv_sim_fit &amp;lt;- fitdistrplus::fitdist(log_norm$curv_sim, &amp;quot;lnorm&amp;quot;)
pressure_sim_fit &amp;lt;- fitdistrplus::fitdist(log_norm$pressure_sim, &amp;quot;lnorm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Obtain and store the correlation, covariances, and parameters of simulated set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get correlation and covariances of simulated data
sim_cor_ec &amp;lt;- cor(x = log_norm$ellip_sim, log_norm$curv_sim)
sim_cor_ep &amp;lt;- cor(x = log_norm$ellip_sim, log_norm$pressure_sim)
sim_cor_cp &amp;lt;- cor(x = log_norm$curv_sim, log_norm$pressure_sim)

sim_cov_ellip_curv &amp;lt;- cov(x = log_norm$ellip_sim, y = log_norm$curv_sim)
sim_cov_ellip_ellip &amp;lt;- cov(x = log_norm$ellip_sim, y = log_norm$ellip_sim)
sim_cov_curv_curv &amp;lt;- cov(x = log_norm$curv_sim, y = log_norm$curv_sim)

sim_cov_ellip_pressure &amp;lt;- cov(x = log_norm$ellip_sim, y = log_norm$pressure_sim)
sim_cov_pressure_pressure &amp;lt;- cov(x = log_norm$pressure_sim, y = log_norm$pressure_sim)
sim_cov_curv_pressure &amp;lt;- cov(x = log_norm$curv_sim, y = log_norm$pressure_sim)

# store parameters of simulated data
ellip_sim_meanlog &amp;lt;- ellip_sim_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
ellip_sim_sdlog &amp;lt;- ellip_sim_fit$estimate[[&amp;quot;sdlog&amp;quot;]]
curv_sim_meanlog &amp;lt;- curv_sim_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
curv_sim_sdlog &amp;lt;- curv_sim_fit$estimate[[&amp;quot;sdlog&amp;quot;]]
pressure_sim_meanlog &amp;lt;- pressure_sim_fit$estimate[[&amp;quot;meanlog&amp;quot;]]
pressure_sim_sdlog &amp;lt;- pressure_sim_fit$estimate[[&amp;quot;sdlog&amp;quot;]]

# collect parameters from simulated data
sim_data_param_tbl &amp;lt;- tibble(
  ellip_meanlog = ellip_sim_meanlog,
  ellip_sdlog = ellip_sim_sdlog,
  curv_meanlog = curv_sim_meanlog,
  curv_sdlog = curv_sim_sdlog,
  pressure_meanlog = pressure_sim_meanlog,
  pressure_sdlog = pressure_sim_sdlog,

  ellip_curv_correlation = sim_cor_ec,
  ellip_pressure_correlation = sim_cor_ep,
  curv_pressure_correlation = sim_cor_cp,

  ellip_curv_covariance = sim_cov_ellip_curv,
  ellip_ellip_covariance = sim_cov_ellip_ellip,
  curv_curv_covariance = sim_cov_curv_curv,

  ellip_pressure_covariance = sim_cov_ellip_pressure,
  pressure_pressure_covariance = sim_cov_pressure_pressure,
  curv_pressure_covariance = sim_cov_curv_pressure
) %&amp;gt;%
  pivot_longer(cols = everything(), names_to = &amp;quot;feature&amp;quot;, values_to = &amp;quot;value&amp;quot;) %&amp;gt;%
  mutate(dataset = &amp;quot;simulated_data&amp;quot;) %&amp;gt;%
  mutate_if(is.character, as_factor)

sim_data_param_tbl %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;feature&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;value&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;dataset&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1932042&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0630117&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1626798&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.3092643&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.7878497&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1900026&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_curv_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2505145&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_pressure_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.3644292&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_pressure_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1956149&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_curv_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0203344&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_ellip_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0058779&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_curv_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1209300&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.6534943&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;547.0647415&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.8440727&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;simulated_data&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;compare-original-data-to-simulated-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compare Original Data to Simulated Data&lt;/h2&gt;
&lt;p&gt;A bit more wrangling let’s us compare the feature of the original dataset to the new, simulated population to see if they agree.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compare_tbl &amp;lt;- bind_rows(original_data_param_tbl, sim_data_param_tbl) %&amp;gt;%
  pivot_wider(id_cols = everything(), names_from = dataset)

compare_tbl %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;, digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;feature&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;original_data&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;simulated_data&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.193&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.193&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.064&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.063&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.158&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.163&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.309&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.309&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_meanlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.783&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.788&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_sdlog&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.191&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.190&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_curv_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.268&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.251&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_pressure_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.369&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.364&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_pressure_correlation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.213&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.196&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_ellip_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.006&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_curv_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.022&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.020&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_curv_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.157&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.121&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;ellip_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.659&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.653&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;pressure_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;530.683&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;547.065&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;curv_pressure_covariance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.285&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.844&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix-b---2d-kde-plot-with-probability-traces&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix B - 2d kde plot with probability traces&lt;/h1&gt;
&lt;p&gt;First, select the 2 variables of interest.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;- correlated_ln_draws_tbl %&amp;gt;% select(ellip, curv)

## density function
kd &amp;lt;- ks::kde(d, compute.cont = TRUE, h = 0.05)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s ellipticity vs. curvature (these lines are not probability region boundaries, but they are related)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cp_plt &amp;lt;- correlated_ln_draws_tbl %&amp;gt;%
  ggplot(aes(x = ellip, y = curv)) +
  geom_point(alpha = .3, size = .5) +
  geom_density2d(size = 1.3) +
  theme_classic() +
  xlim(c(.9, 1.6)) +
  ylim(c(1, 7.5)) +
  labs(
    title = &amp;quot;Joint Distribution of Vessel Ellipticity and Curvature&amp;quot;,
    subtitle = &amp;quot;Density Contours at Default Settings&amp;quot;,
    x = &amp;quot;Ellipticity (unitless)&amp;quot;,
    y = &amp;quot;Radius of Curvature (mm)&amp;quot;
  )

cp_plt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-65-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now a a function to extract the points of the contour line from the kde:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_contour &amp;lt;- function(kd_out = kd, prob = &amp;quot;5%&amp;quot;) {
  contour_95 &amp;lt;- with(kd_out, contourLines(
    x = eval.points[[1]], y = eval.points[[2]],
    z = estimate, levels = cont[prob]
  )[[1]])
  as_tibble(contour_95) %&amp;gt;%
    mutate(prob = prob)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Map it over the kd object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_out &amp;lt;- map_dfr(c(&amp;quot;5%&amp;quot;, &amp;quot;20%&amp;quot;, &amp;quot;40%&amp;quot;, &amp;quot;60%&amp;quot;, &amp;quot;80%&amp;quot;, &amp;quot;95%&amp;quot;), ~ get_contour(kd, .)) %&amp;gt;%
  group_by(prob) %&amp;gt;%
  mutate(n_val = 1:n()) %&amp;gt;%
  ungroup()

dat_out %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;level&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;x&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;y&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;prob&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_val&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1144314&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.027589&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.246533&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1144314&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.027172&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.265195&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1144314&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.025855&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.335547&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1144314&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.025083&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.405899&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1144314&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.025079&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.476250&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1144314&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.025998&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.546603&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1144314&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.027589&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.606175&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1144314&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.027847&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.616954&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1144314&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.030135&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.687306&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1144314&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.032082&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.738850&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Clean kde output&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kd_df &amp;lt;- expand_grid(x = kd$eval.points[[1]], y = kd$eval.points[[2]]) %&amp;gt;%
  mutate(z = c(kd$estimate %&amp;gt;% t()))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now visualize again, this time with probability contours at specified values and the 5% curve labeled with geom_label_repel().&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;label_tbl &amp;lt;- dat_out %&amp;gt;%
  filter(
    prob == &amp;quot;5%&amp;quot;,
    n_val == 100
  )

# visualize
ellip_curv_2plt &amp;lt;- ggplot(data = kd_df, aes(x, y)) +
  geom_tile(aes(fill = z)) +
  geom_point(data = d, aes(x = ellip, y = curv), alpha = .4, size = .4, colour = &amp;quot;white&amp;quot;) +
  geom_path(aes(x, y, group = prob),
    data = dat_out %&amp;gt;% filter(prob %in% c(&amp;quot;5%&amp;quot;, &amp;quot;20%&amp;quot;, &amp;quot;40%&amp;quot;, &amp;quot;60%&amp;quot;, &amp;quot;80%&amp;quot;, &amp;quot;95%&amp;quot;)), colour = &amp;quot;white&amp;quot;, size = 1.2, alpha = .8
  ) +
  #  geom_text(aes(label = prob), data =
  #              filter(dat_out, (prob %in% c(&amp;quot;5%&amp;quot;) &amp;amp; n_val==1)), # | (prob %in% c(&amp;quot;90%&amp;quot;) &amp;amp; n_val==20)),
  #            colour = &amp;quot;yellow&amp;quot;, size = 5)+
  geom_label_repel(
    data = label_tbl, aes(x, y),
    label = label_tbl$prob[1],
    fill = &amp;quot;yellow&amp;quot;,
    color = &amp;quot;black&amp;quot;,
    segment.color = &amp;quot;yellow&amp;quot;,
    #    segment.size = 1,
    min.segment.length = unit(1, &amp;quot;lines&amp;quot;),
    nudge_y = .5,
    nudge_x = -.025
  ) +
  xlim(c(.95, 1.5)) +
  ylim(c(0, 7.5)) +
  labs(
    title = &amp;quot;Joint Distribution [Ellipticity and Radius of Curvature]&amp;quot;,
    subtitle = &amp;quot;Simulated Data&amp;quot;,
    caption = &amp;quot;Density Contours shown at 5%, 20%, 40%, 60%, 80%, 95%&amp;quot;
  ) +
  scale_fill_viridis_c(end = .9) +
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  labs(x = &amp;quot;Ellipticity (unitless)&amp;quot;, y = &amp;quot;Radius of Curvature (mm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggExtra::ggMarginal(ellip_curv_2plt, type = &amp;quot;density&amp;quot;, fill = &amp;quot;#403891ff&amp;quot;, alpha = .7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-boundary-conditions-and-anatomy-exploring-correlated-data-simulation-in-r_files/figure-html/unnamed-chunk-70-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Hamdan et. al. Journal of the American College of Cardiology, Volume 59, Issue 2, 2012, Pages 119-127&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;This method would be analogous to creating prediction intervals and are conditional on the model in the sense that the only parameters considered are the maximum likelihood estimates. Alternate, more conservative ways to simulate the population could involve tolerance intervals or bayesian methods with a simulated posterior distribution to push out predictions.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;see Water 2020, 12, 1645; &lt;a href=&#34;doi:10.3390/w12061645&#34; class=&#34;uri&#34;&gt;doi:10.3390/w12061645&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Adapted from this Stack Overflow response: &lt;a href=&#34;https://stackoverflow.com/questions/23437000/how-to-plot-a-contour-line-showing-where-95-of-values-fall-within-in-r-and-in&#34; class=&#34;uri&#34;&gt;https://stackoverflow.com/questions/23437000/how-to-plot-a-contour-line-showing-where-95-of-values-fall-within-in-r-and-in&lt;/a&gt;&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simulation With a Random Effects Model - Gage R&amp;R as a Case Study</title>
      <link>/post/simulation-with-a-random-effects-model-gage-r-r-as-a-case-study/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/simulation-with-a-random-effects-model-gage-r-r-as-a-case-study/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/viz/viz.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/DiagrammeR-styles/styles.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/grViz-binding/grViz.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I&#39;ve heard it said that common statistical tests are just linear models.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; It turns out that Gage R&amp;amp;R, a commonly used measurement system analysis (MSA), is no different. In this post I&#39;ll attempt to provide some background on Gage R&amp;amp;R, describe the underlying model, and then walk through a method for simulation that can be useful for things like power analysis or visualization of uncertainty.&lt;/p&gt;
&lt;p&gt;What is Gage R&amp;amp;R?&lt;/p&gt;
&lt;p&gt;When evaluating implantable medical devices it is generally necessary to perform the following types of inspection to ensure product quality:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dimensional inspection of implant features&lt;/li&gt;
&lt;li&gt;Visual inspection of implant surface and component interfaces&lt;/li&gt;
&lt;li&gt;Benchtop performance evaluation of implant&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The primary purpose of these costly and rigorous inspection processes is to screen out bad product. The ramifications of non-conforming parts reaching the field can be fatal. As such, it is important to understand any limitations of key measurement systems and, if possible, quantity their uncertainty. The primary statistical tool for this job is called Gage R&amp;amp;R. The Gage R&amp;amp;R attempts to quantify the total variation within a series of measurements and then describe the relative contributions of parts, operators, and repeated measurements (unexplained error). Operator error is called &amp;quot;reproducibility&amp;quot;; unexplained error when a measurement is repeated under presumably identical conditions is called &amp;quot;repeatability&amp;quot;. The total variation among these components must be controlled and limited. A typical crossed structure is shown below: &lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/crossed.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Gage R&amp;amp;R training for engineers usually involves:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Definitions of repeatability and reproducibility (the &amp;quot;R&amp;amp;R&amp;quot;)&lt;/li&gt;
&lt;li&gt;Guidance for directing Minitab to set up the experiment&lt;/li&gt;
&lt;li&gt;Guidance for directing Minitab to analyze the results and provide an output&lt;/li&gt;
&lt;li&gt;An acceptance criteria (with no or limited context)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When I was first exposed to the material, I recall grappling with terminology and definitions, struggling with rote memorization, and having no understanding of the assumptions or limitations of the technique. Here&#39;s the piece that was never explained to me (and many other engineers):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A Gage R&amp;amp;R study is a random effects regression model with two random variables: operator and part. By modeling the factors as random effects and applying a few assumptions, we can access and analyze the variance associated with each component using standard ANOVA techniques.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Specifically, the model commonly used for a crossed Gage R&amp;amp;R is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\ y_{ijk} = \mu + O_i + P_j + (PO)_{ij} + E_{(ij)k} \]&lt;/span&gt; where:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\ y_{ijk}\)&lt;/span&gt; = a specific, individual measurement&lt;br /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\ \mu\)&lt;/span&gt; = overall mean of all the measurements&lt;br /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\ O\)&lt;/span&gt; = random variable for effect of operator. Assumed normal: &lt;span class=&#34;math inline&#34;&gt;\(\ O_i \sim N(0,\sigma^2_O)\)&lt;/span&gt;&lt;br /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\ P\)&lt;/span&gt; = random variable for effect of part. Assumed normal: &lt;span class=&#34;math inline&#34;&gt;\(\ P_i \sim N(0,\sigma^2_P)\)&lt;/span&gt;&lt;br /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\ (PO)\)&lt;/span&gt; = random variable for sample x operator interaction. Assumed normal: &lt;span class=&#34;math inline&#34;&gt;\(\ (PO)_{ij} \sim N(0,\sigma^2_{PO})\)&lt;/span&gt;&lt;br /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\ E\)&lt;/span&gt; = random variable for unexplained, residual error (referred to as &amp;quot;repeatability&amp;quot; since differences in measurements taken under identical conditions are mapped here). &lt;span class=&#34;math inline&#34;&gt;\(\ E_{(ij)k} \sim N(0,\sigma^2_{E})\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is really cool! - Understanding the model unlocks the insight behind the method and casts a bright light on the assumptions. It puts a seemingly obscure, memorized technique into a familiar regression framework. It also facilitates simulation.&lt;/p&gt;
&lt;p&gt;Why is it a random effects model? What is a random effects model? The answer to that question is actually tricky (and beyond the scope of this post) but there is some good information &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/published/banova7.pdf&#34;&gt;here&lt;/a&gt; for those who want to dive deeper. &lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; While not a formal definition, it may be sufficient to know that random effects are estimated with partial pooling while others are not.&lt;/p&gt;
&lt;p&gt;In this post I will attempt to show how to use the lme4 to simulate outcomes using a random effects model like the one listed above and then repeat many such simulations to gain understanding of uncertainty and sensitivity in the underlying experiment.&lt;a href=&#34;#fn4&#34; class=&#34;footnoteRef&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; Fun!&lt;/p&gt;
&lt;p&gt;Here are the libraries we&#39;ll use.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)
library(tidyverse)
library(knitr)
library(here)
library(broom.mixed)
library(tidybayes)
library(DiagrammeR)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;simulating-one-outcome-of-a-gage-rr-experiment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulating One Outcome of a Gage R&amp;amp;R Experiment&lt;/h2&gt;
&lt;p&gt;Before we worry about running a bunch of simulations, let&#39;s just figure out how to run one instance of a Gage R&amp;amp;R. There are some really good tutorials out there for simulating outcomes from random and mixed effects models.&lt;a href=&#34;#fn5&#34; class=&#34;footnoteRef&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn6&#34; class=&#34;footnoteRef&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; It ends up being a little bit tricky because the parameters that you select need to combine within the design matrix in a certain way such that an analysis of the simulated outcomes can recover the specified parameters. If you are good at matrix math you can do this manually. I am &lt;em&gt;not&lt;/em&gt; very good at matrix math - but fortunately Robert Long on Cross Validated&lt;a href=&#34;#fn7&#34; class=&#34;footnoteRef&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt; showed me a really cool little hack for figuring out the form of the Design Matrix Z and using it for simulation. Basically, we will first set up a dummy experiment with the desired number of parts, operators, and measurements and then use lme4 to extract Z and store it. Then we can set up a vector of all our simulated random effects and combine them with matrix multiplication to build the simulated observation. It sounds tricky but it&#39;s surprisingly simple! in summary, here is the plan:&lt;/p&gt;
&lt;p&gt;&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:500px;&#34; class=&#34;grViz html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;diagram&#34;:&#34;digraph flowchart {\n      # node definitions with substituted label text\n      node [fontname = Helvetica, shape = rectangle, fillcolor = yellow]        \n      tab1 [label = \&#34;Step 1: Setup a dummy experiment\&#34;]\n      tab2 [label = \&#34;Step 2: Fit a model to the dummy data\&#34;]\n      tab3 [label = \&#34;Step 3: Extract and store the Design Matrix Z from the dummy model\&#34;]\n      tab4 [label = \&#34;Step 4: Simulate random effects using rnorm or similar\&#34;]\n      tab5 [label = \&#34;Step 5: Multiply Z by random effects vector\&#34;]\n      tab6 [label = \&#34;Step 6: Combine result with simulated residual error to generate simulated observations\&#34;]\n      tab7 [label = \&#34;Step 7: Fit a model to the simulated obervations\&#34;]\n      # edge definitions with the node IDs\n      tab1 -&gt; tab2 -&gt; tab3 -&gt; tab4 -&gt; tab5 -&gt; tab6 -&gt; tab7;\n      }\n      &#34;,&#34;config&#34;:{&#34;engine&#34;:&#34;dot&#34;,&#34;options&#34;:null}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt; The good news is that none of the above steps are very hard, even if they look unfamiliar. Let&#39;s go through it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-1-set-up-a-dummy-experiment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1: Set up a dummy experiment&lt;/h2&gt;
&lt;p&gt;I call this a dummy experiment because while it will have the proper number of operators/parts/replicates, we&#39;ll just drop in some dummy data as the observations. The goal here is to allow lme4 to create the structure of the experiment (the design matrix) which we can use later to get the real simulated observations.&lt;/p&gt;
&lt;p&gt;First, we specify the number of parts, operators, and measurements we want the experiment be comprised of. 10, 3, and 2, respectively, is a common experimental setup in industry and we use it here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_part &amp;lt;- 10 # number of parts
n_oper &amp;lt;- 3 # number of opers
n_measurements &amp;lt;- 2 # number of replications&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now assign names to each part, operator, trial and determine how many observations will be in the study: n_matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# assign names to each part, operator, trial
part &amp;lt;- str_glue(&amp;quot;part_{1:n_part}&amp;quot;) %&amp;gt;% as_factor()
operator &amp;lt;- str_glue(&amp;quot;oper_{1:n_oper}&amp;quot;) %&amp;gt;% as_factor()
measurement &amp;lt;- str_glue(&amp;quot;measurment_{1:n_measurements}&amp;quot;) %&amp;gt;% as_factor()

n_matrix &amp;lt;- n_part * n_oper * n_measurements # number of observations in the study

n_matrix&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 60&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we use crossing() to build the full set of experimental conditions. Dummy observations are created for each setting and assigned to a new col: &amp;quot;measurement&amp;quot;. Overall mean of 10 is chosen arbitrarily and isn&#39;t important. Note: we are creating observations(measurements) here but have not concerned ourselves with specifying the parameters of any random variables yet. We just need a placeholder in the measurement column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# generate experimental design and outcomes for dummy study
grr_dummy_tbl &amp;lt;- crossing(part, operator, measurement) %&amp;gt;%
  mutate(measurement = 10 + rnorm(n_matrix))

grr_dummy_tbl %&amp;gt;%
  head(7) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;operator&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;measurement&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.87815&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.82016&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.12168&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.21272&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.55464&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.18606&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.95731&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grr_dummy_tbl %&amp;gt;%
  tail(7) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;operator&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;measurement&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9.661665&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.319520&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.668104&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.483027&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9.700252&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.967124&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9.627140&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-fit-a-model-to-the-dummy-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2: Fit a model to the dummy data&lt;/h2&gt;
&lt;p&gt;Now we fit a model to the dummy data. The summary isn&#39;t important - we just want access to the structure which we will get in the next step.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit model for dummy study
m1 &amp;lt;- lmer(measurement ~ (1 | part) + (1 | operator) + (1 | part:operator), data = grr_dummy_tbl)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-extract-and-store-the-design-matrix-z-from-the-dummy-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3: Extract and store the Design Matrix Z from the dummy model&lt;/h2&gt;
&lt;p&gt;Here&#39;s the little hack: Use getME() to pull the design matrix Z from the dummy model. Alternately, you can use lFormula() but you will have to fish the matrix out and transpose it which is not as intuitive to me.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract design matrix Z from dummy model
design_matrix_Z &amp;lt;- getME(m1, &amp;quot;Z&amp;quot;) %&amp;gt;% as.matrix()

design_matrix_Z %&amp;gt;% head(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   part_1:oper_1 part_1:oper_2 part_1:oper_3 part_2:oper_1 part_2:oper_2
## 1             1             0             0             0             0
##   part_2:oper_3 part_3:oper_1 part_3:oper_2 part_3:oper_3 part_4:oper_1
## 1             0             0             0             0             0
##   part_4:oper_2 part_4:oper_3 part_5:oper_1 part_5:oper_2 part_5:oper_3
## 1             0             0             0             0             0
##   part_6:oper_1 part_6:oper_2 part_6:oper_3 part_7:oper_1 part_7:oper_2
## 1             0             0             0             0             0
##   part_7:oper_3 part_8:oper_1 part_8:oper_2 part_8:oper_3 part_9:oper_1
## 1             0             0             0             0             0
##   part_9:oper_2 part_9:oper_3 part_10:oper_1 part_10:oper_2 part_10:oper_3
## 1             0             0              0              0              0
##   part_1 part_2 part_3 part_4 part_5 part_6 part_7 part_8 part_9 part_10
## 1      1      0      0      0      0      0      0      0      0       0
##   oper_1 oper_2 oper_3
## 1      1      0      0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# alternate method:
# mylF &amp;lt;- lFormula(m1, data = grr_dummy_tbl) # Process the formula against the data
# design_matrix_Z &amp;lt;- mylF$reTrms$Zt %&amp;gt;% as.matrix() %&amp;gt;% t()  # Extract the Z matrix&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So much easier than constructing this matrix yourself! (at least for me - it&#39;s been a while now since I took linear algebra course and tensor notation was always challenging).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4-simulate-random-effects-using-rnorm-or-similar&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 4: Simulate random effects using rnorm or similar&lt;/h2&gt;
&lt;p&gt;With the matrix Z in hand we can get get rid of the dummy model and get down to business with specifying and simulating our random effects. Specify standard deviations for each effect and simulate using rnorm(). 1, 2, 9, and 4 are the parameters that we will compare our estimates against later on.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(0118)
int_intercepts_sd &amp;lt;- 1 # standard dev of interaction random effects
oper_intercepts_sd &amp;lt;- 2 # standard dev of operator random effects
part_intercepts_sd &amp;lt;- 9 # standard dev of operator random effects
random_error_repeatability &amp;lt;- 4 # standard dev of random error (repeatability)

# simulate random effects using input params for sd
int_intercepts &amp;lt;- rnorm(n = n_part * n_oper, mean = 0, sd = int_intercepts_sd)
oper_intercepts &amp;lt;- rnorm(n = n_oper, mean = 0, sd = oper_intercepts_sd)
part_intercepts &amp;lt;- rnorm(n = n_part, mean = 0, sd = part_intercepts_sd)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Combine all the random effects into a vector. Order does matter here - see comment below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# vector of all random effect intercepts (order matters here: ineraction, part, oper if n_oper &amp;lt; n_part, else swith part and oper)

random_effects_intercepts &amp;lt;- c(int_intercepts, part_intercepts, oper_intercepts)
random_effects_intercepts&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  -1.676079782   0.167651720  -0.008545182   0.296888139  -1.706489201
##  [6]  -1.049094451  -0.102206749   0.682492401  -0.511117703   0.487346673
## [11]  -1.345812057   0.527128496   0.686104071  -0.221484626   0.532399538
## [16]   0.597393622   0.831437918   0.735023009   0.830043214   0.769163682
## [21]   1.830416344   0.182049999   1.018859437   0.844012288   0.575312043
## [26]   0.006855854  -0.231251230   0.205834471   0.250942908  -1.575663200
## [31]  19.280822421  10.499576059  -3.997253469  -7.111499870   6.986996777
## [36]  -4.861684848 -13.031232590  14.723410605  16.967969396  22.293922487
## [41]  -1.345816596  -3.905496830  -4.061788248&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-5-multiply-z-by-random-effects-vector&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 5: Multiply Z by random effects vector&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;step-6-combine-result-with-simulated-residual-error-to-generate-simulated-observations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 6: Combine result with simulated residual error to generate simulated observations&lt;/h2&gt;
&lt;p&gt;We&#39;ll do steps 5 and 6 together here: multiply the design matrix Z by the vector of random effects intercepts and then add in a residual error. %*% is the matrix multiplication operator. Again - the overall mean of 10 is arbitrary and does not change the analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create observations (add in repeatability random error to each term). %*% is matrix multiplication
grr_sim_tbl &amp;lt;- grr_dummy_tbl %&amp;gt;%
  mutate(measurement = 10 + design_matrix_Z %*% random_effects_intercepts + rnorm(
    n = nrow(grr_dummy_tbl),
    mean = 0,
    sd = random_error_repeatability
  ))

grr_sim_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;operator&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;measurement&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;25.335155&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;28.246367&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;15.799074&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;23.051405&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;22.791039&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;17.986515&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;19.378715&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14.934401&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9.109815&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;oper_2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14.250238&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;step-7-fit-a-model-to-the-simulated-obervations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 7: Fit a model to the simulated obervations&lt;/h2&gt;
&lt;p&gt;Once again we fit a model, but this time the observations are meaningful because we constructed them properly using the design matrix Z. broom.mixed::tidy() is able to bring the results into tibble format where we can clean a bit and view the variance contribution of each variable. This gives a point estimate of standard deviations for the random effects that can be compared against the reference inputs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit a model to the simulated dataset
sim_m_fit &amp;lt;- lmer(measurement ~ (1 | part) + (1 | operator) + (1 | part:operator), data = grr_sim_tbl)

# tibble of results for a single simulation
one_grr_result_tbl &amp;lt;-
  broom.mixed::tidy(sim_m_fit, effects = &amp;quot;ran_pars&amp;quot;) %&amp;gt;%
  rename(
    st_dev_estimate = estimate,
    variable = group
  ) %&amp;gt;%
  mutate(
    variance_estimate = st_dev_estimate^2,
    sim_number = 1
  ) %&amp;gt;%
  select(sim_number, variable, st_dev_estimate, variance_estimate)

one_grr_result_tbl %&amp;gt;% kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;sim_number&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;variable&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;st_dev_estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;variance_estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.4484307&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2010901&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.4718335&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;131.6029628&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6062900&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.5801677&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.9540576&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;15.6345714&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Recall that the true parameters for sd were 1, 9, 2, and 4. These estimates aren&#39;t dead on but we don&#39;t really understand how much uncertainty is involved with our estimate. We&#39;ll return to that in a moment.&lt;/p&gt;
&lt;p&gt;One common performance metric for a Gage R&amp;amp;R is %tolerance: 6 (or some other constant) times the sum of the measurement system variance (everything except for part variance) divided by the tolerance span for this particular measurement.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\ Percent\space Tolerance = 6 \times (\hat\sigma_E^2 + \hat\sigma_O^2 + \hat\sigma_{PO}^2)\space/\space Tolerance \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It is common for the tolerance span to be approximately 6 x the standard deviation of the parts population. Let&#39;s make that assumption here so we can estimate the percent tolerance from the data and compare to the true value. Once the simulation is established, the standard deviation of the parts can be adjusted to see how the percent tolerance changes for a given sd of operators, part:operator interaction, and residual.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one_grr_tol_outcome_tbl &amp;lt;- one_grr_result_tbl %&amp;gt;%
  filter(variable != &amp;quot;part&amp;quot;) %&amp;gt;%
  group_by(sim_number) %&amp;gt;%
  summarize(grr_variance_est = sum(variance_estimate)) %&amp;gt;%
  mutate(true_tol_pct = scales::percent((int_intercepts_sd^2 + oper_intercepts_sd^2 + random_error_repeatability^2) / part_intercepts_sd)) %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(est_tol_pct = scales::percent(grr_variance_est / part_intercepts_sd))

one_grr_tol_outcome_tbl %&amp;gt;% kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;sim_number&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;grr_variance_est&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;true_tol_pct&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;est_tol_pct&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;18.41583&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;233%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;205%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Since 205% is &amp;gt; 30%, this experiment would &amp;quot;fail&amp;quot; and the measurement system would not be validated. Not really interesting since we just chose arbitrary numbers but the estimate is reasonably close to the true value which is more important. It would be good to know that if we repeated the simulation a lot of times, the average estimate will converge near the true value.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scale-simulation-with-a-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Scale Simulation with a Function&lt;/h1&gt;
&lt;p&gt;If want to simulate a lot of Gage R&amp;amp;R&#39;s, we can take all the code chunks above and wrap them in a function and then just swap out the values we want to adjust for argument in the function. The function below will take:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;n = number of simulations&lt;/li&gt;
&lt;li&gt;np = number of parts&lt;/li&gt;
&lt;li&gt;no = number of operators&lt;/li&gt;
&lt;li&gt;nm = number of measurements per operator&lt;/li&gt;
&lt;li&gt;iisd = interaction intercepts standard deviation&lt;/li&gt;
&lt;li&gt;oisd = operator intercepts standard deviation&lt;/li&gt;
&lt;li&gt;pisd = part intercepts standard deviation&lt;/li&gt;
&lt;li&gt;rer = random error (repeatability) standard deviation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&#39;m pretty sure this operation could be done faster and cleaner than the code shown below, but I like how the code maps to the single case simulation above for easy human readability. For this reason, I use a for loop instead of some map() variant.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grr_fct &amp;lt;- function(n, np, no, nm, iisd, oisd, pisd, rer) {
  all_grr_results_tbl &amp;lt;- NULL # tibble to hold results
  n_sims &amp;lt;- n # number of simulations
  n_part &amp;lt;- np # number of parts
  n_oper &amp;lt;- no # number of opers
  n_measurements &amp;lt;- nm # number of replications

  int_intercepts_sd &amp;lt;- iisd # standard dev of interaction random effects
  oper_intercepts_sd &amp;lt;- oisd # standard dev of operator random effects
  part_intercepts_sd &amp;lt;- pisd # standard dev of parts random effects
  random_error_repeatability &amp;lt;- rer # standard dev of random error (repeatability)

  # assign names to each per, operator, trial
  part &amp;lt;- str_glue(&amp;quot;part_{1:n_part}&amp;quot;) %&amp;gt;% as_factor()
  operator &amp;lt;- str_glue(&amp;quot;oper_{1:n_oper}&amp;quot;) %&amp;gt;% as_factor()
  measurement &amp;lt;- str_glue(&amp;quot;measurment_{1:n_measurements}&amp;quot;) %&amp;gt;% as_factor()

  n_matrix &amp;lt;- n_part * n_oper * n_measurements # number of observations in the study

  for (i in 1:n) {

    # generate experimental designa and outcomes for dummy study
    grr_dummy_tbl &amp;lt;- crossing(part, operator, measurement) %&amp;gt;%
      mutate(measurement = 10 + rnorm(n_matrix))

    # fit model for dummy study
    m1 &amp;lt;- lmer(measurement ~ (1 | part) + (1 | operator) + (1 | part:operator), data = grr_dummy_tbl)

    # extract design matrix Z from dummy model
    design_matrix_Z &amp;lt;- getME(m1, &amp;quot;Z&amp;quot;) %&amp;gt;% as.matrix()

    # simulate random effects using input params for sd
    int_intercepts &amp;lt;- rnorm(n = n_part * n_oper, mean = 0, sd = int_intercepts_sd)
    oper_intercepts &amp;lt;- rnorm(n = n_oper, mean = 0, sd = oper_intercepts_sd)
    part_intercepts &amp;lt;- rnorm(n = n_part, mean = 0, sd = part_intercepts_sd)

    # vector of all random effect intercepts (order matters here: ineraction, oper, part)
    random_effects_intercepts &amp;lt;- c(int_intercepts, part_intercepts, oper_intercepts)

    # create observations (add in repeatability random error to each term). %*% is matrix multiplication
    grr_sim_tbl &amp;lt;- grr_dummy_tbl %&amp;gt;%
      mutate(measurement = 10 + design_matrix_Z %*% random_effects_intercepts + rnorm(
        n = nrow(grr_dummy_tbl),
        mean = 0,
        sd = random_error_repeatability
      ))

    # fit a model to the simulated dataset
    sim_m_fit &amp;lt;- lmer(measurement ~ (1 | part) + (1 | operator) + (1 | part:operator), data = grr_sim_tbl)

    # tibble of results for a single simulation
    one_grr_result_tbl &amp;lt;-
      broom.mixed::tidy(sim_m_fit, effects = &amp;quot;ran_pars&amp;quot;) %&amp;gt;%
      rename(
        st_dev_estimate = estimate,
        variable = group
      ) %&amp;gt;%
      mutate(
        variance_estimate = st_dev_estimate^2,
        sim_number = i
      ) %&amp;gt;%
      select(sim_number, variable, st_dev_estimate, variance_estimate)

    # append this recent simulation to the others
    all_grr_results_tbl &amp;lt;- bind_rows(all_grr_results_tbl, one_grr_result_tbl)
  }
  return(all_grr_results_tbl)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test the function by calling it once, asking for just 3 simulations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fcn_test_tbl &amp;lt;- grr_fct(n = 3, np = 10, no = 3, nm = 2, iisd = 4, oisd = 3, pisd = 2, rer = 1)

fcn_test_tbl %&amp;gt;% kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;sim_number&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;variable&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;st_dev_estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;variance_estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.4214284&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.7061726&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.1832882&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.7667475&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6916881&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.8618086&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0355244&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0723107&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.7726138&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;22.7778428&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0010317&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0000011&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0763577&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1585460&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.0704728&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16.5687489&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2724219&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6190574&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.2107023&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.3086089&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9178515&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8424514&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Everything is looking good! The results from n=3 simulations have completed and are summarized nicely in the results tbl.&lt;/p&gt;
&lt;p&gt;Rather than manually call the function and input the arguments every time, we can populate a &amp;quot;setup tbl&amp;quot; that contains all the arguments that we will want to look at. Within the tbl we can look at anything we want. For example, we might want several different values for number of operators, or several different levels of standard deviation for one of the random effects. In this case, I was interested in several different magnitudes of standard deviation for the population of parts because the part sd is used as a surrogate for the tolerance percentage calculation as shown above. This is a useful simulation because we should be able to visualize:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Does the average of the simulation converge near the true value for percent tolerance?&lt;/li&gt;
&lt;li&gt;How often might individual estimates of pct tol &amp;quot;fail&amp;quot; (&amp;gt; 30%) when the average of the estimates passes (&amp;lt; 30%)?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Fist, the setup_tbl. Note: the variance of the random variables for operator, repeatability(residual), and part:operator interaction are all held at 1 while the variance for part is increased.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_setup_tbl &amp;lt;- tibble(
  n_sims = 200,
  n_part = 10,
  n_oper = 3,
  n_meas = 2,
  int_sd = 1,
  oper_sd = 1,
  #  part_var = 1,
  part_var = c(2^(0:10)),
  repeatab_sd = 1
) %&amp;gt;%
  mutate(
    row_id = row_number()
  ) %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(part_sd = part_var^.5) %&amp;gt;%
  mutate(tol_pct_true = 6 * (int_sd^2 + oper_sd^2 + repeatab_sd^2) / (6 * part_sd))

sim_setup_tbl %&amp;gt;% kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;n_sims&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_oper&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_meas&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;int_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;oper_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;part_var&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;repeatab_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;row_id&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;part_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;tol_pct_true&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.414214&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.1213203&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.828427&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0606602&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.7500000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.656854&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5303301&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;64&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.3750000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;128&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.313709&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2651650&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;256&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1875000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;22.627417&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1325825&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1024&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;32.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0937500&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The following code executes many simulations, one for each set of arguments from the rows above. Each simulation from each row results in a tibble of outcomes which is stored in a list column and the unnested later on to make a big tibble. I&#39;m not actually 100% sure that you need rowwise() here - it works fine with it in place and makes sense to me that you would group by rows here but I&#39;m still trying to figure out what row-based workflow works best for me. I believe there are other good options that use the map family.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(0118)

#commented out because this takes a while to run

# sim_outcomes_tbl &amp;lt;- sim_setup_tbl %&amp;gt;%
#   rowwise() %&amp;gt;% # may not be needed
#   mutate(sim_outcomes = list(grr_fct(n = n_sims, np = n_part, no = n_oper, nm = n_meas, iisd = int_sd, oisd = oper_sd, pisd = part_sd, rer = repeatab_sd))) %&amp;gt;%
#   select(sim_outcomes, everything()) %&amp;gt;%
#   unnest(cols = c(sim_outcomes)) %&amp;gt;%
#   mutate_if(is.character, as_factor)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_outcomes_tbl %&amp;gt;%
  select(sim_number, variable, st_dev_estimate, n_sims, n_part, n_meas, int_sd, oper_sd, repeatab_sd, part_sd) %&amp;gt;%
  head(12) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;sim_number&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;variable&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;st_dev_estimate&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_sims&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_meas&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;int_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;oper_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;repeatab_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;part_sd&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5511238&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8165034&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5369841&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0638795&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8046511&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1717770&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9339445&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9631640&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0850250&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0031052&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7490297&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9284068&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We might look at the results for a single group of arguments in the setup tbl by filtering to a specific row (I choose row 4 arbitrarily here). Note that &amp;quot;row_id&amp;quot; is a little misleading here because the data has been reshaped. Filtering fora specific row_id returns results from the set of simulations from a single row of parameters in the original setup_tbl. Here we look at the results form row_4 where the true part sd was 2.82 while the sd for operator, Residual, and interaction were all 1.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- sim_outcomes_tbl %&amp;gt;%
  filter(row_id == 4) %&amp;gt;%
  filter(st_dev_estimate &amp;gt; .001) %&amp;gt;%
  ggplot(aes(x = variable, y = st_dev_estimate)) +
  geom_jitter(width = .05, alpha = .5, size = .6) +
  geom_hline(yintercept = 1, lty = 2, color = &amp;quot;#2c3e50&amp;quot;) +
  geom_hline(yintercept = 2.8428472, lty = 2, color = &amp;quot;#2c3e50&amp;quot;) +
  #    stat_summary(fun.y= mean, fun.ymin=mean, fun.ymax=mean, geom=&amp;quot;crossbar&amp;quot;, width=0.2, color=&amp;quot;red&amp;quot;) +
  stat_halfeye(aes(fill = variable), point_interval = mean_qi, alpha = .7, position = position_nudge(x = .15)) +
  labs(
    title = &amp;quot;Gage R&amp;amp;R - Estimates for Component Standard Deviations&amp;quot;,
    subtitle = str_glue(&amp;quot;Settings: {sim_outcomes_tbl$n_part[1]} Parts, {sim_outcomes_tbl$n_oper[1]} Operators, {sim_outcomes_tbl$n_meas[1]} Measurements&amp;quot;),
    x = &amp;quot;&amp;quot;,
    y = &amp;quot;Standard Deviation Estimate&amp;quot;,
    caption = &amp;quot;dotted line marks true population standard dev\n Interval marks median, .66 quantile, .95 quantile&amp;quot;
  ) +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  scale_fill_viridis_d(option = &amp;quot;c&amp;quot;, end = .7)

a&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-09-simulation-with-a-random-effects-model-gage-r-r-as-a-case-study_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks good! The averages of the set of simulations are converging nicely and we get a good feel for how much uncertainty would be expected for a single trial.&lt;/p&gt;
&lt;p&gt;Now to plot multiple simulations. A bit of data preparation is required to plot the true values on the same canvas as the individual sims. There is probably a cleaner way to do this directly within ggplot - but the way I do it here is to pull the values from the rows down into tidy format with pivot_longer and then do some grouping and joining.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_tbl &amp;lt;- sim_outcomes_tbl %&amp;gt;% select(sim_number, row_id)

t &amp;lt;- sim_outcomes_tbl %&amp;gt;%
  select(sim_number, variable, row_id, int_sd, oper_sd, part_sd, repeatab_sd, st_dev_estimate) %&amp;gt;%
  pivot_longer(cols = c(int_sd, oper_sd, part_sd, repeatab_sd)) %&amp;gt;%
  right_join(sim_tbl) %&amp;gt;%
  group_by(variable, name, value, row_id) %&amp;gt;%
  count() %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(variable = case_when(
    name == &amp;quot;int_sd&amp;quot; ~ &amp;quot;part:operator&amp;quot;,
    name == &amp;quot;oper_sd&amp;quot; ~ &amp;quot;operator&amp;quot;,
    name == &amp;quot;part_sd&amp;quot; ~ &amp;quot;part&amp;quot;,
    TRUE ~ &amp;quot;Residual&amp;quot;
  )) %&amp;gt;%
  right_join(sim_setup_tbl)

t %&amp;gt;%
  head(10) %&amp;gt;%
  select(variable, value, row_id, n_sims, n_part, n_oper, n_meas, int_sd, oper_sd, part_sd, repeatab_sd, tol_pct_true) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;variable&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;value&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;row_id&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_sims&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_oper&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_meas&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;int_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;oper_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;part_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;repeatab_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;tol_pct_true&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;Residual&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;part:operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;operator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It would be cool to see all the data from all the simulations. Recall that the true values of sd for operator, part:operator interaction, and Residual were 1 and that part variation increased across the different sims. All of this is plotted below, with the true values in red while the results of the simulation shown in black. It can be seen that the simulations group nicely around the true values and we can see the uncertainty.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_outcomes_tbl %&amp;gt;%
  ggplot(aes(x = part_sd, y = st_dev_estimate)) +
  geom_point(size = .4) +
  geom_point(data = t, aes(x = part_sd, y = value), color = &amp;quot;firebrick&amp;quot;) +
  facet_wrap(~variable, scales = &amp;quot;free&amp;quot;) +
  labs(
    title = &amp;quot;Simulation Results Across a Range of Possible Part Standard Deviations&amp;quot;,
    subtitle = &amp;quot;Gage R&amp;amp;R with n=10 parts, n=3 operators, n=2 measurements&amp;quot;,
    x = &amp;quot;True Part Standard Deviation&amp;quot;,
    y = &amp;quot;Estimate of Standard Deviation&amp;quot;,
    caption = &amp;quot;red points mark true value of standard deviation for the effect&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-09-simulation-with-a-random-effects-model-gage-r-r-as-a-case-study_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; Let&#39;s see how the estimated percent tolerance lines up with the true values from the population. This tbl calculates the percent tol across all the simulations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tol_outcomes_tbl &amp;lt;- sim_outcomes_tbl %&amp;gt;%
  filter(variable != &amp;quot;part&amp;quot;) %&amp;gt;%
  group_by(sim_number, row_id) %&amp;gt;%
  summarize(grr_variance_est = sum(variance_estimate)) %&amp;gt;%
  right_join(sim_setup_tbl) %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(est_tol_pct = (grr_variance_est) / (part_sd)) %&amp;gt;%
  select(n_part, n_oper, n_meas, int_sd, oper_sd, part_sd, tol_pct_true, est_tol_pct, everything())

tol_outcomes_tbl %&amp;gt;%
  select(n_part, n_oper, n_meas, int_sd, oper_sd, part_sd, tol_pct_true, est_tol_pct, sim_number, row_id) %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;n_part&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_oper&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;n_meas&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;int_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;oper_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;part_sd&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;tol_pct_true&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;est_tol_pct&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sim_number&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;row_id&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.723929&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.447401&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.098323&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.882222&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.702724&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.381758&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.619832&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.986048&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.440299&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.441025&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This summary tbl captures the mean from simulations conducted at each level.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tol_est_tbl &amp;lt;- tol_outcomes_tbl %&amp;gt;%
  group_by(row_id, part_var) %&amp;gt;%
  summarize(mean_est_tol_pct = mean(est_tol_pct))

tol_est_tbl %&amp;gt;% kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;row_id&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;part_var&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;mean_est_tol_pct&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.9902181&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.1352549&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5002527&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0354094&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.7362949&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5330749&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;64&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.3708208&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;128&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2657111&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;256&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1880981&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1372343&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1024&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.0937739&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Visualize the mean from the simulations vs. the true tol percent:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tol_outcomes_tbl %&amp;gt;%
  ggplot(aes(x = part_var, y = est_tol_pct)) +
  #  geom_point(size = .5) +
  geom_point(aes(x = part_var, y = tol_pct_true), size = 3, color = &amp;quot;limegreen&amp;quot;, position = position_nudge(2), alpha = .85) +
  geom_line(aes(x = part_var, y = tol_pct_true), color = &amp;quot;limegreen&amp;quot;) +
  geom_point(data = tol_est_tbl, aes(x = part_var, y = mean_est_tol_pct), size = 3, color = &amp;quot;firebrick&amp;quot;, position = position_nudge(-2), alpha = .85) +
  geom_hline(yintercept = .3, lty = 2, color = &amp;quot;#2c3e50&amp;quot;) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = &amp;quot;Comparison of Simulation Results to True: Tolerance Percent Metric&amp;quot;,
    subtitle = &amp;quot;Green is true population, Red is mean of simulation estimates&amp;quot;,
    x = &amp;quot;Part Variance&amp;quot;,
    y = &amp;quot;Tolerance Percent&amp;quot;,
    caption = &amp;quot;dotted line shows 30% acceptance limit&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-09-simulation-with-a-random-effects-model-gage-r-r-as-a-case-study_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Very nice agreement between the simulations and the true population values. But the above plot just shows the mean. How much uncertainty is expected across experiments at the same settings? Here I show a subset of data below the 100% level (just to keep the plot a little less messy).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tol_outcomes_tbl %&amp;gt;%
  ggplot(aes(x = part_var, y = est_tol_pct)) +
  geom_point(size = .5) +
  geom_point(aes(x = part_var, y = tol_pct_true), size = 3, color = &amp;quot;limegreen&amp;quot;, position = position_nudge(2), alpha = .85) +
  geom_line(aes(x = part_var, y = tol_pct_true), color = &amp;quot;limegreen&amp;quot;) +
  geom_point(data = tol_est_tbl, aes(x = part_var, y = mean_est_tol_pct), size = 3, color = &amp;quot;firebrick&amp;quot;, position = position_nudge(-2), alpha = .85) +
  geom_hline(yintercept = .3, lty = 2) +
  scale_y_continuous(
    labels = scales::percent,
    expand = expansion(),
    limits = c(0, 1)
  ) +
  labs(
    title = &amp;quot;Comparison of Simulation Results to True: Tolerance Percent Metric&amp;quot;,
    subtitle = &amp;quot;Green is true population, Red is mean of simulation estimates, Black is intividual estimates&amp;quot;,
    x = &amp;quot;Part Variance&amp;quot;,
    y = &amp;quot;Tolerance Percent&amp;quot;,
    caption = &amp;quot;dotted line shows 30% acceptance limit&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-09-09-simulation-with-a-random-effects-model-gage-r-r-as-a-case-study_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Pretty interesting. There is quite a bit of uncertainty here and there are quite a few cases where individual simulations fail just due to chance. The probability of this happening is worst when the part variance is around 100-400% of the operator and repeatability sd.&lt;/p&gt;
&lt;p&gt;From this point one could start tweaking any values of interest to see how the uncertainty of the performance metric is affected. For example, you might look at the optimal number of operators or replicates to give the best chance of passing when the true population value would pass. Pretty powerful stuff!&lt;/p&gt;
&lt;p&gt;In this post I attempted to show how a Gage R&amp;amp;R test can be modeled with random effects model. A simulation was constructed using the extracted design matrix Z and a vector of random effects. The simulation was then scaled to see how well the mean of the simulations converge with the true population parameter and the uncertainty was visualized by plotting individual estimates on the same grid. Good luck and I hope this post is useful!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://lindeloev.github.io/tests-as-linear/&#34; class=&#34;uri&#34;&gt;https://lindeloev.github.io/tests-as-linear/&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Assessment of the Adequacy of Gauge Repeatability and Reproducibility Study Using a Monte Carlo Simulation, &lt;a href=&#34;https://www.hindawi.com/journals/mpe/2017/7237486/&#34; class=&#34;uri&#34;&gt;https://www.hindawi.com/journals/mpe/2017/7237486/&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Conflicting definitions of random/mixed effects &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2005/01/25/why_i_dont_use/&#34; class=&#34;uri&#34;&gt;https://statmodeling.stat.columbia.edu/2005/01/25/why_i_dont_use/&lt;/a&gt;&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Some simulations are motivated/recreated/expanded from the excellent paper by Ha et al, &lt;a href=&#34;https://doi.org/10.1155/2017/7237486&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1155/2017/7237486&lt;/a&gt;&lt;a href=&#34;#fnref4&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://debruine.github.io/tutorials/sim-lmer.html&#34; class=&#34;uri&#34;&gt;https://debruine.github.io/tutorials/sim-lmer.html&lt;/a&gt;&lt;a href=&#34;#fnref5&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://aosmith.rbind.io/2018/04/23/simulate-simulate-part-2/&#34; class=&#34;uri&#34;&gt;https://aosmith.rbind.io/2018/04/23/simulate-simulate-part-2/&lt;/a&gt;&lt;a href=&#34;#fnref6&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/483509/simulating-observations-for-a-2-way-anova-in-r-w-mixed-effects-model-and-reco&#34; class=&#34;uri&#34;&gt;https://stats.stackexchange.com/questions/483509/simulating-observations-for-a-2-way-anova-in-r-w-mixed-effects-model-and-reco&lt;/a&gt;&lt;a href=&#34;#fnref7&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian Stress-Strength Analysis for Product Design (in R and brms)</title>
      <link>/post/bayesian-stress-strength-inference-in-r-and-brms/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-stress-strength-inference-in-r-and-brms/</guid>
      <description>


&lt;p&gt;Whether you are building bridges, baseball bats, or medical devices, one of the most basic rules of engineering is that the thing you build must be strong enough to survive its service environment. Although a simple concept in principle, variation in use conditions, material properties, and geometric tolerances all introduce uncertainty that can doom a product. Stress-Strength analysis attempts to formalize a more rigorous approach to evaluating overlap between the stress and strength distributions. Graphically, a smaller area of overlap represents a smaller probability of failure and greater expected reliability (although it doesn’t exactly equal the probability of failure).&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/stress_strength.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;However, even formal stress-strength analysis usually infers device reliability from point estimates of material strength and/or use conditions. Monte Carlo simulations intending to respect the full spread of stress and strength distributions generally ignore the uncertainty inherent in the distributional parameters themselves. Fortunately there is a Bayesian extension of Stress-Strength analysis that naturally incorporates the uncertainty of the parameters to provide a true probability distribution of device reliability. In this post I will first walk through the frequentist approach to obtaining a point estimate of reliability and then the Bayesian extension that yields a full posterior for reliability.&lt;/p&gt;
&lt;p&gt;First, load the libraries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(broom)
library(survival)
library(brms)
library(knitr)
library(patchwork)
library(tidybayes)
library(gganimate)
library(transformr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll be using a dataset from Liu and Abeyratne that contains stress and strength data for an electrode connector component in an electronic medical device.&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; The stress-in-service data are compiled from characterization tests and customer usage data. The strength data (here called “failure_stress” to emphasize that they can be directly evaluated against stress-in-service) are obtained from benchtop testing and are right censored at 15. Assume the units of each are the same.&lt;/p&gt;
&lt;p&gt;The stress-in-service data are known from historical testing to follow a lognormal distribution. Likewise, the failure stress data are known to follow a Weibull distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Manually enter data
stress_in_service_tbl &amp;lt;- tibble(stress_in_service = c(2.53, 2.76, 1.89, 3.85, 3.62, 3.89, 3.06, 2.16, 2.20, 1.90, 1.96, 2.09, 1.70, 5.77, 4.35, 5.30, 3.61, 2.63, 4.53, 4.77, 1.68, 1.85, 2.32, 2.11, 1.94, 1.81, 1.53, 1.60, 0.47, 1.06, 1.30, 2.84, 3.84, 3.32))

# Peek at data
stress_in_service_tbl %&amp;gt;%
  head(7) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;stress_in_service&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.76&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.89&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.85&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.62&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.89&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.06&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# manually enter failure stress data
failure_stress_tbl &amp;lt;- tibble(failure_stress = c(7.52, 15, 8.44, 6.67, 11.48, 11.09, 15, 5.85, 13.27, 13.09, 12.73, 11.08, 15, 8.41, 12.34, 8.77, 6.47, 10.51, 7.05, 10.90, 12.38, 7.78, 14.61, 15, 10.99, 11.35, 4.72, 6.72, 11.74, 8.45, 13.26, 13.89, 12.83, 6.49))

# add column to indicate run-out / censoring.  brms convention is 1 = censored, 0 = failure event
failure_stress_tbl &amp;lt;- failure_stress_tbl %&amp;gt;% 
  mutate(censored_brms = case_when(failure_stress == 15 ~ 1, TRUE ~ 0)) %&amp;gt;%
  mutate(censored_surv = case_when(failure_stress == 15 ~ 0,TRUE ~ 1))

# peek at data
failure_stress_tbl %&amp;gt;%
  head(7) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;failure_stress&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;censored_brms&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;censored_surv&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;7.52&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;15.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8.44&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11.48&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11.09&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;15.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;After verifying the data has been imported correctly, the two distributions can be visualized on the same plot and the degree of overlap evaluated qualitatively.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set up a combined stress/strength tibble
a &amp;lt;- tibble(val = stress_in_service_tbl$stress_in_service, label = &amp;quot;stress_in_service&amp;quot;)
b &amp;lt;- tibble(val = failure_stress_tbl$failure_stress, label = &amp;quot;failure_stress&amp;quot;)
overlap_tbl &amp;lt;- bind_rows(a, b) %&amp;gt;%
  mutate(label = as_factor(label))

# view combined tbl
overlap_tbl %&amp;gt;%
  head(5) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;val&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;label&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.53&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;stress_in_service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.76&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;stress_in_service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.89&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;stress_in_service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.85&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;stress_in_service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.62&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;stress_in_service&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;overlap_tbl %&amp;gt;%
  tail(5) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;val&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;label&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8.45&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;failure_stress&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13.26&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;failure_stress&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13.89&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;failure_stress&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;12.83&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;failure_stress&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6.49&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;failure_stress&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot empirical distributions
overlap_tbl %&amp;gt;% ggplot() +
  geom_density(aes(x = val, fill = label), alpha = .5) +
  labs(
    x = &amp;quot;Stress&amp;quot;,
    y = &amp;quot;Density of Observations&amp;quot;,
    title = &amp;quot;Empirical Distributions for Stress-In-Service and Failure Stress&amp;quot;,
    subtitle = &amp;quot;Overlap Region Represents Posssible Device Failure, Failrue Stress Censored at 15&amp;quot;
  ) +
  scale_fill_manual(values = c(&amp;quot;#20A486FF&amp;quot;, &amp;quot;#FDE725FF&amp;quot;)) +
  theme(legend.title = element_blank()) +
  theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;obtain-the-frequentist-point-estimates&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Obtain the Frequentist Point Estimates&lt;/h2&gt;
&lt;p&gt;We can get the best parameter estimates for both data sets using the survreg function from the survival package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#fit stress-in-service data using survreg from survival package
stress_in_service_fit &amp;lt;- survreg(Surv(stress_in_service) ~ 1,
  data = stress_in_service_tbl,
  dist = &amp;quot;lognormal&amp;quot;
)

#extract point estimates of parameters from sis-fit
sis_point_est_tbl &amp;lt;- tidy(stress_in_service_fit)[1, 2] %&amp;gt;%
  rename(meanlog = estimate) %&amp;gt;%
  mutate(sdlog = stress_in_service_fit$scale) %&amp;gt;%
  round(2) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))

sis_point_est_tbl &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;meanlog&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sdlog&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#fit failure stress data using survreg from survival package
failure_stress_fit &amp;lt;- survreg(Surv(failure_stress, censored_surv) ~ 1,
  data = failure_stress_tbl,
  dist = &amp;quot;weibull&amp;quot;
)

# extract scale parameter
scale &amp;lt;- tidy(failure_stress_fit)[1, 2] %&amp;gt;%
  rename(scale = estimate) %&amp;gt;%
  exp() %&amp;gt;%
  round(2)

# extract shape parameter
shape &amp;lt;- tidy(failure_stress_fit)[2, 2] %&amp;gt;%
  rename(shape = estimate) %&amp;gt;%
  exp() %&amp;gt;%
  .^-1 %&amp;gt;%
  round(2)

# summarize
fs_point_est_tbl &amp;lt;- bind_cols(shape, scale) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))

fs_point_est_tbl&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.57&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The reliability point estimate is obtained by drawing randomly from the two fitted distributions and seeing the percentage of occasions where the stress_in_service is greater than the failure_stress:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Monte Carlo to see how often s-i-s &amp;gt; fs
set.seed(10)

#random draws
sis_draws &amp;lt;- rlnorm(n = 100000, meanlog = .88, sdlog = .50)
fs_draws &amp;lt;- rweibull(n = 100000, shape = 3.57, scale = 12)

#assign 1 to cases where sis_draws &amp;gt;= fs_draws
point_sim &amp;lt;- tibble(
  sis_draws = sis_draws,
  fs_draws = fs_draws
) %&amp;gt;%
  mutate(freq = case_when(
    sis_draws &amp;gt;= fs_draws ~ 1,
    TRUE ~ 0
  ))

#take freqency of 0&amp;#39;s
reliability_pt_est &amp;lt;- (1 - mean(point_sim$freq))

#show as tibble
tibble(reliability = 1 - mean(point_sim$freq)) %&amp;gt;%
  round(3) %&amp;gt;% 
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;reliability&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.986&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;model-the-stress-in-service-with-brms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model the Stress-in-Service with brms&lt;/h2&gt;
&lt;p&gt;For the Bayesian approach we fit the models with brms instead of survreg. The result is a posterior of plausible values for each parameter.&lt;/p&gt;
&lt;p&gt;Before running to model, reasonable priors were established through simulation. Code and details are included in the Appendix at the end of this post so as to not derail the flow.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Fit model to stress-in-service data. Data is known to be of lognormal form.  

# stress_in_service_model_1 &amp;lt;-
#  brm(
#    data = stress_in_service_tbl, family = lognormal,
#    stress_in_service ~ 1,
#   prior = c(
#     prior(normal(.5, 1), class = Intercept),
#     prior(uniform(.01, 8), class = sigma)),
#   iter = 41000, warmup = 40000, chains = 4, cores = 4,
#   seed = 4
# )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clean up the posterior tibble and plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract posterior draws 
post_samples_stress_in_service_model_1_tbl &amp;lt;-
  posterior_samples(stress_in_service_model_1) %&amp;gt;%
  select(-lp__) %&amp;gt;%
  rename(&amp;quot;mu&amp;quot; = b_Intercept)

#examine as tibble
post_samples_stress_in_service_model_1_tbl %&amp;gt;%
  head(7) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2), digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;mu&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sigma&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.932&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.537&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.922&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.601&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.801&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.535&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.836&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.526&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.977&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.540&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.732&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.535&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.757&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.535&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get visual of posterior with rough idea of chain convergence
plot(stress_in_service_model_1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here is the summary of the stress-in-service model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# evaluate posterior distribution with 95% CI and rhat diagnostic
summary(stress_in_service_model_1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: lognormal 
##   Links: mu = identity; sigma = identity 
## Formula: stress_in_service ~ 1 
##    Data: stress_in_service_tbl (Number of observations: 34) 
## Samples: 4 chains, each with iter = 41000; warmup = 40000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.88      0.09     0.71     1.06 1.00     1976     2298
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.53      0.07     0.42     0.69 1.00     2399     2016
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-the-failure-stress-data-with-brms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model the Failure Stress Data with brms&lt;/h2&gt;
&lt;p&gt;The failure stress data is fit in a similar way as before. Again, prior predictive simulations are shown in the Appendix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# failure_stress_model_1 &amp;lt;- brm(failure_stress | cens(censored_brms) ~ 1,
# data = failure_stress_tbl, family = weibull(),
# prior = c(
#   prior(student_t(3, 5, 5), class = Intercept),
#   prior(uniform(0, 10), class = shape)),
# iter = 41000, warmup = 40000, chains = 4, cores = 4, seed = 4
# )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following code extracts and converts the parameters from the brms default into the shape and scale that are used in the rweibull() function before displaying the summaries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract posterior draws and examine as tibble
failure_stress_model_1_tbl &amp;lt;-
  posterior_samples(failure_stress_model_1) %&amp;gt;%
  select(-lp__) %&amp;gt;%
  rename(&amp;quot;mu&amp;quot; = b_Intercept)

#compute shape and scale
post_samples_failure_stress_model_1_tbl &amp;lt;- posterior_samples(failure_stress_model_1) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale)

#display as tibble
post_samples_failure_stress_model_1_tbl %&amp;gt;%
  head(7) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2), digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.590&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.972&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.502&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.126&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.363&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.961&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.570&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.310&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.040&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;13.621&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.067&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;13.753&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4.245&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.035&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(failure_stress_model_1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(failure_stress_model_1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: weibull 
##   Links: mu = log; shape = identity 
## Formula: failure_stress | cens(censored_brms) ~ 1 
##    Data: failure_stress_tbl (Number of observations: 34) 
## Samples: 4 chains, each with iter = 41000; warmup = 40000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     2.38      0.06     2.28     2.49 1.00     2257     2279
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## shape     3.56      0.55     2.56     4.67 1.00     1963     2169
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualization-of-uncertainty---credible-curves-for-stress-in-service-and-failure-stress&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualization of Uncertainty - Credible Curves for Stress-in-Service and Failure Stress&lt;/h2&gt;
&lt;p&gt;I haven’t ever used the gganimate package and this seems like a nice opportunity. The code below draws a small handful of parameters from the posterior and plots them to visualize the uncertainty in both distributions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#take 25 sets of parameters, convert to lnorm curves
lnorm_stress_curve_tbl &amp;lt;- post_samples_stress_in_service_model_1_tbl[1:25, ] %&amp;gt;%
  mutate(plotted_y_data = map2(
    mu, sigma,
    ~ tibble(
      x = seq(0, 20, length.out = 100),
      y = dlnorm(x, .x, .y)
    )
  )) %&amp;gt;%
  unnest(plotted_y_data) %&amp;gt;%
  mutate(model = &amp;quot;Stress in Service [lnorm]&amp;quot;) %&amp;gt;%
  rename(
    param_1 = mu,
    param_2 = sigma
  )

#take 25 sets of parameters, convert to Weib curves
weib_stress_curve_tbl &amp;lt;- post_samples_failure_stress_model_1_tbl[1:25, ] %&amp;gt;%
  mutate(plotted_y_data = map2(
    shape, scale,
    ~ tibble(
      x = seq(0, 20, length.out = 100),
      y = dweibull(x, .x, .y)
    )
  )) %&amp;gt;%
  unnest(plotted_y_data) %&amp;gt;%
  mutate(model = &amp;quot;Failure Stress [weib]&amp;quot;) %&amp;gt;%
  rename(
    param_1 = shape,
    param_2 = scale
  )

#combine
a &amp;lt;- bind_rows(lnorm_stress_curve_tbl, weib_stress_curve_tbl) %&amp;gt;% mutate(param_1_fct = as_factor(param_1))

#visualize
p &amp;lt;- a %&amp;gt;%
  ggplot(aes(x, y)) +
  geom_line(aes(x, y, group = param_1_fct, color = model), alpha = 1, size = 1) +
  labs(
    x = &amp;quot;Stress&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    title = &amp;quot;Credible Failure Stress and Service Stress Distributions&amp;quot;,
    subtitle = &amp;quot;n=25 curves sampled from the posterior&amp;quot;
  ) +
  scale_color_viridis_d(end = .8) +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  theme(legend.title = element_blank()) +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  transition_states(param_1_fct, 0, 1) +
  shadow_mark(past = TRUE, future = TRUE, alpha = .3, color = &amp;quot;gray50&amp;quot;, size = .4)

#gganimate 
animate(p, nframes = 50, fps = 2.5, width = 900, height = 600, res = 120, dev = &amp;quot;png&amp;quot;, type = &amp;quot;cairo&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-20-1.gif&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;building-the-credible-reliability-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Building the Credible Reliability Distribution&lt;/h2&gt;
&lt;p&gt;Having now obtained the posterior distributions for both stress-in-service and failure stress, we can select random sets of parameters and compare a random (but credible) pair of distributions. By simulating from each random pair of distributions and calculating a single value of reliability as before, we can build out a credible reliability distribution. The blue vertical line indicates the frequentist point estimate we obtained at the beginning of the analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#set number of simulations
n_sims &amp;lt;- 10000
set.seed(1001)

#stress-in-service (lognormal) simulations
labeled_post_ln_tbl &amp;lt;- post_samples_stress_in_service_model_1_tbl %&amp;gt;%
  mutate(
    model = &amp;quot;lognormal&amp;quot;
  ) %&amp;gt;%
  rename(
    param1 = mu,
    param2 = sigma
  ) %&amp;gt;%
  mutate(nested_data_ln = map2(param1, param2, ~ rlnorm(n_sims, .x, .y)))

#failure stress (Weibull) simulations
labeled_post_wb_tbl &amp;lt;- post_samples_failure_stress_model_1_tbl %&amp;gt;%
  mutate(
    model = &amp;quot;weibull&amp;quot;
  ) %&amp;gt;%
  rename(
    param1 = shape,
    param2 = scale
  ) %&amp;gt;%
  mutate(nested_data_wb = map2(param1, param2, ~ rweibull(n_sims, .x, .y)))

#combine and calculate reliability for each pair to build reliability distribution
all_post_samples_tbl &amp;lt;- bind_cols(labeled_post_ln_tbl, labeled_post_wb_tbl) %&amp;gt;%
  select(nested_data_ln, nested_data_wb) %&amp;gt;%
  mutate(reliability = map2_dbl(nested_data_ln, nested_data_wb, ~ mean(.x &amp;lt; .y)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Visualize the results with some help from tidybayes::geom_halfeyeh()&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#visualize
all_post_samples_tbl %&amp;gt;%
  ggplot(aes(x = reliability, y = 0)) +
  geom_halfeyeh(
    fill = &amp;quot;firebrick&amp;quot;,
    point_interval = median_qi, .width = .95, alpha = .9
  ) +
  geom_vline(xintercept = reliability_pt_est, color = &amp;quot;dodgerblue&amp;quot;, size = 1.1, alpha = .7) +
  #  stat_dotsh(quantiles = 100, size = .5) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(
    title = &amp;quot;Distribution of Predicted Reliability&amp;quot;,
    subtitle = &amp;quot;Marked by median and 95% probability interval. Vertical line is the point estimate&amp;quot;
  ) +
  theme_bw() +
  theme(panel.grid = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Behold, a full reliability distribution supported by the data! So much better for decision making than the point estimate!&lt;/p&gt;
&lt;p&gt;Thank you for reading.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix---prior-predictive-simulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Appendix - Prior Predictive Simulation&lt;/h2&gt;
&lt;div id=&#34;prior-predictive-simulation-for-stress-in-service&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Prior Predictive Simulation for Stress-in-Service&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(45)
mu_prior &amp;lt;- rlnorm(100000, meanlog = .5, sdlog = 1)
mu_prior_tbl &amp;lt;- mu_prior %&amp;gt;%
  as_tibble() %&amp;gt;%
  filter(value &amp;gt; 0)

muuuuu &amp;lt;- mu_prior_tbl %&amp;gt;% ggplot(aes(x = mu_prior)) +
  geom_histogram(aes(y = ..density..), fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6) +
  scale_x_continuous(trans = &amp;quot;log10&amp;quot;)

mu_prior_tbl %&amp;gt;%
  mutate(orig = log(value)) %&amp;gt;%
  pull(orig) %&amp;gt;%
  mean()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5033306&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mu_prior_tbl %&amp;gt;%
  mutate(orig = log(value)) %&amp;gt;%
  pull(orig) %&amp;gt;%
  sd()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.001799&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(45)
sigma_prior &amp;lt;- runif(100000, .01, 8)

p0_priors_tbl &amp;lt;- sigma_prior %&amp;gt;%
  as_tibble() %&amp;gt;%
  bind_cols(mu_prior_tbl) %&amp;gt;%
  rename(sigma = value, mu = value1)


sigmaaa &amp;lt;- p0_priors_tbl %&amp;gt;% ggplot(aes(x = sigma_prior)) +
  geom_histogram(aes(y = ..density..), fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6)

muuuuu + sigmaaa + plot_annotation(title = &amp;quot;Prior Predicitve Simulations for mu and sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Evaluate implied stress-in-service before seeing the data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p0 &amp;lt;- p0_priors_tbl[1:1000, ] %&amp;gt;%
  mutate(row_id = row_number()) %&amp;gt;%
  mutate(plotted_y_data = pmap(
    list(sigma, mu, row_id),
    ~ tibble(
      x = seq(.1, 100, length.out = 1000),
      y = dlnorm(x, .x, .y),
      z = row_id
    )
  )) %&amp;gt;%
  unnest(plotted_y_data) %&amp;gt;%
  filter(x &amp;gt; 1) %&amp;gt;%
  ggplot(aes(x, y)) +
  geom_line(aes(group = row_id), alpha = .15, color = &amp;quot;#2c3e50&amp;quot;) +
  labs(
    x = &amp;quot;Stress-in-Service&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    title = &amp;quot;Implied Stress-in-Service Possibilities&amp;quot;,
    subtitle = &amp;quot;Generated from Priors Only&amp;quot;
  ) +
  scale_x_continuous(trans = &amp;quot;log10&amp;quot;) +
  ylim(c(0, 1))

p0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Evaluate implied failure stress before seeing the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# seed for reproducibility
set.seed(12)

# Evaluate Mildly Informed Priors
shape_prior &amp;lt;- runif(100000, 0, 10)
shape_prior_tbl &amp;lt;- shape_prior %&amp;gt;% as_tibble()
shaaaape &amp;lt;- shape_prior_tbl %&amp;gt;% ggplot(aes(x = shape_prior)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, boundary = 10, fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6)


intercept_prior &amp;lt;- rstudent_t(100000, 3, 5, 5)

priors_tbl &amp;lt;- intercept_prior %&amp;gt;%
  as_tibble() %&amp;gt;%
  bind_cols(shape_prior_tbl) %&amp;gt;%
  rename(intercept = value, shape = value1) %&amp;gt;%
  mutate(scale_prior = exp(intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  filter(scale_prior &amp;lt; 1000) %&amp;gt;%
  select(-intercept)

scaaaale &amp;lt;- priors_tbl %&amp;gt;% ggplot(aes(x = scale_prior)) +
  geom_histogram(aes(y = ..density..), binwidth = 10, boundary = 100, fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6) +
  ylim(c(0, .005))

shaaaape + scaaaale + plot_annotation(title = &amp;quot;Prior Predicitve Simulations for Shape and Scale&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These are the plausible distributions of failure stress we might expect before seeing the data (based on these priors):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- priors_tbl[1:500, ] %&amp;gt;%
  mutate(plotted_y_data = map2(
    shape, scale_prior,
    ~ tibble(
      x = seq(0, 200, length.out = 400),
      y = dweibull(x, .x, .y)
    )
  )) %&amp;gt;%
  unnest(plotted_y_data) %&amp;gt;%
  ggplot(aes(x, y)) +
  geom_line(aes(group = shape), alpha = .2, color = &amp;quot;#2c3e50&amp;quot;) +
  xlim(c(0, 50)) +
  ylim(c(0, .5)) +
  labs(
    x = &amp;quot;Failure Stress Distributions&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    title = &amp;quot;Implied Failure Stress Possibilities&amp;quot;,
    subtitle = &amp;quot;Generated from Priors Only&amp;quot;
  )

p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-05-bayesian-stress-strength-inference-in-r-and-brms_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Image from here: &lt;a href=&#34;https://www.quanterion.com/interference-stressstrength-analysis/&#34; class=&#34;uri&#34;&gt;https://www.quanterion.com/interference-stressstrength-analysis/&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;If the stress and strength distribution were exactly the same and overlapping, the probability of failures would be 50% since you would be pulling 2 draws randomly and comparing stress to strength&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Practical Applications of Bayesian Reliability, pg. 170&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Survival Analysis - Fitting Weibull Models for Improving Device Reliability in R</title>
      <link>/post/bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r/</guid>
      <description>


&lt;p&gt;It’s time to get our hands dirty with some survival analysis! In this post, I’ll explore reliability modeling techniques that are applicable to Class III medical device testing. My goal is to expand on what I’ve been learning about GLM’s and get comfortable fitting data to Weibull distributions. I don’t have a ton of experience with Weibull analysis so I’ll be taking this opportunity to ask questions, probe assumptions, run simulations, explore different libraries, and develop some intuition about what to expect. I will look at the problem from both a frequentist and Bayesian perspective and explore censored and un-censored data types. Fair warning - expect the workflow to be less linear than normal to allow for these excursions.&lt;/p&gt;
&lt;p&gt;First - a bit of background. FDA expects data supporting the durability of implantable devices over a specified service life. Engineers develop and execute benchtop tests that accelerate the cyclic stresses and strains, typically by increasing the frequency. Such a test is shown here for a coronary stent:&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/fracture.gif&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The most common experimental design for this type of testing is to treat the data as attribute i.e. pass/fail by recording whether or not each test article fractured or not after some pre-determined duration &lt;em&gt;t&lt;/em&gt;. By treating each tested device as a Bernoulli trial, a 1-sided confidence interval can be established on the reliability of the population based on the binomial distribution. This approach is not optimal however since it is generally only practical when all tested units pass the test and even then the sample size requirement are quite restricting. Additionally, designers cannot establish any sort of safety margin or understand the failure mode(s) of the design. We can do better by borrowing reliability techniques from other engineering domains where tests are run to failure and modeled as events vs. time. Such data often follows a Weibull distribution which is flexible enough to accommodate many different failure rates and patterns.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#part-1---fitting-models-to-weibull-data-without-censoring-%5Bfrequentist-perspective%5D&#34;&gt;Part 1 - Fitting Models to Weibull Data Without Censoring [Frequentist Perspective]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#construct-weibull-model-from-un-censored-data-using-fitdistrplus&#34;&gt;Construct Weibull model from un-censored data using fitdistrplus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#using-the-model-to-infer-device-reliability&#34;&gt;Using the model to infer device reliability&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#part-2---fitting-models-to-weibull-data-without-censoring-%5Bbayesian-perspective%5D&#34;&gt;Part 2 - Fitting Models to Weibull Data Without Censoring [Bayesian Perspective]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#use-grid-approximation-to-estimate-posterior&#34;&gt;Use grid approximation to estimate posterior&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualize-draws-from-the-posterior&#34;&gt;Visualize draws from the posterior&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#uncertainty-in-the-implied-reliabilty-of-the-device&#34;&gt;Uncertainty in the implied reliabilty of the device&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#part-3---fitting-models-to-weibull-data-with-right-censoring-%5Bfrequentist-perspective%5D&#34;&gt;Part 3 - Fitting Models to Weibull Data with Right-Censoring [Frequentist Perspective]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#point-estimate-with-right-censored-data&#34;&gt;Point estimate with right-censored data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#simulation-to-understand-point-estimate-sensitivity-to-sample-size&#34;&gt;Simulation to understand point estimate sensitivity to sample size&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#simulation-of-95%-confidence-intervals-on-reliability&#34;&gt;Simulation of 95% confidence intervals on reliability&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#part-4---fitting-models-to-weibull-data-with-right-censoring-%5Bbayesian-perspective%5D&#34;&gt;Part 4 - Fitting Models to Weibull Data with Right-Censoring [Bayesian Perspective]&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#use-brm()-to-generate-a-posterior-distribution-for-shape-and-scale&#34;&gt;Use brm() to generate a posterior distribution for shape and scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#evaluation-of-priors&#34;&gt;Evaluation of priors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#evaluate-sensitivity-of-posterior-to-sample-size&#34;&gt;Evaluate sensitivity of posterior to sample size&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#evaluate-sensitivity-of-reliability-estimate-to-sample-size.&#34;&gt;Evaluate Sensitivity of Reliability Estimate to Sample Size.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#wrap-up&#34;&gt;Wrap-up&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix---prior-predictive-simulation---beware-it&amp;#39;s-ugly-in-here&#34;&gt;APPENDIX - Prior Predictive Simulation - BEWARE it’s ugly in here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(patchwork)
library(skimr)
library(ggrepel)
library(tidyverse)
library(knitr)
library(rayshader)
library(fitdistrplus)
library(tidymodels)
library(tidybayes)
library(ggridges)
library(ggExtra)
library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;part-1---fitting-models-to-weibull-data-without-censoring-frequentist-perspective&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 1 - Fitting Models to Weibull Data Without Censoring [Frequentist Perspective]&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tools: fitdist() function form fitdistrplus package&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal: Obtain maximum likelihood point estimate of shape and scale parameters from best fitting Weibull distribution&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;In the following section I work with test data representing the number of days a set of devices were on test before failure.&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; Each day on test represents 1 month in service. All devices were tested until failure (no censored data). To start, I’ll read in the data and take a look at it. There are 100 data points, which is more than typically tested for stents or implants but is reasonable for electronic components. We’ll assume that domain knowledge indicates these data come from a process that can be well described by a Weibull distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Read data in and scan with skim()
data &amp;lt;- read.csv(file = &amp;quot;Example3.1Data.txt&amp;quot;, header = FALSE) %&amp;gt;% as_tibble()
data_tbl &amp;lt;- data %&amp;gt;% rename(fatigue_duration = V1)

data_tbl %&amp;gt;% skim()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Skim summary statistics
##  n obs: 100 
##  n variables: 1 
## 
## -- Variable type:integer --------------------------------------------------------------------------------------------------------------------
##          variable missing complete   n  mean    sd p0   p25  p50   p75
##  fatigue_duration       0      100 100 89.44 51.42  5 51.75 79.5 119.5
##  p100     hist
##   290 &amp;lt;U+2583&amp;gt;&amp;lt;U+2587&amp;gt;&amp;lt;U+2586&amp;gt;&amp;lt;U+2583&amp;gt;&amp;lt;U+2582&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;fatigue_duration&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;75&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;28&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;52&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;67&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;78&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;132&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;169&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;97&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;construct-weibull-model-from-un-censored-data-using-fitdistrplus&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Construct Weibull model from un-censored data using fitdistrplus&lt;/h3&gt;
&lt;p&gt;To start out with, let’s take a frequentist approach and fit a 2-parameter Weibull distribution to these data. Once the parameters of the best fitting Weibull distribution of determined, they can be used to make useful inferences and predictions.&lt;/p&gt;
&lt;p&gt;I’ll use the fitdist() function from the fitdistrplus package to identify the best fit via maximum likelihood. The parameters we care about estimating are the shape and scale.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit model and extract parameters of interest
mle_wieb_nocens_fit &amp;lt;- fitdist(data_tbl$fatigue_duration, &amp;quot;weibull&amp;quot;)
weib_shape &amp;lt;- mle_wieb_nocens_fit$estimate[&amp;quot;shape&amp;quot;]
weib_scale &amp;lt;- mle_wieb_nocens_fit$estimate[&amp;quot;scale&amp;quot;]

# Summarize and plot
summary(mle_wieb_nocens_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Fitting of the distribution &amp;#39; weibull &amp;#39; by maximum likelihood 
## Parameters : 
##         estimate Std. Error
## shape   1.832201  0.1401198
## scale 100.841802  5.8068570
## Loglikelihood:  -526.2573   AIC:  1056.515   BIC:  1061.725 
## Correlation matrix:
##           shape     scale
## shape 1.0000000 0.3186071
## scale 0.3186071 1.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(mle_wieb_nocens_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; The Weibull isn’t the only possible distribution we could have fit. Lognormal and gamma are both known to model time-to-failure data well. They are shown below using the denscomp() function from fitdistrplus.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit gamma model, extract shape, rate
mle_gamma_nocens_fit &amp;lt;- fitdist(data_tbl$fatigue_duration, &amp;quot;gamma&amp;quot;)
gamma_shape &amp;lt;- mle_gamma_nocens_fit$estimate[&amp;quot;shape&amp;quot;]
gamma_rate &amp;lt;- mle_gamma_nocens_fit$estimate[&amp;quot;rate&amp;quot;]

# Fit lognormal model, extract mean, sd
mle_lognormal_nocens_fit &amp;lt;- fitdist(data_tbl$fatigue_duration, &amp;quot;lnorm&amp;quot;)
lnorm_meanlog &amp;lt;- mle_lognormal_nocens_fit$estimate[&amp;quot;meanlog&amp;quot;]
lnorm_sdlog &amp;lt;- mle_lognormal_nocens_fit$estimate[&amp;quot;sdlog&amp;quot;]

# visualize in fitdistrplus
plot.legend &amp;lt;- c(&amp;quot;gamma&amp;quot;, &amp;quot;lognormal&amp;quot;, &amp;quot;Weibull&amp;quot;)
denscomp(list(mle_gamma_nocens_fit, mle_lognormal_nocens_fit, mle_wieb_nocens_fit), legendtext = plot.legend)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I recreate the above in ggplot2, for fun and practice.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x_series &amp;lt;- seq(0, 300, by = 1)
x_tbl &amp;lt;- tibble(x = x_series)


wide_densities_tbl &amp;lt;- x_tbl %&amp;gt;%
  mutate(
    Weibull = dweibull(x, shape = weib_shape, scale = weib_scale),
    gamma = dgamma(x, shape = gamma_shape, rate = gamma_rate),
    lognormal = dlnorm(x, meanlog = lnorm_meanlog, sdlog = lnorm_sdlog)
  ) %&amp;gt;%
  gather(&amp;quot;distribution&amp;quot;, &amp;quot;value&amp;quot;, -x)

wide_densities_tbl %&amp;gt;% ggplot(aes(x = x)) +
  geom_line(aes(
    x = x,
    y = value,
    color = distribution,
    linetype = distribution
  ),
  size = .8
  ) +
  geom_histogram(
    data = data_tbl,
    aes(
      x = fatigue_duration,
      y = ..density..
    ),
    binwidth = 50,
    boundary = 300,
    color = &amp;quot;white&amp;quot;,
    fill = &amp;quot;#2c3e50&amp;quot;,
    alpha = .6
  ) +
  labs(
    x = &amp;quot;Time to Fatigue Failure Event (Days)&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    title = &amp;quot;Histogram and theoretical densities for Fatigue Data&amp;quot;,
    subtitle = &amp;quot;Parametric fits using MLE via fitdist() function&amp;quot;
  ) +
  theme(legend.title = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Goodness-of-fit statistics are available and shown below for reference. If available, we would prefer to use domain knowledge and experience to identify what the true distribution is instead of these statistics which are subject to sampling variation. It is not good practice to stare at the histogram and attempt to identify the distribution of the population from which it was drawn. Nevertheless, we might look at the statistics below if we had absolutely no idea the nature of the data generating process / test.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get goodness-of-fit
gofstat(list(mle_wieb_nocens_fit, mle_gamma_nocens_fit, mle_lognormal_nocens_fit),
  fitnames = c(&amp;quot;weib&amp;quot;, &amp;quot;gamma&amp;quot;, &amp;quot;lnorm&amp;quot;)
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Goodness-of-fit statistics
##                                    weib      gamma      lnorm
## Kolmogorov-Smirnov statistic 0.05066902 0.03643609 0.06948557
## Cramer-von Mises statistic   0.03408173 0.02106615 0.12076742
## Anderson-Darling statistic   0.21634543 0.17192106 0.81630880
## 
## Goodness-of-fit criteria
##                                    weib    gamma    lnorm
## Akaike&amp;#39;s Information Criterion 1056.515 1056.408 1067.427
## Bayesian Information Criterion 1061.725 1061.618 1072.637&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-model-to-infer-device-reliability&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using the model to infer device reliability&lt;/h3&gt;
&lt;p&gt;The model by itself isn’t what we are after. It is the vehicle from which we can infer some very important information about the reliability of the implant design. First and foremost - we would be very interested in understanding the reliability of the device at a time of interest. For instance, suppose our voice of customer research indicates that our new generation of device needs to last 10 months &lt;em&gt;in vivo&lt;/em&gt; to be safe and competitive. Recall that each day on test represents 1 month in service. Once we fit a Weibull model to the test data for our device, we can use the reliability function to calculate the probability of survival beyond time &lt;em&gt;t&lt;/em&gt;.&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{R} (t | \beta, \eta) =  e ^ {- \bigg (\frac{t}{\eta} \bigg ) ^ {\beta}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;t = the time of interest (for example, 10 years)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; = the Weibull scale parameter&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; = the Weibull shape parameter&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This looks a little nasty but it reads something like “the probability of a device surviving beyond time &lt;em&gt;t&lt;/em&gt; conditional on parameters &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; is [some mathy function of &lt;em&gt;t&lt;/em&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt;]. For the model we fit above using MLE, a point estimate of the reliability at t=10 years (per the above VoC) can be calculated with a simple 1-liner:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reliability_at_10 &amp;lt;- exp(-(10 / weib_scale)**(weib_shape))
reliability_at_10 %&amp;gt;%
  scales::percent() %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;x&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;98.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In this way we infer something important about the quality of the product by fitting a model from benchtop data.&lt;/p&gt;
&lt;p&gt;It is common to report confidence intervals about the reliability estimate but this practice suffers many limitations. The intervals change with different stopping intentions and/or additional comparisons. They also do not represent true probabilistic distributions as our intuition expects them to and cannot be propagated through complex systems or simulations. What we’d really like is the posterior distribution for each of the parameters in the Weibull model, which provides all credible pairs of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; that are supported by the data. For that, we need Bayesian methods which happen to also be more fun.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-2---fitting-models-to-weibull-data-without-censoring-bayesian-perspective&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 2 - Fitting Models to Weibull Data Without Censoring [Bayesian Perspective]&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tools: Grid Approximation [manual calculations]&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal: Approximate true posterior distributions for shape and scale via discretization of priors&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;use-grid-approximation-to-estimate-posterior&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use grid approximation to estimate posterior&lt;/h3&gt;
&lt;p&gt;This problem is simple enough that we can apply grid approximation to obtain the posterior. In this method we feed in a sequence of candidate combinations for &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; and determine which pairs were most likely to give rise to the data. The likelihood is multiplied by the prior and converted to a probability for each set of candidate &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt;. Flat priors are used here for simplicity - I’ll put more effort into the priors later on in this post. Since the priors are flat, the posterior estimates should agree with the maximum likelihood point estimate.&lt;/p&gt;
&lt;p&gt;Calculate posterior via grid approximation:&lt;a href=&#34;#fn4&#34; class=&#34;footnoteRef&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# function to get log-likelihood of the data for a given shape &amp;amp; scale pair
grid_function &amp;lt;- function(shape, scale) {
  dweibull(data_tbl$fatigue_duration, shape = shape, scale = scale, log = T) %&amp;gt;%
    sum()
}

# set up grid of possible shape, scale parameters
n &amp;lt;- 100
shape_grid &amp;lt;- seq(1, 3, length.out = n)
scale_grid &amp;lt;- seq(60, 130, length.out = n)
two_param_grid &amp;lt;- expand_grid(shape_grid, scale_grid)

# map the grid_function over all candidate parameter pairs
# multiply LL by prior and convert to probability
full_tbl &amp;lt;- two_param_grid %&amp;gt;%
  mutate(log_likelihood = map2(shape_grid, scale_grid, grid_function)) %&amp;gt;%
  unnest() %&amp;gt;%
  mutate(
    shape_prior = 1,
    scale_prior = 1
  ) %&amp;gt;%
  mutate(product = log_likelihood + shape_prior + scale_prior) %&amp;gt;%
  mutate(probability = exp(product - max(product)))

full_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 7))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape_grid&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale_grid&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;log_likelihood&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;shape_prior&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale_prior&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;product&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;probability&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;60.00000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-558.5011&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-556.5011&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;60.70707&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-557.9365&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-555.9365&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;61.41414&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-557.3982&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-555.3982&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;62.12121&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-556.8853&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-554.8853&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;62.82828&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-556.3968&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-554.3968&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;63.53535&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-555.9317&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-553.9317&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;64.24242&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-555.4890&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-553.4890&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;64.94949&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-555.0680&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-553.0680&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;65.65657&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-554.6678&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-552.6678&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;66.36364&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-554.2875&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-552.2875&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Plot the grid approximation of the posterior. If we super-impose our point estimate from Part 1, we see the maximum likelihood estimate agrees well with the mode of the joint posterior distributions for shape and scale.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# need this data to feed to gg_label_repel to tell it where to attach label
point_tbl &amp;lt;- tibble(x = weib_shape, y = weib_scale)

# visualize and compare to MLE
plt_1 &amp;lt;- full_tbl %&amp;gt;%
  ggplot(aes(x = shape_grid, y = scale_grid)) +
  geom_raster(aes(fill = probability),
    interpolate = T
  ) +
  geom_point(x = weib_shape, y = weib_scale, size = 1.3) +
  geom_label_repel(
    data = point_tbl, aes(x, y),
    label = &amp;quot;Maximum Likelihood Estimate \n[from Part 1]&amp;quot;,
    fill = &amp;quot;#8bd646ff&amp;quot;,
    color = &amp;quot;black&amp;quot;,
    segment.color = &amp;quot;black&amp;quot;,
    segment.size = 1,
    #                   min.segment.length = unit(1, &amp;quot;lines&amp;quot;),
    nudge_y = -16,
    nudge_x = .5
  ) +
  scale_fill_viridis_c() +
  labs(
    title = &amp;quot;Posterior for Weibull Shape and Scale Parameters&amp;quot;,
    subtitle = &amp;quot;Calculated with Grid Approximation&amp;quot;,
    x = expression(eta [&amp;quot;shape&amp;quot;]),
    y = expression(beta [&amp;quot;scale&amp;quot;])
  ) +
  theme(panel.grid = element_blank())

plt_1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;3d with rayshader just to flex :)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# par(mfrow = c(1, 1))
# plot_gg(plt_1, width = 5, height = 4, scale = 300, multicore = TRUE, windowsize = c(1200, 960),
#        fov = 70, zoom = 0.45, theta = 330, phi = 40)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/3d_weib_2.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize-draws-from-the-posterior&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualize draws from the posterior&lt;/h3&gt;
&lt;p&gt;We can sample from the grid to get the same if we weight the draws by probability.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2020)

# take a weighted sample from the posterior
grid_approx_posterior_samples &amp;lt;- full_tbl %&amp;gt;%
  sample_n(size = 2000, replace = T, weight = probability)

# visualize
grid_approx_plot &amp;lt;- grid_approx_posterior_samples %&amp;gt;%
  ggplot(aes(x = shape_grid, y = scale_grid)) +
  geom_point(
    colour = &amp;quot;#e56a5dff&amp;quot;,
    size = 2,
    alpha = 0.3
  ) +
  labs(
    x = expression(eta [&amp;quot;shape&amp;quot;]),
    y = expression(beta [&amp;quot;scale&amp;quot;])
  ) +
  geom_density_2d(color = &amp;quot;black&amp;quot;, size = 1.2, alpha = .4) +
  labs(
    title = &amp;quot;Estimate of Joint Probabilities for Shape and Scale&amp;quot;,
    subtitle = &amp;quot;Via Posterior Sampling&amp;quot;
  )

grid_approx_marg_plot &amp;lt;- ggMarginal(grid_approx_plot,
  type = &amp;quot;density&amp;quot;,
  color = &amp;quot;white&amp;quot;,
  alpha = 0.7,
  fill = &amp;quot;#e56a5dff&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;uncertainty-in-the-implied-time-to-failure-curves&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Uncertainty in the implied time-to-failure curves&lt;/h3&gt;
&lt;p&gt;Each of the credible parameter values implies a possible Weibull distribution of time-to-failure data from which a reliability estimate can be inferred. This is a good way to visualize the uncertainty in a way that makes intuitive sense.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sample from posterior; weighted as prob
grid_approx_posterior_samples_4plot &amp;lt;- full_tbl %&amp;gt;%
  sample_n(size = 1000, replace = T, weight = probability) %&amp;gt;%
  select(shape_grid, scale_grid)

# plot 1000 Weibull curves from samples parameters
weib_uncertainty_plt &amp;lt;- grid_approx_posterior_samples_4plot %&amp;gt;%
  mutate(p_y_data = map2(
    shape_grid, scale_grid,
    ~ tibble(
      x = seq(0, 200, length.out = 400),
      y = dweibull(x, .x, .y)
    )
  )) %&amp;gt;%
  mutate(row_id = row_number()) %&amp;gt;%
  unnest(p_y_data) %&amp;gt;%
  ggplot(aes(x = x, y = y)) +
  geom_line(aes(group = row_id), alpha = .05, color = &amp;quot;#440154ff&amp;quot;) +
  labs(
    x = &amp;quot;Time&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    title = &amp;quot;Distribution of Time at Failure Event&amp;quot;,
    subtitle = &amp;quot;Implied by Posterior Distribution [Sample of n=1000]&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/weib_uncertainty_plt.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;uncertainty-in-the-implied-reliabilty-of-the-device&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Uncertainty in the implied reliabilty of the device&lt;/h3&gt;
&lt;p&gt;Any row-wise operations performed will retain the uncertainty in the posterior distribution. This allows for a straightforward computation of the range of credible reliabilities at t=10 via the reliability function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# use params in posterior to calculate correstponding reliabilities at t=10
grid_approx_posterior_samples_4relplot &amp;lt;- full_tbl %&amp;gt;%
  sample_n(size = 4000, replace = T, weight = probability) %&amp;gt;%
  select(shape_grid, scale_grid) %&amp;gt;%
  mutate(reliability_at_10 = exp(-(10 / scale_grid)**(shape_grid)))

# visualize reliability distribution
grid_approx_posterior_samples_4relplot %&amp;gt;%
  ggplot(aes(reliability_at_10)) +
  geom_histogram(aes(y = ..density..), fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6) +
  labs(
    title = &amp;quot;Reliability Distribution&amp;quot;,
    subtitle = &amp;quot;Calculated from Grid Approximation with Flat Priors&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; This distribution gives much richer information than the MLE point estimate of reliability. The most credible estimate of reliability is ~ 98.8%, but it could plausibly also be as low as 96%. This delta can mean the difference between a successful and a failing product and should be considered as you move through project phase gates.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-3---fitting-models-to-weibull-data-with-right-censoring-frequentist-perspective&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 3 - Fitting Models to Weibull Data with Right-Censoring [Frequentist Perspective]&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tools: survreg() function form survival package&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal: Obtain maximum likelihood point estimate of shape and scale parameters from best fitting Weibull distribution&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;In survival analysis we are waiting to observe the event of interest. For benchtop testing, we wait for fracture or some other failure. In a clinical study, we might be waiting for death, re-intervention, or endpoint. Sometimes the events don’t happen within the observation window but we still must draw the study to a close and crunch the data. Cases in which no events were observed are considered “right-censored” in that we know the start date (and therefore how long they were under observation) but don’t know if and when the event of interest would occur. They must inform the analysis in some way - generally within the likelihood.&lt;/p&gt;
&lt;div id=&#34;point-estimate-with-right-censored-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Point estimate with right-censored data&lt;/h3&gt;
&lt;p&gt;First, I’ll set up a function to generate simulated data from a Weibull distribution and censor any observations greater than 100. I set the function up in anticipation of using the survreg() function from the &lt;strong&gt;survival&lt;/strong&gt; package in R. The syntax is a little funky so some additional detail is provided below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# function to generate random Weibull data and censor data &amp;gt; 100
rweibull_cens_mod_fcn &amp;lt;- function(n, shape, scale) {
  raw_times &amp;lt;- rweibull(n, shape = shape, scale = scale)
  tibble(failure_time_raw = raw_times) %&amp;gt;%
    mutate(time = case_when(
      failure_time_raw &amp;lt; 100 ~ failure_time_raw,
      TRUE ~ 100
    )) %&amp;gt;%
    mutate(censor = case_when(
      time == 100 ~ 0,
      TRUE ~ 1
    )) %&amp;gt;%
    mutate(censor = censor == 1) %&amp;gt;%
    mutate(time = time %&amp;gt;% round(digits = 2)) %&amp;gt;%
    select(-failure_time_raw)
}

# set seed for repeatability
set.seed(54)
first_test_fit_tbl &amp;lt;- rweibull_cens_mod_fcn(30, 3, 100)
first_test_fit_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;time&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;censor&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;31.16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;73.94&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;71.90&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;100.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FALSE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;100.00&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FALSE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;74.91&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;37.79&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;72.28&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;50.63&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;45.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I admit this looks a little strange because the data that were just described as censored (duration greater than 100) show as “FALSE” in the censored column. This is due to the default syntax of the survreg() function in the survival package that we intend to fit the model with:&lt;a href=&#34;#fn5&#34; class=&#34;footnoteRef&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;survival package defaults for censoring:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;0 or FALSE for censoring, 1 or TRUE for observed event&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;To further throw us off the trail, the survreg() function returns “scale”&amp;quot; and “intercept”&amp;quot; that must be converted to recover the shape and scale parameters that align with the rweibull() function used to create the data. Don’t fall for these tricks - just extract the desired information as follows:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;survival package defaults for parameterizing the Weibull distribution:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;survreg’s scale parameter = 1/(rweibull shape parameter)&lt;/li&gt;
&lt;li&gt;survreg’s intercept = log(rweibull scale parameter)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ok let’s see if the model can recover the parameters when we providing survreg() the tibble with n=30 data points (some censored):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit model to simulated data (n=30)
test_fit &amp;lt;- survival::survreg(Surv(time, censor) ~ 1,
  data = first_test_fit_tbl,
  dist = &amp;quot;weibull&amp;quot;
)

# evaluate the fit
summary(test_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## survival::survreg(formula = Surv(time, censor) ~ 1, data = first_test_fit_tbl, 
##     dist = &amp;quot;weibull&amp;quot;)
##               Value Std. Error    z       p
## (Intercept)  4.5469     0.0896 50.7 &amp;lt; 2e-16
## Log(scale)  -0.9266     0.1972 -4.7 2.6e-06
## 
## Scale= 0.396 
## 
## Weibull distribution
## Loglik(model)= -106.7   Loglik(intercept only)= -106.7
## Number of Newton-Raphson Iterations: 5 
## n= 30&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Extract and covert shape and scale with broom::tidy() and dplyr:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract scale parameter
scale &amp;lt;- tidy(test_fit)[1, 2] %&amp;gt;%
  rename(scale = estimate) %&amp;gt;%
  exp() %&amp;gt;%
  round(2)

# extract shape parameter
shape &amp;lt;- tidy(test_fit)[2, 2] %&amp;gt;%
  rename(shape = estimate) %&amp;gt;%
  exp() %&amp;gt;%
  .^-1 %&amp;gt;%
  round(2)

# summarize
point_estimates &amp;lt;- bind_cols(shape, scale)
point_estimates %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.53&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;94.34&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;What has happened here? We know the true parameters are shape = 3, scale = 100 because that’s how the data were generated. These point estimates are pretty far off. Is the survreg() fitting function broken? Are there too few data and we are just seeing sampling variation? Is it confused by the censored data? I honestly don’t know. To answer these questions, we need a new function that fits a model using survreg() for any provided sample size. The data to make the fit are generated internal to the function. The function returns a tibble with estimates of shape and scale for that particular trial:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulation-to-understand-point-estimate-sensitivity-to-sample-size&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Simulation to understand point estimate sensitivity to sample size&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# seed for repeatability
set.seed(2025)

# fcn takes sample size n, simulates weibull(3, 100) data, fits model, estimates params
test_map_fcn &amp;lt;- function(n) {
  holder &amp;lt;- rweibull_cens_mod_fcn(n, 3, 100)

  sr1_fit &amp;lt;- survival::survreg(Surv(time, censor) ~ 1, data = holder, dist = &amp;quot;weibull&amp;quot;)

  scale &amp;lt;- tidy(sr1_fit)[1, 2] %&amp;gt;%
    rename(scale = estimate) %&amp;gt;%
    exp() %&amp;gt;%
    round(2)

  shape &amp;lt;- tidy(sr1_fit)[2, 2] %&amp;gt;%
    rename(shape = estimate) %&amp;gt;%
    exp() %&amp;gt;%
    .^-1 %&amp;gt;%
    round(2)

  point_estimates &amp;lt;- bind_cols(shape, scale)
  point_estimates
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have a function that takes a sample size n and returns fitted shape and scale values, we want to apply the function across many values of n. Let’s look at what happens to our point estimates of shape and scale as the sample size n increases from 10 to 1000 by 1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create sequence of n&amp;#39;s
n_sim_mle &amp;lt;- seq(10, 1000, by = 1) %&amp;gt;%
  tibble() %&amp;gt;%
  rename(n = &amp;quot;.&amp;quot;)

# map the fitting function across vector of n&amp;#39;s.
results_tbl &amp;lt;- n_sim_mle %&amp;gt;%
  mutate(results = map(n, test_map_fcn)) %&amp;gt;%
  unnest()

# peek at format of results
results_tbl %&amp;gt;%
  head(5) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;n&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;85.94&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.89&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;108.29&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.96&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;103.04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;82.20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.98&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;101.62&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Visualize results of the simulation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results_tbl %&amp;gt;%
  gather(key = key, value = value, -n) %&amp;gt;%
  ggplot(aes(x = n, y = value)) +
  geom_point(color = &amp;quot;#5C126EFF&amp;quot;, alpha = 0.3) +
  facet_wrap(~key, scales = &amp;quot;free_y&amp;quot;) +
  geom_smooth(color = &amp;quot;#F17020FF&amp;quot;, alpha = 0.9) +
  labs(
    x = &amp;quot;Sample Size&amp;quot;,
    y = &amp;quot;&amp;quot;,
    title = &amp;quot;Estimated Shape and Scale Parameters for Different Data Set Sizes&amp;quot;,
    subtitle = &amp;quot;Weibull Regressions using survival package.  Data generated from Weibull(3, 100)&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This simulation is illuminating. It’s apparent that there is sampling variability effecting the estimates. On average, the true parameters of shape = 3 and scale = 100 are correctly estimated. But on any given experimental run, the estimate might be off by quite a bit. The precision increases with sample size as expected but the variation is still relevant even at large n.&lt;/p&gt;
&lt;p&gt;Based on this simulation we can conclude that our initial point estimate of 2.5, 94.3 fit from n=30 is within the range of what is to be expected and not a software bug or coding error.&lt;/p&gt;
&lt;p&gt;Estimates for product reliability at 15, 30, 45, and 60 months are shown below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results_tbl %&amp;gt;%
  mutate(reliability_at_15 = exp(-(15 / scale)**(shape))) %&amp;gt;%
  mutate(reliability_at_30 = exp(-(30 / scale)**(shape))) %&amp;gt;%
  mutate(reliability_at_45 = exp(-(45 / scale)**(shape))) %&amp;gt;%
  mutate(reliability_at_60 = exp(-(60 / scale)**(shape))) %&amp;gt;%
  select(-c(shape, scale)) %&amp;gt;%
  gather(key = &amp;quot;key&amp;quot;, value = &amp;quot;value&amp;quot;, -n) %&amp;gt;%
  ggplot(aes(x = n, y = value)) +
  geom_point(aes(color = key), alpha = .4) +
  #  geom_smooth(aes(group = key), color = &amp;quot;black&amp;quot;, size = .4, alpha = .5) +
  ylim(c(.73, 1)) +
  scale_color_viridis_d(option = &amp;quot;C&amp;quot;, begin = 0, end = .8, direction = -1) +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  labs(
    title = &amp;quot;Reliability Point Estimates&amp;quot;,
    subtitle = &amp;quot;Effect of Sample Size and Sampling Variability&amp;quot;,
    x = &amp;quot;Sample Size&amp;quot;,
    y = &amp;quot;Reliability Estimate&amp;quot;
  ) +
  theme(legend.title = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above gives a nice sense of the uncertainty in the reliability estimate as sample size increases, but you can’t actually simulate a confidence interval from those data because there aren’t enough data points at any one sample size. To do that, we need many runs at the same sample size.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulation-of-95-confidence-intervals-on-reliability&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Simulation of 95% confidence intervals on reliability&lt;/h3&gt;
&lt;p&gt;In the code below, I generate n=1000 simulations of n=30 samples drawn from a Weibull distribution with shape = 3 and scale = 100. For each set of 30 I fit a model and record the MLE for the parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# each simulation will be like a benchtop test of n=30 parts
ci_reps_tbl &amp;lt;- tibble(sample_size = rep(30, 1000))

set.seed(98)

# loop: draw 30 from rweibull(30, 100); fit model, estimate parameters
ci_results_tbl &amp;lt;- ci_reps_tbl %&amp;gt;%
  mutate(results = map(sample_size, test_map_fcn)) %&amp;gt;%
  unnest()

# peek at results
ci_results_tbl %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;sample_size&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.06&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;107.10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.80&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;98.42&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.99&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;111.44&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.78&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;108.50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.91&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;100.25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;102.01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;95.47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.72&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;97.98&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;96.99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.74&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;98.30&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;95% of the reliability estimates lik above the .05 quantile. This means the .05 quantile is the analogous boundary for a simulated 95% confidence interval. In the code below, the .05 quantile of reliability is estimated for each time requirement of interest where we have 1000 simulation at each.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# function will take a time of interest and calculate the implied reliability
# only works with the params from the ci_results_tbl above
reliability95_fcn &amp;lt;- function(t_requirement) {
  ci_results2tbl &amp;lt;- ci_results_tbl %&amp;gt;%
    mutate(reliability_at_t = exp(-(t_requirement / scale)**(shape))) %&amp;gt;%
    mutate(q_05 = quantile(reliability_at_t, .05))
  ci_results2tbl
}

# map the function across a sequence of candidate time requirements
reliability_seq_tbl &amp;lt;- tibble(time_requirement = seq(5, 100, by = 5)) %&amp;gt;% mutate(rel_tbl = map(time_requirement, reliability95_fcn))

# calculate the .05 quantile for reliability in each set of 1000 (each candidate time requirement)
reliability_summary_tbl &amp;lt;- reliability_seq_tbl %&amp;gt;%
  unnest(rel_tbl) %&amp;gt;%
  group_by(time_requirement) %&amp;gt;%
  summarize(rel_q05 = mean(q_05)) %&amp;gt;%
  ungroup()

# Peek
reliability_summary_tbl %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;time_requirement&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;rel_q05&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9987176&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9942133&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9858520&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9730873&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9558373&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9344743&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9076116&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;40&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8775053&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;45&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8429503&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;50&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8015775&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;55&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.7562483&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;60&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.7054836&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;65&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.6544688&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;70&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5948305&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;75&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5358066&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;80&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.4756331&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;85&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.4150847&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;90&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.3500516&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;95&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2880577&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2288761&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# reference tibbles for labeling w/ gg_label_repel
label_ci_tbl &amp;lt;- tibble(x = 45, y = 0.8429503)
label_95rel_tbl &amp;lt;- tibble(x = 10, y = 0.95)

# visualize
reliability_seq_tbl %&amp;gt;%
  unnest(rel_tbl) %&amp;gt;%
  ggplot(aes(x = time_requirement, y = reliability_at_t)) +
  geom_jitter(alpha = 0.03) +
  #  geom_point(data = reliability_summary_tbl, aes(x = time_requirement, y = rel_q05), color = &amp;quot;#c44c74ff&amp;quot;, size = 1) +
  geom_smooth(data = reliability_summary_tbl, aes(x = time_requirement, y = rel_q05), color = &amp;quot;#c44c74ff&amp;quot;, size = 1, alpha = .2) +
  geom_hline(aes(yintercept = .95), color = &amp;quot;#240691ff&amp;quot;, size = 1) +
  geom_label_repel(
    data = label_ci_tbl, aes(x, y),
    label = &amp;quot;1-sided 95% Confidence\n bound on Reliability&amp;quot;,
    fill = &amp;quot;#c44c74ff&amp;quot;,
    color = &amp;quot;#f0f921ff&amp;quot;,
    segment.color = &amp;quot;#c44c74ff&amp;quot;,
    segment.size = 1,
    #                   min.segment.length = unit(1, &amp;quot;lines&amp;quot;),
    nudge_y = -.5,
    nudge_x = -5
  ) +
  geom_label_repel(
    data = label_95rel_tbl, aes(x, y),
    label = &amp;quot;Product Reliability\n Requirement: 95%&amp;quot;,
    fill = &amp;quot;#240691ff&amp;quot;,
    color = &amp;quot;#f0f921ff&amp;quot;,
    segment.color = &amp;quot;#240691ff&amp;quot;,
    segment.size = 1,
    #                   min.segment.length = unit(1, &amp;quot;lines&amp;quot;),
    nudge_y = -.25,
    nudge_x = 5
  ) +
  labs(
    title = &amp;quot;Approximate 95% Confidence Interval for Various Durability Requirements&amp;quot;,
    subtitle = &amp;quot;Each Sim: 1000 models fit from 1000 draws of n=30 from Weibull(3, 100)&amp;quot;,
    x = &amp;quot;Device Requirement (Service Life without Failure)&amp;quot;,
    y = &amp;quot;Reliability&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-32-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; There’s a lot going on here so it’s worth it to pause for a minute. If I was to try to communicate this in words, I would say:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Assume we have designed a medical device that fails according to a Weibull distribution with shape = 3 and scale = 100.&lt;/li&gt;
&lt;li&gt;Assume the service life requirement for the device is known and specified within the product’s requirements&lt;/li&gt;
&lt;li&gt;Assume we can only test n=30 units in 1 test run and that testing is expensive and resource intensive&lt;/li&gt;
&lt;li&gt;The n=30 failure/censor times will be subject to sampling variability and the model fit from the data will likely not be Weibull(3, 100)&lt;/li&gt;
&lt;li&gt;The variability in the parameter estimates is propagated to the reliability estimates - a distribution of reliability is generated for each potential service life requirement (in practice we would only have 1 requirement)&lt;/li&gt;
&lt;li&gt;The .05 quantile of the reliability distribution at each requirement approximates the 1-sided lower bound of the 95% confidence interval. This threshold changes for each candidate service life requirement.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Why does any of this even matter? Here’s the TLDR of this whole section:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Suppose the service life requirement for our device is 24 months (2 years). Our boss asks us to set up an experiment to verify with 95% confidence that 95% of our product will meet the 24 month service requirement without failing. The industry standard way to do this is to test n=59 parts for 24 days (each day on test representing 1 month in service). If all n=59 pass then we can claim 95% reliability with 95% confidence. However, if we are willing to test a bit longer then the above figure indicates we can run the test to failure with only n=30 parts instead of n=59. If it cost a lot to obtain and prep test articles (which it often does), then &lt;strong&gt;we just saved a ton of money and test resources by treating the data as variable instead of attribute.&lt;/strong&gt; &lt;a href=&#34;#fn6&#34; class=&#34;footnoteRef&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; We also get information about the failure mode for free.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-4---fitting-models-to-weibull-data-with-right-censoring-bayesian-perspective&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 4 - Fitting Models to Weibull Data with Right-Censoring [Bayesian Perspective]&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tools: brm() function in brms; stan under the hood&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal: Obtain posterior distributions of shape and scale parameters via Hamiltonian Markov Chain Monte Carlo –&amp;gt; calculate reliability distributions&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;These data are just like those used before - a set of n=30 generated from a Weibull with shape = 3 and scale = 100. They represent months to failure as determined by accelerated testing. In the brms framework, censored data are designated by a 1 (not a 0 as with the survival package).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# test data
ttf &amp;lt;- c(100, 84.8, 87.8, 61.5, 99.3, 100, 100, 60.3, 80.3, 100, 51.7, 68.5, 99.6, 100, 53.2, 46.6, 26.4, 72.3, 62.9, 70.5, 22.2, 100, 100, 75.2, 87.2, 47.4, 100, 47.1, 98.2, 67.3)

# indicator of run-out / censoring
censored &amp;lt;- c(1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0)

# combine
months_to_failure_tbl_4.3.3 &amp;lt;- tibble(
  time = ttf,
  censored = censored
)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;use-brm-to-generate-a-posterior-distribution-for-shape-and-scale&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use brm() to generate a posterior distribution for shape and scale&lt;/h3&gt;
&lt;p&gt;The formula for asking brms to fit a model looks relatively the same as with survival. To start, we fit a simple model with default priors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit model with brm() [use default priors]
# mtf_weib_fit &amp;lt;- brm(time | cens(censored) ~ 1,
# data = months_to_failure_tbl_4.3.3, family = weibull())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just like with the survival package, the default parameterization in brms can easily trip you up. We are fitting an intercept-only model meaning there are no predictor variables. The parameters that get estimated by brm() are the Intercept and shape. We can use the shape estimate as-is, but it’s a bit tricky to recover the scale. The key is that brm() uses a log-link function on the mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;. There is no doubt that this is a rambling post - even so, it is not within scope to try to explain link functions and GLM’s (I’m not expert enough to do it anyways, refer to Statistical Rethinking by McElreath). In short, to convert to scale we need to both undo the link function by taking the exponent and then refer to the brms documentation to understand how the mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; relates to the scale &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;. The operation looks like this:&lt;a href=&#34;#fn7&#34; class=&#34;footnoteRef&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#scale = exp(Intercept)/(gamma(1 + 1/shape))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Examine the results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# saveRDS(mtf_weib_fit, file = &amp;quot;censored_data_mtf_weib_fit.rds&amp;quot;)
mtf_weib_fit &amp;lt;- readRDS(file = &amp;quot;censored_data_mtf_weib_fit.rds&amp;quot;)

summary(mtf_weib_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: weibull 
##   Links: mu = log; shape = identity 
## Formula: time | cens(censored) ~ 1 
##    Data: months_to_failure_tbl_4.3.3 (Number of observations: 30) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     4.41      0.08     4.25     4.58 1.00     2349     1782
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## shape     2.74      0.52     1.82     3.84 1.00     2530     2281
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Gut-check on convergence of chains. Things look good visually and Rhat = 1 (also good).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(mtf_weib_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-37-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Within the tibble of posterior draws we convert the intercept to scale using the formula previously stated.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract scale and shape
post_mtf_weib_samples &amp;lt;- posterior_samples(mtf_weib_fit) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale)

# peek
post_mtf_weib_samples %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2), digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.44&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;87.78&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.07&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;91.80&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.49&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.35&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.28&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;86.42&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.23&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;103.19&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.33&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;107.53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.37&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;91.18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;90.43&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here is our first look at the posterior drawn from a model fit with censored data. We know the data were simulated by drawing randomly from a Weibull(3, 100) so the true data generating process is marked with lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtf_plot &amp;lt;- post_mtf_weib_samples %&amp;gt;%
  ggplot(aes(x = shape, y = scale)) +
  geom_point(
    colour = &amp;quot;#453781FF&amp;quot;,
    size = 2,
    alpha = 0.1
  ) +
  geom_hline(aes(yintercept = 100), size = .5, alpha = .3) +
  geom_vline(aes(xintercept = 3), size = .5, alpha = .3) +
  labs(
    title = &amp;quot;Credible Parameters for Shape and Scale&amp;quot;,
    subtitle = &amp;quot;Run-Out Data Treated as Right-Censored&amp;quot;,
    x = expression(eta [&amp;quot;shape&amp;quot;]),
    y = expression(beta [&amp;quot;scale&amp;quot;])
  )


mtf_marg_plot &amp;lt;- ggMarginal(mtf_plot,
  type = &amp;quot;density&amp;quot;,
  color = &amp;quot;white&amp;quot;,
  alpha = 0.7,
  fill = &amp;quot;#453781FF&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-40-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; It looks like we did catch the true parameters of the data generating process within the credible range of our posterior. However, it is certainly not centered. Once again we should question: is the software working properly? Is the sample size a problem? Are the priors appropriate? Was the censoring specified and treated appropriately?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;investigation-of-how-to-treat-censored-data-points&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Investigation of how to treat censored data points&lt;/h3&gt;
&lt;p&gt;Let’s start with the question about the censoring. One question that I’d like to know is: What would happen if we omitted the censored data completely or treated it like the device failed at the last observed time point? This hypothetical should be straightforward to simulate. Let’s fit a model to the same data set, but we’ll just treat the last time point as if the device failed there (i.e. we’ll have lots of failures at t=100).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This model treats the data as though the devices failed at the last observed timepoint
# mtf_weib_nocens_fit &amp;lt;- brm(time ~ 1,
# data = months_to_failure_tbl_4.3.3, family = weibull())&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# saveRDS(mtf_weib_nocens_fit, file = &amp;quot;mtf_weib_nocens_fit.rds&amp;quot;)
mtf_weib_nocens_fit &amp;lt;- readRDS(file = &amp;quot;mtf_weib_nocens_fit.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now another model where we just omit the censored data completely (i.e. remove any units that don’t fail from the data set completely and fit a model to the rest).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This model just omits the censored data completely
# mtf_weib_omit_fit &amp;lt;- brm(time ~ 1,
# data = months_to_failure_tbl_4.3.3 %&amp;gt;% filter(censored == 0), family = weibull())&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt; plot(mtf_weib_nocens_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-45-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt; plot(mtf_weib_omit_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-45-2.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Create tibble of posterior draws from partially censored, un-censored, and censor-omitted models with identifier column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cens_model_post_draws &amp;lt;- posterior_samples(mtf_weib_fit) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale) %&amp;gt;%
  mutate(model = &amp;quot;Weibull with Censoring&amp;quot;)

uncens_model_post_draws &amp;lt;- posterior_samples(mtf_weib_nocens_fit) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale) %&amp;gt;%
  mutate(model = &amp;quot;Weibull (Treat Last Timepoint as Failure)&amp;quot;)

omit_model_post_draws &amp;lt;- posterior_samples(mtf_weib_omit_fit) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale) %&amp;gt;%
  mutate(model = &amp;quot;Weibull Omitting Censored Data&amp;quot;)

combined_weib_tbl &amp;lt;- cens_model_post_draws %&amp;gt;%
  bind_rows(uncens_model_post_draws) %&amp;gt;%
  bind_rows(omit_model_post_draws) %&amp;gt;%
  mutate(model = as_factor(model))

combined_weib_tbl %&amp;gt;%
  head(5) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 3), digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;model&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.44&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;87.78&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Weibull with Censoring&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.07&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;91.80&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Weibull with Censoring&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.49&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Weibull with Censoring&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.28&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.43&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Weibull with Censoring&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;86.42&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Weibull with Censoring&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here we compare the effect of the different treatments of censored data on the parameter estimates. Intervals are 95% HDI.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_shp_1 &amp;lt;- combined_weib_tbl %&amp;gt;% ggplot(aes(x = shape)) +
  geom_density(aes(fill = model), size = 0, alpha = 0.4) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(x = expression(eta[&amp;quot;shape&amp;quot;])) +
  stat_pointintervalh(aes(y = 0),
    point_interval = mode_hdi, .width = .95, show.legend = FALSE
  ) +
  facet_wrap(~model) +
  theme_classic() +
  theme(
    legend.position = &amp;quot;none&amp;quot;,
    axis.line.y = element_blank(),
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    legend.title = element_blank()
  )


d_shp_2 &amp;lt;- combined_weib_tbl %&amp;gt;% ggplot(aes(x = shape)) +
  geom_density(aes(fill = model), size = 0, alpha = 0.4) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(
    x = expression(eta[&amp;quot;shape&amp;quot;]),
    title = &amp;quot;Parameter Estimates&amp;quot;,
    subtitle = &amp;quot;Effect of Including Censored Data in Model&amp;quot;
  ) +
  theme_classic() +
  theme(
    axis.line.y = element_blank(),
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    legend.title = element_blank()
  )

d_scale_1 &amp;lt;- combined_weib_tbl %&amp;gt;% ggplot(aes(x = scale, fill = model)) +
  geom_density(size = 0, alpha = 0.4) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(x = expression(beta[&amp;quot;scale&amp;quot;])) +
  stat_pointintervalh(aes(y = 0),
    point_interval = mode_hdi, .width = .95, show.legend = FALSE
  ) +
  facet_wrap(~model) +
  theme_classic() +
  theme(
    legend.position = &amp;quot;none&amp;quot;,
    axis.line.y = element_blank(),
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    legend.title = element_blank()
  )

d_scale_2 &amp;lt;- combined_weib_tbl %&amp;gt;% ggplot(aes(x = scale)) +
  geom_density(aes(fill = model), size = 0, alpha = 0.4) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(
    x = expression(beta[&amp;quot;scale&amp;quot;]),
    title = &amp;quot;Parameter Estimates&amp;quot;,
    subtitle = &amp;quot;Effect of Including Censored Data in Model&amp;quot;
  ) +
  theme_classic() +
  theme(
    axis.line.y = element_blank(),
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    legend.title = element_blank()
  )

d_shp_2 + d_shp_1 + plot_layout(
  ncol = 1,
  guides = &amp;quot;collect&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-47-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_scale_2 + d_scale_1 + plot_layout(
  ncol = 1,
  guides = &amp;quot;collect&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-47-2.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; When we omit the censored data or treat it as a failure, the shape parameter shifts up and the scale parameter shifts down. In both cases, it moves farther away from true. This should give is confidence that we are treating the censored points appropriately and have specified them correctly in the brm() syntax.&lt;/p&gt;
&lt;p&gt;Plotting the joint distributions for the three groups:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;combined_weib_plt &amp;lt;- combined_weib_tbl %&amp;gt;%
  ggplot(aes(x = shape, y = scale)) +
  geom_point(aes(color = model, fill = model), size = 2, alpha = 0.08) +
  geom_hline(aes(yintercept = 100), size = .5, alpha = .3) +
  geom_vline(aes(xintercept = 3), size = .5, alpha = .3) +
  scale_color_manual(values = c(&amp;quot;#453781FF&amp;quot;, &amp;quot;#EA4F88&amp;quot;, &amp;quot;#FDE725FF&amp;quot;)) +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) + # force legend icons to be alpha = 1 instead of .08
  labs(
    title = &amp;quot;Credible Parameters for Shape and Scale&amp;quot;,
    subtitle = &amp;quot;Effect of Treating Censored Data Points in Different Ways&amp;quot;,
    x = expression(eta [&amp;quot;shape&amp;quot;]),
    y = expression(beta [&amp;quot;scale&amp;quot;])
  ) +
  theme(
    legend.position = &amp;quot;bottom&amp;quot;,
    legend.title = element_blank()
  )

cens_marg_plot &amp;lt;- ggMarginal(combined_weib_plt,
  groupColour = TRUE,
  groupFill = TRUE,
  type = &amp;quot;density&amp;quot;,
  alpha = 0.7
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-49-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; Our censored data set (purple) is closest to true. But we still don’t know why the highest density region of our posterior isn’t centered on the true value.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluation-of-priors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluation of priors&lt;/h3&gt;
&lt;p&gt;We haven’t looked closely at our priors yet (shame on me) so let’s do that now. The default priors are viewed with prior_summary().&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get default priors
prior_summary(mtf_weib_fit) %&amp;gt;%
  select(prior, class) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;prior&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;class&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;student_t(3, 4, 10)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Intercept&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;gamma(0.01, 0.01)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;shape&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I was taught to visualize what the model thinks before seeing the data via prior predictive simulation. I made a good-faith effort to do that, but the results are funky for brms default priors. I an not an expert here, but I believe this is because very vague default Gamma priors aren’t good for prior predictive simulations but quickly adapt to the first few data points they see.&lt;a href=&#34;#fn8&#34; class=&#34;footnoteRef&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;. The prior must be placed on the intercept when must be then propagated to the scale which further muddies things. All in all there isn’t much to see. A lot of the weight is at zero but there are long tails for the defaults. I have all the code for this simulation for the defaults in the Appendix.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/def.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you take this at face value, the model thinks the reliability is always zero before seeing the model. Again, I think this is a special case for vague gamma priors but it doesn’t give us much confidence that we are setting things up correctly.&lt;/p&gt;
&lt;p&gt;After viewing the default predictions, I did my best to iterate on the priors to generate something more realistic. My process was manual and my general plan was to force some crdibility over higher values of shape using a uniform distribution. The intercept values were more diffcult to iterate. Here are the revised priors I tried:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(prior = c(&amp;quot;student_t(3, 5, 5)&amp;quot;, &amp;quot;uniform(0, 10)&amp;quot;),
       class = c(&amp;quot;Intercept&amp;quot;, &amp;quot;shape&amp;quot;)) %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;prior&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;class&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;student_t(3, 5, 5)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Intercept&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;uniform(0, 10)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;shape&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As can be seen, the revised priors were able to spread some credibility up across the middle reliability values but ended up a lot of mass on either end, which wasn’t to goal.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/imp_priors.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Regardless, I refit the model with the (potentially) improved more realistic (but still not great) priors and found minimal difference in the model fit as shown below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/prior_compare.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note: all models throughout the remainder of this post use the “better” priors (even though there is minimal difference in the model fits relative to brms default).&lt;/p&gt;
&lt;p&gt;The above analysis, while not comprehensive, was enough to convince me that the default brms priors are not the problem with initial model fit (recall above where the mode of the posterior was not centered at the true data generating process and we wondered why). I do need to get better at doing these prior predictive simulations but it’s a deep, dark rabbit hole to go down on an already long post. Given the low model sensitivity across the range of priors I tried, I’m comfortable moving on to investigate sample size.&lt;/p&gt;
&lt;p&gt;The original model was fit from n=30. We need a simulation that lets us adjust n.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluate-sensitivity-of-posterior-to-sample-size&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluate sensitivity of posterior to sample size&lt;/h3&gt;
&lt;p&gt;Here we write a function to generate censored data of different shape, scale, and sample size. The syntax of the censoring column is brms (1 = censored).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rweibull_cens_gen_fcn &amp;lt;- function(n, shape, scale) {
  raw_times &amp;lt;- rweibull(n, shape = shape, scale = scale)
  tibble(failure_time_raw = raw_times) %&amp;gt;%
    mutate(time = case_when(
      failure_time_raw &amp;lt; 100 ~ failure_time_raw,
      TRUE ~ 100
    )) %&amp;gt;%
    mutate(censor = case_when(
      time == 100 ~ 1,
      TRUE ~ 0
    )) %&amp;gt;%
    select(-failure_time_raw)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the function above is used to create simulated data sets for different sample sizes (all have shape 3, scale = 100)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(3980)

fit_weib_45_tbl &amp;lt;- rweibull_cens_gen_fcn(45, 3, 100)
fit_weib_60_tbl &amp;lt;- rweibull_cens_gen_fcn(60, 3, 100)
fit_weib_100_tbl &amp;lt;- rweibull_cens_gen_fcn(100, 3, 100)
fit_weib_200_tbl &amp;lt;- rweibull_cens_gen_fcn(200, 3, 100)
fit_weib_300_tbl &amp;lt;- rweibull_cens_gen_fcn(300, 3, 100)
fit_weib_400_tbl &amp;lt;- rweibull_cens_gen_fcn(400, 3, 100)
fit_weib_500_tbl &amp;lt;- rweibull_cens_gen_fcn(500, 3, 100)
fit_weib_600_tbl &amp;lt;- rweibull_cens_gen_fcn(600, 3, 100)
fit_weib_700_tbl &amp;lt;- rweibull_cens_gen_fcn(700, 3, 100)
fit_weib_800_tbl &amp;lt;- rweibull_cens_gen_fcn(800, 3, 100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fit and save a model to each of the above data sets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mtf_700_weib_fit &amp;lt;- brm(time | cens(censor) ~ 1,
# data = fit_weib_700_tbl, family = weibull(),
#    prior = c(
#     prior(student_t(3, 5, 5), class = Intercept),
#     prior(uniform(0, 10), class = shape)
#    ),
#    iter = 41000, warmup = 40000, chains = 4, cores = 4,
#    seed = 4
#  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Draw from the posterior of each model and combine into one tibble along with the original fit from n=30.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtf_30_weib_fit_post_draws &amp;lt;- post_mwnp_samples # this is original data fit to milely informed priors, see Appendix
mtf_60_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_60_weib_fit)
mtf_100_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_100_weib_fit)
mtf_200_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_200_weib_fit)
mtf_300_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_300_weib_fit)
mtf_400_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_400_weib_fit)
mtf_500_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_500_weib_fit)
mtf_600_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_600_weib_fit)
mtf_700_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_700_weib_fit)
mtf_800_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_800_weib_fit)


combined_n_tbl &amp;lt;- bind_rows(
  &amp;quot;60&amp;quot;  = mtf_60_weib_fit_post_draws,
  &amp;quot;100&amp;quot; = mtf_100_weib_fit_post_draws,
  &amp;quot;200&amp;quot; = mtf_200_weib_fit_post_draws,
  &amp;quot;300&amp;quot; = mtf_300_weib_fit_post_draws,
  &amp;quot;400&amp;quot; = mtf_400_weib_fit_post_draws,
  &amp;quot;500&amp;quot; = mtf_500_weib_fit_post_draws,
  &amp;quot;600&amp;quot; = mtf_600_weib_fit_post_draws,
  &amp;quot;700&amp;quot; = mtf_700_weib_fit_post_draws,
  &amp;quot;800&amp;quot; = mtf_800_weib_fit_post_draws,
  .id = &amp;quot;model&amp;quot;
) %&amp;gt;%
  mutate(model = as_factor(model)) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale, model)

# have to add in the n=30 set seperately since it is already converted from Intercept to shape
combined_n_tbl &amp;lt;- mtf_30_weib_fit_post_draws %&amp;gt;%
  mutate(model = &amp;quot;30&amp;quot;) %&amp;gt;%
  bind_rows(combined_n_tbl) %&amp;gt;%
  mutate(model = as_factor(model))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally we can visualize the effect of sample size on precision of posterior estimates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;combined_n_plt &amp;lt;- combined_n_tbl %&amp;gt;%
  ggplot(aes(x = shape, y = scale)) +
  geom_point(aes(color = model, fill = model), size = 2, alpha = 0.01) +
  scale_color_viridis_d() +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) + # force legend icons to be alpha = 1 instead of .05
  geom_hline(yintercept = 100, colour = &amp;quot;black&amp;quot;, alpha = 0.3, size = .5) +
  geom_vline(xintercept = 3, colour = &amp;quot;black&amp;quot;, alpha = 0.3, size = .5) +
  labs(
    title = &amp;quot;Effect of Sample Size on Parameter Estimation&amp;quot;,
    subtitle = &amp;quot;Model: Weibull with Censoring; True ~ Weibull(shape = 3, scale = 100)&amp;quot;,
    x = expression(eta [&amp;quot;shape&amp;quot;]),
    y = expression(beta [&amp;quot;scale&amp;quot;])
  ) +
  theme(
    legend.position = &amp;quot;bottom&amp;quot;,
    legend.title = element_blank()
  )

cens_marg_2_plot &amp;lt;- ggMarginal(combined_n_plt,
  groupColour = TRUE,
  groupFill = TRUE,
  type = &amp;quot;density&amp;quot;,
  alpha = 0.7
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-63-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; This figure tells a lot. We simply needed more data points to zero in on the true data generating process. At n=30, there’s just a lot of uncertainty due to the randomness of sampling.&lt;/p&gt;
&lt;p&gt;This plot looks really cool, but the marginal distributions are bit cluttered. This is a perfect use case for ggridges which will let us see the same type of figure but without overlap.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cn1 &amp;lt;- combined_n_tbl %&amp;gt;%
  gather(key = &amp;quot;key&amp;quot;, value = &amp;quot;value&amp;quot;, -model) %&amp;gt;%
  mutate(true_p = case_when(
    key == &amp;quot;scale&amp;quot; ~ 100,
    TRUE ~ 3
  )) %&amp;gt;%
  ggplot(aes(x = value, y = model, group = model, fill = model)) +
  geom_density_ridges(size = 1 / 3, rel_min_height = .005, alpha = .65) +
  geom_vline(aes(xintercept = true_p), color = &amp;quot;#711a6eff&amp;quot;) +
  stat_pointintervalh(
    point_interval = mode_hdi,
    .width = .95,
    show.legend = FALSE
  ) +
  coord_flip() +
  scale_fill_viridis_d() +
  facet_wrap(~key, scales = &amp;quot;free_y&amp;quot;) +
  labs(
    x = &amp;quot;Parameter Value&amp;quot;,
    y = &amp;quot;Number of Data Points Used to Fit Model&amp;quot;,
    title = &amp;quot;Model Fitting Variability due to Random Sampling [New Draw Each Fit]&amp;quot;,
    subtitle = &amp;quot;True Distribution ~ Weibull(3, 100)&amp;quot;
  ) +
  theme(legend.position = &amp;quot;&amp;quot;)

cn1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-64-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Set of 800 to demonstrate Bayesian updating.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(125)
fit_weib_800_bu_tbl &amp;lt;- rweibull_cens_gen_fcn(800, 3, 100)

fit_weib_30_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:30, ]
fit_weib_60_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:60, ]
fit_weib_100_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:100, ]
fit_weib_200_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:200, ]
fit_weib_300_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:300, ]
fit_weib_400_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:400, ]
fit_weib_500_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:500, ]
fit_weib_600_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:600, ]
fit_weib_700_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:700, ]
fit_weib_800_bu_tbl &amp;lt;- fit_weib_800_bu_tbl[1:800, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fit a model the first set of n=30&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mtf_30_bu_weib_fit &amp;lt;- brm(time | cens(censor) ~ 1,
# data = fit_weib_30_bu_tbl, family = weibull(),
#    prior = c(
#     prior(student_t(3, 5, 5), class = Intercept),
#     prior(uniform(0, 10), class = shape)
#    ),
#    iter = 41000, warmup = 40000, chains = 4, cores = 4,
#    seed = 4
#  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We use the update() function in brms to update and save each model with additional data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mtf_60_bu_weib_fit &amp;lt;- update(mtf_30_bu_weib_fit, newdata = fit_weib_60_bu_tbl)
# mtf_100_bu_weib_fit &amp;lt;- update(mtf_60_bu_weib_fit, newdata = fit_weib_100_bu_tbl)
# mtf_200_bu_weib_fit &amp;lt;- update(mtf_100_bu_weib_fit, newdata = fit_weib_200_bu_tbl)
# mtf_300_bu_weib_fit &amp;lt;- update(mtf_200_bu_weib_fit, newdata = fit_weib_300_bu_tbl)
# mtf_400_bu_weib_fit &amp;lt;- update(mtf_300_bu_weib_fit, newdata = fit_weib_400_bu_tbl)
# mtf_500_bu_weib_fit &amp;lt;- update(mtf_400_bu_weib_fit, newdata = fit_weib_500_bu_tbl)
# mtf_600_bu_weib_fit &amp;lt;- update(mtf_500_bu_weib_fit, newdata = fit_weib_600_bu_tbl)
# mtf_700_bu_weib_fit &amp;lt;- update(mtf_600_bu_weib_fit, newdata = fit_weib_700_bu_tbl)
# mtf_800_bu_weib_fit &amp;lt;- update(mtf_700_bu_weib_fit, newdata = fit_weib_800_bu_tbl)

# save each one
# saveRDS(mtf_800_bu_weib_fit, file = &amp;quot;mtf_800_bu_weib_fit.rds&amp;quot;)

mtf_800_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_800_bu_weib_fit.rds&amp;quot;)
mtf_700_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_700_bu_weib_fit.rds&amp;quot;)
mtf_600_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_600_bu_weib_fit.rds&amp;quot;)
mtf_500_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_500_bu_weib_fit.rds&amp;quot;)
mtf_400_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_400_bu_weib_fit.rds&amp;quot;)
mtf_300_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_300_bu_weib_fit.rds&amp;quot;)
mtf_200_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_200_bu_weib_fit.rds&amp;quot;)
mtf_100_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_100_bu_weib_fit.rds&amp;quot;)
mtf_60_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_60_bu_weib_fit.rds&amp;quot;)
mtf_30_bu_weib_fit &amp;lt;- readRDS(file = &amp;quot;mtf_30_bu_weib_fit.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Extract posterior draws for each one.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtf_30_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_30_bu_weib_fit)
mtf_60_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_60_bu_weib_fit)
mtf_100_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_100_bu_weib_fit)
mtf_200_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_200_bu_weib_fit)
mtf_300_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_300_bu_weib_fit)
mtf_400_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_400_bu_weib_fit)
mtf_500_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_500_bu_weib_fit)
mtf_600_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_600_bu_weib_fit)
mtf_700_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_700_bu_weib_fit)
mtf_800_bu_weib_fit_post_draws &amp;lt;- posterior_samples(mtf_800_bu_weib_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Combine into single tibble and convert intercept to scale. Some data wrangling is in anticipation for ggplot().&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;combined_nbu_tbl &amp;lt;- bind_rows(
  &amp;quot;30&amp;quot;  = mtf_30_bu_weib_fit_post_draws, # note: this one is the original dataset
  &amp;quot;60&amp;quot;  = mtf_60_bu_weib_fit_post_draws,
  &amp;quot;100&amp;quot; = mtf_100_bu_weib_fit_post_draws,
  &amp;quot;200&amp;quot; = mtf_200_bu_weib_fit_post_draws,
  &amp;quot;300&amp;quot; = mtf_300_bu_weib_fit_post_draws,
  &amp;quot;400&amp;quot; = mtf_400_bu_weib_fit_post_draws,
  &amp;quot;500&amp;quot; = mtf_500_bu_weib_fit_post_draws,
  &amp;quot;600&amp;quot; = mtf_600_bu_weib_fit_post_draws,
  &amp;quot;700&amp;quot; = mtf_700_bu_weib_fit_post_draws,
  &amp;quot;800&amp;quot; = mtf_800_bu_weib_fit_post_draws,
  .id = &amp;quot;model&amp;quot;
) %&amp;gt;%
  mutate(model = as_factor(model)) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale, model)

cn2 &amp;lt;- combined_nbu_tbl %&amp;gt;%
  gather(key = &amp;quot;key&amp;quot;, value = &amp;quot;value&amp;quot;, -model) %&amp;gt;%
  mutate(true_p = case_when(
    key == &amp;quot;scale&amp;quot; ~ 100,
    TRUE ~ 3
  )) %&amp;gt;%
  ggplot(aes(x = value, y = model, group = model, fill = model)) +
  geom_density_ridges(size = 1 / 3, rel_min_height = .005, alpha = .65) +
  geom_vline(aes(xintercept = true_p), color = &amp;quot;#711a6eff&amp;quot;) +
  stat_pointintervalh(
    point_interval = mode_hdi,
    .width = .95,
    show.legend = FALSE
  ) +
  coord_flip() +
  scale_fill_viridis_d() +
  facet_wrap(~key, scales = &amp;quot;free_y&amp;quot;) +
  labs(
    x = &amp;quot;Parameter Value&amp;quot;,
    y = &amp;quot;Number of Data Points Used to Fit Model&amp;quot;,
    title = &amp;quot;Model Fitting Variability due to Random Sampling [Updated Model Each Fit]&amp;quot;,
    subtitle = &amp;quot;True Distribution ~ Weibull(3, 100)&amp;quot;
  ) +
  theme(legend.position = &amp;quot;&amp;quot;)

cn1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-70-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#cn2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-71-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The precision increase here is more smooth since supplemental data is added to the original set instead of just drawing completely randomly for each sample size. This is Bayesian updating.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluate-sensitivity-of-reliability-estimate-to-sample-size.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluate Sensitivity of Reliability Estimate to Sample Size.&lt;/h3&gt;
&lt;p&gt;To wrap things up, we should should translate the above figures into a reliability metric because that is the prediction we care about at the end of the day. I chose an arbitrary time point of t=40 to evaluate the reliability.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;combined_nbu_rr_tbl &amp;lt;- combined_nbu_tbl %&amp;gt;% mutate(reliability_at_t40 = exp(-(40 / scale)**(shape)))

rq05_tbl &amp;lt;- combined_nbu_rr_tbl %&amp;gt;% group_by(model) %&amp;gt;%
  summarize(rel_q05 = quantile(reliability_at_t40, .05)) %&amp;gt;%
  mutate(model = as.numeric(model)) %&amp;gt;%
  ungroup()

reliability_ridge_plt &amp;lt;- combined_nbu_rr_tbl %&amp;gt;%
  gather(key = &amp;quot;key&amp;quot;, value = &amp;quot;value&amp;quot;, -c(model, reliability_at_t40)) %&amp;gt;%
  ggplot(aes(x = reliability_at_t40, y = model, group = model, fill = model)) +
  geom_density_ridges(size = 1 / 3, rel_min_height = .005, alpha = .8) +
  stat_pointintervalh(
    point_interval = mode_hdi,
    .width = .95,
    show.legend = FALSE
  ) +
  coord_flip() +
  scale_fill_viridis_d() +
  labs(
    x = &amp;quot;Reliability at t=40&amp;quot;,
    y = &amp;quot;Number of Data Points Used to Fit Model&amp;quot;,
    title = &amp;quot;Uncertainty in Reliability Posterior&amp;quot;,
    subtitle = &amp;quot;Reliability Assessed at t = 40&amp;quot;
  ) +
  theme(legend.position = &amp;quot;&amp;quot;) +
  xlim(c(.85, 1))



reliability_ridge_plt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-72-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;wrap-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Wrap-up&lt;/h2&gt;
&lt;p&gt;Here is a summary of where we ended up going in the post:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Fit some models using fitdistr plus using data that was not censored. Calculated reliability at time of interest.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Fit the same models using a Bayesian approach with grid approximation. Visualized what happens if we incorrectly omit the censored data or treat it as if it failed at the last observed time point.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Explored fitting censored data using the survival package. Evaluated sensitivity to sample size.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Used brms to fit Bayesian models with censored data. Assessed sensitivity of priors and tried to improve our priors over the default. Evaluated effect of sample size and explored the different between updating an existing data set vs. drawing new samples.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you made it this far - I appreciate your patience with this long and rambling post. Thank you for reading!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix---prior-predictive-simulation---beware-its-ugly-in-here&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;APPENDIX - Prior Predictive Simulation - BEWARE it’s ugly in here&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# evaluate default priors
default_shape_prior &amp;lt;- rgamma(10000, .01, .01)
default_shape_prior_tbl &amp;lt;- default_shape_prior %&amp;gt;% as_tibble()
default_shape_prior_tbl %&amp;gt;% ggplot(aes(x = default_shape_prior)) +
  geom_histogram(aes(y = ..density..), binwidth = 3, boundary = 0, fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6) + geom_density(color = &amp;quot;#cf4c74ff&amp;quot;) +
  labs(title = &amp;quot;Default Prior for Shape Parameter&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-73-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#   ylim(c(0, 1e-3))

default_intercept_prior &amp;lt;- rstudent_t(10000, 3, 4, 10)

default_priors_tbl &amp;lt;- default_intercept_prior %&amp;gt;%
  as_tibble() %&amp;gt;%
  bind_cols(default_shape_prior_tbl) %&amp;gt;%
  rename(intercept = value, shape = value1) %&amp;gt;%
  mutate(scale_prior = exp(intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  filter(scale_prior &amp;lt; 1000) %&amp;gt;%
  select(-intercept)

default_priors_tbl %&amp;gt;% ggplot(aes(x = scale_prior)) +
  geom_histogram(aes(y = ..density..), binwidth = 5, boundary = 100, fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .8) +
  geom_density(color = &amp;quot;#cf4c74ff&amp;quot;) +
  labs(title = &amp;quot;Default Prior for Scale Parameter&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-73-2.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#  ylim(c(0, .001))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Prior Predictive Simulation - Default Priors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d1 &amp;lt;- default_priors_tbl[1:350, ] %&amp;gt;%
  mutate(plotted_y_data = map2(
    shape, scale_prior,
    ~ tibble(
      x = seq(0, 200, length.out = 400),
      y = dweibull(x, .x, .y)
    )
  )) %&amp;gt;%
  unnest(plotted_y_data) %&amp;gt;%
  ggplot(aes(x, y)) +
  geom_line(aes(group = shape), alpha = .2) +
  labs(
    x = &amp;quot;Time to Event&amp;quot;,
    y = &amp;quot;Density&amp;quot;
  )

d2 &amp;lt;- d1 +
  xlim(c(0, 25)) +
  ylim(c(0, .1))

d1 + d2 + plot_layout(
  nrow = 1,
  guides = &amp;quot;collect&amp;quot;
) +
  plot_annotation(title = &amp;quot;Implied Time-to-Failure Weibull Distributions (from default priors)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-74-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; Here are the reliabilities at t=15 implied by the default priors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r15_pp_default_tbl &amp;lt;- default_priors_tbl %&amp;gt;% mutate(reliability_at_t15 = exp(-(15 / scale_prior)**(shape)))

r1 &amp;lt;- r15_pp_default_tbl %&amp;gt;% ggplot(aes(x = reliability_at_t15)) +
  geom_histogram(aes(y = ..density..), binwidth = .01, boundary = 1, fill = &amp;quot;#de6065ff&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6) +
  labs(title = &amp;quot;Reliability at t=15 implied by default priors&amp;quot;)

def_plt &amp;lt;- (d1 + d2) / r1 + plot_layout(guides = &amp;quot;collect&amp;quot;) +
  plot_annotation(title = &amp;quot;Implied Time-to-Failure Weibull Distributions (from default priors)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not too useful. In the following section I try to tweak the priors such that the simulations indicate some spread of reliability from 0 to 1 before seeing the data. Again, it’s tough because we have to work through the Intercept and the annoying gamma function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Evaluate Mildly Informed Priors
shape_prior &amp;lt;- runif(100000, 0, 10)
shape_prior_tbl &amp;lt;- shape_prior %&amp;gt;% as_tibble()
shaaaape &amp;lt;- shape_prior_tbl %&amp;gt;% ggplot(aes(x = shape_prior)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, boundary = 10, fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6)

intercept_prior &amp;lt;- rstudent_t(100000, 3, 5, 5)

priors_tbl &amp;lt;- intercept_prior %&amp;gt;%
  as_tibble() %&amp;gt;%
  bind_cols(shape_prior_tbl) %&amp;gt;%
  rename(intercept = value, shape = value1) %&amp;gt;%
  mutate(scale_prior = exp(intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  filter(scale_prior &amp;lt; 1000) %&amp;gt;%
  select(-intercept)

scaaaale &amp;lt;- priors_tbl %&amp;gt;% ggplot(aes(x = scale_prior)) +
  geom_histogram(aes(y = ..density..), binwidth = 10, boundary = 100, fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .8) +
  ylim(c(0, .005))

shaaaape + scaaaale + plot_annotation(title = &amp;quot;Prior Predicitve Simulations for Shape and Scale&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-76-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; Implied time-to-event curves:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- priors_tbl[1:500, ] %&amp;gt;%
  mutate(plotted_y_data = map2(
    shape, scale_prior,
    ~ tibble(
      x = seq(0, 200, length.out = 400),
      y = dweibull(x, .x, .y)
    )
  )) %&amp;gt;%
  unnest(plotted_y_data) %&amp;gt;%
  ggplot(aes(x, y)) +
  geom_line(aes(group = shape), alpha = .2) +
  xlim(c(0, 50)) +
  ylim(c(0, .5)) +
  labs(
    x = &amp;quot;Time to Event&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    title = &amp;quot;Implied Time-to-Event Curves from Iterated Priors&amp;quot;
  )

p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-77-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; And the implied prior predictive reliability at t=15:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r15_pp_mi_tbl &amp;lt;- priors_tbl %&amp;gt;% mutate(reliability_at_t15 = exp(-(15 / scale_prior)**(shape)))

pz &amp;lt;- r15_pp_mi_tbl %&amp;gt;% ggplot(aes(x = reliability_at_t15)) +
  geom_histogram(aes(y = ..density..), binwidth = .1, boundary = 1, fill = &amp;quot;#7b0288ff&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = .6) +
  labs(
    title = &amp;quot;Prior Predictive Estimate at t=15&amp;quot;,
    subtitle = &amp;quot;Iterated Priors&amp;quot;
  )

p1 + pz&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-78-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; This still isn’t great - now I’ve stacked most of the weight at 0 and 1 always fail or never fail. This is hard and I do know I need to get better at it. But since I’m already down a rabbit hole let’s just check to see how the different priors impact the estimates.&lt;/p&gt;
&lt;p&gt;Fit the model with iterated priors: student_t(3, 5, 5) for Intercept and uniform(0, 10) for shape.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit model with better priors (original n=30 data point)
# mtf_weib_new_priors_fit &amp;lt;-
#  brm(
#    data = months_to_failure_tbl_4.3.3, family = weibull(),
#    time | cens(censored) ~ 1,
#    prior = c(
#      prior(student_t(3, 5, 5), class = Intercept),
#     prior(uniform(0, 10), class = shape)
#    ),
#    iter = 41000, warmup = 40000, chains = 4, cores = 4,
#   seed = 4
#  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Evaluate chains and convert to shape and scale&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(mtf_weib_new_priors_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-81-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post_mwnp_samples &amp;lt;- posterior_samples(mtf_weib_new_priors_fit) %&amp;gt;%
  mutate(scale = exp(b_Intercept) / (gamma(1 + 1 / shape))) %&amp;gt;%
  select(shape, scale)

post_mwnp_samples %&amp;gt;%
  head(10) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2), digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;shape&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;scale&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.66&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;98.52&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.66&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;98.52&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;98.48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;95.86&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.02&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;92.85&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.05&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;90.54&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;97.18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.50&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;97.05&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2.48&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;92.92&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;87.81&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Evaluate the effect of the different priors (default vs. iterated) on the model fit for original n=30 censored data points.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseline_30_default_prior_tbl &amp;lt;- post_mtf_weib_samples %&amp;gt;% mutate(priors = &amp;quot;shape: gamma(.01, .01) \nIntercept: student_t(3, 4, 10)&amp;quot;)

baseline_30_mi_prior_tbl &amp;lt;- post_mwnp_samples %&amp;gt;% mutate(priors = &amp;quot;shape: uniform(0, 10) \nIntercept: student_t(3, 5, 5)&amp;quot;)

baseline_30_prior_compare_tbl &amp;lt;- bind_rows(
  baseline_30_default_prior_tbl,
  baseline_30_mi_prior_tbl
)

b_30_prior_plt &amp;lt;- baseline_30_prior_compare_tbl %&amp;gt;% ggplot(aes(x = shape, y = scale)) +
  geom_point(aes(color = priors), alpha = .1) +
  geom_hline(aes(yintercept = 100), size = .5, alpha = .3) +
  geom_vline(aes(xintercept = 3), size = .5, alpha = .3) +
  scale_color_viridis_d() +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) + # force legend icons to be alpha = 1 instead of .05
  labs(
    title = &amp;quot;Credible Parameters for Shape and Scale; Effect of Priors&amp;quot;,
    subtitle = &amp;quot;Model: Weibull with Censoring; True ~ Weibull(shape = 3, scale = 100)&amp;quot;,
    x = expression(eta [&amp;quot;shape&amp;quot;]),
    y = expression(beta [&amp;quot;scale&amp;quot;])
  ) +
  theme(legend.position = &amp;quot;bottom&amp;quot;)


b_30_prior_marg_plot &amp;lt;- ggMarginal(b_30_prior_plt,
  groupColour = TRUE,
  groupFill = TRUE,
  type = &amp;quot;density&amp;quot;,
  alpha = 0.5
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-31-bayesian-modeling-of-censored-and-uncensored-fatigue-data-in-r_files/figure-html/unnamed-chunk-84-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;At the end of the day, both the default and the iterated priors result in similar model fits and parameter estimates after seeing just n=30 data points. This is sort of cheating but I’m still new to this so I’m cutting myself some slack.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Stent fatigue testing &lt;a href=&#34;https://www.youtube.com/watch?v=YhUluh5V8uM&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=YhUluh5V8uM&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Data taken from &lt;strong&gt;Practical Applications of Bayesian Reliability&lt;/strong&gt; by Abeyratne and Liu, 2019&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Note: the reliability function is sometimes called the survival function in reference to patient outcomes and survival analysis&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;grid_function borrowed from Kurz, &lt;a href=&#34;https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/&#34; class=&#34;uri&#34;&gt;https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/&lt;/a&gt;&lt;a href=&#34;#fnref4&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Survival package documentation, &lt;a href=&#34;https://stat.ethz.ch/R-manual/R-devel/library/survival/html/survreg.html&#34; class=&#34;uri&#34;&gt;https://stat.ethz.ch/R-manual/R-devel/library/survival/html/survreg.html&lt;/a&gt;&lt;a href=&#34;#fnref5&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;We would want to de-risk this appoach by makng sure we have a bit of historical data on file indicating our device fails at times that follow a Weibull(3, 100) or similar&lt;a href=&#34;#fnref6&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;See the “Survival Model” section of this document: &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_families.html#survival-models&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/brms/vignettes/brms_families.html#survival-models&lt;/a&gt;&lt;a href=&#34;#fnref7&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;Thread about vague gamma priors &lt;a href=&#34;https://math.stackexchange.com/questions/449234/vague-gamma-prior&#34; class=&#34;uri&#34;&gt;https://math.stackexchange.com/questions/449234/vague-gamma-prior&lt;/a&gt;&lt;a href=&#34;#fnref8&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Confounders and Colliders - Modeling Spurious Correlations in R</title>
      <link>/post/confounders-and-colliders-modeling-spurious-correlations-in-r/</link>
      <pubDate>Tue, 29 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/confounders-and-colliders-modeling-spurious-correlations-in-r/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;/./img/dag.png&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Like many engineers, my first models were based on Designed Experiments in the tradition of Cox and Montgomery. I hadn’t seen anything like a causal diagram until I picked the &lt;strong&gt;The Book of Why&lt;/strong&gt; which explores all sorts of experimental relationships and structures I never imagined.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Colliders, confounders, causal diagrams, M-bias - these concepts are all relatively new to me and I want to understand them better. In this post I will attempt to create some simple structural causal models (SCMs) for myself using the Dagitty and GGDag packages and then show the potential effects of confounders and colliders on a simulated experiment adapted from here.&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It turns out that it is not as simple as identifying lurking variables and holding them constant while we conduct the experiment of interest (as I was always taught).&lt;/p&gt;
&lt;p&gt;First, load the libraries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load libraries
library(tidyverse)
library(kableExtra)
library(tidymodels)
library(viridisLite)
library(GGally)
library(dagitty)
library(ggdag)
library(visreg)
library(styler)
library(cowplot)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A structural causal model (SCM) is a type of directed acyclic graph (DAG) that maps causal assumptions onto a simple model of experimental variables. In the figure below, each node(blue dot) represents a variable. The edges(yellow lines) between nodes represent assumed causal effects.&lt;/p&gt;
&lt;p&gt;Dagitty uses the dafigy() function to create the relationships in the DAG. These are stored in a DAG object which is provided to ggplot and can then be customized and adjusted. Most of the code below the DAG object is just formatting the figure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create DAG object
g &amp;lt;- dagify(
  A ~ J,
  X ~ J,
  X ~ A
)

# tidy the dag object and supply to ggplot
set.seed(100)
g %&amp;gt;%
  tidy_dagitty() %&amp;gt;%
  mutate(x = c(0, 1, 1, 2)) %&amp;gt;%
  mutate(y = c(0, 2, 2, 0)) %&amp;gt;%
  mutate(xend = c(2, 0, 2, NA)) %&amp;gt;%
  mutate(yend = c(0, 0, 0, NA)) %&amp;gt;%
  dag_label(labels = c(
    &amp;quot;A&amp;quot; = &amp;quot;Independent\n Variable&amp;quot;,
    &amp;quot;X&amp;quot; = &amp;quot;Dependent\n Variable&amp;quot;,
    &amp;quot;J&amp;quot; = &amp;quot;The\n Confounder&amp;quot;
  )) %&amp;gt;%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges(
    edge_colour = &amp;quot;#b8de29ff&amp;quot;,
    edge_width = .8
  ) +
  geom_dag_node(
    color = &amp;quot;#2c3e50&amp;quot;,
    alpha = 0.8
  ) +
  geom_dag_text(color = &amp;quot;white&amp;quot;) +
  geom_dag_label_repel(aes(label = label),
    col = &amp;quot;white&amp;quot;,
    label.size = .4,
    fill = &amp;quot;#20a486ff&amp;quot;,
    alpha = 0.8,
    show.legend = FALSE,
    nudge_x = .7,
    nudge_y = .3
  ) +
  labs(
    title = &amp;quot; Directed Acyclic Graph&amp;quot;,
    subtitle = &amp;quot; Two Variables of Interest with a Confounder&amp;quot;
  ) +
  xlim(c(-1.5, 3.5)) +
  ylim(c(-.33, 2.2)) +
  geom_rect(
    xmin = -.5,
    xmax = 3.25,
    ymin = -.25,
    ymax = .65,
    alpha = .04,
    fill = &amp;quot;white&amp;quot;
  ) +
  theme_void() +
  theme(
    plot.background = element_rect(fill = &amp;quot;#222222&amp;quot;),
    plot.title = element_text(color = &amp;quot;white&amp;quot;),
    plot.subtitle = element_text(color = &amp;quot;white&amp;quot;)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-29-confounders-and-colliders-modeling-spurious-correlations-in-r_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; The relationship of interest is captured in the lower rectangle: we want to change the value of independent variable &lt;strong&gt;A&lt;/strong&gt; and record the effect on dependent variable &lt;strong&gt;X&lt;/strong&gt; (in epidemiology these might be called “treatment” and “outcome”). There also happens to be a confounding variable &lt;strong&gt;J&lt;/strong&gt; that has a causal effect on both &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;X&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We can set up a simulated experiment that follows the structure of the SCM above:&lt;/p&gt;
&lt;p&gt;Each variable will have n=1000 values. &lt;strong&gt;J&lt;/strong&gt; is generated by drawing randomly from a standard normal distribution. We want &lt;strong&gt;J&lt;/strong&gt; to be a cause of &lt;strong&gt;A&lt;/strong&gt; so we use &lt;strong&gt;J&lt;/strong&gt; in the creation of &lt;strong&gt;A&lt;/strong&gt; along with a random error term to represent noise. The model above shows a causal link from &lt;strong&gt;A&lt;/strong&gt; to &lt;strong&gt;X&lt;/strong&gt; but we don’t actually know if this exists - that’s the point of the experiment. It may or may not be there (from the point of view of the experimenter/engineer). For the purposes of demonstration we will structure the simulation such that there is &lt;strong&gt;no&lt;/strong&gt; causal relationship between &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;X&lt;/strong&gt; (&lt;strong&gt;A&lt;/strong&gt; will not be used in the creation of the variable &lt;strong&gt;J&lt;/strong&gt;). Again we need &lt;strong&gt;J&lt;/strong&gt; as a cause of &lt;strong&gt;X&lt;/strong&gt; so we use &lt;strong&gt;J&lt;/strong&gt; in the creation of the &lt;strong&gt;dependent_var_X&lt;/strong&gt; object along with a random noise component.&lt;/p&gt;
&lt;p&gt;The simulation is now set up to model an experiment where the experimenter/engineer wants to understand the effect of &lt;strong&gt;A&lt;/strong&gt; on &lt;strong&gt;X&lt;/strong&gt; but the true effect is zero. Meanwhile, there is a confounding variable &lt;strong&gt;J&lt;/strong&gt; that is a parent to both &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;X&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set seed for repeatability
set.seed(805)

# n = 1000 points for the simulation
n &amp;lt;- 1000

# create variables
# J is random draws from standard normal (mean = 0, stdev = 1)
confounding_var_J &amp;lt;- rnorm(n)

# J is used in creation of A since it is a cause of A (confounder)
independent_var_A &amp;lt;- 1.1 * confounding_var_J + rnorm(n)

# J is used in creation of X since it is a cause of X (confounder)
dependent_var_X &amp;lt;- 1.9 * confounding_var_J + rnorm(n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In reality, the experimenter may or may not be aware of the parent confounder &lt;strong&gt;J&lt;/strong&gt;. We will create two different regression models below. In the first, denoted &lt;strong&gt;crude_model&lt;/strong&gt;, we will assume the experimenter was unaware of the confounder. The model is then created with &lt;strong&gt;A&lt;/strong&gt; as the only predictor variable of &lt;strong&gt;X&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the second, denoted &lt;strong&gt;confounder_model&lt;/strong&gt;, we will assume the experimenter was aware of the confounder and chose to include it in their model. This version is created with &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;J&lt;/strong&gt; as predictors of &lt;strong&gt;X&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create crude regression model with A predicting X.  J is omitted
crude_model &amp;lt;- lm(dependent_var_X ~ independent_var_A)

# create confounder model with A and J predicting X
confounder_model &amp;lt;- lm(dependent_var_X ~ independent_var_A + confounding_var_J)

# tidy the crude model and examine it
crude_model_tbl &amp;lt;- summary(crude_model) %&amp;gt;% tidy()
crude_model_kbl &amp;lt;- summary(crude_model) %&amp;gt;%
  tidy() %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 5), digits = 3)
crude_model_kbl&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.007
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.051
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.135
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.893
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_A
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.967
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.034
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
28.415
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Tidy the confounder model and examine it
confounder_model_tbl &amp;lt;- summary(confounder_model) %&amp;gt;% tidy()
confounder_model_kbl &amp;lt;- summary(confounder_model) %&amp;gt;%
  tidy() %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 5), digits = 3)
confounder_model_kbl&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.005
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.151
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.880
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_A
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.005
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.033
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.153
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.878
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
confounding_var_J
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.860
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.048
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
38.460
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add column for labels
crude_model_tbl &amp;lt;- crude_model_tbl %&amp;gt;% mutate(model = &amp;quot;crude_model: no confounder&amp;quot;)
confounder_model_tbl &amp;lt;- confounder_model_tbl %&amp;gt;% mutate(model = &amp;quot;confounder_model: with confounder&amp;quot;)

# combine into a single kable
confounder_model_summary_tbl &amp;lt;- bind_rows(crude_model_tbl, confounder_model_tbl)
confounder_model_summary_tbl &amp;lt;- confounder_model_summary_tbl %&amp;gt;% select(model, everything())
confounder_model_summary_tbl %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 6), digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
model
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
crude_model: no confounder
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.007
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.051
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.135
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.893
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
crude_model: no confounder
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_A
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.967
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.034
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
28.415
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
confounder_model: with confounder
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.005
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.151
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.880
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
confounder_model: with confounder
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_A
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.005
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.033
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.153
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.878
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
confounder_model: with confounder
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
confounding_var_J
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.860
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.048
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
38.460
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The combined summary table above provides the effect sizes and the difference between the two models is striking. Conditional plots are a way to visualize regression models. The visreg package creates conditional plots by supplying a model object and a predictor variable to the visreg() function. The x-axis shows the value of the predictor variable and the y-axis shows change in the response variable. All other variables are held constant at their medians.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# visualize conditional plot of A vs X, crude model
v1 &amp;lt;- visreg(crude_model,
  &amp;quot;independent_var_A&amp;quot;,
  gg = TRUE,
  line = list(col = &amp;quot;#E66101&amp;quot;)
) +
  labs(
    title = &amp;quot;Relationship Between A and X&amp;quot;,
    subtitle = &amp;quot;Neglecting Confounder Variable J&amp;quot;
  ) +
  ylab(&amp;quot;Change in Response X&amp;quot;) +
  ylim(-6, 6) +
  theme(plot.subtitle = element_text(face = &amp;quot;bold&amp;quot;, color = &amp;quot;#404788FF&amp;quot;))

# visualize conditional plot of A vs X, confounder model
v2 &amp;lt;- visreg(confounder_model,
  &amp;quot;independent_var_A&amp;quot;,
  gg = TRUE,
  line = list(col = &amp;quot;#E66101&amp;quot;)
) +
  labs(
    title = &amp;quot;Relationship Between A and X&amp;quot;,
    subtitle = &amp;quot;Considering Confounder Variable J&amp;quot;
  ) +
  ylab(&amp;quot;Change in Response X&amp;quot;) +
  ylim(-6, 6) +
  theme(plot.subtitle = element_text(face = &amp;quot;bold&amp;quot;, color = &amp;quot;#20a486ff&amp;quot;))

plot_grid(v1, v2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-29-confounders-and-colliders-modeling-spurious-correlations-in-r_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We know from creating the simulated data that &lt;strong&gt;A&lt;/strong&gt; has no real effect on the outcome &lt;strong&gt;X&lt;/strong&gt;. &lt;strong&gt;X&lt;/strong&gt; was created using only &lt;strong&gt;J&lt;/strong&gt; and some noise. But the left plot shows a large, positive slope and significant coefficient! How can this be? This faulty estimate of the true effect is biased; more specifically we are seeing “confounder bias” or “omitted variable bias”. Adding &lt;strong&gt;J&lt;/strong&gt; to the regression model has the effect of conditioning on &lt;strong&gt;J&lt;/strong&gt; and revealing the true relationship between &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;X&lt;/strong&gt;: no effect of &lt;strong&gt;A&lt;/strong&gt; on &lt;strong&gt;X&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Confounding is pretty easy to understand. “Correlation does not imply causation” has been drilled into my brain effectively. Still, confounders that aren’t anticipated can derail studies and confuse observers. For example, the first generation of drug eluting stents was released in the early 2000’s. They showed great promise but their long-term risk profile was not well understood. Observational studies indicated an improved mortality rate for drug-eluting stents relative to their bare-metal counterparts. However, the performance benefit could not be replicated in randomized controlled trials.&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The disconnect was eventually linked (at least in part) to a confounding factor. Outside of a RCT, clinicians took into account the health of the patient going into the procedure. Specifically, if the patient was scheduled for a pending surgery or had a history of clotting then the clinician would hedge towards a bare-metal stent (since early gen DES tended to have thrombotic events at a greater frequency than BMS). Over the long term, these sicker patients were assigned BMS disproportionately, biasing the effect of stent type on long-term mortality via patient health as a confounder.&lt;/p&gt;
&lt;p&gt;So we always want to include every variable we know about in our regression models, right? Wrong. Here is a case that looks similar to the confounder scenario but is slightly different. The question of interest is the same: evaluate the effect of predictor &lt;strong&gt;B&lt;/strong&gt; on the outcome &lt;strong&gt;Y&lt;/strong&gt;. Again, there is a 3rd variable at play. But this time, the third variable is caused by both &lt;strong&gt;B&lt;/strong&gt; and &lt;strong&gt;Y&lt;/strong&gt; rather than being itself the common cause.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# assign DAG object
h &amp;lt;- dagify(
  K ~ B + Y,
  Y ~ B
)

# tidy the dag object and suppply to ggplot
set.seed(100)
h %&amp;gt;%
  tidy_dagitty() %&amp;gt;%
  mutate(x = c(0, 0, 2, 1)) %&amp;gt;%
  mutate(y = c(0, 0, 0, 2)) %&amp;gt;%
  mutate(xend = c(1, 2, 1, NA)) %&amp;gt;%
  mutate(yend = c(2, 0, 2, NA)) %&amp;gt;%
  dag_label(labels = c(
    &amp;quot;B&amp;quot; = &amp;quot;Independent\n Variable&amp;quot;,
    &amp;quot;Y&amp;quot; = &amp;quot;Dependent\n Variable&amp;quot;,
    &amp;quot;K&amp;quot; = &amp;quot;The\n Collider&amp;quot;
  )) %&amp;gt;%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges(
    edge_colour = &amp;quot;#b8de29ff&amp;quot;,
    edge_width = .8
  ) +
  geom_dag_node(
    color = &amp;quot;#2c3e50&amp;quot;,
    alpha = 0.8
  ) +
  geom_dag_text(color = &amp;quot;white&amp;quot;) +
  geom_dag_label_repel(aes(label = label),
    col = &amp;quot;white&amp;quot;,
    label.size = .4,
    fill = &amp;quot;#20a486ff&amp;quot;,
    alpha = 0.8,
    show.legend = FALSE,
    nudge_x = .7,
    nudge_y = .3
  ) +
  labs(
    title = &amp;quot; Directed Acyclic Graph&amp;quot;,
    subtitle = &amp;quot; Two Variables of Interest with a Collider&amp;quot;
  ) +
  xlim(c(-1.5, 3.5)) +
  ylim(c(-.33, 2.2)) +
  geom_rect(
    xmin = -.5,
    xmax = 3.25,
    ymin = -.25,
    ymax = .65,
    alpha = .04,
    fill = &amp;quot;white&amp;quot;
  ) +
  theme_void() +
  theme(
    plot.background = element_rect(fill = &amp;quot;#222222&amp;quot;),
    plot.title = element_text(color = &amp;quot;white&amp;quot;),
    plot.subtitle = element_text(color = &amp;quot;white&amp;quot;)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-29-confounders-and-colliders-modeling-spurious-correlations-in-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A variable like this is called a collider because the causal arrows from from &lt;strong&gt;B&lt;/strong&gt; and &lt;strong&gt;Y&lt;/strong&gt; collide at &lt;strong&gt;K&lt;/strong&gt;. &lt;strong&gt;K&lt;/strong&gt; is created in the simulation below using both &lt;strong&gt;B&lt;/strong&gt; and &lt;strong&gt;Y&lt;/strong&gt; plus random noise. This time, the outcome &lt;strong&gt;Y&lt;/strong&gt; is created using &lt;strong&gt;B&lt;/strong&gt; as an input, thereby assigning a causal relation with an effect size of 0.3.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create variables
# B is random draws from standard normal (mean = 0, stdev = 1)
independent_var_B &amp;lt;- rnorm(n)

# Y is created with B and noise. Effect size of B on Y is 0.3
dependent_var_Y &amp;lt;- .3 * independent_var_B + rnorm(n)

# K (collider) is created with B and Y + noise
collider_var_K &amp;lt;- 1.2 * independent_var_B + 0.9 * dependent_var_Y + rnorm(n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s assume that the experimenter knows about possible collider variable &lt;strong&gt;K&lt;/strong&gt;. What should they do with it when they go to create their regression model? Let’s create two models again to compare results. Following the nomenclature from before: &lt;strong&gt;crude_model_b&lt;/strong&gt; uses only &lt;strong&gt;B&lt;/strong&gt; to predict &lt;strong&gt;Y&lt;/strong&gt; and &lt;strong&gt;collider_model&lt;/strong&gt; uses both &lt;strong&gt;B&lt;/strong&gt; and &lt;strong&gt;K&lt;/strong&gt; to predict &lt;strong&gt;Y&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create crude regression model with B predicting Y.  K is omitted
crude_model_b &amp;lt;- lm(dependent_var_Y ~ independent_var_B)

# create collider model with B and K predicting Y
collider_model &amp;lt;- lm(dependent_var_Y ~ independent_var_B + collider_var_K)

# tidy the crude model and examine it
crude_model_b_kbl &amp;lt;- summary(crude_model_b) %&amp;gt;%
  tidy() %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 5), digits = 3)
crude_model_b_tbl &amp;lt;- summary(crude_model_b) %&amp;gt;% tidy()
crude_model_b_kbl&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.021
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.666
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.506
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_B
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.247
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7.820
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# tidy the collider model and examine it
collider_model_kbl &amp;lt;- summary(collider_model) %&amp;gt;%
  tidy() %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 5), digits = 3)
collider_model_tbl &amp;lt;- summary(collider_model) %&amp;gt;% tidy()
collider_model_kbl&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.011
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.023
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.453
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.651
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_B
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.481
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.034
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-14.250
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
collider_var_K
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.519
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.018
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
29.510
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add label column
crude_model_b_tbl &amp;lt;- crude_model_b_tbl %&amp;gt;% mutate(model = &amp;quot;crude_model_b: no collider&amp;quot;)
collider_model_tbl &amp;lt;- collider_model_tbl %&amp;gt;% mutate(model = &amp;quot;collider_model: with collider&amp;quot;)

# combine and examine
collider_model_summary_tbl &amp;lt;- bind_rows(crude_model_b_tbl, collider_model_tbl)
collider_model_summary_tbl &amp;lt;- collider_model_summary_tbl %&amp;gt;% select(model, everything())
collider_model_summary_tbl %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 6), digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
model
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
crude_model_b: no collider
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.021
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.666
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.506
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
crude_model_b: no collider
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_B
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.247
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7.820
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
collider_model: with collider
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.011
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.023
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.453
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.651
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
collider_model: with collider
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
independent_var_B
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.481
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.034
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-14.250
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
collider_model: with collider
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
collider_var_K
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.519
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.018
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
29.510
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This time, omitting the collider variable is the proper way to recover the true effect of &lt;strong&gt;B&lt;/strong&gt; on &lt;strong&gt;Y&lt;/strong&gt;. Let’s verify with conditional plots as before. Again, we know the true slope should be around 0.3.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create conditional plot with crude_model_b and B
v3 &amp;lt;- visreg(crude_model_b,
  &amp;quot;independent_var_B&amp;quot;,
  gg = TRUE,
  line = list(col = &amp;quot;#E66101&amp;quot;)
) +
  labs(
    title = &amp;quot;Relationship Between B and Y&amp;quot;,
    subtitle = &amp;quot;Neglecting Collider Variable K&amp;quot;
  ) +
  ylab(&amp;quot;Change in Response Y&amp;quot;) +
  ylim(-6, 6) +
  theme(plot.subtitle = element_text(face = &amp;quot;bold&amp;quot;, color = &amp;quot;#f68f46b2&amp;quot;))

# create conditional plot with collider_model and B
v4 &amp;lt;- visreg(collider_model,
  &amp;quot;independent_var_B&amp;quot;,
  gg = TRUE,
  line = list(col = &amp;quot;#E66101&amp;quot;)
) +
  labs(
    title = &amp;quot;Relationship Between B and Y&amp;quot;,
    subtitle = &amp;quot;Considering Collider Variable K&amp;quot;
  ) +
  ylab(&amp;quot;Change in Response Y&amp;quot;) +
  ylim(-6, 6) +
  theme(plot.subtitle = element_text(face = &amp;quot;bold&amp;quot;, color = &amp;quot;#403891b2&amp;quot;))

plot_grid(v3, v4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-29-confounders-and-colliders-modeling-spurious-correlations-in-r_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; Incredibly, the conclusion one draws about the relationship between &lt;strong&gt;B&lt;/strong&gt; and &lt;strong&gt;Y&lt;/strong&gt; completely reverses depending upon which model is used. The true effect is positive (we only know this for sure because we created the data) but by including the collider variable in the model we observe it as negative. &lt;strong&gt;We should not control for a collider variable!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Controlling for a confounder reduces bias but controlling for a collider increases it - a simple summary that I will try to remember as I design future experiments or attempt to derive meaning from observational studies. These are the simple insights that make learning this stuff really fun (for me at least)!&lt;/p&gt;
&lt;p&gt;Thanks for reading.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://bayes.cs.ucla.edu/WHY/&#34; class=&#34;uri&#34;&gt;http://bayes.cs.ucla.edu/WHY/&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://scholar.harvard.edu/files/malf/files/ijeluquecollider.pdf&#34; class=&#34;uri&#34;&gt;https://scholar.harvard.edu/files/malf/files/ijeluquecollider.pdf&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3681250/&#34; class=&#34;uri&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3681250/&lt;/a&gt;&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Heart Disease Prediction From Patient Data in R</title>
      <link>/post/heart-disease-prediction-from-patient-data-in-r/</link>
      <pubDate>Sun, 29 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/heart-disease-prediction-from-patient-data-in-r/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In this post I’ll be attempting to leverage the parsnip package in R to run through some straightforward predictive analytics/machine learning. Parsnip provides a flexible and consistent interface to apply common regression and classification algorithms in R. I’ll be working with the Cleveland Clinic Heart Disease dataset which contains 13 variables related to patient diagnostics and one outcome variable indicating the presence or absence of heart disease.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; The data was accessed from the UCI Machine Learning Repository in September 2019.&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. The goal is to be able to accurately classify as having or not having heart disease based on diagnostic test data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/cda.jpg&#34; width=&#34;100%&#34; height=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Load the libraries to be used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Load libraries
library(tidyverse)
library(kableExtra)
library(rsample)
library(recipes)
library(parsnip)
library(yardstick)
library(viridisLite)
library(GGally)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first part of the analysis is to read in the data set and clean the column names up a bit.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Read in data
heart_disease_dataset &amp;lt;- read.csv(file = &amp;quot;processed.cleveland.data&amp;quot;, header = F)

#Prepare column names
names &amp;lt;- c(&amp;quot;Age&amp;quot;,
           &amp;quot;Sex&amp;quot;,
           &amp;quot;Chest_Pain_Type&amp;quot;,
           &amp;quot;Resting_Blood_Pressure&amp;quot;,
           &amp;quot;Serum_Cholesterol&amp;quot;,
           &amp;quot;Fasting_Blood_Sugar&amp;quot;,
           &amp;quot;Resting_ECG&amp;quot;,
           &amp;quot;Max_Heart_Rate_Achieved&amp;quot;,
           &amp;quot;Exercise_Induced_Angina&amp;quot;,
           &amp;quot;ST_Depression_Exercise&amp;quot;,
           &amp;quot;Peak_Exercise_ST_Segment&amp;quot;,
           &amp;quot;Num_Major_Vessels_Flouro&amp;quot;,
           &amp;quot;Thalassemia&amp;quot;,
           &amp;quot;Diagnosis_Heart_Disease&amp;quot;)

#Apply column names to the dataframe
colnames(heart_disease_dataset) &amp;lt;- names

#Glimpse data to verify new column names are in place
heart_disease_dataset %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 303
## Variables: 14
## $ Age                      &amp;lt;dbl&amp;gt; 63, 67, 67, 37, 41, 56, 62, 57, 63, 5...
## $ Sex                      &amp;lt;dbl&amp;gt; 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1...
## $ Chest_Pain_Type          &amp;lt;dbl&amp;gt; 1, 4, 4, 3, 2, 2, 4, 4, 4, 4, 4, 2, 3...
## $ Resting_Blood_Pressure   &amp;lt;dbl&amp;gt; 145, 160, 120, 130, 130, 120, 140, 12...
## $ Serum_Cholesterol        &amp;lt;dbl&amp;gt; 233, 286, 229, 250, 204, 236, 268, 35...
## $ Fasting_Blood_Sugar      &amp;lt;dbl&amp;gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1...
## $ Resting_ECG              &amp;lt;dbl&amp;gt; 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2...
## $ Max_Heart_Rate_Achieved  &amp;lt;dbl&amp;gt; 150, 108, 129, 187, 172, 178, 160, 16...
## $ Exercise_Induced_Angina  &amp;lt;dbl&amp;gt; 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1...
## $ ST_Depression_Exercise   &amp;lt;dbl&amp;gt; 2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0....
## $ Peak_Exercise_ST_Segment &amp;lt;dbl&amp;gt; 3, 2, 2, 3, 1, 1, 3, 1, 2, 3, 2, 2, 2...
## $ Num_Major_Vessels_Flouro &amp;lt;fct&amp;gt; 0.0, 3.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0....
## $ Thalassemia              &amp;lt;fct&amp;gt; 6.0, 3.0, 7.0, 3.0, 3.0, 3.0, 3.0, 3....
## $ Diagnosis_Heart_Disease  &amp;lt;int&amp;gt; 0, 2, 1, 0, 0, 0, 3, 0, 2, 1, 0, 0, 2...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are 14 variables provided in the data set and the last one is the dependent variable that we want to be able to predict. Here is a summary of what the other variables mean:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Age&lt;/strong&gt;: Age of subject&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Sex&lt;/strong&gt;: Gender of subject:&lt;br /&gt;
0 = female 1 = male&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Chest-pain type&lt;/strong&gt;: Type of chest-pain experienced by the individual:&lt;br /&gt;
1 = typical angina&lt;br /&gt;
2 = atypical angina&lt;br /&gt;
3 = non-angina pain&lt;br /&gt;
4 = asymptomatic angina&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Resting Blood Pressure&lt;/strong&gt;: Resting blood pressure in mm Hg&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Serum Cholesterol&lt;/strong&gt;: Serum cholesterol in mg/dl&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Fasting Blood Sugar&lt;/strong&gt;: Fasting blood sugar level relative to 120 mg/dl: 0 = fasting blood sugar &amp;lt;= 120 mg/dl&lt;br /&gt;
1 = fasting blood sugar &amp;gt; 120 mg/dl&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Resting ECG&lt;/strong&gt;: Resting electrocardiographic results&lt;br /&gt;
0 = normal&lt;br /&gt;
1 = ST-T wave abnormality&lt;br /&gt;
2 = left ventricle hyperthrophy&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Max Heart Rate Achieved&lt;/strong&gt;: Max heart rate of subject&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Exercise Induced Angina&lt;/strong&gt;:&lt;br /&gt;
0 = no 1 = yes&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;ST Depression Induced by Exercise Relative to Rest&lt;/strong&gt;: ST Depression of subject&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Peak Exercise ST Segment&lt;/strong&gt;:&lt;br /&gt;
1 = Up-sloaping&lt;br /&gt;
2 = Flat&lt;br /&gt;
3 = Down-sloaping&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Number of Major Vessels (0-3) Visible on Flouroscopy&lt;/strong&gt;: Number of visible vessels under flouro&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Thal&lt;/strong&gt;: Form of thalassemia: &lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;br /&gt;
3 = normal&lt;br /&gt;
6 = fixed defect&lt;br /&gt;
7 = reversible defect&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Diagnosis of Heart Disease&lt;/strong&gt;: Indicates whether subject is suffering from heart disease or not:&lt;br /&gt;
0 = absence&lt;br /&gt;
1, 2, 3, 4 = heart disease present&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A closer look at the data identifies some NA and “?” values that will need to be addressed in the cleaning step. We also want to know the number of observations in the dependent variable column to understand if the dataset is relatively balanced.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Determine the number of values in each level of dependent variable
heart_disease_dataset %&amp;gt;% 
  drop_na() %&amp;gt;%
  group_by(Diagnosis_Heart_Disease) %&amp;gt;%
  count() %&amp;gt;% 
  ungroup() %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2)) %&amp;gt;% kable_styling(&amp;quot;full_width&amp;quot; = F)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Diagnosis_Heart_Disease
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
n
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
164
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
55
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
35
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
13
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Identify the different levels of Thalassemia
heart_disease_dataset %&amp;gt;% 
  drop_na() %&amp;gt;%
  group_by(Thalassemia) %&amp;gt;%
  count() %&amp;gt;% 
  ungroup() %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2)) %&amp;gt;% kable_styling(&amp;quot;full_width&amp;quot; = F)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Thalassemia
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
n
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
?
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
166
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
18
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
117
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Since any value above 0 in ‘Diagnosis_Heart_Disease’ (column 14) indicates the presence of heart disease, we can lump all levels &amp;gt; 0 together so the classification predictions are binary - Yes or No (1 or 0). The total count of positive heart disease results is less than the number of negative results so the fct_lump() call with default arguments will convert that variable from 4 levels to 2.&lt;/p&gt;
&lt;p&gt;The data cleaning pipeline below deals with NA values, converts some variables to factors, lumps the dependent variable into two buckets, removes the rows that had “?” for observations, and reorders the variables within the dataframe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Drop NA&amp;#39;s, convert to factors, lump target variable to 2 levels, remove &amp;quot;?&amp;quot;, reorder variables
heart_dataset_clean_tbl &amp;lt;- heart_disease_dataset %&amp;gt;% 
    drop_na() %&amp;gt;%
    mutate_at(c(&amp;quot;Resting_ECG&amp;quot;, 
                &amp;quot;Fasting_Blood_Sugar&amp;quot;, 
                &amp;quot;Sex&amp;quot;, 
                &amp;quot;Diagnosis_Heart_Disease&amp;quot;, 
                &amp;quot;Exercise_Induced_Angina&amp;quot;,
                &amp;quot;Peak_Exercise_ST_Segment&amp;quot;, 
                &amp;quot;Chest_Pain_Type&amp;quot;), as_factor) %&amp;gt;%
    mutate(Num_Major_Vessels_Flouro = as.numeric(Num_Major_Vessels_Flouro)) %&amp;gt;%
    mutate(Diagnosis_Heart_Disease = fct_lump(Diagnosis_Heart_Disease, other_level = &amp;quot;1&amp;quot;)) %&amp;gt;% 
    filter(Thalassemia != &amp;quot;?&amp;quot;) %&amp;gt;%
    select(Age, 
           Resting_Blood_Pressure, 
           Serum_Cholesterol, 
           Max_Heart_Rate_Achieved, 
           ST_Depression_Exercise,
           Num_Major_Vessels_Flouro,
           everything())

#Glimpse data
heart_dataset_clean_tbl %&amp;gt;%
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 301
## Variables: 14
## $ Age                      &amp;lt;dbl&amp;gt; 63, 67, 67, 37, 41, 56, 62, 57, 63, 5...
## $ Resting_Blood_Pressure   &amp;lt;dbl&amp;gt; 145, 160, 120, 130, 130, 120, 140, 12...
## $ Serum_Cholesterol        &amp;lt;dbl&amp;gt; 233, 286, 229, 250, 204, 236, 268, 35...
## $ Max_Heart_Rate_Achieved  &amp;lt;dbl&amp;gt; 150, 108, 129, 187, 172, 178, 160, 16...
## $ ST_Depression_Exercise   &amp;lt;dbl&amp;gt; 2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0....
## $ Num_Major_Vessels_Flouro &amp;lt;dbl&amp;gt; 2, 5, 4, 2, 2, 2, 4, 2, 3, 2, 2, 2, 3...
## $ Sex                      &amp;lt;fct&amp;gt; 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1...
## $ Chest_Pain_Type          &amp;lt;fct&amp;gt; 1, 4, 4, 3, 2, 2, 4, 4, 4, 4, 4, 2, 3...
## $ Fasting_Blood_Sugar      &amp;lt;fct&amp;gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1...
## $ Resting_ECG              &amp;lt;fct&amp;gt; 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2...
## $ Exercise_Induced_Angina  &amp;lt;fct&amp;gt; 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1...
## $ Peak_Exercise_ST_Segment &amp;lt;fct&amp;gt; 3, 2, 2, 3, 1, 1, 3, 1, 2, 3, 2, 2, 2...
## $ Thalassemia              &amp;lt;fct&amp;gt; 6.0, 3.0, 7.0, 3.0, 3.0, 3.0, 3.0, 3....
## $ Diagnosis_Heart_Disease  &amp;lt;fct&amp;gt; 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Time for some basic exploratory data analysis. The workflow below breaks out the categorical variables and visualizes them on a faceted bar plot. I’m recoding the factors levels from numeric back to text-based so the labels are easy to interpret on the plots and stripping the y-axis labels since the relative differences are what matters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Select categorical vars, recode them to their character values, convert to long format
hd_long_fact_tbl &amp;lt;- heart_dataset_clean_tbl  %&amp;gt;%
  select(Sex,
         Chest_Pain_Type,
         Fasting_Blood_Sugar,
         Resting_ECG,
         Exercise_Induced_Angina,
         Peak_Exercise_ST_Segment,
         Thalassemia,
         Diagnosis_Heart_Disease) %&amp;gt;%
  mutate(Sex = recode_factor(Sex, `0` = &amp;quot;female&amp;quot;, 
                                  `1` = &amp;quot;male&amp;quot; ),
         Chest_Pain_Type = recode_factor(Chest_Pain_Type, `1` = &amp;quot;typical&amp;quot;,   
                                                          `2` = &amp;quot;atypical&amp;quot;,
                                                          `3` = &amp;quot;non-angina&amp;quot;, 
                                                          `4` = &amp;quot;asymptomatic&amp;quot;),
         Fasting_Blood_Sugar = recode_factor(Fasting_Blood_Sugar, `0` = &amp;quot;&amp;lt;= 120 mg/dl&amp;quot;, 
                                                                  `1` = &amp;quot;&amp;gt; 120 mg/dl&amp;quot;),
         Resting_ECG = recode_factor(Resting_ECG, `0` = &amp;quot;normal&amp;quot;,
                                                  `1` = &amp;quot;ST-T abnormality&amp;quot;,
                                                  `2` = &amp;quot;LV hypertrophy&amp;quot;),
         Exercise_Induced_Angina = recode_factor(Exercise_Induced_Angina, `0` = &amp;quot;no&amp;quot;,
                                                                          `1` = &amp;quot;yes&amp;quot;),
         Peak_Exercise_ST_Segment = recode_factor(Peak_Exercise_ST_Segment, `1` = &amp;quot;up-sloaping&amp;quot;,
                                                                            `2` = &amp;quot;flat&amp;quot;,
                                                                            `3` = &amp;quot;down-sloaping&amp;quot;),
         Thalassemia = recode_factor(Thalassemia, `3` = &amp;quot;normal&amp;quot;,
                                                  `6` = &amp;quot;fixed defect&amp;quot;,
                                                  `7` = &amp;quot;reversible defect&amp;quot;)) %&amp;gt;%
  gather(key = &amp;quot;key&amp;quot;, value = &amp;quot;value&amp;quot;, -Diagnosis_Heart_Disease)

#Visualize with bar plot
hd_long_fact_tbl %&amp;gt;% 
  ggplot(aes(value)) +
    geom_bar(aes(x        = value, 
                 fill     = Diagnosis_Heart_Disease), 
                 alpha    = .6, 
                 position = &amp;quot;dodge&amp;quot;, 
                 color    = &amp;quot;black&amp;quot;,
                 width    = .8
             ) +
    labs(x = &amp;quot;&amp;quot;,
         y = &amp;quot;&amp;quot;,
         title = &amp;quot;Scaled Effect of Categorical Variables&amp;quot;) +
    theme(
         axis.text.y  = element_blank(),
         axis.ticks.y = element_blank()) +
    facet_wrap(~ key, scales = &amp;quot;free&amp;quot;, nrow = 4) +
    scale_fill_manual(
         values = c(&amp;quot;#fde725ff&amp;quot;, &amp;quot;#20a486ff&amp;quot;),
         name   = &amp;quot;Heart\nDisease&amp;quot;,
         labels = c(&amp;quot;No HD&amp;quot;, &amp;quot;Yes HD&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-29-heart-disease-prediction-from-patient-data-in-r_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I prefer boxplots for evaluating the numeric variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Must gather() data first in order to facet wrap by key 
#(default gather call puts all var names into new key col)
hd_long_cont_tbl &amp;lt;- heart_dataset_clean_tbl  %&amp;gt;%
  select(Age,
         Resting_Blood_Pressure,
         Serum_Cholesterol,
         Max_Heart_Rate_Achieved,
         ST_Depression_Exercise,
         Num_Major_Vessels_Flouro,
         Diagnosis_Heart_Disease) %&amp;gt;% 
  gather(key   = &amp;quot;key&amp;quot;, 
         value = &amp;quot;value&amp;quot;,
         -Diagnosis_Heart_Disease)

#Visualize numeric variables as boxplots
hd_long_cont_tbl %&amp;gt;% 
  ggplot(aes(y = value)) +
       geom_boxplot(aes(fill = Diagnosis_Heart_Disease),
                      alpha  = .6,
                      fatten = .7) +
        labs(x = &amp;quot;&amp;quot;,
             y = &amp;quot;&amp;quot;,
             title = &amp;quot;Boxplots for Numeric Variables&amp;quot;) +
      scale_fill_manual(
            values = c(&amp;quot;#fde725ff&amp;quot;, &amp;quot;#20a486ff&amp;quot;),
            name   = &amp;quot;Heart\nDisease&amp;quot;,
            labels = c(&amp;quot;No HD&amp;quot;, &amp;quot;Yes HD&amp;quot;)) +
      theme(
         axis.text.x  = element_blank(),
         axis.ticks.x = element_blank()) +
      facet_wrap(~ key, 
                 scales = &amp;quot;free&amp;quot;, 
                 ncol   = 2) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-29-heart-disease-prediction-from-patient-data-in-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; The faceted plots for categorical and numeric variables suggest the following conditions are associated with increased prevalence of heart disease (note: this does not mean the relationship is causal).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Asymptomatic angina chest pain (relative to typical angina chest pain, atypical angina pain, or non-angina pain)&lt;/li&gt;
&lt;li&gt;Presence of exercise induced angina&lt;/li&gt;
&lt;li&gt;Lower fasting blood sugar&lt;/li&gt;
&lt;li&gt;Flat or down-sloaping peak exercise ST segment&lt;/li&gt;
&lt;li&gt;Presence of left ventricle hypertrophy&lt;/li&gt;
&lt;li&gt;Male&lt;/li&gt;
&lt;li&gt;Higher thelassemia score&lt;/li&gt;
&lt;li&gt;Higher age&lt;/li&gt;
&lt;li&gt;Lower max heart rate achieved&lt;/li&gt;
&lt;li&gt;Higher resting blood pressure&lt;/li&gt;
&lt;li&gt;Higher cholesterol&lt;/li&gt;
&lt;li&gt;Higher ST depression induced by exercise relative to rest&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can’t all be cardiologists but these do seem to pass the eye check. Particularly: age, blood pressure, cholesterol, and sex all point in the right direction based on what we generally know about the world around us. This provides a nice phase gate to let us proceed with the analysis.&lt;/p&gt;
&lt;p&gt;Highly correlated variables can lead to overly complicated models or wonky predictions. The ggcorr() function from GGally package provides a nice, clean correlation matrix of the numeric variables. The default method is Pearson which I use here first. Pearson isn’t ideal if the data is skewed or has a lot of outliers so I’ll check using the rank-based Kendall method as well.&lt;a href=&#34;#fn4&#34; class=&#34;footnoteRef&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Correlation matrix using Pearson method, default method is Pearson
heart_dataset_clean_tbl %&amp;gt;% ggcorr(high       = &amp;quot;#20a486ff&amp;quot;,
                                   low        = &amp;quot;#fde725ff&amp;quot;,
                                   label      = TRUE, 
                                   hjust      = .75, 
                                   size       = 3, 
                                   label_size = 3,
                                   nbreaks    = 5
                                              ) +
  labs(title = &amp;quot;Correlation Matrix&amp;quot;,
  subtitle = &amp;quot;Pearson Method Using Pairwise Obervations&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-29-heart-disease-prediction-from-patient-data-in-r_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Correlation matrix using Kendall method
heart_dataset_clean_tbl %&amp;gt;% ggcorr(method     = c(&amp;quot;pairwise&amp;quot;, &amp;quot;kendall&amp;quot;),
                                   high       = &amp;quot;#20a486ff&amp;quot;,
                                   low        = &amp;quot;#fde725ff&amp;quot;,
                                   label      = TRUE, 
                                   hjust      = .75, 
                                   size       = 3, 
                                   label_size = 3,
                                   nbreaks    = 5
                                   ) +
  labs(title = &amp;quot;Correlation Matrix&amp;quot;,
  subtitle = &amp;quot;Kendall Method Using Pairwise Observations&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-29-heart-disease-prediction-from-patient-data-in-r_files/figure-html/unnamed-chunk-8-2.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are very minor differences between the Pearson and Kendall results. No variables appear to be highly correlated. As such, it seems reasonable to stay with the original 14 variables as we proceed into the modeling section.&lt;/p&gt;
&lt;p&gt;The plan is to split up the original data set to form a training group and testing group. The training group will be used to fit the model while the testing group will be used to evaluate predictions. The initial_split() function creates a split object which is just an efficient way to store both the training and testing sets. The training() and testing() functions are used to extract the appropriate dataframes out of the split object when needed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#set seed for repeatability
set.seed(1333)

#create split object 
train_test_split &amp;lt;- heart_dataset_clean_tbl %&amp;gt;% initial_split(prop = .8, strata = &amp;quot;Diagnosis_Heart_Disease&amp;quot;)

#pipe split obj to training() fcn to create training set
train_tbl &amp;lt;- train_test_split %&amp;gt;% training()

#pipe split obj to testing() fcn to create test set
test_tbl &amp;lt;- train_test_split %&amp;gt;% testing()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We chose to do our data preparation early on during the cleaning phase. For more complicated modeling operations it may be desirable to set up a recipe to do the pre-processing in a repeatable and reversible fashion and I chose here to leave some placeholder lines commented out and available for future work. The recipe is the spot to transform, scale, or binarize the data. We have to tell the recipe() function what we want to model: Diagnosis_Heart_Disease as a function of all the other variables (not needed here since we took care of the necessary conversions). The training data should be used exclusively to train the recipe to avoid data leakage. After giving the model syntax to the recipe, the data is piped into the prep() function which will extract all the processing parameters (if we had implemented processing steps here). The trained recipe is stored as an object and bake function is used to apply the trained recipe to a new (test) data set.&lt;/p&gt;
&lt;p&gt;Juice() is a shortcut to extract the finalized training set which is already embedded in the recipe by default. Calling the bake() function and providing the recipe and a new data set will apply the processing steps to that dataframe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set up recipe (use training data here to avoid leakage)
the_recipe &amp;lt;- recipe(Diagnosis_Heart_Disease ~ . , data = train_tbl) %&amp;gt;%
              #[Processing Step 1]
              #[Processing Step 2]
              prep(train_tbl, retain = TRUE)

#Apply recipe to training data to create processed training_data_obj (already populated in the recipe object)
train_processed_data &amp;lt;- juice(the_recipe)

#Apply recipe to test data to create processed test_data_obj
test_processed_data &amp;lt;- bake(the_recipe, new_data = test_tbl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the training and testing data have been processed and stored, the logistic regression model can be set up using the parsnip workflow. Parsnip uses a 3-step process:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;specify the model and its arguments&lt;/li&gt;
&lt;li&gt;set the engine (how the model is created)&lt;/li&gt;
&lt;li&gt;fit the model to the processed training data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Logistic regression is a convenient first model to work with since it is relatively easy to implement and yields results that have intuitive meaning. It can be easily interpreted when the odds ratio is calculated from the model structure. &lt;a href=&#34;#fn5&#34; class=&#34;footnoteRef&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set up and train the model using processed training_data_obj
set.seed(100)
log_regr_hd_model &amp;lt;- logistic_reg(mode = &amp;quot;classification&amp;quot;) %&amp;gt;%
                     set_engine(&amp;quot;glm&amp;quot;) %&amp;gt;% 
                     fit(Diagnosis_Heart_Disease ~ ., data = train_processed_data)

#Take a look at model coefficients and add odds ratio for interpretability
broom::tidy(log_regr_hd_model$fit) %&amp;gt;%
  arrange(desc(estimate)) %&amp;gt;% 
  mutate(odds_ratio = exp(estimate)) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 5), digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.value
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
odds_ratio
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Thalassemia7.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.932
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.519
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.726
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6.906
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Chest_Pain_Type4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.694
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.770
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.201
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.028
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
5.443
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sex1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.473
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.648
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.274
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.023
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4.364
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Num_Major_Vessels_Flouro
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.264
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.307
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4.119
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.000
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.538
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Chest_Pain_Type2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.255
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.874
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.436
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.151
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.507
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Resting_ECG2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.022
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.447
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.287
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.022
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.780
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Peak_Exercise_ST_Segment3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.003
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.984
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.020
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.308
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.727
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Peak_Exercise_ST_Segment2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.833
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.551
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.512
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.130
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.300
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Exercise_Induced_Angina1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.704
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.526
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.339
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.181
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.023
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Resting_ECG1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.675
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.314
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.204
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.839
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.965
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
ST_Depression_Exercise
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.340
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.268
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.267
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.205
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.405
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Thalassemia6.0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.127
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.882
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.144
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.885
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.136
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Resting_Blood_Pressure
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.036
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.014
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.535
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.011
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.037
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Serum_Cholesterol
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.003
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.005
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.644
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.520
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.003
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Max_Heart_Rate_Achieved
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.032
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.014
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-2.271
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.023
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.969
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Age
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.035
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.029
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-1.198
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.231
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.966
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Chest_Pain_Type3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.282
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.770
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.366
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.714
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.755
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fasting_Blood_Sugar1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.684
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.718
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.953
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.341
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.504
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-6.350
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.439
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-1.846
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.065
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.002
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In the above code I’ve converted the estimate of the coefficient into the odds ratio. The odds ratio represents the odds that an outcome will occur given the presence of a specific predictor, compared to the odds of the outcome occurring in the absence of that predictor, assuming all other predictors remain constant. The odds ratio is calculated from the exponential function of the coefficient estimate based on a unit increase in the predictor. An example with a numeric variable: for 1 mm Hg increased in resting blood pressure rest_bp, the odds of having heart disease increases by a factor of 1.04.&lt;/p&gt;
&lt;p&gt;Now let’s feed the model the testing data that we held out from the fitting process. It’s the first time the model will have seen these data so we should get a fair assessment (absent of over-fitting). The new_data argument in the predict() function is used to supply the test data to the model and have it output a vector of predictions, one for each observation in the testing data. The results vector can be added as a column into the original dataframe to append the predictions next to the true values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Make predictions using testing set
first_training_prediction &amp;lt;- predict(log_regr_hd_model, 
                                     new_data = test_tbl, 
                                     type     = &amp;quot;class&amp;quot;)

#Add predictions as new column in heart data set
first_training_prediction_full_tbl &amp;lt;- test_processed_data %&amp;gt;% 
  mutate(Predicted_Heart_Disease = first_training_prediction$.pred_class)

#Glimpse data
first_training_prediction_full_tbl %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 59
## Variables: 15
## $ Age                      &amp;lt;dbl&amp;gt; 56, 63, 56, 52, 54, 60, 64, 43, 65, 4...
## $ Resting_Blood_Pressure   &amp;lt;dbl&amp;gt; 120, 130, 140, 172, 140, 117, 140, 12...
## $ Serum_Cholesterol        &amp;lt;dbl&amp;gt; 236, 254, 294, 199, 239, 230, 335, 17...
## $ Max_Heart_Rate_Achieved  &amp;lt;dbl&amp;gt; 178, 147, 153, 162, 160, 160, 158, 12...
## $ ST_Depression_Exercise   &amp;lt;dbl&amp;gt; 0.8, 1.4, 1.3, 0.5, 1.2, 1.4, 0.0, 2....
## $ Num_Major_Vessels_Flouro &amp;lt;dbl&amp;gt; 2, 3, 2, 2, 2, 4, 2, 2, 5, 2, 2, 2, 2...
## $ Sex                      &amp;lt;fct&amp;gt; 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1...
## $ Chest_Pain_Type          &amp;lt;fct&amp;gt; 2, 4, 2, 3, 4, 4, 3, 4, 4, 1, 4, 3, 3...
## $ Fasting_Blood_Sugar      &amp;lt;fct&amp;gt; 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1...
## $ Resting_ECG              &amp;lt;fct&amp;gt; 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2...
## $ Exercise_Induced_Angina  &amp;lt;fct&amp;gt; 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0...
## $ Peak_Exercise_ST_Segment &amp;lt;fct&amp;gt; 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3...
## $ Thalassemia              &amp;lt;fct&amp;gt; 3.0, 7.0, 3.0, 7.0, 3.0, 7.0, 3.0, 7....
## $ Diagnosis_Heart_Disease  &amp;lt;fct&amp;gt; 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0...
## $ Predicted_Heart_Disease  &amp;lt;fct&amp;gt; 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A confusion matrix is a visual way to display the results of the model’s predictions. It’s not just the ability to predict the presence of heart disease that is of interest - we also want to know the number of times the model successfully predicts the absence of heart disease. Likewise, we want to know the number of false positives and false negatives. The confusion matrix captures all these metrics nicely.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Use predictions col and truth col to make a confusion matrix object
conf_mat_obj &amp;lt;- first_training_prediction_full_tbl %&amp;gt;% 
  conf_mat(truth    = Diagnosis_Heart_Disease, 
           estimate = Predicted_Heart_Disease)

#Call conf_mat and supply columns for truth, prediction
#Pluck() to extract the conf_matrix data into cols and convert to tibble for plotting
conf_matrix_plt_obj &amp;lt;- first_training_prediction_full_tbl %&amp;gt;% 
  conf_mat(truth    = Diagnosis_Heart_Disease, 
           estimate = Predicted_Heart_Disease) %&amp;gt;%
  pluck(1) %&amp;gt;%
  as_tibble() %&amp;gt;%
  mutate(&amp;quot;outcome&amp;quot; = c(&amp;quot;true_negative&amp;quot;,
                       &amp;quot;false_positive&amp;quot;,
                       &amp;quot;false_negative&amp;quot;,
                       &amp;quot;true_positive&amp;quot;)) %&amp;gt;%
  mutate(Prediction = recode(Prediction, &amp;quot;0&amp;quot; = &amp;quot;No Heart Disease&amp;quot;,
                                         &amp;quot;1&amp;quot; = &amp;quot;Heart Disease&amp;quot;)) %&amp;gt;%
  mutate(Truth = recode(Truth,  &amp;quot;0&amp;quot; = &amp;quot;No Heart Disease&amp;quot;,
                                &amp;quot;1&amp;quot; = &amp;quot;Heart Disease&amp;quot;))

#Convert to kable format
conf_matrix_plt_obj %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 4))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Prediction
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Truth
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
n
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
outcome
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
No Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
No Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
29
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
true_negative
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
No Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
false_positive
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
No Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
false_negative
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Heart Disease
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
true_positive
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Plot confusion matrix
p1 &amp;lt;- conf_matrix_plt_obj %&amp;gt;% ggplot(aes(x = Truth, y = Prediction)) +
  geom_tile(aes(fill = n), alpha = .8) +
  geom_text(aes(label = n), color = &amp;quot;white&amp;quot;) +
  scale_fill_viridis_c() +
  theme(legend.title = element_blank()) +
  labs(
    title    = &amp;quot;Confusion Matrix&amp;quot;,
    subtitle = &amp;quot;Heart Disease Prediction Using Logistic Regression&amp;quot;
  )
  
p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-29-heart-disease-prediction-from-patient-data-in-r_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Calling summary() on the confusion_matrix_obj gives all the performance measures
#Filter to the ones we care about
log_reg_performance_tbl &amp;lt;- summary(conf_mat_obj) %&amp;gt;% filter(
                                 .metric == &amp;quot;accuracy&amp;quot; | 
                                 .metric == &amp;quot;sens&amp;quot; |
                                 .metric == &amp;quot;spec&amp;quot; |
                                 .metric == &amp;quot;ppv&amp;quot;  |
                                 .metric == &amp;quot;npv&amp;quot;  |
                                 .metric == &amp;quot;f_meas&amp;quot;) %&amp;gt;%
  select(-.estimator) %&amp;gt;%
  rename(&amp;quot;metric&amp;quot; = .metric, 
         &amp;quot;estimate&amp;quot; = .estimate) %&amp;gt;%
  mutate(&amp;quot;estimate&amp;quot; = estimate %&amp;gt;% signif(digits = 3)) %&amp;gt;%
  mutate(metric = recode(metric, &amp;quot;sens&amp;quot; = &amp;quot;sensitivity&amp;quot;),
         metric = recode(metric, &amp;quot;spec&amp;quot; = &amp;quot;specificity&amp;quot;),
         metric = recode(metric, &amp;quot;ppv&amp;quot;  = &amp;quot;positive predictive value&amp;quot;),
         metric = recode(metric, &amp;quot;npv&amp;quot;  = &amp;quot;negative predictive value&amp;quot;)) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 3))
  
#Display perfomance summary as kable
log_reg_performance_tbl &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
metric
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
estimate
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.847
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
sensitivity
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.906
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
specificity
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.778
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
positive predictive value
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.829
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
negative predictive value
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.875
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
f_meas
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.866
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Other common performance metrics are summarized above. Accuracy represents the percentage of correct predictions. Descriptions for each can be found at this link.&lt;a href=&#34;#fn6&#34; class=&#34;footnoteRef&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The initial split of the data set into training/testing was done randomly so a replicate of the procedure would yield slightly different results. V-fold cross validation is a resampling technique that allows for repeating the process of splitting the data, training the model, and assessing the results many times from the same data set. Each stop in the CV process is annotated in the comments within the code below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create multiple split objects w/ vfold cross-validation resampling
set.seed(925)
hd_cv_split_objects &amp;lt;- heart_dataset_clean_tbl %&amp;gt;% vfold_cv(strata = Diagnosis_Heart_Disease)
hd_cv_split_objects&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 2
##    splits           id    
##    &amp;lt;named list&amp;gt;     &amp;lt;chr&amp;gt; 
##  1 &amp;lt;split [270/31]&amp;gt; Fold01
##  2 &amp;lt;split [270/31]&amp;gt; Fold02
##  3 &amp;lt;split [270/31]&amp;gt; Fold03
##  4 &amp;lt;split [271/30]&amp;gt; Fold04
##  5 &amp;lt;split [271/30]&amp;gt; Fold05
##  6 &amp;lt;split [271/30]&amp;gt; Fold06
##  7 &amp;lt;split [271/30]&amp;gt; Fold07
##  8 &amp;lt;split [271/30]&amp;gt; Fold08
##  9 &amp;lt;split [272/29]&amp;gt; Fold09
## 10 &amp;lt;split [272/29]&amp;gt; Fold10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#I want a big function that takes a split object and an id
make_cv_predictions_fcn &amp;lt;- function(split, id){
  #extract data for analysis set from split obj
  #prep(train) the recipe and return updated recipe
  #bake(apply) trained recipe to new data  
  analysis_tbl &amp;lt;- analysis(split)
  trained_analysis_recipe &amp;lt;- prep(the_recipe ,training = analysis_tbl)
  baked_analysis_data_tbl &amp;lt;- bake(trained_analysis_recipe, new_data = analysis_tbl)
  
  #define model in parsnip syntax
  model &amp;lt;- logistic_reg(mode = &amp;quot;classification&amp;quot;) %&amp;gt;%
    set_engine(&amp;quot;glm&amp;quot;) %&amp;gt;%
    fit(Diagnosis_Heart_Disease ~ ., data = baked_analysis_data_tbl)
  
  #same as above but for assessment set (like the test set but for resamples)
  assessment_tbl &amp;lt;- assessment(split)
  trained_assessment_recipe &amp;lt;- prep(the_recipe, training = assessment_tbl)
  baked_assessment_data_tbl &amp;lt;- bake(trained_assessment_recipe, new_data = assessment_tbl)
  
  #make a tibble with the results
  tibble(&amp;quot;id&amp;quot;         = id,
         &amp;quot;truth&amp;quot;      = baked_assessment_data_tbl$Diagnosis_Heart_Disease,
         &amp;quot;prediction&amp;quot; = unlist(predict(model, new_data = baked_assessment_data_tbl))
  )
}

#map the big function to every split obj / id in the initial cv split tbl
cv_predictions_tbl &amp;lt;- map2_df(.x = hd_cv_split_objects$splits,
                              .y = hd_cv_split_objects$id,
                              ~make_cv_predictions_fcn(split = .x, id = .y))

#see results 
cv_predictions_tbl %&amp;gt;% head(10) %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
id
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
truth
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
prediction
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#define desired metrics
desired_metrics &amp;lt;- metric_set(accuracy,
                              sens,
                              spec,
                              ppv,
                              npv,
                              f_meas)

#group by fold and use get desired metrics [metric_set fcn is from yardstick]
cv_metrics_long_tbl &amp;lt;- cv_predictions_tbl %&amp;gt;% 
                       group_by(id) %&amp;gt;% 
                       desired_metrics(truth = truth, estimate = prediction) 

#see results
cv_metrics_long_tbl %&amp;gt;% head(10) %&amp;gt;% kable(align = rep(&amp;quot;c&amp;quot;, 4))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
id
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
.metric
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
.estimator
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
.estimate
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8709677
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold02
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9354839
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold03
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8387097
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold04
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.7666667
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold06
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold07
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold08
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.7333333
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold09
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.7931034
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Fold10
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
binary
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9310345
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#visualize results
cv_metrics_long_tbl %&amp;gt;% ggplot(aes(x = .metric, y = .estimate)) +
  geom_boxplot(aes(fill = .metric), 
               alpha = .6, 
               fatten = .7) +
  geom_jitter(alpha = 0.2, width = .05) +
  labs(x = &amp;quot;&amp;quot;,
       y = &amp;quot;&amp;quot;,
       title = &amp;quot;Boxplots for Logistic Regression&amp;quot;,
       subtitle = &amp;quot;Model Metrics, 10-Fold Cross Validation&amp;quot;) +
  scale_fill_viridis_d() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1) ) +
  theme(legend.title = element_blank(),
        axis.text.x  = element_blank(),
        axis.ticks.x = element_blank()) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-29-heart-disease-prediction-from-patient-data-in-r_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#calculate the mean from all the folds for each metric
cv_mean_metrics_tbl &amp;lt;- cv_metrics_long_tbl %&amp;gt;%
                       group_by(.metric) %&amp;gt;%
                       summarize(&amp;quot;Avg&amp;quot; = mean(.estimate)) %&amp;gt;%
                       ungroup()
  
cv_mean_metrics_tbl %&amp;gt;% 
  mutate(Average = Avg %&amp;gt;% signif(digits = 3)) %&amp;gt;% 
  select(.metric,
         Average) %&amp;gt;%
  kable(align = rep(&amp;quot;c&amp;quot;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
.metric
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Average
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.837
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
f_meas
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.853
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
npv
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.852
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
ppv
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.839
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
sens
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.876
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
spec
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.790
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Got there! Average of .837 accuracy after 10-fold cross-validation. Not bad for a basic logistic regression. It is certainly possible that .837 is not sufficient for our purposes given that we are in the domain of health care where false classifications have dire consequences. Evaluating other algorithms would be a logical next step for improving the accuracy and reducing patient risk.&lt;/p&gt;
&lt;p&gt;Thanks for reading.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Image Credit: Shutterstock/Crevis&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;UCI Machine Learning Repository, &lt;a href=&#34;https://archive.ics.uci.edu/ml/datasets/Heart+Disease&#34; class=&#34;uri&#34;&gt;https://archive.ics.uci.edu/ml/datasets/Heart+Disease&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Nuclear stress testing requires the injection of a tracer, commonly technicium 99M (Myoview or Cardiolyte), which is then taken up by healthy, viable myocardial cells. A camera (detector) is used afterwards to image the heart and compare segments. A coronary stenosis is detected when a myocardial segment takes up the nuclear tracer at rest, but not during cardiac stress. This is called a “reversible defect.” Scarred myocardium from prior infarct will not take up tracer at all and is referred to as a “fixed defect.”&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/3730/pearsons-or-spearmans-correlation-with-non-normal-data&#34; class=&#34;uri&#34;&gt;https://stats.stackexchange.com/questions/3730/pearsons-or-spearmans-correlation-with-non-normal-data&lt;/a&gt;&lt;a href=&#34;#fnref4&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://notast.netlify.com/post/explaining-predictions-interpretable-models-logistic-regression/&#34; class=&#34;uri&#34;&gt;https://notast.netlify.com/post/explaining-predictions-interpretable-models-logistic-regression/&lt;/a&gt;&lt;a href=&#34;#fnref5&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2019/08/11-important-model-evaluation-error-metrics/&#34; class=&#34;uri&#34;&gt;https://www.analyticsvidhya.com/blog/2019/08/11-important-model-evaluation-error-metrics/&lt;/a&gt;&lt;a href=&#34;#fnref6&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Modeling Particulate Counts as a Poisson Process in R</title>
      <link>/post/modeling-particulate-counts-as-a-poisson-process-in-r/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/modeling-particulate-counts-as-a-poisson-process-in-r/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I’ve never really worked much with Poisson data and wanted to get my hands dirty. I thought that for this project I might combine a Poisson data set with the simple Bayesian methods that I’ve explored before since it turns out the Poisson rate parameter lambda also has a nice conjugate prior (more on that later). Poisson distributed data are counts per unit time or space - they are events that arrive at random intervals but that have a characteristic rate parameter which also equals the variance. This rate parameter is usually denoted as lambda. No-hitters in baseball are often modeled as Poisson data, as are certain types of processing defects in electronics and medical devices. A particularly relevant application is in particulate testing for implantable devices. Particulate shed is an unassuming but potentially costly and dangerous phenomenon.&lt;/p&gt;
&lt;p&gt;Particulate can be shed from the surface of medical devices even when the manufacturing environment is diligently controlled. The source of the particulate can vary: light particulate is attracted to the surface of sheaths and luers due to static charge; hydrophilic coatings may delaminate from the surface during delivery; therapeutic coating on the implant’s surface may degrade over time in the presence of blood.&lt;/p&gt;
&lt;p&gt;The clinical harms that the patient may face due to particulate shed include neurological events if the particulate migrates cranially or embolism it migrates caudally. The occurrence and severity of symptoms are understood to be functions of both size and quantity of particulate. In recent years, FDA and friends have been more stringent in requiring manufacturers to quantify and understand the nature of the particulate burden associated with their devices. In the analysis below, I’m going to simulate an experiment in which particulate data are collected for 20 devices.&lt;/p&gt;
&lt;p&gt;Before I get there, I want to remind myself of what Poisson data look like for different rate parameters. I set up a function to make a Poisson pdf based on number of events n and rate parameter lambda. The function then converts the information to a tibble for use with ggplot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Load libraries
library(tidyverse)
library(knitr)
library(kableExtra)
library(tolerance)
library(ggrepel)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Sequence from 0 to 24 by 1 (x-axis of plot)
number_of_events &amp;lt;- seq(0, 24, by = 1)

#Function to make a Poisson density vector from n and lambda, convert into tibble
pois_fcn &amp;lt;- function(lambda){
            pois_vector &amp;lt;- dpois(x = number_of_events, lambda = lambda, log = FALSE)
            pois_tbl    &amp;lt;- tibble(&amp;quot;num_of_events&amp;quot; = number_of_events,
                                  &amp;quot;prob&amp;quot;          = pois_vector,
                                  &amp;quot;lambda&amp;quot;        = lambda)
            }
#Objects to hold tibbles for different Poisson rates
pois_dist_1_tbl &amp;lt;-  pois_fcn(lambda = 1)
pois_dist_5_tbl &amp;lt;-  pois_fcn(lambda = 5)
pois_dist_15_tbl &amp;lt;- pois_fcn(lambda = 15)

#Combine in one df
pois_total_tbl &amp;lt;- bind_rows(pois_dist_1_tbl,
                            pois_dist_5_tbl,
                            pois_dist_15_tbl)

#Convert lambda front int to factor so ggplot maps aesthetics as levels, not gradient
pois_total_int_tbl &amp;lt;- pois_total_tbl %&amp;gt;% 
  mutate(lambda = as_factor(lambda))

#Make and store ggplot obj
h1 &amp;lt;- pois_total_int_tbl %&amp;gt;% ggplot(aes(x = num_of_events, y = prob)) +
  geom_col(aes(y = prob, fill = lambda), position = &amp;quot;dodge&amp;quot;, color = &amp;quot;black&amp;quot;) +
  scale_fill_manual(values = c(&amp;quot;#2C728EFF&amp;quot;, &amp;quot;#75D054FF&amp;quot;, &amp;quot;#FDE725FF&amp;quot;)) +
  labs(x        = &amp;quot;Number of Events&amp;quot;, 
       y        = &amp;quot;Probability&amp;quot;,
       title    = &amp;quot;Probability Mass Function&amp;quot;,
       subtitle = &amp;quot;Poisson Distributions with Different Rates (Lambda)&amp;quot;)

h1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-18-modeling-device-particulate-counts-as-a-poisson-process_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Cool - so when the rate is low it looks sort of like the discrete version of an exponential curve. It’s still not symmetric at lambda = 5 but by lambda = 15 it looks a lot like a binomial distribution.&lt;/p&gt;
&lt;p&gt;The data I simulate below are intended to represent the fluid collected during bench-top simulated use testing in a clean “flow loop” or vascular deployment model. The fluid would generally be passed through light obscuration censors to quantify the size and counts of particulate relative to a control. Particulate requirements for many endovascular devices are borrowed from USP &amp;lt;788&amp;gt;. According to that standard, no more than 60 particles greater than 25 micron effective diameter are acceptable. I want to know the probability of passing the test but don’t know the rate parameter lambda. The end goal is to understand what the most credible values for lambda are based on the bench-top data from multiple devices. First I’ll try to quantify the uncertainty in the rate parameter lambda. Each lambda can then be used to estimate a reliability. The large number of simulated lamdas will make a large set of simulated reliabilities. From there I should be able to extract any information needed regarding the uncertainty of the device reliability as it relates to particulate shed. That’s the plan! Note: I’m trying out knitr::kable() which generates html tables nicely. I’m not too good at it yet so bare with me please.&lt;/p&gt;
&lt;p&gt;Take a look at the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Peek at some data
particulate_data %&amp;gt;% head(5) %&amp;gt;%
  kable() %&amp;gt;% kable_styling(&amp;quot;full_width&amp;quot; = F)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
x
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
58
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
62
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I’m using a Bayesian approach again - partially because I need practice and partially because the Poisson parameter lambda has a convenient conjugate prior: the gamma distribution. This means that some simple math can get me from the prior to the posterior. I love simple math. Using the gamma distribution to describe the prior belief in lambda, the posterior distribution for lambda is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox{prior:  lambda ~ Gamma}(a, b)\]&lt;/span&gt; As a reminder to myself, this is read as “lambda is distributed as a Gamma distribution with parameters a and b”.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox{posterior:  lambda ~ Gamma}(a + \sum_{i=1}^{n} x_i\ , b + n)\]&lt;/span&gt; It is reasonable to use an relatively uninformed prior for lambda since I don’t have much preliminary knowledge about particulate data for my device design. Setting the shape a to 1 and the rate b to 0.1 provides allocates the credibility across a wide range of lambdas to start. To go from prior to posterior we need only sum up all the particulate counts in the data set and add the total to the shape a, then add the total number of devices tested (sample size n) to the rate b.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set parameters and constants
a &amp;lt;- 1
b &amp;lt;- 0.1
n &amp;lt;- length(particulate_data)
total_particulate_count &amp;lt;- sum(particulate_data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I like to peek at the prior and posterior distributions of lambda since they are easy to visualize via the relationships above. We are back into continuous distribution mode because the rate parameter lambda can be any positive value even though the particulate counts the come from the process are discrete.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set sequence of x values; generate prior using a,b; generate posterior 
x_values  &amp;lt;- seq(0, 60, length.out = 1000)
prior     &amp;lt;- dgamma(x_values, shape = 1, rate = 0.1)
posterior &amp;lt;- dgamma(x_values, shape = a + total_particulate_count, rate = b + n)

#Prior in tibble format
prior_tbl &amp;lt;- tibble(
  &amp;quot;x_values&amp;quot; = x_values,
  &amp;quot;prob&amp;quot;     = prior,
  &amp;quot;config&amp;quot;   = &amp;quot;prior&amp;quot;
)

#Posterior in tibble format
posterior_tbl &amp;lt;- tibble(
  &amp;quot;x_values&amp;quot; = x_values,
  &amp;quot;prob&amp;quot;     = posterior,
  &amp;quot;config&amp;quot;   = &amp;quot;posterior&amp;quot;
)

#Combine prior and posterior in 1 tibble
prior_post_tbl &amp;lt;- bind_rows(prior_tbl, posterior_tbl)

#Visualize 
prior_post_tbl %&amp;gt;% ggplot(aes(x = x_values, y = prob)) +
  geom_line(aes(color = config), size = 1.5, alpha = 0.8) +
  scale_y_continuous(name=&amp;quot;Density&amp;quot;, limits=c(0, 0.3)) +
  scale_color_manual(values = c(&amp;quot;#75D054FF&amp;quot;, &amp;quot;#2C728EFF&amp;quot;)) +
  labs(
    title    = &amp;quot;Rate Parameter Lambda For Particle Counts&amp;quot;,
    subtitle = &amp;quot;Modeled as Poisson Process&amp;quot;,
    x        = &amp;quot;Lambda&amp;quot;,
    color    = &amp;quot;&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-18-modeling-device-particulate-counts-as-a-poisson-process_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Having access to the posterior distribution of lambda enables simulation of possible values of lambda by drawing random values from the distributions. The probability of drawing any particular value of lambda is based on the density shown on the y-axis (although the probability of any particular point is zero; we must calculate over a span of x via integration). Each of the values randomly drawn from the posterior can be used to simulate a distribution of particulate counts for comparison with the spec. The workflow is essentially a series of questions:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;What might the values of the rate parameter lambda be based on the data? -&amp;gt; Combine data with conjugate prior to generate the posterior distribution of credible lambdas. (Done and shown above)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If a random value of lambda is pulled from the posterior distribution , what would we expect regarding the uncertainty of the original experiment? -&amp;gt; Draw random values lambda and then evaluate what percentage of the cdf lies above the spec (could also run simulations for each random lambda and then count the number of simulated runs above the spec but this is time consuming (10,000 lambdas x 10,000 simulations to build out the particle count distribution for each one…)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Combine each of these tail areas into a new distribution. This new distribution represents the uncertainty in the reliability estimate based on uncertainty in lambda. How to estimate the reliability of the real device while taking uncertainty into account? -&amp;gt; Calculate the lower bound of the 95% credible interval by finding the .05 quantile from the set of simulated reliability values.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s do this!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Sample and store 10000 random lambda values from posterior 
n_posterior_samples &amp;lt;- 10000
sampled_posterior_lambda &amp;lt;- rgamma(n_posterior_samples, shape = a + total_particulate_count, rate = b + n)

#Initialize empty vector to hold reliability data
reliability_vector &amp;lt;- rep(NA, n_posterior_samples)

#For each lambda value, calc cumulative probability of less than or equal to q particles shed from 1 sample?
for(i in 1:n_posterior_samples){
  reliability_vector[i] &amp;lt;- ppois(q = 60, lambda = sampled_posterior_lambda[i])
}

#Visualize
reliability_vector %&amp;gt;% head() %&amp;gt;% 
  kable(align=rep(&amp;#39;c&amp;#39;)) %&amp;gt;% kable_styling(&amp;quot;full_width&amp;quot; = F)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
x
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9147028
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9506510
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9431756
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9700806
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9546490
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.9540933
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Checking what the simulated reliabilities are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Convert reliability vector to tibble
reliability_tbl &amp;lt;- reliability_vector %&amp;gt;% 
  as_tibble() %&amp;gt;%
  mutate(&amp;quot;reliability&amp;quot; = value) %&amp;gt;%
  select(reliability)

#Visualize with histogram
reliability_tbl %&amp;gt;% ggplot(aes(reliability)) +
  geom_histogram(fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, binwidth = .01, alpha = 0.8) +
    labs(
        x        = &amp;quot;Reliability&amp;quot;,
        title    = &amp;quot;Estimated Reliability Range for Particulate Shed Performance&amp;quot;,
        subtitle = &amp;quot;Requirement: 60 or less of 25 um or larger&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-18-modeling-device-particulate-counts-as-a-poisson-process_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The 95% credible interval for the reliability (conformance rate) is the .05 quantile of this distribution since the spec is 1-sided:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Calculate .05 quantile
reliability_tbl$reliability %&amp;gt;% 
  quantile(probs = .05)     %&amp;gt;% 
  signif(digits = 3)    &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    5% 
## 0.893&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, the answer! The lowest reliability expected is 89.3 % based on a 95% credible interval. This would likely not meet the product requirements (assigned based on risk of the harms that come from this particular failure mode) and we would likely need to improve our design or processes to reduce particulate shed from the product.&lt;/p&gt;
&lt;p&gt;This concludes the Bayesian inference of reliability in Poisson distributed particle counts. But hey, since we’re here… one of the things I love about R is the ability to easily check sensitivities, assumptions, and alternatives easily. What would this analysis look like using the conventional frequentist approach? I admit I’m not sure exactly but I assume we would extend the standard tolerance interval approach that is common in Class III medical device submissions. Tolerance intervals are easy to pull from tables or software but actually pretty tricky (for me at least) to derive. They involve uncertainty in both the mean and the variance. For simplicity (and because I’m not confident enough to derive the formula), I’ll use the tolerance package in R to calculate tolerance intervals for Poisson data. It turns out that there are 8 methods and I’ll use them all because I’m feeling a little wild and I want to see if they result in different results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## 95%/95% 1-sided Poisson tolerance limits for future
## occurrences in a period of length 1 part. All eight methods
## are presented for comparison.
tl_tab &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;TAB&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;TAB&amp;quot;) %&amp;gt;% as_tibble() 

tl_ls &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;LS&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;LS&amp;quot;) %&amp;gt;% as_tibble() 

tl_sc &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;SC&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;SC&amp;quot;) %&amp;gt;% as_tibble() 

tl_cc &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;CC&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;CC&amp;quot;) %&amp;gt;% as_tibble()

tl_vs &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;VS&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;VS&amp;quot;) %&amp;gt;% as_tibble() 

tl_rvs &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;RVS&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;RVS&amp;quot;) %&amp;gt;% as_tibble() 

tl_ft &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;FT&amp;quot;) %&amp;gt;%mutate(method = &amp;quot;FT&amp;quot;) %&amp;gt;% as_tibble() 

tl_csc &amp;lt;- poistol.int(x = sum_part_data, n = n, m = 1, alpha = 0.05, P = 0.95,
side = 1, method = &amp;quot;CSC&amp;quot;) %&amp;gt;% mutate(method = &amp;quot;CSC&amp;quot;) %&amp;gt;% as_tibble() 

tl_all_tbl &amp;lt;-  bind_rows(tl_tab,
                         tl_ls,
                         tl_sc,
                         tl_cc,
                         tl_vs,
                         tl_rvs,
                         tl_ft,
                         tl_csc)

tl_all_tbl %&amp;gt;% kable(align=rep(&amp;#39;c&amp;#39;, 5)) &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
alpha
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
P
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
lambda.hat
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
1-sided.lower
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
1-sided.upper
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
method
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
TAB
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
LS
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
SC
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
CC
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
VS
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
RVS
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
FT
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49.15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
36
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
CSC
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For this data set it can be seen that all 8 methods produce the same 1-sided 95/95 upper tolerance interval 64 counts per device. N=60 was the requirement - since the edge of our tolerance interval lies above the 1-sided spec we would fail this test. This conclusion is consistent with the Bayesian method that estimates the reliability below the 95% requirement.&lt;/p&gt;
&lt;p&gt;But what sort of reliability claim could our data support? For the Bayesian approach we concluded that the answer was 89.3% (lower bound of 1-sided 95% credible interval). For the frequentist method, we don’t have a posterior distribution to examine. We could try using the tolerance interval function above with various values of P to impute the value of P which coincides with the spec limit of 60.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Sequence of reliability values for which to use as P 
reliability_freq_tbl &amp;lt;- tibble(
  &amp;quot;proportion_covered_P&amp;quot; = seq(.40, .99, .01)
)

#Function that is just like poistol.int but extracts and reports only the upper limit
#of the tolerance interval
tol_interval_fcn &amp;lt;- function(data_vec = sum_part_data, n=20, m=1, alpha=.05, P=.95, side=1, method=&amp;quot;TAB&amp;quot;){
  holder &amp;lt;- poistol.int(data_vec, n, m, alpha, P, side, method)
  holder_2 &amp;lt;- holder[1,5]
}

#Test the function
test_1 &amp;lt;- tol_interval_fcn(data_vec = sum_part_data, n=n, m=1, alpha = .05, P = .95, side = 1, method = &amp;quot;TAB&amp;quot;)

#Test the function
test_2 &amp;lt;- tol_interval_fcn(P = .95)

#Map the function across a vector of proportions
#Note to future self: map() arguments are: the list of values map the fn over, the fn
#itself, then all the additional arguments of the fn that you aren&amp;#39;t mapping over (odd syntax)
upper_tol_tbl &amp;lt;- reliability_freq_tbl %&amp;gt;% mutate(
  particles_per_part = map(proportion_covered_P, tol_interval_fcn, data_vec = sum_part_data, n=n, m=1, alpha = .05, side = 1, method = &amp;quot;TAB&amp;quot;) %&amp;gt;% as.integer() 
)

#View haead and tail of data
upper_tol_tbl %&amp;gt;% head(20) %&amp;gt;% kable(align=rep(&amp;#39;c&amp;#39;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
proportion_covered_P
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
particles_per_part
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.40
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.41
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.42
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.44
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.45
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.46
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.47
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.48
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.49
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.50
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.51
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.52
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.54
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.55
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
53
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.56
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
53
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.57
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
53
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.58
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
53
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.59
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
53
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;upper_tol_tbl %&amp;gt;% tail(20) %&amp;gt;% kable(align=rep(&amp;#39;c&amp;#39;, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
proportion_covered_P
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
particles_per_part
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.80
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
58
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.81
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
58
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.82
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
58
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.83
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
59
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.84
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
59
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.85
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
59
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.86
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
60
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.87
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
60
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.88
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
60
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.89
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
61
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.90
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
61
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.91
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
62
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.92
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
62
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.93
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
63
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.94
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
63
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.95
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
64
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.96
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
65
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.97
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
66
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.98
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
67
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.99
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
69
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#need this data to feed to gg_label_repel to tell it where to attach label
point_tbl &amp;lt;- tibble(x = .65, y = 60)

#visualize 
upper_tol_tbl %&amp;gt;% ggplot(aes(x = proportion_covered_P, y = particles_per_part)) +
  geom_line(color = &amp;quot;#2c3e50&amp;quot;,
            size = 2.5) +
    labs(x = &amp;quot;Estimated Reliability at .95 Confidence Level&amp;quot;,
         y = &amp;quot;Edge of 1-Sided Tolerance Interval (Particles per Device)&amp;quot;,
         title = &amp;quot;Edge of Tolerance Interval vs. Specified Reliability&amp;quot;,
         subtitle = &amp;quot;95% Confidence Level Using TAB Tolerance Technique&amp;quot;) +
  scale_y_continuous(breaks = seq(40, 70, 5)) +
  geom_vline(xintercept = .88) +
  geom_hline(yintercept = 60) +
  geom_point(x = .65, y = 60, size = 0, alpha = 0) +
  geom_label_repel(data = point_tbl, aes(x, y), 
                   label = &amp;quot;Spec Limit: 60 Particles Max&amp;quot;,
                   fill = &amp;quot;#2c3e50&amp;quot;, 
                   color = &amp;quot;white&amp;quot;,
                   segment.color = &amp;quot;#2c3e50&amp;quot;,
                   segment.size = 1,
                   min.segment.length = unit(1, &amp;quot;lines&amp;quot;),
                   nudge_y = 2,
                   nudge_x = .05)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-18-modeling-device-particulate-counts-as-a-poisson-process_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here’s a plot that I’ve never made or seen before. For given set of data (in this case: particulate_data from earlier with n=20 from a Poisson distribution, lambda = 50), the x-axis shows the estimated reliability and the y-axis represents the number of particles at the edge the calculated tolerance interval using the TAB method. That is to say: the standard approaches to calculate the edge of the relevant tolerance interval for a specified proportion at a specified confidence level. For example, we could state we want to know the estimate for the 95th percentile at 95% confidence level - the answer would be 64 particles per device. Since the requirement for clinical safety is set at 60 particles max, we would not pass the test because we could not state with high confidence that 95 or more (out of 100) would pass. Usually it’s just a binary pass/fail decision.&lt;/p&gt;
&lt;p&gt;It’s obvious that the 95/95 edge of the tolerance interval is out of spec… but what would be the greatest reliability we could claim at 95% confidence? It ends up being .88 or 88% - very close to the predicted lower bound of the 95% credible interval calculated from the Bayesian method (which was 89.3%, from above)! In this case, the frequentist and Bayesian methods happen to be similar (even though they aren’t measuring the same thing). Interesting stuff!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stopping Rules for Significance Testing in R</title>
      <link>/post/stopping-rules-for-significance-testing-in-r/</link>
      <pubDate>Fri, 06 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/stopping-rules-for-significance-testing-in-r/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;When doing comparative testing it can be tempting to stop when we see the result that we hoped for. In the case of null hypothesis significance testing (NHST), the desired outcome is often a p-value of &amp;lt; .05. In the medical device industry, bench top testing can cost a lot of money. Why not just recalculate the p-value after every test and stop when the p-value reaches .05? The reason is that the confidence statement attached to your testing is only valid for a specific stopping rule. In other words, to achieve the desired false positive rate we must continue testing speciments until the pre-determined sample size is reached. Evaluating the p-value as you proceed through the testing is known as “peeking” and it’s a statistical no-no.&lt;/p&gt;
&lt;p&gt;Suppose we are attempting to demonstrate that a raw material provided by a new vendor results in better corrosion resistance in finished stents relative to the standard supplier. A bench top test is set up to measure the breakdown potential of each sample in a cyclic potentiodynamic polarization (CPP) test. Our goal is to compare the means of the CPP data from the old supplier and the new supplier. The null hypothesis is that the means are equivalent and if the t-test results in a p-value of .05 or lower then we will reject the null and claim improved performance. What happens to the p-value over the course of the testing? We can run a simulation to monitor the p-value and calculate the effect of peeking on the long-term false positive rate. For the test to perform as intended, the long-term false positive rate should be controlled at a level equal to (1 - confidence level).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(knitr)
library(kableExtra)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, initialize the objects to hold the data and establish any constants we might need later.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Initial offset constant to keep minimum group size at n=6
INITIAL_OFFSET &amp;lt;- 5

#Initial values for number of inner and outer loop iterations
n_inner_loop &amp;lt;- 50
n_inner_data &amp;lt;- n_inner_loop + INITIAL_OFFSET
n_outer &amp;lt;- 100

#Initialize empty vector to store p values
store_p_values_vec &amp;lt;- rep(NA, n_inner_loop)

#Initialize a tibble with placeholder column
many_runs_tbl &amp;lt;-  tibble(
  V1 = rep(NA,  n_inner_loop)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The simulation requires 2 for loops. The inner loop performs a series of t-test adding 1 more experimental observation to each group after each iteration. The p-value for that iteration is extracted and stored. In the outer loop, the initial data for the 2 groups are generated randomly from normal distributions. Since we can’t really run a t-test on groups with very low sample sizes, we use an initial offset value so that the t-test loops don’t start until both groups have a few observations from which to calculate the means.&lt;/p&gt;
&lt;p&gt;The p-value for a traditional t-test should be an indication of the long-term false positive rate. In other words: if we ran a t-test on samples drawn from 2 identical populations many times we would see a few large differences in means simply due to chance draws. Among all such simulations, the value at the 95% quantile represents the p-value of .05.&lt;/p&gt;
&lt;p&gt;We can gut-check our simulation in this way by setting the two populations identical to each other and drawing random values in the outer loop as mentioned above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set seed for repeatability
set.seed(1234)

#Outer loop: replicates a t-test between 2 groups
for(l in 1:n_outer) {
    
    #Generate simulated data for each group.  The parameters are set the same to represent 1 population
    example_group_1 &amp;lt;- rnorm(n = n_inner_data, mean = 10, sd = 4)
    example_group_2 &amp;lt;- rnorm(n = n_inner_data, mean = 10, sd = 4)
    
    #Inner loop: subset the first (i + initial offset) values from grp 1 and grp 2 (y)
    #Perform t-test, extract p-value, store in a vector
    #Increment each group&amp;#39;s size by 1 after each iteration
    for (i in 1:n_inner_loop) {
    t_test_obj &amp;lt;- t.test(x = example_group_1[1:(INITIAL_OFFSET + i)], y = example_group_2[1:(INITIAL_OFFSET + i)])
    store_p_values_vec[i] = t_test_obj$p.value
  }
  
    #Store each vector of n_inner_loop p-values to a column in the many_runs_tbl
    many_runs_tbl[,l] &amp;lt;- store_p_values_vec
}

#visualize tibble 
many_runs_tbl[,1:12] %&amp;gt;% 
  signif(digits = 3) %&amp;gt;%
  head(10) %&amp;gt;% 
  kable(align=rep(&amp;#39;c&amp;#39;, 100))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V1
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V2
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V3
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V4
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V5
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V6
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V7
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V8
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V9
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V10
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V11
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
V12
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3960
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0990
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.204
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.412
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0686
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1450
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.894
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.360
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.721
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.897
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0535
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.668
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1700
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0628
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.106
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.951
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2240
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0834
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.802
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.614
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.750
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.886
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3170
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.517
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1410
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0929
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.057
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.618
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1360
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0296
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.499
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.561
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.846
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.809
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1740
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.410
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1560
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.4050
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.146
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.800
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1690
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0625
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.724
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.700
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.857
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.687
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3620
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.338
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1140
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2610
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.104
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.992
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2550
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1860
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.548
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.846
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.727
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.911
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.4270
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.334
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0540
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3400
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.143
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.889
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3180
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1740
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.775
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.768
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.795
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.666
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.5630
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.229
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0693
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.4030
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.125
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.871
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.7340
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0757
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.826
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.792
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.704
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.755
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.4810
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.694
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0324
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.4050
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.181
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.930
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8630
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0617
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.738
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.564
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.501
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.611
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3930
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.472
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0206
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.4550
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.112
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.912
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.7560
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0958
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.644
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.708
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.265
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.687
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2520
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.638
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0294
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.6690
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.103
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.777
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.8680
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1700
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.664
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.703
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.284
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.912
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2450
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.441
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Each column above represents n=50 p-values, with each successive value calculated after observing the newest data point in the simulated test sequence. These are the p-values we see if we peek at the calculation every time.&lt;/p&gt;
&lt;p&gt;We need to convert data into tidy format for better visualization. In the tidy format, every column should be a unique variable. The gather() function converts data from wide to long by adding a new variable called “rep_sim_number” and combining all the various runs from 1 to 100 in a single column. In total, we’ll have only 3 columns in the tidy version.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#add new column with row id numbers
final_runs_tbl &amp;lt;- many_runs_tbl %&amp;gt;% 
    mutate(row_id = row_number()) %&amp;gt;%
    select(row_id, everything())

#convert from wide format (untidy) to long (tidy) using gather()
final_runs_tidy_tbl &amp;lt;- final_runs_tbl %&amp;gt;% gather(key = &amp;quot;rep_sim_number&amp;quot;, value = &amp;quot;p_value&amp;quot;, -row_id)

#visualize tidy data structure
final_runs_tidy_tbl %&amp;gt;% 
  head(10) %&amp;gt;% 
  kable(align=rep(&amp;#39;c&amp;#39;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
row_id
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
rep_sim_number
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p_value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3963352
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1704697
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1414021
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1557261
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1141854
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0539595
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0693410
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0324232
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0205511
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0293952
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;final_runs_tidy_tbl %&amp;gt;% 
  tail(10) %&amp;gt;% 
  kable(align=rep(&amp;#39;c&amp;#39;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
row_id
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
rep_sim_number
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p_value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
41
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0515933
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0509430
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
43
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0386845
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
44
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0567804
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0762953
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0933081
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
47
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0755494
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0558263
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0731072
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
50
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0496300
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;From here it is straightforward to visualize the trajectory of the p-values through the course of the testing for all 100 simulations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#visualize history of n_outer p-values across n_inner_loop consecutive data points as lineplot
lp_1 &amp;lt;- final_runs_tidy_tbl %&amp;gt;% ggplot(aes(x = row_id, y = p_value, group = rep_sim_number)) +
  geom_line(show.legend = &amp;quot;none&amp;quot;,
            color       = &amp;quot;grey&amp;quot;,
            alpha       = 0.7) +
  labs(x        = &amp;quot;Sequential Benchtop Test Observations&amp;quot;,
       title    = &amp;quot;P-Value History for Difference in Means, Standard T-Test&amp;quot;,
       subtitle = &amp;quot;Both Groups Sampled From Same Population&amp;quot;
       )

lp_1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-06-stopping-rules-for-significance-testing_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The p-values are all over the place! It makes sense that at the pre-determined stopping point (n=50) we would have a spread of p-values since the population parameters for the two groups were identical and p should only rarely land below .05. However, this visualization makes it clear that prior to the stopping point, the path of any particular p-value fluctuates wildly. This is the reason why we can’t stop early or peek!&lt;/p&gt;
&lt;p&gt;Let’s take a look at the false positives, defined here as the runs where the p-value ended up less than or equal to .05 at the pre-determined stopping point of n=50.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#filter for runs that ended in false positives (p &amp;lt; .05) at the last data point
filtered_endpoint_tbl &amp;lt;- final_runs_tidy_tbl %&amp;gt;% 
    filter(row_id == 50,
           p_value &amp;lt;= 0.05) %&amp;gt;%
    select(rep_sim_number) %&amp;gt;%
    rename(&amp;quot;false_positives&amp;quot; = rep_sim_number)

filtered_endpoint_tbl %&amp;gt;% 
  head(10) %&amp;gt;% 
  kable(align=&amp;#39;c&amp;#39;) %&amp;gt;%
  kable_styling(full_width = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
false_positives
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V23
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V48
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V54
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V77
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V86
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V89
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V100
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So 8 out of 100 simulations have p-values &amp;lt; .05. This is about as expected since the long term false positive rate should be 5%. Having now identified the false positives, we can visualize the trajectory of their p-values after obtaining each successive data point. This is what happens when we peek early or stop the test when we first see a desired outcome. The following code pulls the full history of the false positive test sequences so we can see their paths before the stopping point.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#extract full false positive test histories.  %in% filters rows that match anything in the false_positives vector
full_low_runs_tbl &amp;lt;- final_runs_tidy_tbl %&amp;gt;%
    filter(rep_sim_number %in% filtered_endpoint_tbl$false_positives)

#visualize trajectory of false positives by highlighting their traces
lp_2 &amp;lt;- final_runs_tidy_tbl %&amp;gt;% 
    ggplot(aes(x = row_id, y = p_value, group = rep_sim_number)) +
    geom_line(alpha = 0.7, show.legend = FALSE, color = &amp;quot;grey&amp;quot;) +
    geom_line(aes(color = rep_sim_number), data = full_low_runs_tbl, show.legend = FALSE, size = .8, alpha = 0.7) +
    labs(x       = &amp;quot;Sequential Benchtop Test Observations&amp;quot;,
        title    = &amp;quot;P-Value History for Difference in Means, Standard T-Test&amp;quot;,
        subtitle = &amp;quot;Highlighted Traces Represent Sequences with p &amp;lt; .05 at n=50&amp;quot;
        )

lp_2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-06-stopping-rules-for-significance-testing_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt; Indeed, the p-values that end up less than .05 do not take a straight line path to get there. Likewise, there may be tests that dip below p=.05 at some point but culminate well above .05 at the pre-determined stopping point. These represent additional false-positives we invite when we peek or stop early. Let’s identify and count these:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#filter for all run who&amp;#39;s p-value ever dipped to .05 or lower at any point 
low_p_tbl &amp;lt;- final_runs_tidy_tbl %&amp;gt;% 
    filter(p_value &amp;lt;= .05) %&amp;gt;% 
    distinct(rep_sim_number)

#visualize
low_p_tbl %&amp;gt;% 
  head(10) %&amp;gt;% 
  kable(align=&amp;#39;c&amp;#39;) %&amp;gt;% 
  kable_styling(full_width = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
rep_sim_number
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V6
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V7
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V16
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V17
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V20
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V21
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V23
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V30
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V33
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#count total number of false positives with peeking
low_p_tbl %&amp;gt;% nrow() %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;) %&amp;gt;% 
  kable_styling(full_width = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
x
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
37
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The false positives go from 8 to 37!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#filter for only the rows where rep_sim_number here matches at least 1 value from low_p_tbl$rep_sim_number
#this extracts the full history of runs who&amp;#39;s p-value dipped to .05 or lower at any point 
any_low_runs_tbl &amp;lt;- final_runs_tidy_tbl %&amp;gt;%
    filter(rep_sim_number %in% low_p_tbl$rep_sim_number)

#visualize
any_low_runs_tbl %&amp;gt;% 
  head(10) %&amp;gt;% 
  kable(align = rep(&amp;quot;c&amp;quot;, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
row_id
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
rep_sim_number
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p_value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.3963352
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1704697
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1414021
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1557261
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1141854
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0539595
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0693410
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0324232
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0205511
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
V1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0293952
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#visualize the trajectory or runs that dipped to .05 or below
lp_3 &amp;lt;- final_runs_tidy_tbl %&amp;gt;% 
    ggplot(aes(x = row_id, y = p_value, group = rep_sim_number)) +
    geom_line(alpha = 0.7, show.legend = FALSE, color = &amp;quot;grey&amp;quot;) +
    geom_line(aes(color = rep_sim_number), data = any_low_runs_tbl, show.legend = FALSE, size = .8, alpha = 0.7) +
    labs(x       = &amp;quot;Sequential Benchtop Test Observations&amp;quot;,
        title    = &amp;quot;P-Value History for Difference in Means, Standard T-Test&amp;quot;,
        subtitle = &amp;quot;Highlighted Runs Represent p &amp;lt; .05 at Any Point&amp;quot;
        )

lp_3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-06-stopping-rules-for-significance-testing_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;All these differences in means would be considered significant if we don’t observe our pre-determined stopping rule. This could be a big deal. We might claim a performance benefit when there is none, or waste precious time and money trying to figure out why we can’t replicate an earlier experiment!&lt;/p&gt;
&lt;p&gt;Thanks for reading.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Assessing Design Verification Risk with Bayesian Estimation in R</title>
      <link>/post/assessing-dv-risk-w-bayesian-estimation-in-r/</link>
      <pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/assessing-dv-risk-w-bayesian-estimation-in-r/</guid>
      <description>


&lt;p&gt;Suppose our team is preparing to freeze a new implant design. In order to move into the next phase of the PDP, it is common to perform a suite of formal “Design Freeze” testing. If the results of the Design Freeze testing are acceptable, the project can advance from Design Freeze (DF) into Design Verification (DV). DV is an expensive and resource intensive phase culminating in formal reports that are included in the regulatory submission. One key goal of DF is therefore to burn down enough risk to feel confident going into DV. Despite the high stakes, I haven’t ever seen a quantitative assessment of residual risk at the phase review. In this post we’ll attempt to use some simple Bayesian methods to quantify the DV risk as a function of DF sample size for a single, high-risk test.&lt;/p&gt;
&lt;p&gt;Consider the requirement for accelerated durability (sometimes called fatigue resistance). In this test, the device is subjected to cyclic loading for a number of cycles equal to the desired service life. For 10 years of loading due to systolic - diastolic pressure cycles, vascular implants must survive approximately 400 million cycles. Accelerated durability is usually treated as attribute type data because the results can be only pass (if no fractures observed) or fail (if fractures are observed). Each test specimen can therefore be considered a Bernoulli trial and the number of passing units in n samples can be modeled with the binomial.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/fatigue.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;How many samples should we include in DF? We’ll set up some simulations to find out. In order to incorporate the outcome of the DF data into a statement about the probability of success for DV, we’ll need to apply Bayesian methods.&lt;/p&gt;
&lt;p&gt;First, load the libraries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(cowplot)
library(gghighlight)
library(knitr)
library(kableExtra)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The simulation should start off before we even execute Design Freeze testing. If we’re going to use Bayesian techniques we need to express our uncertainty about the parameters in terms of probability. In this case, the parameter we care about is the reliability. Before seeing any DF data we might know very little about what the true reliability is for this design. If we were asked to indicate what we thought the reliability might be, we should probably state a wide range of possibilities. The design might be good but it might be quite poor. Our belief about the reliability before we do any testing at all is called the prior and we expess it as a probability density function, not a point estimate. We need a mathematical function to describe how we want to spread out our belief in the true reliability.&lt;/p&gt;
&lt;p&gt;The beta is a flexible distribution that can be adjusted to take a variety of different forms. By tweaking the two shape factors of the beta we can customize the probability density curve in many different ways. If we were super confident that every part we ever made would pass the durability testing, we could put a “spike” prior right on 1.0. This is like saying “there’s no way any part could ever fail”. But the whole point is to communicate uncertainty and in reality there is always a chance the reliability might only be 97%, or 94%, etc. Since we haven’t really seen any DF data, we should probably drop some of our credibility into many different possible values of the reliability. Let’s be very conservative here and just use the flat prior. By evenly binning all of our credibility across the full range of reliability from 0 to 1, we’re saying we don’t want our pre-conceived notions to influence the final estimated reliability much. We’ll instead use the DF data themselves to re-allocate the credibility across the range of reliabilities appropriately according to Bayes’ rule after looking at the Design Freeze results. The more DF data we observe, the more precise the posterior estimate.&lt;/p&gt;
&lt;p&gt;The mathematical way to turn the beta distribution into a straight line (flat prior) is to set the shape parameters alpha and beta to (1,1). Note the area under the curve must always sum to 1. The image on the left shows a flat prior generated from a beta density with parameters (1,1).&lt;/p&gt;
&lt;p&gt;Another way to display the prior is to build out the visualization manually by drawing random values from the beta(1,1) distribution and constructing a histogram. This method isn’t terribly useful since we already know the exact distribution we want to use but I like to include it to emphasize the idea of “binning” the credibility across different values of reliability. It’s also nice to see the uncertainty we might see when we start to randomly draw from the distribution (full disclosure: I also just to practice my coding).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Plot flat prior using stat_function and ggplot
p_1 &amp;lt;- tibble(x_canvas=c(0,1)) %&amp;gt;% ggplot(aes(x=x_canvas)) +
    stat_function(fun   = dbeta,
                  args  = list(1, 1),
                  color = &amp;quot;#2c3e50&amp;quot;, 
                  size  = 1,
                  alpha = .8) +
    ylim(c(0,1.5)) +
    labs(
        y = &amp;quot;Density of Beta&amp;quot;,
        x = &amp;quot;Reliability&amp;quot;,
        title = &amp;quot;Credibility Allocation, Start of DF&amp;quot;,
        subtitle = &amp;quot;Uninformed Prior with Beta (1,1)&amp;quot;
    )

#Set the number of random draws from beta(1,1) to construct histogram flat prior
set.seed(123)
n_draws &amp;lt;- 100000

#Draw random values from beta(1,1), store in object
prior_dist_sim &amp;lt;- rbeta(n = n_draws, shape1 = 1, shape2 = 1)

#Convert from vector to tibble
prior_dist_sim_tbl &amp;lt;- prior_dist_sim %&amp;gt;% as_tibble()

#Visualize with ggplot
p_2 &amp;lt;- prior_dist_sim_tbl %&amp;gt;% ggplot(aes(x = value)) +
    geom_histogram(
        boundary = 1, 
        binwidth = .05, 
        color    = &amp;quot;white&amp;quot;,
        fill     = &amp;quot;#2c3e50&amp;quot;,
        alpha    = 0.8
        ) +
    xlim(c(-0.05, 1.05)) +
    ylim(c(0, 7500)) +
    labs(
        y = &amp;quot;Count&amp;quot;,
        title = &amp;quot;Credibility Simulation , Start of DF&amp;quot;,
        subtitle = &amp;quot;Uninformed Prior with Beta (1,1)&amp;quot;,
        x = &amp;quot;Reliability&amp;quot;
    
    ) 

plot_grid(p_1,p_2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-23-assessing-dv-risk-w-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;OK now the fun stuff. There is a cool, mathematical shortcut we can take to combine our simulated Design Freeze data with our flat prior to create the posterior distribution. It’s very simple: we just add the number of passing DF units to our alpha parameter and the number of failing DF units to our beta parameter. The reason why this works so well is beyond the scope of this post, but the main idea is that when the functional form of the prior (beta function in our case) is similar to the functional form of the likelihood function (Bernoulli in our case), then you can multiply them together easily and the product also takes a similar form. When this happens, the prior is said to be the “conjugate prior” of the likelihood function &lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; The beta and binomial are a special case that go together like peanut butter and jelly.&lt;/p&gt;
&lt;p&gt;Again, to understand how our belief in the reliability should be allocated after observing the DF data, all we need to do is update the beta function by adding the number of passing units from DF testing to alpha (Shape1 parameter) and the number of failing units to beta (Shape2 parameter).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox{Beta}(\alpha_0+\mbox{passes}, \beta_0+\mbox{fails})\]&lt;/span&gt; We’re going to assume all units pass DF, so we only need to adjust the alpha parameter. The resulting beta distribution that we get after updating the alpha parameter represents our belief in where the true reliability may lie after observing the DF data. Remember, even though every unit passed, we can’t just say the reliability is 100% because we’re smart enough to know that if the sample size was, for example, n=15 - there is a reasonable chance that a product with true reliability of 97% could run off n=15 in a row without failing. Even 90% reliability might hit 15 straight every once in a while but it would be pretty unlikely.&lt;/p&gt;
&lt;p&gt;The code below looks at four different possible sample size options for DF: n=15, n=30, n=45, and a full n=59 (just like we plan for DV).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Draw radomly from 4 different beta distributions. Alpha parameter is adjusted based on DF sample size
posterior_dist_sim_15 &amp;lt;- rbeta(n_draws, 16, 1)
posterior_dist_sim_30 &amp;lt;- rbeta(n_draws, 31, 1)
posterior_dist_sim_45 &amp;lt;- rbeta(n_draws, 46, 1)
posterior_dist_sim_59 &amp;lt;- rbeta(n_draws, 60, 1)

#Function to convert vectors above into tibbles and add column for Sample Size 
pds_clean_fcn &amp;lt;- function(pds, s_size){
    pds %&amp;gt;% as_tibble() %&amp;gt;% mutate(Sample_Size = s_size) %&amp;gt;%
    mutate(Sample_Size = factor(Sample_Size, levels = unique(Sample_Size)))}

#Apply function to 4 vectors above
posterior_dist_sim_15_tbl &amp;lt;- pds_clean_fcn(posterior_dist_sim_15, 15)
posterior_dist_sim_30_tbl &amp;lt;- pds_clean_fcn(posterior_dist_sim_30, 30)
posterior_dist_sim_45_tbl &amp;lt;- pds_clean_fcn(posterior_dist_sim_45, 45)
posterior_dist_sim_59_tbl &amp;lt;- pds_clean_fcn(posterior_dist_sim_59, 59)

#Combine the tibbles in a tidy format for visualization
full_post_df_tbl &amp;lt;- bind_rows(
            posterior_dist_sim_15_tbl,
            posterior_dist_sim_30_tbl, 
            posterior_dist_sim_45_tbl, 
            posterior_dist_sim_59_tbl
            )

#Visualize with density plot
df_density_plt &amp;lt;- full_post_df_tbl %&amp;gt;% ggplot(aes(x = value, fill = Sample_Size)) +
    geom_density(alpha = .6) +
    xlim(c(0.85,1)) +
    labs(x = &amp;quot;&amp;quot;,
         y = &amp;quot;Density of Beta&amp;quot;,
         title = &amp;quot;Credibility Simulation, After Design Freeze&amp;quot;,
         subtitle = &amp;quot;Updated Belief Modeled with Beta(1 + n,1)&amp;quot;) +
    scale_fill_manual(values = c(&amp;quot;#2C728EFF&amp;quot;, &amp;quot;#20A486FF&amp;quot;, &amp;quot;#75D054FF&amp;quot;, &amp;quot;#FDE725FF&amp;quot;)) 

#Visualize with histogram 
df_hist_plt &amp;lt;- full_post_df_tbl %&amp;gt;% ggplot(aes(x = value, fill = Sample_Size)) +
    geom_histogram(alpha = .9,
                   position = &amp;quot;dodge&amp;quot;,
                   boundary = 1,
                   color = &amp;quot;black&amp;quot;) +
    xlim(c(0.85,1)) +
    labs(x = &amp;quot;Reliability&amp;quot;,
         y = &amp;quot;Count&amp;quot;) +
    scale_fill_manual(values = c(&amp;quot;#2C728EFF&amp;quot;, &amp;quot;#20A486FF&amp;quot;, &amp;quot;#75D054FF&amp;quot;, &amp;quot;#FDE725FF&amp;quot;))

plot_grid(df_density_plt, df_hist_plt, ncol = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-23-assessing-dv-risk-w-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we unpack these charts a bit, we can see that if we only do n=15 in Design Freeze, we still need to allocate some credibility to reliability parameters below .90. For a full n=59, anything below .95 reliability is very unlikely, yet the 59 straight passing units could have very well come from a product with reliability = .98 or .97.&lt;/p&gt;
&lt;p&gt;We now have a good feel for our uncertainty about the reliability after DF, but what we really want to know is our likelihood of passing Design Verification. To answer this question, we’ll extend our simulation to perform many replicates of n=59 Bernoulli trials, each representing a round of Design Verification testing. The probability of failure will be randomly drawn from the distributions via Monte Carlo. Let’s see how many of these virtual DV tests end with 59/59 passing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Perform many sets of random binom runs, each with n=59 trials. p is taken from the probs previously generated 
DV_acceptable_units_15 &amp;lt;- rbinom(size = 59, n = n_draws, 
                                 prob = (posterior_dist_sim_15_tbl$value))
DV_acceptable_units_30 &amp;lt;- rbinom(size = 59, n = n_draws, 
                                 prob = (posterior_dist_sim_30_tbl$value))
DV_acceptable_units_45 &amp;lt;- rbinom(size = 59, n = n_draws, 
                                 prob = (posterior_dist_sim_45_tbl$value))
DV_acceptable_units_59 &amp;lt;- rbinom(size = 59, n = n_draws, 
                                 prob = (posterior_dist_sim_59_tbl$value))

#Function to convert vectors to tibbles and add col for sample size
setup_fcn &amp;lt;- function(vec, ss){
    vec %&amp;gt;% as_tibble() %&amp;gt;% mutate(DF_Sample_Size = ss) %&amp;gt;%
    mutate(DF_Sample_Size = factor(DF_Sample_Size, levels = unique(DF_Sample_Size)))}

#Apply function
DV_acceptable_units_15_tbl &amp;lt;- setup_fcn(DV_acceptable_units_15, 15)
DV_acceptable_units_30_tbl &amp;lt;- setup_fcn(DV_acceptable_units_30, 30)
DV_acceptable_units_45_tbl &amp;lt;- setup_fcn(DV_acceptable_units_45, 45)
DV_acceptable_units_59_tbl &amp;lt;- setup_fcn(DV_acceptable_units_59, 59)

#Combine the tibbles in a tidy format for visualization
DV_acceptable_full_tbl &amp;lt;- bind_rows(DV_acceptable_units_15_tbl,
                                    DV_acceptable_units_30_tbl,
                                    DV_acceptable_units_45_tbl,
                                    DV_acceptable_units_59_tbl)

#Visualize with ggplot.  Apply gghighlight where appropriate
g1 &amp;lt;- DV_acceptable_full_tbl %&amp;gt;%
   ggplot(aes(x = value)) +
   geom_histogram(aes(fill = DF_Sample_Size),binwidth = 1, color = &amp;quot;black&amp;quot;, position = &amp;quot;dodge&amp;quot;, alpha = .9) +
    xlim(c(45, 60)) +
    scale_x_continuous(limits = c(45, 60), breaks=seq(45, 60, 1)) +
    scale_fill_manual(values = c(&amp;quot;#2C728EFF&amp;quot;, &amp;quot;#20A486FF&amp;quot;, &amp;quot;#75D054FF&amp;quot;, &amp;quot;#FDE725FF&amp;quot;)) +
    labs(
        x = &amp;quot;Passing Parts out of 59 total&amp;quot;,
        title = &amp;quot;Simulated Design Verification Testing&amp;quot;,
        subtitle = &amp;quot;100,000 Simulated DV Runs of n=59&amp;quot;
    )

g2 &amp;lt;- g1 +
    gghighlight(value == 59, use_direct_label = FALSE) +
    labs(
        title = &amp;quot;Simulations that PASSED Design Verification&amp;quot;
     )
    
g3 &amp;lt;- g1 +
    gghighlight(value &amp;lt; 59, use_direct_label = FALSE) +
    labs(
        title = &amp;quot;Simulations that FAILED Design Verification&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-23-assessing-dv-risk-w-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;img src=&#34;/post/2019-08-23-assessing-dv-risk-w-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;img src=&#34;/post/2019-08-23-assessing-dv-risk-w-bayesian-estimation-in-r_files/figure-html/unnamed-chunk-5-3.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Taking into consideration the uncertainty of the true reliability after the DF testing, the percentage of times we expect to pass Design Verification is shown below. These percentages are calculated as the number of simulated DV runs that achieved 59/59 passing units divided by the total number of simulated DV runs. Any simulation with 58 or less passing units would have failed DV.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox{expected probability of passing DV  = (number of sims with n=59 pass) / (total sims) }\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Function to calculate how many DV simulations resulted in 59/59 passing units
pct_pass_fct &amp;lt;- function(tbl, n){
    pct_dv_pass &amp;lt;- tbl %&amp;gt;% filter(value == 59) %&amp;gt;% nrow() / n_draws
    paste(&amp;quot;DF with n = &amp;quot;,n, &amp;quot;(all pass): &amp;quot;, pct_dv_pass %&amp;gt;% scales::percent(), &amp;quot;expected probability of next 59/59 passing DV&amp;quot;)}&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
DF with n = 15 (all pass): 21.3% expected probability of next 59/59 passing DV
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
DF with n = 30 (all pass): 34.5% expected probability of next 59/59 passing DV
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
DF with n = 45 (all pass): 43.5% expected probability of next 59/59 passing DV
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
DF with n = 59 (all pass): 50.3% expected probability of next 59/59 passing DV
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The percentage of time we expect to pass Design Verification is shockingly low! Even when we did a full n=59 in Design Freeze, we still only be able to predict 50% success in DV! This is because even with 59/59 passes, we still must account for the possibility that the reliability isn’t 100%. We don’t have enough DF data to shift the credibility all the way near 100%, and when the credibility is spread to include possible reliabilities in the mid .90’s we should always be prepared for the possibility of failing Design Verification.&lt;/p&gt;
&lt;p&gt;We could just leave it at that but I have found that when discussing risk, stakeholders want more than just an estimation of the rate of bad outcomes. They want a recommendation and a mitigation plan. Here are a few ideas; can you think of any more?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Maintain multiple design configurations as long as possible (often not feasible, but provides an out if 1 design fails)&lt;/li&gt;
&lt;li&gt;Perform durability testing as “fatigue-to-failure”. In this methodology, the devices are run to failure and the cycles to failure are treated as variable data. By varying the amplitude of the loading cycles, we can force the devices to fail and understand the uncertainty within the failure envelope. &lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Fold in information from pre-DF testing, predicate testing, etc to inform the prior better. I will look at the sensitivity of the reliability estimations to the prior in a future post.&lt;/li&gt;
&lt;li&gt;Build redundant design cycles into the project schedule to accomodate additional design turns without falling behind the contracted timeline&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Kruschke, Doing Bayesian Data Analysis, &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34; class=&#34;uri&#34;&gt;https://sites.google.com/site/doingbayesiandataanalysis/&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Fatigue-to Fracture ASTM Standard: &lt;a href=&#34;https://www.astm.org/Standards/F3211.htm&#34; class=&#34;uri&#34;&gt;https://www.astm.org/Standards/F3211.htm&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Permutation Test for NHST of 2 Samples in R</title>
      <link>/post/permutation-test-for-nhst-of-2-samples-in-r/</link>
      <pubDate>Sat, 10 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/permutation-test-for-nhst-of-2-samples-in-r/</guid>
      <description>


&lt;p&gt;As engineers, it is not uncommon to be asked to determine whether or not two different configurations of a product perform the same. Perhaps we are asked to compare the durability of a next-generation prototype to the current generation. Sometimes we are testing the flexibility of our device versus a competitor for marketing purposes. Maybe we identify a new vendor for a raw material but must first understand whether the resultant finished product will perform any differently than when built using material from the standard supplier. All of these situations call for a comparison between two groups culminating in a statistically supported recommendation.&lt;/p&gt;
&lt;p&gt;There are a lot of interesting ways to do this: regions of practical equivalence, Bayes Factors, etc. The most common method is still null hypothesis significance testing (NHST) and that’s what I want to explore in this first post. Frequentist methods yield the least useful inferences but have the advantage of a long usage history. Most medical device professionals will be looking for a p-value, so a p-value we must provide.&lt;/p&gt;
&lt;p&gt;In NHST, the plan is usually to calculate a test statistic from our data and use a table of reference values or a statistical program to tell us how surprising our derived statistic would be in a world where the null hypothesis was true. We generally do this by comparing our statistic to a reference distribution or table of tabulated values. Unfortunately, whenever our benchtop data violates an assumption of the reference model, we are no longer comparing apples-to-apples. We must make tweaks and adjustments to try to compensate. It is easy to get overwhelmed in a decision tree of test names and use cases.&lt;/p&gt;
&lt;p&gt;A more robust and intuitive approach to NHST is to replace the off-the-shelf distributions and tables with a simulation built right from our dataset. The workflow any such test is shown below. &lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/workflow.png&#34; width=&#34;75%&#34; height=&#34;75%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The main difference here is that we create the distribution of the data under the null hypothesis using simulation instead of relying on a reference distribution. It’s intuitive, powerful, and fun.&lt;/p&gt;
&lt;p&gt;Imagine we have just designed a benchtop experiment in which we intend to measure the pressure (in mm Hg) at which a pair of overlapped stent grafts started to migrate or disconnect when deployed in a large thoracic aneurysm. &lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/./img/migration_model.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A common null hypothesis for comparing groups is that there is no difference between them. Under this model, &lt;strong&gt;we can treat all the experimental data as one big group instead of 2 different groups&lt;/strong&gt;. We therefore pool the data from our completed experiment into one big group, shuffle it, and randomly assign data points into two groups of the original size. This is our generative model. After each round of permutation and assignment, we calculate and store the test statistic for the observed effect (difference in means between the two groups). Once many simulations have been completed, we’ll see where our true data falls relative to the virtual data.&lt;/p&gt;
&lt;p&gt;One way to setup and execute a simulation-based NHST for comparing two groups in R is as follows (note: there are quicker shortcuts to executing this type of testing but the long version below allows for customization, visualization, and adjust-ability):&lt;/p&gt;
&lt;p&gt;First, we read in the libraries and transcribe the benchtop data into R and evaluate sample size&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(cowplot)
library(knitr)
library(kableExtra)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Migration pressure for predicate device
predicate &amp;lt;-  c(186, 188, 189, 189, 192, 193, 194, 194, 194, 195, 195, 196, 196, 197, 197, 198, 198, 199, 199, 201, 206, 207, 210, 213, 216, 218)

#Migration pressure for next_gen device
next_gen &amp;lt;-  c(189, 190, 192, 193, 193, 196, 199, 199, 199, 202, 203, 204, 205, 206, 206, 207, 208, 208, 210, 210, 212, 214, 216, 216, 217, 218)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sample Size of Predicate Device Data: 26
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sample Size of Next-Gen Device Data: 26
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So we have slightly uneven groups and relatively small sample sizes. No problem - assign each group to a variable and convert to tibble format:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Assign variables for each group and convert to tibble
predicate_tbl &amp;lt;- tibble(Device = &amp;quot;Predicate&amp;quot;,
                        Pressure = predicate)

next_gen_tbl &amp;lt;- tibble(Device = &amp;quot;Next_Gen&amp;quot;,
                        Pressure = next_gen)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Combine predicate and next_gen data into a single, pooled group called results_tbl. Taking a look at the first few and last few rows in the pooled tibble confirm it was combined appropriately.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Combine in tibble
results_tbl &amp;lt;- bind_rows(predicate_tbl, next_gen_tbl)
results_tbl %&amp;gt;% 
  head() %&amp;gt;% 
  kable(align = rep(&amp;quot;c&amp;quot;,2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Device
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Pressure
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Predicate
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
186
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Predicate
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
188
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Predicate
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
189
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Predicate
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
189
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Predicate
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
192
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Predicate
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
193
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results_tbl %&amp;gt;% tail() %&amp;gt;% 
  head() %&amp;gt;% 
  kable(align = rep(&amp;quot;c&amp;quot;,2))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Device
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Pressure
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Next_Gen
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
212
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Next_Gen
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
214
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Next_Gen
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
216
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Next_Gen
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
216
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Next_Gen
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
217
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Next_Gen
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
218
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now we do some exploratory data analysis to identify general shape and distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Visualize w/ basic boxplot
boxplot_eda &amp;lt;- results_tbl %&amp;gt;% 
    ggplot(aes(x=Device, y=Pressure)) +
    geom_boxplot(
        alpha  = .6,
        width  = .4,
        size   = .8,
        fatten = .5,
        fill   = c(&amp;quot;#FDE725FF&amp;quot;,&amp;quot;#20A486FF&amp;quot;)) +
    labs(
        y        = &amp;quot;Pressure (mm Hg)&amp;quot;,
        title    = &amp;quot;Predicate and Next-Gen Data&amp;quot;,
        subtitle = &amp;quot;Modular Disconnect Pressure&amp;quot;
    )

boxplot_eda&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-10-simple-permutation-test-for-nhst-of-2-samples_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Visualize with density plot
density_eda &amp;lt;- results_tbl %&amp;gt;% 
    ggplot(aes(x = Pressure)) +
    geom_density(aes(fill = Device),
        color = &amp;quot;black&amp;quot;,
        alpha = 0.6
        ) +
    scale_fill_manual(values = c(&amp;quot;#FDE725FF&amp;quot;,&amp;quot;#20A486FF&amp;quot;)) +
    labs(
        x        = &amp;quot;Pressure (mm Hg)&amp;quot;,
        title    = &amp;quot;Predicate and Next-Gen Data&amp;quot;,
        subtitle = &amp;quot;Modular Disconnect Pressure&amp;quot;
    )

density_eda&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-10-simple-permutation-test-for-nhst-of-2-samples_files/figure-html/unnamed-chunk-7-2.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yikes! These data do not look normal. Fortunately, the permutation test does not need the data to take on any particular distribution. The main assumption is exchangability, meaning it must be reasonable that the labels could be arbitrarily permuted under the null hypothesis. Provided the sample size is approximately equal, the permutation test is robust against unequal variances.&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; This gives us an attractive option for data shaped as shown above.&lt;/p&gt;
&lt;p&gt;To get started with our permutation test we create a function that accepts 3 arguments: the pooled data from all trials in our benchtop experiment (x), the number of observations taken from Group 1 (n1), and the number of observations taken from Group 2 (n2). The function creates an object containing indices 1:n, then randomly assigns indices into two Groups A and B with sizes to match the original group sizes. It then uses the randomly assigned indices to splice the dataset x producing 2 “shuffled” groups from the original data. Finally, it computes and returns the mean between the 2 randomly assigned groups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Function to permute vector indices and then compute difference in group means
perm_fun &amp;lt;- function(x, n1, n2){
  n &amp;lt;- n1 + n2
  group_B &amp;lt;- sample(1:n, n1)
  group_A &amp;lt;- setdiff(1:n, group_B)
  mean_diff &amp;lt;- mean(x[group_B] - mean(x[group_A]))
  return(mean_diff)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we initialize an dummy vector called perm_diffs to hold the results of the loop we are about to use. It’ll have all 0’s to start and then we’ll assign values from each iteration of the for loop.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set number of simulations to run
n_sims &amp;lt;- 10000

#Initialize empty vector
perm_diffs &amp;lt;- rep(0,n_sims)
perm_diffs %&amp;gt;% head()  %&amp;gt;% 
  kable(align = &amp;quot;c&amp;quot;, col.names = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Set up a simple for loop to execute the same evaluation using perm_fun() 10,000 times. On each iteration, we’ll store the results into the corresponding index within perm_diffs that we initialized above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set seed for reproducibility
set.seed(2015)

#Iterate over desired number of simulations using permutation function
for (i in 1:n_sims)
  perm_diffs[i] = perm_fun(results_tbl$Pressure, 26, 26)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have 10,000 replicates of our permutation test stored in perm_diffs. We want to visualize the data with ggplot so we convert it into a tibble frame using tibble().&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Convert results to a tibble and look at it
perm_diffs_df &amp;lt;- tibble(perm_diffs)
perm_diffs_df %&amp;gt;% head()  %&amp;gt;% 
  kable(align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
perm_diffs
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.6153846
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-3.3076923
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.6923077
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-2.3846154
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.3076923
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.1538462
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Visualize the difference in means as a histogram and density plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Visualize difference in means as a histogram
diffs_histogram_plot &amp;lt;- perm_diffs_df %&amp;gt;% ggplot(aes(perm_diffs)) +
  geom_histogram(fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, binwidth = .3, alpha = 0.8) +
    labs(
        x = &amp;quot;Pressure (mm Hg)&amp;quot;,
        title = &amp;quot;Histogram of Difference in Means&amp;quot;,
        subtitle = &amp;quot;Generated Under Null Hypothesis&amp;quot;
    )

#Visualize difference in means as a density plot
diffs_density_plot &amp;lt;-  perm_diffs_df %&amp;gt;% ggplot(aes(perm_diffs)) +
  geom_density(fill = &amp;quot;#2c3e50&amp;quot;, color = &amp;quot;white&amp;quot;, alpha = 0.8) +
     labs(
        x = &amp;quot;Pressure (mm Hg)&amp;quot;,
        title = &amp;quot;Density Plot of Difference in Means&amp;quot;,
        subtitle = &amp;quot;Generated Under Null Hypothesis&amp;quot;
    )

plot_grid(diffs_histogram_plot, diffs_density_plot)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-10-simple-permutation-test-for-nhst-of-2-samples_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We just simulated many tests from the null hypothesis. These virtual data give us a good understanding of what sort of difference in means we might observe if there truly was no difference between the groups. As expected, most of the time the difference is around 0. But occasionally there is a noticeable difference in means just due to chance.&lt;/p&gt;
&lt;p&gt;But how big was the difference in means from our real world dataset? We’ll call this “baseline difference”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Evaluate difference in means from true data set
predicate_pressure_mean &amp;lt;- mean(predicate_tbl$Pressure)
next_gen_pressure_mean &amp;lt;- mean(next_gen_tbl$Pressure)

baseline_difference &amp;lt;- predicate_pressure_mean - next_gen_pressure_mean
baseline_difference  %&amp;gt;% 
  signif(digits = 3) %&amp;gt;%
  kable(align = &amp;quot;c&amp;quot;, col.names = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-5.85
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So our real, observed data show a difference in means of -5.85. Is this large or small? With the context of the shuffle testing we already performed, we know exactly how extreme our observed data is and can visualize it with a vertical line.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Visualize real data in context of simulations
g1 &amp;lt;- diffs_histogram_plot + 
  geom_vline(xintercept = baseline_difference, 
             linetype   = &amp;quot;dotted&amp;quot;, 
             color      = &amp;quot;#2c3e50&amp;quot;, 
             size       = 1
             ) 

g2 &amp;lt;- diffs_density_plot + 
  geom_vline(xintercept = baseline_difference, 
             linetype   =&amp;quot;dotted&amp;quot;, 
             color      = &amp;quot;#2c3e50&amp;quot;, 
             size       = 1
             ) 

plot_grid(g1,g2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-10-simple-permutation-test-for-nhst-of-2-samples_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It looks like the our benchtop data was pretty extreme relative to the null. We should start to consider the possibility that this effect was not due solely to chance alone. 0.05 is a commonly used threshold for declaring statistical significance. Let’s see if our data is more or less extreme than 0.05 (solid line).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Calculate the 5% quantile of the simulated distribution for difference in means
the_five_percent_quantile &amp;lt;- quantile(perm_diffs_df$perm_diffs, probs = 0.05)
the_five_percent_quantile&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        5% 
## -4.153846&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Visualize the 5% quantile on the histogram and density plots
g3 &amp;lt;- g1 +
         geom_vline(xintercept = the_five_percent_quantile, 
             color      = &amp;quot;#2c3e50&amp;quot;, 
             size       = 1
             )

g4 &amp;lt;- g2 +
        geom_vline(xintercept = the_five_percent_quantile, 
             color      = &amp;quot;#2c3e50&amp;quot;, 
             size       = 1
             )

plot_grid(g3,g4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-10-simple-permutation-test-for-nhst-of-2-samples_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;100%&#34; height=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see here that our data is more extreme than the 5% quantile which means our p-value is less than 0.05. This satisfies the traditional, frequentist definition of statistically significant. If we want to actual p-value, we have to determine the percentage of simulated data that are as extreme or more extreme than our observed data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Calculate percentage of simulations as extreme or more extreme than the observed data (p-value)
p_value &amp;lt;- perm_diffs_df %&amp;gt;% 
    filter(perm_diffs &amp;lt;= baseline_difference) %&amp;gt;%
    nrow() / n_sims

paste(&amp;quot;The empirical p-value is: &amp;quot;, p_value)  %&amp;gt;% 
  kable(align = &amp;quot;c&amp;quot;, col.names = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
The empirical p-value is: 0.0096
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Our p-value is well below 0.05. This is likely enough evidence for us to claim that there was a statistically significant difference observed between the Next Gen device and the predicate device.&lt;/p&gt;
&lt;p&gt;Our marketing team will be thrilled, but we should always be wary that statistically significant does not mean practically important. Domain knowledge should provide the context to interpret the relevance of the observed difference. A difference in mean Pressure of a few mm Hg seems to be enough to claim a statistically significant improvement in our new device vs. the predicate, but is it enough for our marketing team to make a meaningful campaign? In reality, a few mm Hg is noticeable on the bench but is likely lost in the noise of anatomical variation within real patient anatomies.&lt;/p&gt;
&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Probably Overthinking It, &lt;a href=&#34;http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html&#34; class=&#34;uri&#34;&gt;http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;J ENDOVASC THER 2011;18:559-568, open access &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3163409/&#34; class=&#34;uri&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3163409/&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Simulations and Explanation of Unequal Variance and Sample Sizes, &lt;a href=&#34;https://stats.stackexchange.com/questions/87215/does-a-big-difference-in-sample-sizes-together-with-a-difference-in-variances-ma&#34; class=&#34;uri&#34;&gt;https://stats.stackexchange.com/questions/87215/does-a-big-difference-in-sample-sizes-together-with-a-difference-in-variances-ma&lt;/a&gt;&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>